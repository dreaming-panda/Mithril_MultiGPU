The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 4
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 4
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 4
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 4
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 4
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 4
The scaling down factor of out-of-chunk gradients: 0.100000
Initialized node 0 on machine g000.anvil.rcac.purdue.edu
Initialized node 3 on machine g004.anvil.rcac.purdue.edu
Initialized node 2 on machine g003.anvil.rcac.purdue.edu
Initialized node 1 on machine g001.anvil.rcac.purdue.edu
Initialized node 4 on machine g005.anvil.rcac.purdue.edu
Initialized node 5 on machine g006.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.889 seconds.
Building the CSC structure...
        It takes 1.891 seconds.
Building the CSC structure...
        It takes 1.925 seconds.
Building the CSC structure...
        It takes 1.898 seconds.
Building the CSC structure...
        It takes 1.925 seconds.
Building the CSC structure...
        It takes 1.932 seconds.
Building the CSC structure...
        It takes 1.857 seconds.
        It takes 1.843 seconds.
        It takes 1.852 seconds.
        It takes 1.852 seconds.
        It takes 1.891 seconds.
        It takes 1.911 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.587 seconds.
Building the Label Vector...
        It takes 0.574 seconds.
Building the Label Vector...
        It takes 0.567 seconds.
Building the Label Vector...
        It takes 0.578 seconds.
Building the Label Vector...
        It takes 0.609 seconds.
Building the Label Vector...
        It takes 0.592 seconds.
Building the Label Vector...
        It takes 0.318 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.314 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.313 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.318 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.329 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.323 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 3, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 3 owns the partition [16, 21) x [0, 2449029)
*** Node 3, constructing the helper classes...
(Forwarding) Node 3 (fragment 0) depends on nodes: 2 (Tensor: 15)
(Backwarding) Node 3 (fragment 0) depends on nodes: 4 (Tensor: 20)
(I-link dependencies): node 3 should send activation to nodes:
(I-link dependencies): node 3 should receive activation from nodes:
(I-link dependencies): node 3 should send gradient to nodes:
(I-link dependencies): node 3 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 1, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [6, 11) x [0, 2449029)
*** Node 1, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 5)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 10)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 4, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 4, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 4, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 4 owns the partition [21, 26) x [0, 2449029)
*** Node 4, constructing the helper classes...
(Forwarding) Node 4 (fragment 0) depends on nodes: 3 (Tensor: 20)
(Backwarding) Node 4 (fragment 0) depends on nodes: 5 (Tensor: 25)
(I-link dependencies): node 4 should send activation to nodes:
(I-link dependencies): node 4 should receive activation from nodes:
(I-link dependencies): node 4 should send gradient to nodes:
(I-link dependencies): node 4 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 2, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the partition [11, 16) x [0, 2449029)
*** Node 2, constructing the helper classes...
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 10)
(Backwarding) Node 2 (fragment 0) depends on nodes: 3 (Tensor: 15)
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 6) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_WEIGHT, output tensors: 21
    Op 22: type OPERATOR_MATMUL, output tensors: 22
    Op 23: type OPERATOR_AGGREGATION, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_WEIGHT, output tensors: 26
    Op 27: type OPERATOR_MATMUL, output tensors: 27
    Op 28: type OPERATOR_AGGREGATION, output tensors: 28
    Op 29: type OPERATOR_SOFTMAX, output tensors: 29
Boundaries: 0 0 0 0 0 0 2449029 2449029 2449029 2449029 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 24): 0-[0, 102043) 1-[102043, 204086) 2-[204086, 306129) 3-[306129, 408172) 4-[408172, 510215) 5-[510215, 612258) 6-[612258, 714301) 7-[714301, 816344) 8-[816344, 918387) ... 23-[2346989, 2449029)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 5)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 5, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 5, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 5, Pipeline Output Tensor: NULL
*** Node 5 owns the partition [26, 30) x [0, 2449029)
*** Node 5, constructing the helper classes...
(Forwarding) Node 5 (fragment 0) depends on nodes: 4 (Tensor: 25)
(Backwarding) Node 5 (fragment 0) depends on nodes:
(I-link dependencies): node 5 should send activation to nodes:
(I-link dependencies): node 5 should receive activation from nodes:
(I-link dependencies): node 5 should send gradient to nodes:
(I-link dependencies): node 5 should receive gradient from nodes:
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 4, setting up some other necessary information...
csr in-out ready !*** Node 5, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
csr in-out ready !*** Node 3, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 4, starting the helper threads...
*** Node 5, starting the helper threads...
*** Node 1, starting the helper threads...
*** Node 2, starting the helper threads...
*** Node 3, starting the helper threads...
+++++++++ Node 5 initializing the weights for op[26, 30)...
+++++++++ Node 5, mapping weight op 26
+++++++++ Node 0 initializing the weights for op[0, 6)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 3 initializing the weights for op[16, 21)...
+++++++++ Node 3, mapping weight op 16
+++++++++ Node 4 initializing the weights for op[21, 26)...
+++++++++ Node 4, mapping weight op 21
+++++++++ Node 2 initializing the weights for op[11, 16)...
+++++++++ Node 2, mapping weight op 11
+++++++++ Node 1 initializing the weights for op[6, 11)...
+++++++++ Node 1, mapping weight op 6
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...
*** Node 2, starting task scheduling...
*** Node 4, starting task scheduling...



*** Node 5, starting task scheduling...
*** Node 1, starting task scheduling...
*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 2.97362	TrainAcc 0.3591	ValidAcc 0.3589	TestAcc 0.2855
    Epoch 19:	Loss 1.92949	TrainAcc 0.5300	ValidAcc 0.5330	TestAcc 0.4135
    Epoch 29:	Loss 1.30177	TrainAcc 0.6996	ValidAcc 0.6926	TestAcc 0.5126
    Epoch 39:	Loss 1.02442	TrainAcc 0.7761	ValidAcc 0.7663	TestAcc 0.5800
    Epoch 49:	Loss 0.82952	TrainAcc 0.8183	ValidAcc 0.8112	TestAcc 0.6286
    Epoch 59:	Loss 0.73938	TrainAcc 0.8403	ValidAcc 0.8340	TestAcc 0.6534
    Epoch 69:	Loss 0.64840	TrainAcc 0.8573	ValidAcc 0.8511	TestAcc 0.6729
    Epoch 79:	Loss 0.60915	TrainAcc 0.8634	ValidAcc 0.8583	TestAcc 0.6804
    Epoch 89:	Loss 0.56449	TrainAcc 0.8705	ValidAcc 0.8643	TestAcc 0.6880
    Epoch 99:	Loss 0.54449	TrainAcc 0.8736	ValidAcc 0.8672	TestAcc 0.6943
    Epoch 109:	Loss 0.51489	TrainAcc 0.8784	ValidAcc 0.8719	TestAcc 0.7009
    Epoch 119:	Loss 0.50296	TrainAcc 0.8796	ValidAcc 0.8747	TestAcc 0.7056
    Epoch 129:	Loss 0.48297	TrainAcc 0.8836	ValidAcc 0.8772	TestAcc 0.7128
    Epoch 139:	Loss 0.47310	TrainAcc 0.8854	ValidAcc 0.8800	TestAcc 0.7148
    Epoch 149:	Loss 0.46177	TrainAcc 0.8865	ValidAcc 0.8820	TestAcc 0.7193
    Epoch 159:	Loss 0.45285	TrainAcc 0.8892	ValidAcc 0.8827	TestAcc 0.7227
    Epoch 169:	Loss 0.44523	TrainAcc 0.8903	ValidAcc 0.8846	TestAcc 0.7241
    Epoch 179:	Loss 0.44008	TrainAcc 0.8915	ValidAcc 0.8866	TestAcc 0.7253
    Epoch 189:	Loss 0.42997	TrainAcc 0.8945	ValidAcc 0.8879	TestAcc 0.7268
    Epoch 199:	Loss 0.42656	TrainAcc 0.8943	ValidAcc 0.8876	TestAcc 0.7267
    Epoch 209:	Loss 0.42076	TrainAcc 0.8962	ValidAcc 0.8889	TestAcc 0.7315
    Epoch 219:	Loss 0.41698	TrainAcc 0.8971	ValidAcc 0.8901	TestAcc 0.7317
    Epoch 229:	Loss 0.41177	TrainAcc 0.8978	ValidAcc 0.8919	TestAcc 0.7325
    Epoch 239:	Loss 0.40991	TrainAcc 0.8983	ValidAcc 0.8920	TestAcc 0.7337
    Epoch 249:	Loss 0.40391	TrainAcc 0.8996	ValidAcc 0.8915	TestAcc 0.7349
    Epoch 259:	Loss 0.40046	TrainAcc 0.9000	ValidAcc 0.8916	TestAcc 0.7361
    Epoch 269:	Loss 0.39592	TrainAcc 0.9012	ValidAcc 0.8922	TestAcc 0.7379
    Epoch 279:	Loss 0.39412	TrainAcc 0.9016	ValidAcc 0.8927	TestAcc 0.7367
    Epoch 289:	Loss 0.39022	TrainAcc 0.9020	ValidAcc 0.8925	TestAcc 0.7385
    Epoch 299:	Loss 0.38710	TrainAcc 0.9033	ValidAcc 0.8932	TestAcc 0.7378
    Epoch 309:	Loss 0.38493	TrainAcc 0.9032	ValidAcc 0.8943	TestAcc 0.7391
    Epoch 319:	Loss 0.38169	TrainAcc 0.9046	ValidAcc 0.8937	TestAcc 0.7398
    Epoch 329:	Loss 0.37990	TrainAcc 0.9043	ValidAcc 0.8948	TestAcc 0.7403
    Epoch 339:	Loss 0.37820	TrainAcc 0.9051	ValidAcc 0.8956	TestAcc 0.7406
    Epoch 349:	Loss 0.37590	TrainAcc 0.9056	ValidAcc 0.8955	TestAcc 0.7407
    Epoch 359:	Loss 0.37502	TrainAcc 0.9055	ValidAcc 0.8949	TestAcc 0.7400
    Epoch 369:	Loss 0.37378	TrainAcc 0.9061	ValidAcc 0.8961	TestAcc 0.7431
    Epoch 379:	Loss 0.37162	TrainAcc 0.9060	ValidAcc 0.8958	TestAcc 0.7405
    Epoch 389:	Loss 0.36870	TrainAcc 0.9071	ValidAcc 0.8973	TestAcc 0.7409
    Epoch 399:	Loss 0.36812	TrainAcc 0.9068	ValidAcc 0.8974	TestAcc 0.7427
    Epoch 409:	Loss 0.36488	TrainAcc 0.9078	ValidAcc 0.8980	TestAcc 0.7429
    Epoch 419:	Loss 0.36494	TrainAcc 0.9081	ValidAcc 0.8985	TestAcc 0.7420
    Epoch 429:	Loss 0.36176	TrainAcc 0.9085	ValidAcc 0.8986	TestAcc 0.7456
    Epoch 439:	Loss 0.36170	TrainAcc 0.9087	ValidAcc 0.8975	TestAcc 0.7443
    Epoch 449:	Loss 0.36074	TrainAcc 0.9088	ValidAcc 0.8987	TestAcc 0.7436
    Epoch 459:	Loss 0.35935	TrainAcc 0.9093	ValidAcc 0.8983	TestAcc 0.7452
    Epoch 469:	Loss 0.35726	TrainAcc 0.9098	ValidAcc 0.8987	TestAcc 0.7438
    Epoch 479:	Loss 0.35641	TrainAcc 0.9100	ValidAcc 0.9005	TestAcc 0.7450
    Epoch 489:	Loss 0.35281	TrainAcc 0.9113	ValidAcc 0.8991	TestAcc 0.7460
    Epoch 499:	Loss 0.35313	TrainAcc 0.9110	ValidAcc 0.8991	TestAcc 0.7479
    Epoch 509:	Loss 0.35244	TrainAcc 0.9104	ValidAcc 0.8998	TestAcc 0.7461
    Epoch 519:	Loss 0.35053	TrainAcc 0.9108	ValidAcc 0.9003	TestAcc 0.7480
    Epoch 529:	Loss 0.34959	TrainAcc 0.9111	ValidAcc 0.9005	TestAcc 0.7463
    Epoch 539:	Loss 0.34895	TrainAcc 0.9113	ValidAcc 0.9004	TestAcc 0.7467
    Epoch 549:	Loss 0.34708	TrainAcc 0.9115	ValidAcc 0.8999	TestAcc 0.7464
    Epoch 559:	Loss 0.34545	TrainAcc 0.9122	ValidAcc 0.9008	TestAcc 0.7481
    Epoch 569:	Loss 0.34580	TrainAcc 0.9113	ValidAcc 0.9006	TestAcc 0.7485
    Epoch 579:	Loss 0.34457	TrainAcc 0.9121	ValidAcc 0.9015	TestAcc 0.7469
    Epoch 589:	Loss 0.34354	TrainAcc 0.9120	ValidAcc 0.9019	TestAcc 0.7480
    Epoch 599:	Loss 0.34373	TrainAcc 0.9126	ValidAcc 0.9012	TestAcc 0.7480
    Epoch 609:	Loss 0.34188	TrainAcc 0.9128	ValidAcc 0.9014	TestAcc 0.7494
    Epoch 619:	Loss 0.34115	TrainAcc 0.9134	ValidAcc 0.9022	TestAcc 0.7461
    Epoch 629:	Loss 0.34030	TrainAcc 0.9129	ValidAcc 0.9018	TestAcc 0.7478
    Epoch 639:	Loss 0.33899	TrainAcc 0.9133	ValidAcc 0.9021	TestAcc 0.7478
    Epoch 649:	Loss 0.33800	TrainAcc 0.9134	ValidAcc 0.9018	TestAcc 0.7492
    Epoch 659:	Loss 0.33816	TrainAcc 0.9136	ValidAcc 0.9028	TestAcc 0.7469
    Epoch 669:	Loss 0.33834	TrainAcc 0.9132	ValidAcc 0.9013	TestAcc 0.7485
    Epoch 679:	Loss 0.33597	TrainAcc 0.9132	ValidAcc 0.9014	TestAcc 0.7488
    Epoch 689:	Loss 0.33467	TrainAcc 0.9142	ValidAcc 0.9033	TestAcc 0.7487
    Epoch 699:	Loss 0.33499	TrainAcc 0.9145	ValidAcc 0.9036	TestAcc 0.7494
    Epoch 709:	Loss 0.33405	TrainAcc 0.9144	ValidAcc 0.9041	TestAcc 0.7487
    Epoch 719:	Loss 0.33391	TrainAcc 0.9143	ValidAcc 0.9033	TestAcc 0.7474
    Epoch 729:	Loss 0.33309	TrainAcc 0.9151	ValidAcc 0.9015	TestAcc 0.7501
    Epoch 739:	Loss 0.33187	TrainAcc 0.9150	ValidAcc 0.9031	TestAcc 0.7513
    Epoch 749:	Loss 0.33027	TrainAcc 0.9157	ValidAcc 0.9043	TestAcc 0.7486
    Epoch 759:	Loss 0.33043	TrainAcc 0.9154	ValidAcc 0.9034	TestAcc 0.7490
    Epoch 769:	Loss 0.32997	TrainAcc 0.9149	ValidAcc 0.9039	TestAcc 0.7484
    Epoch 779:	Loss 0.32928	TrainAcc 0.9148	ValidAcc 0.9035	TestAcc 0.7492
    Epoch 789:	Loss 0.32887	TrainAcc 0.9155	ValidAcc 0.9049	TestAcc 0.7500
    Epoch 799:	Loss 0.32733	TrainAcc 0.9156	ValidAcc 0.9048	TestAcc 0.7515
    Epoch 809:	Loss 0.32811	TrainAcc 0.9156	ValidAcc 0.9033	TestAcc 0.7487
    Epoch 819:	Loss 0.32744	TrainAcc 0.9155	ValidAcc 0.9057	TestAcc 0.7516
    Epoch 829:	Loss 0.32823	TrainAcc 0.9159	ValidAcc 0.9032	TestAcc 0.7487
    Epoch 839:	Loss 0.32608	TrainAcc 0.9159	ValidAcc 0.9030	TestAcc 0.7505
    Epoch 849:	Loss 0.32468	TrainAcc 0.9164	ValidAcc 0.9043	TestAcc 0.7496
    Epoch 859:	Loss 0.32400	TrainAcc 0.9165	ValidAcc 0.9044	TestAcc 0.7480
    Epoch 869:	Loss 0.32470	TrainAcc 0.9159	ValidAcc 0.9060	TestAcc 0.7517
    Epoch 879:	Loss 0.32316	TrainAcc 0.9166	ValidAcc 0.9056	TestAcc 0.7487
    Epoch 889:	Loss 0.32294	TrainAcc 0.9173	ValidAcc 0.9057	TestAcc 0.7510
    Epoch 899:	Loss 0.32271	TrainAcc 0.9170	ValidAcc 0.9049	TestAcc 0.7484
    Epoch 909:	Loss 0.32251	TrainAcc 0.9168	ValidAcc 0.9044	TestAcc 0.7484
    Epoch 919:	Loss 0.32248	TrainAcc 0.9167	ValidAcc 0.9047	TestAcc 0.7511
    Epoch 929:	Loss 0.32107	TrainAcc 0.9167	ValidAcc 0.9045	TestAcc 0.7493
    Epoch 939:	Loss 0.32081	TrainAcc 0.9166	ValidAcc 0.9050	TestAcc 0.7519
    Epoch 949:	Loss 0.31961	TrainAcc 0.9179	ValidAcc 0.9058	TestAcc 0.7486
    Epoch 959:	Loss 0.31973	TrainAcc 0.9174	ValidAcc 0.9057	TestAcc 0.7497
    Epoch 969:	Loss 0.31826	TrainAcc 0.9177	ValidAcc 0.9062	TestAcc 0.7489
    Epoch 979:	Loss 0.31854	TrainAcc 0.9176	ValidAcc 0.9076	TestAcc 0.7499
    Epoch 989:	Loss 0.31782	TrainAcc 0.9173	ValidAcc 0.9063	TestAcc 0.7487
    Epoch 999:	Loss 0.31787	TrainAcc 0.9177	ValidAcc 0.9058	TestAcc 0.7524
    Epoch 1009:	Loss 0.31738	TrainAcc 0.9180	ValidAcc 0.9052	TestAcc 0.7510
    Epoch 1019:	Loss 0.31685	TrainAcc 0.9182	ValidAcc 0.9068	TestAcc 0.7501
    Epoch 1029:	Loss 0.31608	TrainAcc 0.9186	ValidAcc 0.9058	TestAcc 0.7493
    Epoch 1039:	Loss 0.31607	TrainAcc 0.9177	ValidAcc 0.9068	TestAcc 0.7516
    Epoch 1049:	Loss 0.31527	TrainAcc 0.9182	ValidAcc 0.9064	TestAcc 0.7479
    Epoch 1059:	Loss 0.31445	TrainAcc 0.9176	ValidAcc 0.9062	TestAcc 0.7496
    Epoch 1069:	Loss 0.31495	TrainAcc 0.9185	ValidAcc 0.9071	TestAcc 0.7495
    Epoch 1079:	Loss 0.31390	TrainAcc 0.9186	ValidAcc 0.9073	TestAcc 0.7499
    Epoch 1089:	Loss 0.31382	TrainAcc 0.9184	ValidAcc 0.9075	TestAcc 0.7507
    Epoch 1099:	Loss 0.31459	TrainAcc 0.9181	ValidAcc 0.9062	TestAcc 0.7489
    Epoch 1109:	Loss 0.31203	TrainAcc 0.9191	ValidAcc 0.9072	TestAcc 0.7498
    Epoch 1119:	Loss 0.31283	TrainAcc 0.9185	ValidAcc 0.9073	TestAcc 0.7514
    Epoch 1129:	Loss 0.31313	TrainAcc 0.9184	ValidAcc 0.9065	TestAcc 0.7502
    Epoch 1139:	Loss 0.31188	TrainAcc 0.9191	ValidAcc 0.9073	TestAcc 0.7499
    Epoch 1149:	Loss 0.31259	TrainAcc 0.9186	ValidAcc 0.9071	TestAcc 0.7494
    Epoch 1159:	Loss 0.31094	TrainAcc 0.9188	ValidAcc 0.9070	TestAcc 0.7484
    Epoch 1169:	Loss 0.30973	TrainAcc 0.9192	ValidAcc 0.9080	TestAcc 0.7526
    Epoch 1179:	Loss 0.30967	TrainAcc 0.9192	ValidAcc 0.9062	TestAcc 0.7500
    Epoch 1189:	Loss 0.31027	TrainAcc 0.9188	ValidAcc 0.9080	TestAcc 0.7502
    Epoch 1199:	Loss 0.31064	TrainAcc 0.9189	ValidAcc 0.9058	TestAcc 0.7506
    Epoch 1209:	Loss 0.30980	TrainAcc 0.9193	ValidAcc 0.9077	TestAcc 0.7522
    Epoch 1219:	Loss 0.30990	TrainAcc 0.9190	ValidAcc 0.9071	TestAcc 0.7501
    Epoch 1229:	Loss 0.30898	TrainAcc 0.9192	ValidAcc 0.9077	TestAcc 0.7496
    Epoch 1239:	Loss 0.30877	TrainAcc 0.9192	ValidAcc 0.9082	TestAcc 0.7509
    Epoch 1249:	Loss 0.30827	TrainAcc 0.9194	ValidAcc 0.9083	TestAcc 0.7511
    Epoch 1259:	Loss 0.30671	TrainAcc 0.9193	ValidAcc 0.9077	TestAcc 0.7507
    Epoch 1269:	Loss 0.30703	TrainAcc 0.9201	ValidAcc 0.9068	TestAcc 0.7484
    Epoch 1279:	Loss 0.30556	TrainAcc 0.9198	ValidAcc 0.9087	TestAcc 0.7515
    Epoch 1289:	Loss 0.30611	TrainAcc 0.9197	ValidAcc 0.9065	TestAcc 0.7502
    Epoch 1299:	Loss 0.30546	TrainAcc 0.9204	ValidAcc 0.9085	TestAcc 0.7502
    Epoch 1309:	Loss 0.30670	TrainAcc 0.9204	ValidAcc 0.9081	TestAcc 0.7515
    Epoch 1319:	Loss 0.30452	TrainAcc 0.9203	ValidAcc 0.9079	TestAcc 0.7509
    Epoch 1329:	Loss 0.30487	TrainAcc 0.9199	ValidAcc 0.9077	TestAcc 0.7506
    Epoch 1339:	Loss 0.30521	TrainAcc 0.9206	ValidAcc 0.9089	TestAcc 0.7502
    Epoch 1349:	Loss 0.30411	TrainAcc 0.9209	ValidAcc 0.9085	TestAcc 0.7508
    Epoch 1359:	Loss 0.30426	TrainAcc 0.9203	ValidAcc 0.9079	TestAcc 0.7490
    Epoch 1369:	Loss 0.30361	TrainAcc 0.9205	ValidAcc 0.9062	TestAcc 0.7503
    Epoch 1379:	Loss 0.30356	TrainAcc 0.9210	ValidAcc 0.9073	TestAcc 0.7508
    Epoch 1389:	Loss 0.30361	TrainAcc 0.9208	ValidAcc 0.9086	TestAcc 0.7476
    Epoch 1399:	Loss 0.30438	TrainAcc 0.9206	ValidAcc 0.9085	TestAcc 0.7524
    Epoch 1409:	Loss 0.30314	TrainAcc 0.9209	ValidAcc 0.9079	TestAcc 0.7524
    Epoch 1419:	Loss 0.30361	TrainAcc 0.9200	ValidAcc 0.9084	TestAcc 0.7521
    Epoch 1429:	Loss 0.30276	TrainAcc 0.9211	ValidAcc 0.9093	TestAcc 0.7497
    Epoch 1439:	Loss 0.30156	TrainAcc 0.9211	ValidAcc 0.9081	TestAcc 0.7500
    Epoch 1449:	Loss 0.30101	TrainAcc 0.9211	ValidAcc 0.9072	TestAcc 0.7486
    Epoch 1459:	Loss 0.30104	TrainAcc 0.9211	ValidAcc 0.9092	TestAcc 0.7489
    Epoch 1469:	Loss 0.30130	TrainAcc 0.9213	ValidAcc 0.9079	TestAcc 0.7508
    Epoch 1479:	Loss 0.30007	TrainAcc 0.9213	ValidAcc 0.9090	TestAcc 0.7507
    Epoch 1489:	Loss 0.30033	TrainAcc 0.9213	ValidAcc 0.9080	TestAcc 0.7502
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 11.165 GBps
Node 2, Layer-level comm throughput (act): 10.878 GBps
Node 3, Layer-level comm throughput (act): 9.961 GBps
Node 4, Layer-level comm throughput (act): 10.649 GBps
Node 5, Layer-level comm throughput (act): 11.269 GBps
Node 5, Layer-level comm throughput (grad): -nan GBps
Node 4, Layer-level comm throughput (grad): 11.051 GBps
Node 3, Layer-level comm throughput (grad): 11.141 GBps
Node 2, Layer-level comm throughput (grad): 10.323 GBps
Node 1, Layer-level comm throughput (grad): 10.146 GBps
Node 0, Layer-level comm throughput (grad): 11.101 GBps
    Epoch 1499:	Loss 0.30019	TrainAcc 0.9214	ValidAcc 0.9076	TestAcc 0.7507
Node 0, compression time: 4.450s, compression size: 875.841GB, throughput: 196.840GBps
Node 0, decompression time: 14.420s, compression size: 875.841GB, throughput: 60.739GBps
Node 0, pure compute time: 80.926 s, total compute time: 99.795 s
Node 0, wait_for_task_time: 135.280 s, wait_for_other_gpus_time: 0.038 s
------------------------node id 0,  per-epoch time: 0.162827 s---------------
Node 4, compression time: 10.482s, compression size: 1751.682GB, throughput: 167.120GBps
Node 4, decompression time: 37.536s, compression size: 1751.682GB, throughput: 46.667GBps
Node 4, pure compute time: 64.843 s, total compute time: 112.860 s
Node 4, wait_for_task_time: 69.733 s, wait_for_other_gpus_time: 0.038 s
------------------------node id 4,  per-epoch time: 0.162827 s---------------
Node 1, compression time: 10.591s, compression size: 1751.682GB, throughput: 165.398GBps
Node 1, decompression time: 47.212s, compression size: 1751.682GB, throughput: 37.102GBps
Node 1, pure compute time: 65.131 s, total compute time: 122.933 s
Node 1, wait_for_task_time: 106.059 s, wait_for_other_gpus_time: 0.030 s
------------------------node id 1,  per-epoch time: 0.162827 s---------------
Node 2, compression time: 10.826s, compression size: 1751.682GB, throughput: 161.810GBps
Node 2, decompression time: 103.267s, compression size: 1751.682GB, throughput: 16.963GBps
Node 2, pure compute time: 65.247 s, total compute time: 179.340 s
Node 2, wait_for_task_time: 44.527 s, wait_for_other_gpus_time: 0.030 s
------------------------node id 2,  per-epoch time: 0.162827 s---------------
Node 3, compression time: 10.812s, compression size: 1751.682GB, throughput: 162.006GBps
Node 3, decompression time: 84.364s, compression size: 1751.682GB, throughput: 20.763GBps
Node 3, pure compute time: 65.189 s, total compute time: 160.365 s
Node 3, wait_for_task_time: 53.540 s, wait_for_other_gpus_time: 0.032 s
------------------------node id 3,  per-epoch time: 0.162827 s---------------
Node 5, compression time: 6.214s, compression size: 875.841GB, throughput: 140.936GBps
Node 5, decompression time: 15.197s, compression size: 875.841GB, throughput: 57.631GBps
Node 5, pure compute time: 81.621 s, total compute time: 103.033 s
Node 5, wait_for_task_time: 57.836 s, wait_for_other_gpus_time: 0.029 s
------------------------node id 5,  per-epoch time: 0.162827 s---------------
************ Profiling Results ************
	Bubble: 53.892638 (s) (22.01 percentage)
	Compute: 138.048413 (s) (56.39 percentage)
	GradSync: 1.432225 (s) (0.58 percentage)
	GraphComm: 0.445974 (s) (0.18 percentage)
	Imbalance: 26.201277 (s) (10.70 percentage)
	LayerComm: 24.804257 (s) (10.13 percentage)
	Layer-level communication (cluster-wide, per epoch): 2.507 GB
Highest valid_acc: 0.9093
Target test_acc: 0.7497
Epoch to reach the target acc: 1430
[MPI Rank 0] Success 
[MPI Rank 5] Success 
[MPI Rank 3] Success 
[MPI Rank 2] Success 
[MPI Rank 1] Success 
[MPI Rank 4] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g000.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.947 seconds.
Building the CSC structure...
        It takes 1.908 seconds.
Building the Feature Vector...
        It takes 0.570 seconds.
Building the Label Vector...
        It takes 0.315 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.000 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.3697	ValidAcc 0.3707	TestAcc 0.2901
Version 1	TrainAcc 0.5540	ValidAcc 0.5578	TestAcc 0.4449
Version 2	TrainAcc 0.7143	ValidAcc 0.7082	TestAcc 0.5363
Version 3	TrainAcc 0.7889	ValidAcc 0.7819	TestAcc 0.6024
Version 4	TrainAcc 0.8248	ValidAcc 0.8209	TestAcc 0.6542
Version 5	TrainAcc 0.8466	ValidAcc 0.8436	TestAcc 0.6763
Version 6	TrainAcc 0.8606	ValidAcc 0.8560	TestAcc 0.6914
Version 7	TrainAcc 0.8670	ValidAcc 0.8633	TestAcc 0.6982
Version 8	TrainAcc 0.8734	ValidAcc 0.8687	TestAcc 0.7051
Version 9	TrainAcc 0.8774	ValidAcc 0.8724	TestAcc 0.7134
Version 10	TrainAcc 0.8795	ValidAcc 0.8761	TestAcc 0.7185
Version 11	TrainAcc 0.8839	ValidAcc 0.8796	TestAcc 0.7248
Version 12	TrainAcc 0.8862	ValidAcc 0.8827	TestAcc 0.7330
Version 13	TrainAcc 0.8882	ValidAcc 0.8843	TestAcc 0.7383
Version 14	TrainAcc 0.8903	ValidAcc 0.8857	TestAcc 0.7396
Version 15	TrainAcc 0.8910	ValidAcc 0.8867	TestAcc 0.7422
Version 16	TrainAcc 0.8935	ValidAcc 0.8882	TestAcc 0.7450
Version 17	TrainAcc 0.8951	ValidAcc 0.8894	TestAcc 0.7470
Version 18	TrainAcc 0.8963	ValidAcc 0.8907	TestAcc 0.7459
Version 19	TrainAcc 0.8973	ValidAcc 0.8911	TestAcc 0.7492
Version 20	TrainAcc 0.8979	ValidAcc 0.8919	TestAcc 0.7524
Version 21	TrainAcc 0.8987	ValidAcc 0.8928	TestAcc 0.7534
Version 22	TrainAcc 0.9003	ValidAcc 0.8936	TestAcc 0.7565
Version 23	TrainAcc 0.9012	ValidAcc 0.8948	TestAcc 0.7563
Version 24	TrainAcc 0.9014	ValidAcc 0.8943	TestAcc 0.7569
Version 25	TrainAcc 0.9024	ValidAcc 0.8951	TestAcc 0.7587
Version 26	TrainAcc 0.9033	ValidAcc 0.8959	TestAcc 0.7614
Version 27	TrainAcc 0.9041	ValidAcc 0.8964	TestAcc 0.7596
Version 28	TrainAcc 0.9044	ValidAcc 0.8964	TestAcc 0.7606
Version 29	TrainAcc 0.9055	ValidAcc 0.8972	TestAcc 0.7611
Version 30	TrainAcc 0.9057	ValidAcc 0.8971	TestAcc 0.7631
Version 31	TrainAcc 0.9060	ValidAcc 0.8972	TestAcc 0.7630
Version 32	TrainAcc 0.9069	ValidAcc 0.8981	TestAcc 0.7620
Version 33	TrainAcc 0.9072	ValidAcc 0.8990	TestAcc 0.7634
Version 34	TrainAcc 0.9077	ValidAcc 0.8985	TestAcc 0.7620
Version 35	TrainAcc 0.9082	ValidAcc 0.8994	TestAcc 0.7649
Version 36	TrainAcc 0.9083	ValidAcc 0.8993	TestAcc 0.7666
Version 37	TrainAcc 0.9091	ValidAcc 0.8998	TestAcc 0.7637
Version 38	TrainAcc 0.9097	ValidAcc 0.9000	TestAcc 0.7651
Version 39	TrainAcc 0.9100	ValidAcc 0.8996	TestAcc 0.7653
Version 40	TrainAcc 0.9103	ValidAcc 0.9010	TestAcc 0.7664
Version 41	TrainAcc 0.9106	ValidAcc 0.9011	TestAcc 0.7670
Version 42	TrainAcc 0.9109	ValidAcc 0.9012	TestAcc 0.7677
Version 43	TrainAcc 0.9116	ValidAcc 0.9015	TestAcc 0.7679
Version 44	TrainAcc 0.9117	ValidAcc 0.9014	TestAcc 0.7676
Version 45	TrainAcc 0.9115	ValidAcc 0.9012	TestAcc 0.7668
Version 46	TrainAcc 0.9118	ValidAcc 0.9012	TestAcc 0.7685
Version 47	TrainAcc 0.9125	ValidAcc 0.9024	TestAcc 0.7681
Version 48	TrainAcc 0.9124	ValidAcc 0.9025	TestAcc 0.7693
Version 49	TrainAcc 0.9127	ValidAcc 0.9023	TestAcc 0.7681
Version 50	TrainAcc 0.9123	ValidAcc 0.9033	TestAcc 0.7694
Version 51	TrainAcc 0.9130	ValidAcc 0.9038	TestAcc 0.7702
Version 52	TrainAcc 0.9130	ValidAcc 0.9033	TestAcc 0.7703
Version 53	TrainAcc 0.9135	ValidAcc 0.9040	TestAcc 0.7696
Version 54	TrainAcc 0.9143	ValidAcc 0.9033	TestAcc 0.7689
Version 55	TrainAcc 0.9145	ValidAcc 0.9045	TestAcc 0.7711
Version 56	TrainAcc 0.9144	ValidAcc 0.9035	TestAcc 0.7710
Version 57	TrainAcc 0.9144	ValidAcc 0.9045	TestAcc 0.7722
Version 58	TrainAcc 0.9146	ValidAcc 0.9047	TestAcc 0.7707
Version 59	TrainAcc 0.9148	ValidAcc 0.9045	TestAcc 0.7716
Version 60	TrainAcc 0.9151	ValidAcc 0.9052	TestAcc 0.7698
Version 61	TrainAcc 0.9151	ValidAcc 0.9046	TestAcc 0.7702
Version 62	TrainAcc 0.9157	ValidAcc 0.9056	TestAcc 0.7709
Version 63	TrainAcc 0.9154	ValidAcc 0.9050	TestAcc 0.7712
Version 64	TrainAcc 0.9157	ValidAcc 0.9056	TestAcc 0.7709
Version 65	TrainAcc 0.9156	ValidAcc 0.9058	TestAcc 0.7695
Version 66	TrainAcc 0.9157	ValidAcc 0.9052	TestAcc 0.7717
Version 67	TrainAcc 0.9160	ValidAcc 0.9059	TestAcc 0.7718
Version 68	TrainAcc 0.9162	ValidAcc 0.9058	TestAcc 0.7701
Version 69	TrainAcc 0.9162	ValidAcc 0.9059	TestAcc 0.7726
Version 70	TrainAcc 0.9166	ValidAcc 0.9061	TestAcc 0.7712
Version 71	TrainAcc 0.9161	ValidAcc 0.9058	TestAcc 0.7707
Version 72	TrainAcc 0.9170	ValidAcc 0.9064	TestAcc 0.7709
Version 73	TrainAcc 0.9170	ValidAcc 0.9067	TestAcc 0.7722
Version 74	TrainAcc 0.9174	ValidAcc 0.9074	TestAcc 0.7712
Version 75	TrainAcc 0.9173	ValidAcc 0.9071	TestAcc 0.7709
Version 76	TrainAcc 0.9175	ValidAcc 0.9070	TestAcc 0.7716
Version 77	TrainAcc 0.9173	ValidAcc 0.9071	TestAcc 0.7711
Version 78	TrainAcc 0.9175	ValidAcc 0.9071	TestAcc 0.7720
Version 79	TrainAcc 0.9176	ValidAcc 0.9072	TestAcc 0.7737
Version 80	TrainAcc 0.9175	ValidAcc 0.9074	TestAcc 0.7726
Version 81	TrainAcc 0.9176	ValidAcc 0.9074	TestAcc 0.7718
Version 82	TrainAcc 0.9180	ValidAcc 0.9084	TestAcc 0.7716
Version 83	TrainAcc 0.9183	ValidAcc 0.9081	TestAcc 0.7708
Version 84	TrainAcc 0.9188	ValidAcc 0.9072	TestAcc 0.7730
Version 85	TrainAcc 0.9186	ValidAcc 0.9083	TestAcc 0.7718
Version 86	TrainAcc 0.9186	ValidAcc 0.9083	TestAcc 0.7735
Version 87	TrainAcc 0.9187	ValidAcc 0.9079	TestAcc 0.7709
Version 88	TrainAcc 0.9190	ValidAcc 0.9089	TestAcc 0.7726
Version 89	TrainAcc 0.9193	ValidAcc 0.9091	TestAcc 0.7723
Version 90	TrainAcc 0.9189	ValidAcc 0.9088	TestAcc 0.7723
Version 91	TrainAcc 0.9189	ValidAcc 0.9087	TestAcc 0.7739
Version 92	TrainAcc 0.9186	ValidAcc 0.9077	TestAcc 0.7699
Version 93	TrainAcc 0.9193	ValidAcc 0.9083	TestAcc 0.7735
Version 94	TrainAcc 0.9195	ValidAcc 0.9092	TestAcc 0.7727
Version 95	TrainAcc 0.9196	ValidAcc 0.9090	TestAcc 0.7733
Version 96	TrainAcc 0.9198	ValidAcc 0.9094	TestAcc 0.7727
Version 97	TrainAcc 0.9199	ValidAcc 0.9089	TestAcc 0.7723
Version 98	TrainAcc 0.9195	ValidAcc 0.9085	TestAcc 0.7711
Version 99	TrainAcc 0.9193	ValidAcc 0.9095	TestAcc 0.7741
Version 100	TrainAcc 0.9201	ValidAcc 0.9091	TestAcc 0.7710
Version 101	TrainAcc 0.9201	ValidAcc 0.9100	TestAcc 0.7733
Version 102	TrainAcc 0.9199	ValidAcc 0.9091	TestAcc 0.7719
Version 103	TrainAcc 0.9203	ValidAcc 0.9096	TestAcc 0.7725
Version 104	TrainAcc 0.9205	ValidAcc 0.9096	TestAcc 0.7730
Version 105	TrainAcc 0.9207	ValidAcc 0.9093	TestAcc 0.7709
Version 106	TrainAcc 0.9208	ValidAcc 0.9096	TestAcc 0.7725
Version 107	TrainAcc 0.9207	ValidAcc 0.9094	TestAcc 0.7736
Version 108	TrainAcc 0.9207	ValidAcc 0.9099	TestAcc 0.7730
Version 109	TrainAcc 0.9209	ValidAcc 0.9092	TestAcc 0.7717
Version 110	TrainAcc 0.9209	ValidAcc 0.9103	TestAcc 0.7720
Version 111	TrainAcc 0.9211	ValidAcc 0.9106	TestAcc 0.7727
Version 112	TrainAcc 0.9211	ValidAcc 0.9102	TestAcc 0.7714
Version 113	TrainAcc 0.9211	ValidAcc 0.9104	TestAcc 0.7735
Version 114	TrainAcc 0.9212	ValidAcc 0.9100	TestAcc 0.7722
Version 115	TrainAcc 0.9215	ValidAcc 0.9102	TestAcc 0.7715
Version 116	TrainAcc 0.9207	ValidAcc 0.9099	TestAcc 0.7747
Version 117	TrainAcc 0.9212	ValidAcc 0.9095	TestAcc 0.7710
Version 118	TrainAcc 0.9217	ValidAcc 0.9102	TestAcc 0.7734
Version 119	TrainAcc 0.9221	ValidAcc 0.9106	TestAcc 0.7723
Version 120	TrainAcc 0.9213	ValidAcc 0.9104	TestAcc 0.7738
Version 121	TrainAcc 0.9216	ValidAcc 0.9104	TestAcc 0.7725
Version 122	TrainAcc 0.9215	ValidAcc 0.9094	TestAcc 0.7710
Version 123	TrainAcc 0.9215	ValidAcc 0.9096	TestAcc 0.7721
Version 124	TrainAcc 0.9217	ValidAcc 0.9105	TestAcc 0.7730
Version 125	TrainAcc 0.9219	ValidAcc 0.9104	TestAcc 0.7729
Version 126	TrainAcc 0.9222	ValidAcc 0.9107	TestAcc 0.7709
Version 127	TrainAcc 0.9219	ValidAcc 0.9113	TestAcc 0.7732
Version 128	TrainAcc 0.9224	ValidAcc 0.9097	TestAcc 0.7721
Version 129	TrainAcc 0.9224	ValidAcc 0.9111	TestAcc 0.7731
Version 130	TrainAcc 0.9223	ValidAcc 0.9108	TestAcc 0.7738
Version 131	TrainAcc 0.9225	ValidAcc 0.9116	TestAcc 0.7704
Version 132	TrainAcc 0.9221	ValidAcc 0.9115	TestAcc 0.7717
Version 133	TrainAcc 0.9223	ValidAcc 0.9112	TestAcc 0.7727
Version 134	TrainAcc 0.9227	ValidAcc 0.9113	TestAcc 0.7736
Version 135	TrainAcc 0.9227	ValidAcc 0.9112	TestAcc 0.7704
Version 136	TrainAcc 0.9221	ValidAcc 0.9117	TestAcc 0.7732
Version 137	TrainAcc 0.9229	ValidAcc 0.9111	TestAcc 0.7724
Version 138	TrainAcc 0.9231	ValidAcc 0.9115	TestAcc 0.7729
Version 139	TrainAcc 0.9230	ValidAcc 0.9117	TestAcc 0.7729
Version 140	TrainAcc 0.9231	ValidAcc 0.9115	TestAcc 0.7726
Version 141	TrainAcc 0.9229	ValidAcc 0.9113	TestAcc 0.7732
Version 142	TrainAcc 0.9232	ValidAcc 0.9108	TestAcc 0.7696
Version 143	TrainAcc 0.9233	ValidAcc 0.9116	TestAcc 0.7717
Version 144	TrainAcc 0.9224	ValidAcc 0.9128	TestAcc 0.7723
Version 145	TrainAcc 0.9233	ValidAcc 0.9121	TestAcc 0.7695
Version 146	TrainAcc 0.9228	ValidAcc 0.9115	TestAcc 0.7727
Version 147	TrainAcc 0.9234	ValidAcc 0.9115	TestAcc 0.7716
Version 148	TrainAcc 0.9232	ValidAcc 0.9114	TestAcc 0.7728
Version 149	TrainAcc 0.9235	ValidAcc 0.9113	TestAcc 0.7733
Version 144 achieved the highest validation accuracy 0.9128 (test accuracy: 0.7723)
