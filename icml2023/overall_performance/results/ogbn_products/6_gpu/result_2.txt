The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
Initialized node 1 on machine g001.anvil.rcac.purdue.edu
Initialized node 3 on machine g007.anvil.rcac.purdue.edu
Initialized node 2 on machine g004.anvil.rcac.purdue.edu
Initialized node 0 on machine g000.anvil.rcac.purdue.edu
Initialized node 4 on machine g008.anvil.rcac.purdue.edu
Initialized node 5 on machine g009.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.897 seconds.
Building the CSC structure...
        It takes 1.934 seconds.
Building the CSC structure...
        It takes 1.931 seconds.
Building the CSC structure...
        It takes 1.950 seconds.
Building the CSC structure...
        It takes 1.953 seconds.
Building the CSC structure...
        It takes 1.959 seconds.
Building the CSC structure...
        It takes 1.842 seconds.
        It takes 1.894 seconds.
        It takes 1.898 seconds.
        It takes 1.919 seconds.
        It takes 1.921 seconds.
        It takes 1.932 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.609 seconds.
Building the Label Vector...
        It takes 0.566 seconds.
Building the Label Vector...
        It takes 0.582 seconds.
Building the Label Vector...
        It takes 0.597 seconds.
Building the Label Vector...
        It takes 0.593 seconds.
Building the Label Vector...
        It takes 0.607 seconds.
Building the Label Vector...
        It takes 0.333 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.310 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.318 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.323 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.324 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.327 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 5, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 5, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 5, Pipeline Output Tensor: NULL
*** Node 5 owns the partition [26, 30) x [0, 2449029)
*** Node 5, constructing the helper classes...
(Forwarding) Node 5 (fragment 0) depends on nodes: 4 (Tensor: 25)
(Backwarding) Node 5 (fragment 0) depends on nodes:
(I-link dependencies): node 5 should send activation to nodes:
(I-link dependencies): node 5 should receive activation from nodes:
(I-link dependencies): node 5 should send gradient to nodes:
(I-link dependencies): node 5 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 6) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_WEIGHT, output tensors: 21
    Op 22: type OPERATOR_MATMUL, output tensors: 22
    Op 23: type OPERATOR_AGGREGATION, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_WEIGHT, output tensors: 26
    Op 27: type OPERATOR_MATMUL, output tensors: 27
    Op 28: type OPERATOR_AGGREGATION, output tensors: 28
    Op 29: type OPERATOR_SOFTMAX, output tensors: 29
Boundaries: 0 0 0 0 0 0 2449029 2449029 2449029 2449029 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 24): 0-[0, 102043) 1-[102043, 204086) 2-[204086, 306129) 3-[306129, 408172) 4-[408172, 510215) 5-[510215, 612258) 6-[612258, 714301) 7-[714301, 816344) 8-[816344, 918387) ... 23-[2346989, 2449029)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 5)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
*** Node 2, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
WARNING: the current version only applies to linear GNN models!
0 2449029 21 26
0 2449029 26 30
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the partition [11, 16) x [0, 2449029)
*** Node 2, constructing the helper classes...
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 10)
(Backwarding) Node 2 (fragment 0) depends on nodes: 3 (Tensor: 15)
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 3, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 3 owns the partition [16, 21) x [0, 2449029)
*** Node 3, constructing the helper classes...
(Forwarding) Node 3 (fragment 0) depends on nodes: 2 (Tensor: 15)
(Backwarding) Node 3 (fragment 0) depends on nodes: 4 (Tensor: 20)
(I-link dependencies): node 3 should send activation to nodes:
(I-link dependencies): node 3 should receive activation from nodes:
(I-link dependencies): node 3 should send gradient to nodes:
(I-link dependencies): node 3 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 1, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [6, 11) x [0, 2449029)
*** Node 1, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 5)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 10)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 4, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 4, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 4, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 4 owns the partition [21, 26) x [0, 2449029)
*** Node 4, constructing the helper classes...
(Forwarding) Node 4 (fragment 0) depends on nodes: 3 (Tensor: 20)
(Backwarding) Node 4 (fragment 0) depends on nodes: 5 (Tensor: 25)
(I-link dependencies): node 4 should send activation to nodes:
(I-link dependencies): node 4 should receive activation from nodes:
(I-link dependencies): node 4 should send gradient to nodes:
(I-link dependencies): node 4 should receive gradient from nodes:
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 3, setting up some other necessary information...
csr in-out ready !*** Node 5, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 4, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 5, starting the helper threads...
*** Node 1, starting the helper threads...
*** Node 2, starting the helper threads...
*** Node 4, starting the helper threads...
*** Node 3, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 6)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 5 initializing the weights for op[26, 30)...
+++++++++ Node 5, mapping weight op 26
+++++++++ Node 1 initializing the weights for op[6, 11)...
+++++++++ Node 1, mapping weight op 6
+++++++++ Node 2 initializing the weights for op[11, 16)...
+++++++++ Node 2, mapping weight op 11
+++++++++ Node 3 initializing the weights for op[16, 21)...
+++++++++ Node 3, mapping weight op 16
+++++++++ Node 4 initializing the weights for op[21, 26)...
+++++++++ Node 4, mapping weight op 21
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.003000000
*** Node 5, starting task scheduling...
*** Node 1, starting task scheduling...
*** Node 4, starting task scheduling...
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.003000000
*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 2.54699	TrainAcc 0.4854	ValidAcc 0.4818	TestAcc 0.3545
    Epoch 19:	Loss 1.52451	TrainAcc 0.6506	ValidAcc 0.6458	TestAcc 0.4893
    Epoch 29:	Loss 1.00596	TrainAcc 0.7830	ValidAcc 0.7776	TestAcc 0.5903
    Epoch 39:	Loss 0.81770	TrainAcc 0.8141	ValidAcc 0.8082	TestAcc 0.6200
    Epoch 49:	Loss 0.69289	TrainAcc 0.8427	ValidAcc 0.8398	TestAcc 0.6669
    Epoch 59:	Loss 0.63458	TrainAcc 0.8558	ValidAcc 0.8518	TestAcc 0.6767
    Epoch 69:	Loss 0.57463	TrainAcc 0.8664	ValidAcc 0.8619	TestAcc 0.6870
    Epoch 79:	Loss 0.54811	TrainAcc 0.8711	ValidAcc 0.8666	TestAcc 0.6900
    Epoch 89:	Loss 0.51420	TrainAcc 0.8780	ValidAcc 0.8721	TestAcc 0.6974
    Epoch 99:	Loss 0.49778	TrainAcc 0.8812	ValidAcc 0.8753	TestAcc 0.7019
    Epoch 109:	Loss 0.47781	TrainAcc 0.8845	ValidAcc 0.8772	TestAcc 0.7067
    Epoch 119:	Loss 0.46864	TrainAcc 0.8871	ValidAcc 0.8791	TestAcc 0.7114
    Epoch 129:	Loss 0.45478	TrainAcc 0.8892	ValidAcc 0.8813	TestAcc 0.7177
    Epoch 139:	Loss 0.44780	TrainAcc 0.8897	ValidAcc 0.8830	TestAcc 0.7182
    Epoch 149:	Loss 0.43995	TrainAcc 0.8918	ValidAcc 0.8834	TestAcc 0.7220
    Epoch 159:	Loss 0.43314	TrainAcc 0.8931	ValidAcc 0.8855	TestAcc 0.7244
    Epoch 169:	Loss 0.42570	TrainAcc 0.8944	ValidAcc 0.8882	TestAcc 0.7311
    Epoch 179:	Loss 0.42184	TrainAcc 0.8950	ValidAcc 0.8875	TestAcc 0.7320
    Epoch 189:	Loss 0.41501	TrainAcc 0.8971	ValidAcc 0.8891	TestAcc 0.7352
    Epoch 199:	Loss 0.41170	TrainAcc 0.8976	ValidAcc 0.8907	TestAcc 0.7373
    Epoch 209:	Loss 0.40560	TrainAcc 0.8991	ValidAcc 0.8906	TestAcc 0.7403
    Epoch 219:	Loss 0.40275	TrainAcc 0.8991	ValidAcc 0.8916	TestAcc 0.7410
    Epoch 229:	Loss 0.39785	TrainAcc 0.9002	ValidAcc 0.8933	TestAcc 0.7419
    Epoch 239:	Loss 0.39456	TrainAcc 0.9016	ValidAcc 0.8941	TestAcc 0.7419
    Epoch 249:	Loss 0.38966	TrainAcc 0.9026	ValidAcc 0.8960	TestAcc 0.7438
    Epoch 259:	Loss 0.38823	TrainAcc 0.9027	ValidAcc 0.8948	TestAcc 0.7456
    Epoch 269:	Loss 0.38482	TrainAcc 0.9026	ValidAcc 0.8960	TestAcc 0.7449
    Epoch 279:	Loss 0.38229	TrainAcc 0.9041	ValidAcc 0.8968	TestAcc 0.7466
    Epoch 289:	Loss 0.37854	TrainAcc 0.9044	ValidAcc 0.8976	TestAcc 0.7485
    Epoch 299:	Loss 0.37720	TrainAcc 0.9043	ValidAcc 0.8982	TestAcc 0.7477
    Epoch 309:	Loss 0.37449	TrainAcc 0.9059	ValidAcc 0.8984	TestAcc 0.7481
    Epoch 319:	Loss 0.37155	TrainAcc 0.9056	ValidAcc 0.8981	TestAcc 0.7494
    Epoch 329:	Loss 0.36895	TrainAcc 0.9065	ValidAcc 0.8986	TestAcc 0.7498
    Epoch 339:	Loss 0.36753	TrainAcc 0.9068	ValidAcc 0.8980	TestAcc 0.7488
    Epoch 349:	Loss 0.36454	TrainAcc 0.9074	ValidAcc 0.9001	TestAcc 0.7485
    Epoch 359:	Loss 0.36335	TrainAcc 0.9075	ValidAcc 0.8993	TestAcc 0.7508
    Epoch 369:	Loss 0.36137	TrainAcc 0.9081	ValidAcc 0.9013	TestAcc 0.7502
    Epoch 379:	Loss 0.36081	TrainAcc 0.9088	ValidAcc 0.8999	TestAcc 0.7495
    Epoch 389:	Loss 0.35960	TrainAcc 0.9084	ValidAcc 0.9000	TestAcc 0.7505
    Epoch 399:	Loss 0.35750	TrainAcc 0.9093	ValidAcc 0.9006	TestAcc 0.7496
    Epoch 409:	Loss 0.35483	TrainAcc 0.9092	ValidAcc 0.9007	TestAcc 0.7503
    Epoch 419:	Loss 0.35353	TrainAcc 0.9099	ValidAcc 0.9010	TestAcc 0.7507
    Epoch 429:	Loss 0.35256	TrainAcc 0.9101	ValidAcc 0.9006	TestAcc 0.7500
    Epoch 439:	Loss 0.35092	TrainAcc 0.9099	ValidAcc 0.9013	TestAcc 0.7503
    Epoch 449:	Loss 0.34995	TrainAcc 0.9100	ValidAcc 0.9011	TestAcc 0.7522
    Epoch 459:	Loss 0.34812	TrainAcc 0.9106	ValidAcc 0.9003	TestAcc 0.7509
    Epoch 469:	Loss 0.34726	TrainAcc 0.9110	ValidAcc 0.9023	TestAcc 0.7505
    Epoch 479:	Loss 0.34600	TrainAcc 0.9107	ValidAcc 0.9021	TestAcc 0.7512
    Epoch 489:	Loss 0.34447	TrainAcc 0.9117	ValidAcc 0.9019	TestAcc 0.7497
    Epoch 499:	Loss 0.34451	TrainAcc 0.9111	ValidAcc 0.9017	TestAcc 0.7518
    Epoch 509:	Loss 0.34265	TrainAcc 0.9121	ValidAcc 0.9027	TestAcc 0.7524
    Epoch 519:	Loss 0.34166	TrainAcc 0.9120	ValidAcc 0.9026	TestAcc 0.7527
    Epoch 529:	Loss 0.34123	TrainAcc 0.9119	ValidAcc 0.9021	TestAcc 0.7501
    Epoch 539:	Loss 0.33890	TrainAcc 0.9126	ValidAcc 0.9031	TestAcc 0.7518
    Epoch 549:	Loss 0.33821	TrainAcc 0.9128	ValidAcc 0.9027	TestAcc 0.7534
    Epoch 559:	Loss 0.33800	TrainAcc 0.9130	ValidAcc 0.9037	TestAcc 0.7501
    Epoch 569:	Loss 0.33749	TrainAcc 0.9132	ValidAcc 0.9024	TestAcc 0.7519
    Epoch 579:	Loss 0.33610	TrainAcc 0.9135	ValidAcc 0.9034	TestAcc 0.7526
    Epoch 589:	Loss 0.33614	TrainAcc 0.9132	ValidAcc 0.9026	TestAcc 0.7511
    Epoch 599:	Loss 0.33493	TrainAcc 0.9134	ValidAcc 0.9016	TestAcc 0.7509
    Epoch 609:	Loss 0.33322	TrainAcc 0.9139	ValidAcc 0.9041	TestAcc 0.7515
    Epoch 619:	Loss 0.33270	TrainAcc 0.9136	ValidAcc 0.9044	TestAcc 0.7520
    Epoch 629:	Loss 0.33252	TrainAcc 0.9141	ValidAcc 0.9034	TestAcc 0.7497
    Epoch 639:	Loss 0.33127	TrainAcc 0.9145	ValidAcc 0.9043	TestAcc 0.7502
    Epoch 649:	Loss 0.33111	TrainAcc 0.9146	ValidAcc 0.9044	TestAcc 0.7512
    Epoch 659:	Loss 0.32880	TrainAcc 0.9151	ValidAcc 0.9041	TestAcc 0.7514
    Epoch 669:	Loss 0.33018	TrainAcc 0.9146	ValidAcc 0.9037	TestAcc 0.7512
    Epoch 679:	Loss 0.32773	TrainAcc 0.9149	ValidAcc 0.9047	TestAcc 0.7500
    Epoch 689:	Loss 0.32687	TrainAcc 0.9155	ValidAcc 0.9059	TestAcc 0.7505
    Epoch 699:	Loss 0.32628	TrainAcc 0.9154	ValidAcc 0.9034	TestAcc 0.7497
    Epoch 709:	Loss 0.32568	TrainAcc 0.9156	ValidAcc 0.9042	TestAcc 0.7498
    Epoch 719:	Loss 0.32473	TrainAcc 0.9157	ValidAcc 0.9060	TestAcc 0.7498
    Epoch 729:	Loss 0.32543	TrainAcc 0.9160	ValidAcc 0.9048	TestAcc 0.7518
    Epoch 739:	Loss 0.32379	TrainAcc 0.9158	ValidAcc 0.9051	TestAcc 0.7527
    Epoch 749:	Loss 0.32358	TrainAcc 0.9158	ValidAcc 0.9057	TestAcc 0.7491
    Epoch 759:	Loss 0.32441	TrainAcc 0.9155	ValidAcc 0.9058	TestAcc 0.7481
    Epoch 769:	Loss 0.32292	TrainAcc 0.9159	ValidAcc 0.9056	TestAcc 0.7536
    Epoch 779:	Loss 0.32103	TrainAcc 0.9162	ValidAcc 0.9050	TestAcc 0.7531
    Epoch 789:	Loss 0.32208	TrainAcc 0.9160	ValidAcc 0.9052	TestAcc 0.7501
    Epoch 799:	Loss 0.31972	TrainAcc 0.9168	ValidAcc 0.9063	TestAcc 0.7517
    Epoch 809:	Loss 0.31990	TrainAcc 0.9172	ValidAcc 0.9072	TestAcc 0.7501
    Epoch 819:	Loss 0.31884	TrainAcc 0.9172	ValidAcc 0.9056	TestAcc 0.7525
    Epoch 829:	Loss 0.31940	TrainAcc 0.9166	ValidAcc 0.9039	TestAcc 0.7512
    Epoch 839:	Loss 0.31836	TrainAcc 0.9177	ValidAcc 0.9059	TestAcc 0.7502
    Epoch 849:	Loss 0.31737	TrainAcc 0.9173	ValidAcc 0.9070	TestAcc 0.7502
    Epoch 859:	Loss 0.31683	TrainAcc 0.9171	ValidAcc 0.9056	TestAcc 0.7509
    Epoch 869:	Loss 0.31636	TrainAcc 0.9171	ValidAcc 0.9057	TestAcc 0.7515
    Epoch 879:	Loss 0.31572	TrainAcc 0.9177	ValidAcc 0.9068	TestAcc 0.7484
    Epoch 889:	Loss 0.31493	TrainAcc 0.9177	ValidAcc 0.9061	TestAcc 0.7517
    Epoch 899:	Loss 0.31540	TrainAcc 0.9174	ValidAcc 0.9059	TestAcc 0.7500
    Epoch 909:	Loss 0.31421	TrainAcc 0.9183	ValidAcc 0.9074	TestAcc 0.7500
    Epoch 919:	Loss 0.31307	TrainAcc 0.9189	ValidAcc 0.9068	TestAcc 0.7500
    Epoch 929:	Loss 0.31307	TrainAcc 0.9187	ValidAcc 0.9056	TestAcc 0.7522
    Epoch 939:	Loss 0.31315	TrainAcc 0.9179	ValidAcc 0.9074	TestAcc 0.7513
    Epoch 949:	Loss 0.31333	TrainAcc 0.9179	ValidAcc 0.9067	TestAcc 0.7505
    Epoch 959:	Loss 0.31219	TrainAcc 0.9186	ValidAcc 0.9065	TestAcc 0.7497
    Epoch 969:	Loss 0.31275	TrainAcc 0.9186	ValidAcc 0.9063	TestAcc 0.7523
    Epoch 979:	Loss 0.31192	TrainAcc 0.9185	ValidAcc 0.9066	TestAcc 0.7519
    Epoch 989:	Loss 0.31136	TrainAcc 0.9182	ValidAcc 0.9064	TestAcc 0.7506
    Epoch 999:	Loss 0.31103	TrainAcc 0.9184	ValidAcc 0.9069	TestAcc 0.7501
    Epoch 1009:	Loss 0.31044	TrainAcc 0.9185	ValidAcc 0.9059	TestAcc 0.7507
    Epoch 1019:	Loss 0.30941	TrainAcc 0.9186	ValidAcc 0.9073	TestAcc 0.7523
    Epoch 1029:	Loss 0.30914	TrainAcc 0.9188	ValidAcc 0.9068	TestAcc 0.7517
    Epoch 1039:	Loss 0.30944	TrainAcc 0.9190	ValidAcc 0.9067	TestAcc 0.7499
    Epoch 1049:	Loss 0.30968	TrainAcc 0.9188	ValidAcc 0.9074	TestAcc 0.7498
    Epoch 1059:	Loss 0.30803	TrainAcc 0.9189	ValidAcc 0.9079	TestAcc 0.7517
    Epoch 1069:	Loss 0.30860	TrainAcc 0.9188	ValidAcc 0.9060	TestAcc 0.7524
    Epoch 1079:	Loss 0.30737	TrainAcc 0.9195	ValidAcc 0.9049	TestAcc 0.7508
    Epoch 1089:	Loss 0.30798	TrainAcc 0.9191	ValidAcc 0.9073	TestAcc 0.7520
    Epoch 1099:	Loss 0.30691	TrainAcc 0.9196	ValidAcc 0.9071	TestAcc 0.7483
    Epoch 1109:	Loss 0.30726	TrainAcc 0.9189	ValidAcc 0.9073	TestAcc 0.7494
    Epoch 1119:	Loss 0.30552	TrainAcc 0.9195	ValidAcc 0.9079	TestAcc 0.7508
    Epoch 1129:	Loss 0.30694	TrainAcc 0.9189	ValidAcc 0.9073	TestAcc 0.7525
    Epoch 1139:	Loss 0.30661	TrainAcc 0.9195	ValidAcc 0.9065	TestAcc 0.7515
    Epoch 1149:	Loss 0.30554	TrainAcc 0.9197	ValidAcc 0.9070	TestAcc 0.7521
    Epoch 1159:	Loss 0.30375	TrainAcc 0.9204	ValidAcc 0.9069	TestAcc 0.7513
    Epoch 1169:	Loss 0.30398	TrainAcc 0.9197	ValidAcc 0.9083	TestAcc 0.7523
    Epoch 1179:	Loss 0.30359	TrainAcc 0.9207	ValidAcc 0.9078	TestAcc 0.7524
    Epoch 1189:	Loss 0.30298	TrainAcc 0.9203	ValidAcc 0.9088	TestAcc 0.7516
    Epoch 1199:	Loss 0.30307	TrainAcc 0.9202	ValidAcc 0.9066	TestAcc 0.7524
    Epoch 1209:	Loss 0.30288	TrainAcc 0.9203	ValidAcc 0.9066	TestAcc 0.7518
    Epoch 1219:	Loss 0.30237	TrainAcc 0.9205	ValidAcc 0.9079	TestAcc 0.7515
    Epoch 1229:	Loss 0.30299	TrainAcc 0.9203	ValidAcc 0.9078	TestAcc 0.7513
    Epoch 1239:	Loss 0.30114	TrainAcc 0.9203	ValidAcc 0.9067	TestAcc 0.7533
    Epoch 1249:	Loss 0.30156	TrainAcc 0.9200	ValidAcc 0.9068	TestAcc 0.7519
    Epoch 1259:	Loss 0.30155	TrainAcc 0.9200	ValidAcc 0.9069	TestAcc 0.7515
    Epoch 1269:	Loss 0.30098	TrainAcc 0.9203	ValidAcc 0.9079	TestAcc 0.7538
    Epoch 1279:	Loss 0.30014	TrainAcc 0.9203	ValidAcc 0.9086	TestAcc 0.7525
    Epoch 1289:	Loss 0.30042	TrainAcc 0.9208	ValidAcc 0.9081	TestAcc 0.7519
    Epoch 1299:	Loss 0.30074	TrainAcc 0.9201	ValidAcc 0.9078	TestAcc 0.7508
    Epoch 1309:	Loss 0.29942	TrainAcc 0.9208	ValidAcc 0.9085	TestAcc 0.7513
    Epoch 1319:	Loss 0.30009	TrainAcc 0.9205	ValidAcc 0.9075	TestAcc 0.7527
    Epoch 1329:	Loss 0.30005	TrainAcc 0.9200	ValidAcc 0.9077	TestAcc 0.7488
    Epoch 1339:	Loss 0.30010	TrainAcc 0.9204	ValidAcc 0.9084	TestAcc 0.7501
    Epoch 1349:	Loss 0.29977	TrainAcc 0.9216	ValidAcc 0.9077	TestAcc 0.7513
    Epoch 1359:	Loss 0.29980	TrainAcc 0.9209	ValidAcc 0.9085	TestAcc 0.7512
    Epoch 1369:	Loss 0.29853	TrainAcc 0.9213	ValidAcc 0.9082	TestAcc 0.7533
    Epoch 1379:	Loss 0.29828	TrainAcc 0.9223	ValidAcc 0.9074	TestAcc 0.7521
    Epoch 1389:	Loss 0.29714	TrainAcc 0.9214	ValidAcc 0.9075	TestAcc 0.7517
    Epoch 1399:	Loss 0.29703	TrainAcc 0.9209	ValidAcc 0.9092	TestAcc 0.7544
    Epoch 1409:	Loss 0.29830	TrainAcc 0.9211	ValidAcc 0.9080	TestAcc 0.7520
    Epoch 1419:	Loss 0.29663	TrainAcc 0.9218	ValidAcc 0.9079	TestAcc 0.7538
    Epoch 1429:	Loss 0.29845	TrainAcc 0.9212	ValidAcc 0.9088	TestAcc 0.7535
    Epoch 1439:	Loss 0.29664	TrainAcc 0.9211	ValidAcc 0.9080	TestAcc 0.7509
    Epoch 1449:	Loss 0.29668	TrainAcc 0.9214	ValidAcc 0.9095	TestAcc 0.7521
    Epoch 1459:	Loss 0.29663	TrainAcc 0.9207	ValidAcc 0.9082	TestAcc 0.7531
    Epoch 1469:	Loss 0.29679	TrainAcc 0.9207	ValidAcc 0.9076	TestAcc 0.7541
    Epoch 1479:	Loss 0.29488	TrainAcc 0.9221	ValidAcc 0.9079	TestAcc 0.7543
    Epoch 1489:	Loss 0.29530	TrainAcc 0.9211	ValidAcc 0.9081	TestAcc 0.7549
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 11.186 GBps
Node 2, Layer-level comm throughput (act): 10.966 GBps
Node 3, Layer-level comm throughput (act): 10.904 GBps
Node 4, Layer-level comm throughput (act): 11.087 GBps
Node 5, Layer-level comm throughput (act): 11.269 GBps
Node 5, Layer-level comm throughput (grad): -nan GBps
Node 4, Layer-level comm throughput (grad): 11.232 GBps
Node 3, Layer-level comm throughput (grad): 11.042 GBps
Node 2, Layer-level comm throughput (grad): 11.115 GBps
Node 1, Layer-level comm throughput (grad): 11.005 GBps
Node 0, Layer-level comm throughput (grad): 11.279 GBps
    Epoch 1499:	Loss 0.29481	TrainAcc 0.9216	ValidAcc 0.9078	TestAcc 0.7541
Node 0, compression time: 4.365s, compression size: 875.841GB, throughput: 200.640GBps
Node 0, decompression time: 14.344s, compression size: 875.841GB, throughput: 61.059GBps
Node 0, pure compute time: 82.260 s, total compute time: 100.970 s
Node 0, wait_for_task_time: 85.385 s, wait_for_other_gpus_time: 0.012 s
------------------------node id 0,  per-epoch time: 0.130315 s---------------
Node 4, compression time: 10.801s, compression size: 1751.682GB, throughput: 162.181GBps
Node 4, decompression time: 40.016s, compression size: 1751.682GB, throughput: 43.774GBps
Node 4, pure compute time: 64.864 s, total compute time: 115.681 s
Node 3, compression time: 10.906s, compression size: 1751.682GB, throughput: 160.623GBps
Node 3, decompression time: 49.961s, compression size: 1751.682GB, throughput: 35.061GBps
Node 3, pure compute time: 65.056 s, total compute time: 125.922 s
Node 3, wait_for_task_time: 41.780 s, wait_for_other_gpus_time: 0.015 s
------------------------node id 3,  per-epoch time: 0.130315 s---------------
Node 5, compression time: 6.097s, compression size: 875.841GB, throughput: 143.657GBps
Node 5, decompression time: 16.919s, compression size: 875.841GB, throughput: 51.767GBps
Node 5, pure compute time: 80.778 s, total compute time: 103.794 s
Node 5, wait_for_task_time: 32.785 s, wait_for_other_gpus_time: 0.017 s
Node 1, compression time: 10.517s, compression size: 1751.682GB, throughput: 166.557GBps
Node 1, decompression time: 46.489s, compression size: 1751.682GB, throughput: 37.679GBps
Node 1, pure compute time: 64.912 s, total compute time: 121.919 s
Node 1, wait_for_task_time: 59.803 s, wait_for_other_gpus_time: 0.019 s
------------------------node id 1,  per-epoch time: 0.130315 s---------------
Node 2, compression time: 11.017s, compression size: 1751.682GB, throughput: 158.996GBps
Node 2, decompression time: 59.225s, compression size: 1751.682GB, throughput: 29.577GBps
Node 2, pure compute time: 64.926 s, total compute time: 135.168 s
------------------------node id 5,  per-epoch time: 0.130315 s---------------
Node 2, wait_for_task_time: 40.668 s, wait_for_other_gpus_time: 0.016 s
------------------------node id 2,  per-epoch time: 0.130315 s---------------
Node 4, wait_for_task_time: 42.140 s, wait_for_other_gpus_time: 0.017 s
------------------------node id 4,  per-epoch time: 0.130315 s---------------
************ Profiling Results ************
	Bubble: 38.956225 (s) (19.88 percentage)
	Compute: 125.750088 (s) (64.16 percentage)
	GradSync: 1.271791 (s) (0.65 percentage)
	GraphComm: 0.048105 (s) (0.02 percentage)
	Imbalance: 17.681466 (s) (9.02 percentage)
	LayerComm: 12.281622 (s) (6.27 percentage)
	Layer-level communication (cluster-wide, per epoch): 2.613 GB
Highest valid_acc: 0.9095
Target test_acc: 0.7521
Epoch to reach the target acc: 1450
[MPI Rank 5] Success 
[MPI Rank 0] Success 
[MPI Rank 3] Success 
[MPI Rank 2] Success 
[MPI Rank 1] Success 
[MPI Rank 4] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g000.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.943 seconds.
Building the CSC structure...
        It takes 1.905 seconds.
Building the Feature Vector...
        It takes 0.574 seconds.
Building the Label Vector...
        It takes 0.309 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.000 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.4148	ValidAcc 0.4174	TestAcc 0.3399
Version 1	TrainAcc 0.6877	ValidAcc 0.6849	TestAcc 0.5383
Version 2	TrainAcc 0.7938	ValidAcc 0.7924	TestAcc 0.6340
Version 3	TrainAcc 0.8247	ValidAcc 0.8241	TestAcc 0.6574
Version 4	TrainAcc 0.8495	ValidAcc 0.8487	TestAcc 0.6935
Version 5	TrainAcc 0.8606	ValidAcc 0.8581	TestAcc 0.6979
Version 6	TrainAcc 0.8699	ValidAcc 0.8678	TestAcc 0.7049
Version 7	TrainAcc 0.8760	ValidAcc 0.8722	TestAcc 0.7112
Version 8	TrainAcc 0.8811	ValidAcc 0.8771	TestAcc 0.7169
Version 9	TrainAcc 0.8849	ValidAcc 0.8795	TestAcc 0.7217
Version 10	TrainAcc 0.8864	ValidAcc 0.8821	TestAcc 0.7253
Version 11	TrainAcc 0.8888	ValidAcc 0.8823	TestAcc 0.7292
Version 12	TrainAcc 0.8913	ValidAcc 0.8845	TestAcc 0.7369
Version 13	TrainAcc 0.8929	ValidAcc 0.8857	TestAcc 0.7382
Version 14	TrainAcc 0.8936	ValidAcc 0.8875	TestAcc 0.7405
Version 15	TrainAcc 0.8947	ValidAcc 0.8892	TestAcc 0.7461
Version 16	TrainAcc 0.8962	ValidAcc 0.8911	TestAcc 0.7529
Version 17	TrainAcc 0.8977	ValidAcc 0.8916	TestAcc 0.7562
Version 18	TrainAcc 0.8986	ValidAcc 0.8930	TestAcc 0.7550
Version 19	TrainAcc 0.8995	ValidAcc 0.8943	TestAcc 0.7589
Version 20	TrainAcc 0.9010	ValidAcc 0.8954	TestAcc 0.7619
Version 21	TrainAcc 0.9020	ValidAcc 0.8965	TestAcc 0.7629
Version 22	TrainAcc 0.9024	ValidAcc 0.8972	TestAcc 0.7609
Version 23	TrainAcc 0.9036	ValidAcc 0.8985	TestAcc 0.7618
Version 24	TrainAcc 0.9041	ValidAcc 0.8988	TestAcc 0.7647
Version 25	TrainAcc 0.9052	ValidAcc 0.8994	TestAcc 0.7677
Version 26	TrainAcc 0.9050	ValidAcc 0.8996	TestAcc 0.7647
Version 27	TrainAcc 0.9059	ValidAcc 0.8996	TestAcc 0.7649
Version 28	TrainAcc 0.9069	ValidAcc 0.9007	TestAcc 0.7677
Version 29	TrainAcc 0.9070	ValidAcc 0.9003	TestAcc 0.7689
Version 30	TrainAcc 0.9077	ValidAcc 0.9010	TestAcc 0.7694
Version 31	TrainAcc 0.9078	ValidAcc 0.9019	TestAcc 0.7714
Version 32	TrainAcc 0.9085	ValidAcc 0.9027	TestAcc 0.7709
Version 33	TrainAcc 0.9091	ValidAcc 0.9024	TestAcc 0.7716
Version 34	TrainAcc 0.9092	ValidAcc 0.9031	TestAcc 0.7714
Version 35	TrainAcc 0.9096	ValidAcc 0.9028	TestAcc 0.7710
Version 36	TrainAcc 0.9100	ValidAcc 0.9024	TestAcc 0.7700
Version 37	TrainAcc 0.9102	ValidAcc 0.9041	TestAcc 0.7716
Version 38	TrainAcc 0.9109	ValidAcc 0.9044	TestAcc 0.7715
Version 39	TrainAcc 0.9112	ValidAcc 0.9033	TestAcc 0.7705
Version 40	TrainAcc 0.9112	ValidAcc 0.9052	TestAcc 0.7707
Version 41	TrainAcc 0.9110	ValidAcc 0.9040	TestAcc 0.7727
Version 42	TrainAcc 0.9118	ValidAcc 0.9042	TestAcc 0.7700
Version 43	TrainAcc 0.9124	ValidAcc 0.9049	TestAcc 0.7708
Version 44	TrainAcc 0.9118	ValidAcc 0.9052	TestAcc 0.7732
Version 45	TrainAcc 0.9125	ValidAcc 0.9050	TestAcc 0.7708
Version 46	TrainAcc 0.9129	ValidAcc 0.9054	TestAcc 0.7728
Version 47	TrainAcc 0.9131	ValidAcc 0.9050	TestAcc 0.7733
Version 48	TrainAcc 0.9131	ValidAcc 0.9053	TestAcc 0.7703
Version 49	TrainAcc 0.9132	ValidAcc 0.9050	TestAcc 0.7716
Version 50	TrainAcc 0.9137	ValidAcc 0.9057	TestAcc 0.7730
Version 51	TrainAcc 0.9140	ValidAcc 0.9063	TestAcc 0.7718
Version 52	TrainAcc 0.9140	ValidAcc 0.9056	TestAcc 0.7739
Version 53	TrainAcc 0.9146	ValidAcc 0.9057	TestAcc 0.7724
Version 54	TrainAcc 0.9149	ValidAcc 0.9068	TestAcc 0.7723
Version 55	TrainAcc 0.9153	ValidAcc 0.9065	TestAcc 0.7707
Version 56	TrainAcc 0.9144	ValidAcc 0.9061	TestAcc 0.7746
Version 57	TrainAcc 0.9153	ValidAcc 0.9062	TestAcc 0.7699
Version 58	TrainAcc 0.9154	ValidAcc 0.9066	TestAcc 0.7710
Version 59	TrainAcc 0.9153	ValidAcc 0.9070	TestAcc 0.7713
Version 60	TrainAcc 0.9159	ValidAcc 0.9078	TestAcc 0.7713
Version 61	TrainAcc 0.9157	ValidAcc 0.9075	TestAcc 0.7725
Version 62	TrainAcc 0.9161	ValidAcc 0.9075	TestAcc 0.7701
Version 63	TrainAcc 0.9163	ValidAcc 0.9080	TestAcc 0.7691
Version 64	TrainAcc 0.9166	ValidAcc 0.9078	TestAcc 0.7736
Version 65	TrainAcc 0.9163	ValidAcc 0.9071	TestAcc 0.7723
Version 66	TrainAcc 0.9170	ValidAcc 0.9072	TestAcc 0.7700
Version 67	TrainAcc 0.9171	ValidAcc 0.9075	TestAcc 0.7694
Version 68	TrainAcc 0.9174	ValidAcc 0.9085	TestAcc 0.7715
Version 69	TrainAcc 0.9174	ValidAcc 0.9086	TestAcc 0.7725
Version 70	TrainAcc 0.9176	ValidAcc 0.9086	TestAcc 0.7727
Version 71	TrainAcc 0.9172	ValidAcc 0.9084	TestAcc 0.7711
Version 72	TrainAcc 0.9182	ValidAcc 0.9082	TestAcc 0.7714
Version 73	TrainAcc 0.9179	ValidAcc 0.9080	TestAcc 0.7732
Version 74	TrainAcc 0.9182	ValidAcc 0.9079	TestAcc 0.7709
Version 75	TrainAcc 0.9183	ValidAcc 0.9091	TestAcc 0.7713
Version 76	TrainAcc 0.9182	ValidAcc 0.9082	TestAcc 0.7737
Version 77	TrainAcc 0.9183	ValidAcc 0.9076	TestAcc 0.7701
Version 78	TrainAcc 0.9192	ValidAcc 0.9088	TestAcc 0.7704
Version 79	TrainAcc 0.9189	ValidAcc 0.9089	TestAcc 0.7726
Version 80	TrainAcc 0.9183	ValidAcc 0.9087	TestAcc 0.7723
Version 81	TrainAcc 0.9187	ValidAcc 0.9090	TestAcc 0.7734
Version 82	TrainAcc 0.9189	ValidAcc 0.9096	TestAcc 0.7722
Version 83	TrainAcc 0.9196	ValidAcc 0.9096	TestAcc 0.7722
Version 84	TrainAcc 0.9193	ValidAcc 0.9097	TestAcc 0.7707
Version 85	TrainAcc 0.9191	ValidAcc 0.9095	TestAcc 0.7718
Version 86	TrainAcc 0.9194	ValidAcc 0.9083	TestAcc 0.7726
Version 87	TrainAcc 0.9195	ValidAcc 0.9096	TestAcc 0.7713
Version 88	TrainAcc 0.9194	ValidAcc 0.9097	TestAcc 0.7709
Version 89	TrainAcc 0.9198	ValidAcc 0.9098	TestAcc 0.7727
Version 90	TrainAcc 0.9200	ValidAcc 0.9102	TestAcc 0.7714
Version 91	TrainAcc 0.9203	ValidAcc 0.9102	TestAcc 0.7703
Version 92	TrainAcc 0.9198	ValidAcc 0.9105	TestAcc 0.7735
Version 93	TrainAcc 0.9198	ValidAcc 0.9101	TestAcc 0.7725
Version 94	TrainAcc 0.9203	ValidAcc 0.9093	TestAcc 0.7696
Version 95	TrainAcc 0.9201	ValidAcc 0.9098	TestAcc 0.7719
Version 96	TrainAcc 0.9206	ValidAcc 0.9102	TestAcc 0.7721
Version 97	TrainAcc 0.9202	ValidAcc 0.9099	TestAcc 0.7732
Version 98	TrainAcc 0.9206	ValidAcc 0.9102	TestAcc 0.7711
Version 99	TrainAcc 0.9207	ValidAcc 0.9104	TestAcc 0.7708
Version 100	TrainAcc 0.9205	ValidAcc 0.9108	TestAcc 0.7707
Version 101	TrainAcc 0.9205	ValidAcc 0.9096	TestAcc 0.7714
Version 102	TrainAcc 0.9207	ValidAcc 0.9101	TestAcc 0.7714
Version 103	TrainAcc 0.9213	ValidAcc 0.9102	TestAcc 0.7706
Version 104	TrainAcc 0.9212	ValidAcc 0.9110	TestAcc 0.7740
Version 105	TrainAcc 0.9213	ValidAcc 0.9111	TestAcc 0.7745
Version 106	TrainAcc 0.9212	ValidAcc 0.9102	TestAcc 0.7714
Version 107	TrainAcc 0.9218	ValidAcc 0.9102	TestAcc 0.7716
Version 108	TrainAcc 0.9213	ValidAcc 0.9104	TestAcc 0.7722
Version 109	TrainAcc 0.9219	ValidAcc 0.9104	TestAcc 0.7716
Version 110	TrainAcc 0.9196	ValidAcc 0.9078	TestAcc 0.7714
Version 111	TrainAcc 0.9202	ValidAcc 0.9090	TestAcc 0.7723
Version 112	TrainAcc 0.9225	ValidAcc 0.9102	TestAcc 0.7722
Version 113	TrainAcc 0.9223	ValidAcc 0.9105	TestAcc 0.7708
Version 114	TrainAcc 0.9220	ValidAcc 0.9105	TestAcc 0.7694
Version 115	TrainAcc 0.9221	ValidAcc 0.9106	TestAcc 0.7707
Version 116	TrainAcc 0.9227	ValidAcc 0.9107	TestAcc 0.7737
Version 117	TrainAcc 0.9221	ValidAcc 0.9103	TestAcc 0.7717
Version 118	TrainAcc 0.9223	ValidAcc 0.9103	TestAcc 0.7710
Version 119	TrainAcc 0.9225	ValidAcc 0.9106	TestAcc 0.7731
Version 120	TrainAcc 0.9219	ValidAcc 0.9107	TestAcc 0.7741
Version 121	TrainAcc 0.9222	ValidAcc 0.9111	TestAcc 0.7729
Version 122	TrainAcc 0.9231	ValidAcc 0.9116	TestAcc 0.7724
Version 123	TrainAcc 0.9223	ValidAcc 0.9105	TestAcc 0.7727
Version 124	TrainAcc 0.9227	ValidAcc 0.9108	TestAcc 0.7743
Version 125	TrainAcc 0.9227	ValidAcc 0.9104	TestAcc 0.7740
Version 126	TrainAcc 0.9228	ValidAcc 0.9110	TestAcc 0.7727
Version 127	TrainAcc 0.9229	ValidAcc 0.9104	TestAcc 0.7718
Version 128	TrainAcc 0.9225	ValidAcc 0.9113	TestAcc 0.7729
Version 129	TrainAcc 0.9234	ValidAcc 0.9114	TestAcc 0.7729
Version 130	TrainAcc 0.9229	ValidAcc 0.9109	TestAcc 0.7737
Version 131	TrainAcc 0.9228	ValidAcc 0.9102	TestAcc 0.7731
Version 132	TrainAcc 0.9233	ValidAcc 0.9108	TestAcc 0.7717
Version 133	TrainAcc 0.9220	ValidAcc 0.9103	TestAcc 0.7693
Version 134	TrainAcc 0.9230	ValidAcc 0.9113	TestAcc 0.7727
Version 135	TrainAcc 0.9231	ValidAcc 0.9109	TestAcc 0.7751
Version 136	TrainAcc 0.9232	ValidAcc 0.9109	TestAcc 0.7749
Version 137	TrainAcc 0.9233	ValidAcc 0.9112	TestAcc 0.7753
Version 138	TrainAcc 0.9227	ValidAcc 0.9109	TestAcc 0.7753
Version 139	TrainAcc 0.9230	ValidAcc 0.9113	TestAcc 0.7749
Version 140	TrainAcc 0.9234	ValidAcc 0.9112	TestAcc 0.7732
Version 141	TrainAcc 0.9233	ValidAcc 0.9114	TestAcc 0.7748
Version 142	TrainAcc 0.9239	ValidAcc 0.9110	TestAcc 0.7756
Version 143	TrainAcc 0.9240	ValidAcc 0.9106	TestAcc 0.7738
Version 144	TrainAcc 0.9237	ValidAcc 0.9114	TestAcc 0.7759
Version 145	TrainAcc 0.9236	ValidAcc 0.9106	TestAcc 0.7766
Version 146	TrainAcc 0.9235	ValidAcc 0.9120	TestAcc 0.7774
Version 147	TrainAcc 0.9239	ValidAcc 0.9117	TestAcc 0.7779
Version 148	TrainAcc 0.9236	ValidAcc 0.9112	TestAcc 0.7771
Version 149	TrainAcc 0.9239	ValidAcc 0.9113	TestAcc 0.7762
Version 146 achieved the highest validation accuracy 0.9120 (test accuracy: 0.7774)
