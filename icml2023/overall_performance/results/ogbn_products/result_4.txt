The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
Initialized node 5 on machine g006.anvil.rcac.purdue.edu
Initialized node 0 on machine g000.anvil.rcac.purdue.edu
Initialized node 1 on machine g001.anvil.rcac.purdue.edu
Initialized node 2 on machine g003.anvil.rcac.purdue.edu
Initialized node 3 on machine g004.anvil.rcac.purdue.edu
Initialized node 4 on machine g005.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.854 seconds.
Building the CSC structure...
        It takes 1.853 seconds.
Building the CSC structure...
        It takes 1.890 seconds.
Building the CSC structure...
        It takes 1.911 seconds.
Building the CSC structure...
        It takes 1.912 seconds.
Building the CSC structure...
        It takes 1.922 seconds.
Building the CSC structure...
        It takes 1.821 seconds.
        It takes 1.818 seconds.
        It takes 1.856 seconds.
        It takes 1.855 seconds.
        It takes 1.878 seconds.
        It takes 1.887 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.574 seconds.
Building the Label Vector...
        It takes 0.583 seconds.
Building the Label Vector...
        It takes 0.574 seconds.
Building the Label Vector...
        It takes 0.566 seconds.
Building the Label Vector...
        It takes 0.620 seconds.
Building the Label Vector...
        It takes 0.609 seconds.
Building the Label Vector...
        It takes 0.316 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.318 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.316 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.312 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.336 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.332 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
WARNING: the current version only applies to linear GNN models!
GPU 5, layer [5, 6)
*** Node 2, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the partition [11, 16) x [0, 2449029)
*** Node 2, constructing the helper classes...
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 10)
(Backwarding) Node 2 (fragment 0) depends on nodes: 3 (Tensor: 15)
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 3, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 3 owns the partition [16, 21) x [0, 2449029)
*** Node 3, constructing the helper classes...
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 4, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 4, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 4, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 4 owns the partition [21, 26) x [0, 2449029)
*** Node 4, constructing the helper classes...
(Forwarding) Node 3 (fragment 0) depends on nodes: 2 (Tensor: 15)
(Backwarding) Node 3 (fragment 0) depends on nodes: 4 (Tensor: 20)
(I-link dependencies): node 3 should send activation to nodes:
(I-link dependencies): node 3 should receive activation from nodes:
(I-link dependencies): node 3 should send gradient to nodes:
(I-link dependencies): node 3 should receive gradient from nodes:
(Forwarding) Node 4 (fragment 0) depends on nodes: 3 (Tensor: 20)
(Backwarding) Node 4 (fragment 0) depends on nodes: 5 (Tensor: 25)
(I-link dependencies): node 4 should send activation to nodes:
(I-link dependencies): node 4 should receive activation from nodes:
(I-link dependencies): node 4 should send gradient to nodes:
(I-link dependencies): node 4 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 6) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_WEIGHT, output tensors: 21
    Op 22: type OPERATOR_MATMUL, output tensors: 22
    Op 23: type OPERATOR_AGGREGATION, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_WEIGHT, output tensors: 26
    Op 27: type OPERATOR_MATMUL, output tensors: 27
    Op 28: type OPERATOR_AGGREGATION, output tensors: 28
    Op 29: type OPERATOR_SOFTMAX, output tensors: 29
Boundaries: 0 0 0 0 0 0 2449029 2449029 2449029 2449029 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 24): 0-[0, 102043) 1-[102043, 204086) 2-[204086, 306129) 3-[306129, 408172) 4-[408172, 510215) 5-[510215, 612258) 6-[612258, 714301) 7-[714301, 816344) 8-[816344, 918387) ... 23-[2346989, 2449029)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 5)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 5, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 5, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 5, Pipeline Output Tensor: NULL
*** Node 5 owns the partition [26, 30) x [0, 2449029)
*** Node 5, constructing the helper classes...
(Forwarding) Node 5 (fragment 0) depends on nodes: 4 (Tensor: 25)
(Backwarding) Node 5 (fragment 0) depends on nodes:
(I-link dependencies): node 5 should send activation to nodes:
(I-link dependencies): node 5 should receive activation from nodes:
(I-link dependencies): node 5 should send gradient to nodes:
(I-link dependencies): node 5 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 6
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
GPU 4, layer [4, 5)
GPU 5, layer [5, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 1, starting model training...
Number of operators: 30
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 21
0 2449029 21 26
0 2449029 26 30
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [6, 11) x [0, 2449029)
*** Node 1, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 5)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 10)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
2449029, 126167053, 126167053
Number of vertices per chunk: 102043
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 4, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 5, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
csr in-out ready !*** Node 3, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 2, starting the helper threads...
*** Node 4, starting the helper threads...
*** Node 1, starting the helper threads...
*** Node 3, starting the helper threads...
*** Node 5, starting the helper threads...
+++++++++ Node 5 initializing the weights for op[26, 30)...
+++++++++ Node 5, mapping weight op 26
+++++++++ Node 1 initializing the weights for op[6, 11)...
+++++++++ Node 1, mapping weight op 6
+++++++++ Node 2 initializing the weights for op[11, 16)...
+++++++++ Node 2, mapping weight op 11
+++++++++ Node 3 initializing the weights for op[16, 21)...
+++++++++ Node 3, mapping weight op 16
+++++++++ Node 4 initializing the weights for op[21, 26)...
+++++++++ Node 4, mapping weight op 21
+++++++++ Node 0 initializing the weights for op[0, 6)...
+++++++++ Node 0, mapping weight op 1
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.003000000
*** Node 5, starting task scheduling...
*** Node 2, starting task scheduling...
*** Node 4, starting task scheduling...
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
*** Node 1, starting task scheduling...
*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 2.82834	TrainAcc 0.3497	ValidAcc 0.3460	TestAcc 0.2782
    Epoch 19:	Loss 1.75205	TrainAcc 0.6163	ValidAcc 0.6142	TestAcc 0.4579
    Epoch 29:	Loss 1.15651	TrainAcc 0.7223	ValidAcc 0.7161	TestAcc 0.5357
    Epoch 39:	Loss 0.92103	TrainAcc 0.7938	ValidAcc 0.7894	TestAcc 0.5943
    Epoch 49:	Loss 0.73011	TrainAcc 0.8334	ValidAcc 0.8269	TestAcc 0.6410
    Epoch 59:	Loss 0.65349	TrainAcc 0.8513	ValidAcc 0.8433	TestAcc 0.6643
    Epoch 69:	Loss 0.58990	TrainAcc 0.8624	ValidAcc 0.8566	TestAcc 0.6802
    Epoch 79:	Loss 0.56314	TrainAcc 0.8668	ValidAcc 0.8615	TestAcc 0.6877
    Epoch 89:	Loss 0.52715	TrainAcc 0.8726	ValidAcc 0.8671	TestAcc 0.6971
    Epoch 99:	Loss 0.50881	TrainAcc 0.8773	ValidAcc 0.8720	TestAcc 0.7011
    Epoch 109:	Loss 0.49071	TrainAcc 0.8809	ValidAcc 0.8760	TestAcc 0.7043
    Epoch 119:	Loss 0.47914	TrainAcc 0.8832	ValidAcc 0.8765	TestAcc 0.7087
    Epoch 129:	Loss 0.46564	TrainAcc 0.8847	ValidAcc 0.8790	TestAcc 0.7127
    Epoch 139:	Loss 0.45707	TrainAcc 0.8867	ValidAcc 0.8800	TestAcc 0.7164
    Epoch 149:	Loss 0.44703	TrainAcc 0.8889	ValidAcc 0.8826	TestAcc 0.7186
    Epoch 159:	Loss 0.44224	TrainAcc 0.8896	ValidAcc 0.8846	TestAcc 0.7221
    Epoch 169:	Loss 0.43273	TrainAcc 0.8914	ValidAcc 0.8855	TestAcc 0.7237
    Epoch 179:	Loss 0.42614	TrainAcc 0.8929	ValidAcc 0.8876	TestAcc 0.7276
    Epoch 189:	Loss 0.41942	TrainAcc 0.8944	ValidAcc 0.8882	TestAcc 0.7277
    Epoch 199:	Loss 0.41587	TrainAcc 0.8955	ValidAcc 0.8893	TestAcc 0.7290
    Epoch 209:	Loss 0.40942	TrainAcc 0.8970	ValidAcc 0.8895	TestAcc 0.7280
    Epoch 219:	Loss 0.40641	TrainAcc 0.8976	ValidAcc 0.8900	TestAcc 0.7297
    Epoch 229:	Loss 0.39930	TrainAcc 0.9007	ValidAcc 0.8930	TestAcc 0.7315
    Epoch 239:	Loss 0.39671	TrainAcc 0.9003	ValidAcc 0.8928	TestAcc 0.7320
    Epoch 249:	Loss 0.39313	TrainAcc 0.9000	ValidAcc 0.8943	TestAcc 0.7331
    Epoch 259:	Loss 0.38959	TrainAcc 0.9023	ValidAcc 0.8946	TestAcc 0.7342
    Epoch 269:	Loss 0.38621	TrainAcc 0.9018	ValidAcc 0.8942	TestAcc 0.7363
    Epoch 279:	Loss 0.38389	TrainAcc 0.9030	ValidAcc 0.8947	TestAcc 0.7384
    Epoch 289:	Loss 0.37992	TrainAcc 0.9036	ValidAcc 0.8963	TestAcc 0.7379
    Epoch 299:	Loss 0.37736	TrainAcc 0.9042	ValidAcc 0.8973	TestAcc 0.7401
    Epoch 309:	Loss 0.37415	TrainAcc 0.9048	ValidAcc 0.8965	TestAcc 0.7399
    Epoch 319:	Loss 0.37255	TrainAcc 0.9045	ValidAcc 0.8970	TestAcc 0.7406
    Epoch 329:	Loss 0.36976	TrainAcc 0.9060	ValidAcc 0.8971	TestAcc 0.7431
    Epoch 339:	Loss 0.36791	TrainAcc 0.9061	ValidAcc 0.8974	TestAcc 0.7425
    Epoch 349:	Loss 0.36501	TrainAcc 0.9077	ValidAcc 0.8982	TestAcc 0.7415
    Epoch 359:	Loss 0.36360	TrainAcc 0.9066	ValidAcc 0.8998	TestAcc 0.7446
    Epoch 369:	Loss 0.36118	TrainAcc 0.9083	ValidAcc 0.8979	TestAcc 0.7444
    Epoch 379:	Loss 0.35970	TrainAcc 0.9082	ValidAcc 0.8997	TestAcc 0.7441
    Epoch 389:	Loss 0.35838	TrainAcc 0.9085	ValidAcc 0.9002	TestAcc 0.7438
    Epoch 399:	Loss 0.35709	TrainAcc 0.9089	ValidAcc 0.8990	TestAcc 0.7459
    Epoch 409:	Loss 0.35509	TrainAcc 0.9098	ValidAcc 0.9009	TestAcc 0.7452
    Epoch 419:	Loss 0.35306	TrainAcc 0.9100	ValidAcc 0.9009	TestAcc 0.7455
    Epoch 429:	Loss 0.35093	TrainAcc 0.9101	ValidAcc 0.9001	TestAcc 0.7456
    Epoch 439:	Loss 0.35017	TrainAcc 0.9098	ValidAcc 0.9011	TestAcc 0.7463
    Epoch 449:	Loss 0.34857	TrainAcc 0.9105	ValidAcc 0.9006	TestAcc 0.7442
    Epoch 459:	Loss 0.34828	TrainAcc 0.9103	ValidAcc 0.9017	TestAcc 0.7445
    Epoch 469:	Loss 0.34661	TrainAcc 0.9112	ValidAcc 0.9024	TestAcc 0.7463
    Epoch 479:	Loss 0.34470	TrainAcc 0.9109	ValidAcc 0.9006	TestAcc 0.7476
    Epoch 489:	Loss 0.34340	TrainAcc 0.9118	ValidAcc 0.9021	TestAcc 0.7458
    Epoch 499:	Loss 0.34309	TrainAcc 0.9117	ValidAcc 0.9023	TestAcc 0.7444
    Epoch 509:	Loss 0.34184	TrainAcc 0.9118	ValidAcc 0.9013	TestAcc 0.7480
    Epoch 519:	Loss 0.34094	TrainAcc 0.9124	ValidAcc 0.9021	TestAcc 0.7476
    Epoch 529:	Loss 0.34030	TrainAcc 0.9120	ValidAcc 0.9028	TestAcc 0.7458
    Epoch 539:	Loss 0.33930	TrainAcc 0.9124	ValidAcc 0.9029	TestAcc 0.7479
    Epoch 549:	Loss 0.33721	TrainAcc 0.9131	ValidAcc 0.9025	TestAcc 0.7485
    Epoch 559:	Loss 0.33771	TrainAcc 0.9128	ValidAcc 0.9024	TestAcc 0.7473
    Epoch 569:	Loss 0.33615	TrainAcc 0.9129	ValidAcc 0.9030	TestAcc 0.7474
    Epoch 579:	Loss 0.33553	TrainAcc 0.9135	ValidAcc 0.9039	TestAcc 0.7493
    Epoch 589:	Loss 0.33402	TrainAcc 0.9133	ValidAcc 0.9023	TestAcc 0.7471
    Epoch 599:	Loss 0.33348	TrainAcc 0.9143	ValidAcc 0.9049	TestAcc 0.7475
    Epoch 609:	Loss 0.33162	TrainAcc 0.9138	ValidAcc 0.9030	TestAcc 0.7489
    Epoch 619:	Loss 0.33105	TrainAcc 0.9149	ValidAcc 0.9039	TestAcc 0.7471
    Epoch 629:	Loss 0.33046	TrainAcc 0.9145	ValidAcc 0.9035	TestAcc 0.7474
    Epoch 639:	Loss 0.32894	TrainAcc 0.9148	ValidAcc 0.9041	TestAcc 0.7476
    Epoch 649:	Loss 0.32979	TrainAcc 0.9144	ValidAcc 0.9043	TestAcc 0.7500
    Epoch 659:	Loss 0.32853	TrainAcc 0.9148	ValidAcc 0.9044	TestAcc 0.7475
    Epoch 669:	Loss 0.32784	TrainAcc 0.9154	ValidAcc 0.9045	TestAcc 0.7487
    Epoch 679:	Loss 0.32625	TrainAcc 0.9154	ValidAcc 0.9053	TestAcc 0.7488
    Epoch 689:	Loss 0.32628	TrainAcc 0.9152	ValidAcc 0.9027	TestAcc 0.7472
    Epoch 699:	Loss 0.32557	TrainAcc 0.9155	ValidAcc 0.9049	TestAcc 0.7490
    Epoch 709:	Loss 0.32331	TrainAcc 0.9154	ValidAcc 0.9036	TestAcc 0.7488
    Epoch 719:	Loss 0.32343	TrainAcc 0.9157	ValidAcc 0.9047	TestAcc 0.7490
    Epoch 729:	Loss 0.32325	TrainAcc 0.9160	ValidAcc 0.9050	TestAcc 0.7481
    Epoch 739:	Loss 0.32122	TrainAcc 0.9162	ValidAcc 0.9054	TestAcc 0.7472
    Epoch 749:	Loss 0.32196	TrainAcc 0.9167	ValidAcc 0.9044	TestAcc 0.7460
    Epoch 759:	Loss 0.32143	TrainAcc 0.9169	ValidAcc 0.9056	TestAcc 0.7474
    Epoch 769:	Loss 0.32212	TrainAcc 0.9155	ValidAcc 0.9046	TestAcc 0.7453
    Epoch 779:	Loss 0.32106	TrainAcc 0.9163	ValidAcc 0.9055	TestAcc 0.7490
    Epoch 789:	Loss 0.31979	TrainAcc 0.9170	ValidAcc 0.9026	TestAcc 0.7467
    Epoch 799:	Loss 0.31990	TrainAcc 0.9165	ValidAcc 0.9038	TestAcc 0.7471
    Epoch 809:	Loss 0.31857	TrainAcc 0.9171	ValidAcc 0.9054	TestAcc 0.7487
    Epoch 819:	Loss 0.31848	TrainAcc 0.9172	ValidAcc 0.9045	TestAcc 0.7476
    Epoch 829:	Loss 0.31832	TrainAcc 0.9170	ValidAcc 0.9045	TestAcc 0.7498
    Epoch 839:	Loss 0.31724	TrainAcc 0.9172	ValidAcc 0.9061	TestAcc 0.7467
    Epoch 849:	Loss 0.31724	TrainAcc 0.9166	ValidAcc 0.9051	TestAcc 0.7474
    Epoch 859:	Loss 0.31638	TrainAcc 0.9170	ValidAcc 0.9061	TestAcc 0.7501
    Epoch 869:	Loss 0.31517	TrainAcc 0.9181	ValidAcc 0.9050	TestAcc 0.7494
    Epoch 879:	Loss 0.31488	TrainAcc 0.9180	ValidAcc 0.9052	TestAcc 0.7475
    Epoch 889:	Loss 0.31353	TrainAcc 0.9185	ValidAcc 0.9069	TestAcc 0.7492
    Epoch 899:	Loss 0.31431	TrainAcc 0.9175	ValidAcc 0.9057	TestAcc 0.7477
    Epoch 909:	Loss 0.31310	TrainAcc 0.9185	ValidAcc 0.9063	TestAcc 0.7463
    Epoch 919:	Loss 0.31284	TrainAcc 0.9182	ValidAcc 0.9069	TestAcc 0.7460
    Epoch 929:	Loss 0.31122	TrainAcc 0.9186	ValidAcc 0.9061	TestAcc 0.7464
    Epoch 939:	Loss 0.31181	TrainAcc 0.9183	ValidAcc 0.9078	TestAcc 0.7477
    Epoch 949:	Loss 0.31175	TrainAcc 0.9191	ValidAcc 0.9064	TestAcc 0.7483
    Epoch 959:	Loss 0.31096	TrainAcc 0.9189	ValidAcc 0.9065	TestAcc 0.7463
    Epoch 969:	Loss 0.31031	TrainAcc 0.9189	ValidAcc 0.9069	TestAcc 0.7457
    Epoch 979:	Loss 0.30996	TrainAcc 0.9191	ValidAcc 0.9065	TestAcc 0.7470
    Epoch 989:	Loss 0.30990	TrainAcc 0.9188	ValidAcc 0.9063	TestAcc 0.7470
    Epoch 999:	Loss 0.30995	TrainAcc 0.9188	ValidAcc 0.9076	TestAcc 0.7485
    Epoch 1009:	Loss 0.30882	TrainAcc 0.9192	ValidAcc 0.9066	TestAcc 0.7462
    Epoch 1019:	Loss 0.30903	TrainAcc 0.9191	ValidAcc 0.9074	TestAcc 0.7464
    Epoch 1029:	Loss 0.30760	TrainAcc 0.9194	ValidAcc 0.9067	TestAcc 0.7465
    Epoch 1039:	Loss 0.30777	TrainAcc 0.9193	ValidAcc 0.9071	TestAcc 0.7482
    Epoch 1049:	Loss 0.30784	TrainAcc 0.9197	ValidAcc 0.9072	TestAcc 0.7474
    Epoch 1059:	Loss 0.30650	TrainAcc 0.9200	ValidAcc 0.9062	TestAcc 0.7469
    Epoch 1069:	Loss 0.30673	TrainAcc 0.9197	ValidAcc 0.9072	TestAcc 0.7477
    Epoch 1079:	Loss 0.30550	TrainAcc 0.9196	ValidAcc 0.9066	TestAcc 0.7481
    Epoch 1089:	Loss 0.30602	TrainAcc 0.9195	ValidAcc 0.9074	TestAcc 0.7471
    Epoch 1099:	Loss 0.30522	TrainAcc 0.9194	ValidAcc 0.9074	TestAcc 0.7473
    Epoch 1109:	Loss 0.30596	TrainAcc 0.9197	ValidAcc 0.9074	TestAcc 0.7435
    Epoch 1119:	Loss 0.30595	TrainAcc 0.9199	ValidAcc 0.9077	TestAcc 0.7477
    Epoch 1129:	Loss 0.30407	TrainAcc 0.9203	ValidAcc 0.9074	TestAcc 0.7474
    Epoch 1139:	Loss 0.30553	TrainAcc 0.9197	ValidAcc 0.9070	TestAcc 0.7478
    Epoch 1149:	Loss 0.30377	TrainAcc 0.9203	ValidAcc 0.9075	TestAcc 0.7476
    Epoch 1159:	Loss 0.30352	TrainAcc 0.9204	ValidAcc 0.9070	TestAcc 0.7465
    Epoch 1169:	Loss 0.30304	TrainAcc 0.9208	ValidAcc 0.9073	TestAcc 0.7452
    Epoch 1179:	Loss 0.30316	TrainAcc 0.9204	ValidAcc 0.9073	TestAcc 0.7465
    Epoch 1189:	Loss 0.30301	TrainAcc 0.9207	ValidAcc 0.9061	TestAcc 0.7467
    Epoch 1199:	Loss 0.30233	TrainAcc 0.9207	ValidAcc 0.9071	TestAcc 0.7467
    Epoch 1209:	Loss 0.30130	TrainAcc 0.9208	ValidAcc 0.9078	TestAcc 0.7454
    Epoch 1219:	Loss 0.30098	TrainAcc 0.9211	ValidAcc 0.9078	TestAcc 0.7460
    Epoch 1229:	Loss 0.30181	TrainAcc 0.9205	ValidAcc 0.9078	TestAcc 0.7474
    Epoch 1239:	Loss 0.30147	TrainAcc 0.9206	ValidAcc 0.9067	TestAcc 0.7454
    Epoch 1249:	Loss 0.30131	TrainAcc 0.9210	ValidAcc 0.9073	TestAcc 0.7467
    Epoch 1259:	Loss 0.30110	TrainAcc 0.9208	ValidAcc 0.9075	TestAcc 0.7465
    Epoch 1269:	Loss 0.30069	TrainAcc 0.9205	ValidAcc 0.9088	TestAcc 0.7477
    Epoch 1279:	Loss 0.29956	TrainAcc 0.9211	ValidAcc 0.9084	TestAcc 0.7469
    Epoch 1289:	Loss 0.30078	TrainAcc 0.9205	ValidAcc 0.9074	TestAcc 0.7429
    Epoch 1299:	Loss 0.29929	TrainAcc 0.9213	ValidAcc 0.9062	TestAcc 0.7447
    Epoch 1309:	Loss 0.29911	TrainAcc 0.9211	ValidAcc 0.9077	TestAcc 0.7456
    Epoch 1319:	Loss 0.29829	TrainAcc 0.9217	ValidAcc 0.9072	TestAcc 0.7453
    Epoch 1329:	Loss 0.29913	TrainAcc 0.9211	ValidAcc 0.9079	TestAcc 0.7471
    Epoch 1339:	Loss 0.29865	TrainAcc 0.9213	ValidAcc 0.9076	TestAcc 0.7455
    Epoch 1349:	Loss 0.29727	TrainAcc 0.9217	ValidAcc 0.9080	TestAcc 0.7463
    Epoch 1359:	Loss 0.29782	TrainAcc 0.9213	ValidAcc 0.9085	TestAcc 0.7439
    Epoch 1369:	Loss 0.29697	TrainAcc 0.9213	ValidAcc 0.9084	TestAcc 0.7461
    Epoch 1379:	Loss 0.29654	TrainAcc 0.9214	ValidAcc 0.9083	TestAcc 0.7461
    Epoch 1389:	Loss 0.29646	TrainAcc 0.9213	ValidAcc 0.9080	TestAcc 0.7464
    Epoch 1399:	Loss 0.29572	TrainAcc 0.9216	ValidAcc 0.9088	TestAcc 0.7464
    Epoch 1409:	Loss 0.29677	TrainAcc 0.9214	ValidAcc 0.9095	TestAcc 0.7463
    Epoch 1419:	Loss 0.29550	TrainAcc 0.9224	ValidAcc 0.9089	TestAcc 0.7473
    Epoch 1429:	Loss 0.29539	TrainAcc 0.9220	ValidAcc 0.9085	TestAcc 0.7464
    Epoch 1439:	Loss 0.29522	TrainAcc 0.9212	ValidAcc 0.9075	TestAcc 0.7453
    Epoch 1449:	Loss 0.29491	TrainAcc 0.9221	ValidAcc 0.9080	TestAcc 0.7453
    Epoch 1459:	Loss 0.29454	TrainAcc 0.9217	ValidAcc 0.9082	TestAcc 0.7458
    Epoch 1469:	Loss 0.29511	TrainAcc 0.9222	ValidAcc 0.9084	TestAcc 0.7453
    Epoch 1479:	Loss 0.29483	TrainAcc 0.9216	ValidAcc 0.9086	TestAcc 0.7457
    Epoch 1489:	Loss 0.29551	TrainAcc 0.9214	ValidAcc 0.9084	TestAcc 0.7463
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 11.209 GBps
Node 2, Layer-level comm throughput (act): 10.862 GBps
Node 3, Layer-level comm throughput (act): 10.043 GBps
Node 4, Layer-level comm throughput (act): 10.547 GBps
Node 5, Layer-level comm throughput (act): 11.239 GBps
Node 5, Layer-level comm throughput (grad): -nan GBps
Node 4, Layer-level comm throughput (grad): 11.183 GBps
Node 3, Layer-level comm throughput (grad): 11.064 GBps
Node 2, Layer-level comm throughput (grad): 10.362 GBps
Node 1, Layer-level comm throughput (grad): 10.232 GBps
Node 0, Layer-level comm throughput (grad): 11.004 GBps
    Epoch 1499:	Loss 0.29460	TrainAcc 0.9224	ValidAcc 0.9080	TestAcc 0.7448
Node 0, compression time: 4.450s, compression size: 875.841GB, throughput: 196.797GBps
Node 0, decompression time: 14.631s, compression size: 875.841GB, throughput: 59.861GBps
Node 0, pure compute time: 81.082 s, total compute time: 100.164 s
Node 0, wait_for_task_time: 137.918 s, wait_for_other_gpus_time: 0.030 s
------------------------node id 0,  per-epoch time: 0.164847 s---------------
Node 4, compression time: 10.539s, compression size: 1751.682GB, throughput: 166.204GBps
Node 4, decompression time: 37.903s, compression size: 1751.682GB, throughput: 46.214GBps
Node 4, pure compute time: 64.855 s, total compute time: 113.297 s
Node 4, wait_for_task_time: 70.017 s, wait_for_other_gpus_time: 0.027 s
------------------------node id 4,  per-epoch time: 0.164847 s---------------
Node 1, compression time: 10.758s, compression size: 1751.682GB, throughput: 162.829GBps
Node 1, decompression time: 46.791s, compression size: 1751.682GB, throughput: 37.436GBps
Node 1, pure compute time: 65.905 s, total compute time: 123.454 s
Node 1, wait_for_task_time: 109.937 s, wait_for_other_gpus_time: 0.032 s
------------------------node id 1,  per-epoch time: 0.164847 s---------------
Node 3, compression time: 10.837s, compression size: 1751.682GB, throughput: 161.637GBps
Node 3, decompression time: 86.369s, compression size: 1751.682GB, throughput: 20.281GBps
Node 3, pure compute time: 65.182 s, total compute time: 162.388 s
Node 3, wait_for_task_time: 52.920 s, wait_for_other_gpus_time: 0.021 s
Node 5, compression time: 6.179s, compression size: 875.841GB, throughput: 141.752GBps
Node 5, decompression time: 17.691s, compression size: 875.841GB, throughput: 49.508GBps
Node 5, pure compute time: 80.695 s, total compute time: 104.565 s
Node 5, wait_for_task_time: 58.032 s, wait_for_other_gpus_time: 0.028 s
------------------------node id 5,  per-epoch time: 0.164847 s---------------
Node 2, compression time: 10.944s, compression size: 1751.682GB, throughput: 160.058GBps
Node 2, decompression time: 108.141s, compression size: 1751.682GB, throughput: 16.198GBps
Node 2, pure compute time: 65.337 s, total compute time: 184.422 s
Node 2, wait_for_task_time: 42.861 s, wait_for_other_gpus_time: 0.022 s
------------------------node id 2,  per-epoch time: 0.164847 s---------------
------------------------node id 3,  per-epoch time: 0.164847 s---------------
************ Profiling Results ************
	Bubble: 53.534845 (s) (21.61 percentage)
	Compute: 139.995167 (s) (56.51 percentage)
	GradSync: 1.382236 (s) (0.56 percentage)
	GraphComm: 0.074435 (s) (0.03 percentage)
	Imbalance: 26.823515 (s) (10.83 percentage)
	LayerComm: 25.944937 (s) (10.47 percentage)
	Layer-level communication (cluster-wide, per epoch): 2.599 GB
Highest valid_acc: 0.9095
Target test_acc: 0.7463
Epoch to reach the target acc: 1410
[MPI Rank 0] Success 
[MPI Rank 5] Success 
[MPI Rank 2] Success 
[MPI Rank 4] Success 
[MPI Rank 1] Success 
[MPI Rank 3] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g000.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.925 seconds.
Building the CSC structure...
        It takes 1.867 seconds.
Building the Feature Vector...
        It takes 0.574 seconds.
Building the Label Vector...
        It takes 0.316 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.000 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.3991	ValidAcc 0.4082	TestAcc 0.3365
Version 1	TrainAcc 0.6360	ValidAcc 0.6373	TestAcc 0.4995
Version 2	TrainAcc 0.7383	ValidAcc 0.7343	TestAcc 0.5675
Version 3	TrainAcc 0.8118	ValidAcc 0.8087	TestAcc 0.6313
Version 4	TrainAcc 0.8435	ValidAcc 0.8390	TestAcc 0.6701
Version 5	TrainAcc 0.8558	ValidAcc 0.8516	TestAcc 0.6915
Version 6	TrainAcc 0.8661	ValidAcc 0.8624	TestAcc 0.7008
Version 7	TrainAcc 0.8732	ValidAcc 0.8687	TestAcc 0.7083
Version 8	TrainAcc 0.8783	ValidAcc 0.8734	TestAcc 0.7147
Version 9	TrainAcc 0.8809	ValidAcc 0.8760	TestAcc 0.7198
Version 10	TrainAcc 0.8834	ValidAcc 0.8788	TestAcc 0.7222
Version 11	TrainAcc 0.8854	ValidAcc 0.8809	TestAcc 0.7261
Version 12	TrainAcc 0.8877	ValidAcc 0.8826	TestAcc 0.7302
Version 13	TrainAcc 0.8901	ValidAcc 0.8849	TestAcc 0.7330
Version 14	TrainAcc 0.8918	ValidAcc 0.8866	TestAcc 0.7385
Version 15	TrainAcc 0.8935	ValidAcc 0.8884	TestAcc 0.7399
Version 16	TrainAcc 0.8945	ValidAcc 0.8896	TestAcc 0.7445
Version 17	TrainAcc 0.8957	ValidAcc 0.8911	TestAcc 0.7462
Version 18	TrainAcc 0.8971	ValidAcc 0.8931	TestAcc 0.7466
Version 19	TrainAcc 0.8989	ValidAcc 0.8937	TestAcc 0.7487
Version 20	TrainAcc 0.8995	ValidAcc 0.8940	TestAcc 0.7500
Version 21	TrainAcc 0.9007	ValidAcc 0.8949	TestAcc 0.7492
Version 22	TrainAcc 0.9015	ValidAcc 0.8952	TestAcc 0.7516
Version 23	TrainAcc 0.9024	ValidAcc 0.8969	TestAcc 0.7529
Version 24	TrainAcc 0.9033	ValidAcc 0.8971	TestAcc 0.7550
Version 25	TrainAcc 0.9042	ValidAcc 0.8980	TestAcc 0.7554
Version 26	TrainAcc 0.9041	ValidAcc 0.8984	TestAcc 0.7562
Version 27	TrainAcc 0.9050	ValidAcc 0.8992	TestAcc 0.7604
Version 28	TrainAcc 0.9061	ValidAcc 0.8995	TestAcc 0.7601
Version 29	TrainAcc 0.9065	ValidAcc 0.9005	TestAcc 0.7613
Version 30	TrainAcc 0.9074	ValidAcc 0.9006	TestAcc 0.7607
Version 31	TrainAcc 0.9072	ValidAcc 0.9009	TestAcc 0.7616
Version 32	TrainAcc 0.9078	ValidAcc 0.9002	TestAcc 0.7619
Version 33	TrainAcc 0.9087	ValidAcc 0.9011	TestAcc 0.7640
Version 34	TrainAcc 0.9097	ValidAcc 0.9024	TestAcc 0.7631
Version 35	TrainAcc 0.9099	ValidAcc 0.9023	TestAcc 0.7636
Version 36	TrainAcc 0.9100	ValidAcc 0.9022	TestAcc 0.7640
Version 37	TrainAcc 0.9108	ValidAcc 0.9023	TestAcc 0.7648
Version 38	TrainAcc 0.9108	ValidAcc 0.9021	TestAcc 0.7644
Version 39	TrainAcc 0.9111	ValidAcc 0.9022	TestAcc 0.7658
Version 40	TrainAcc 0.9120	ValidAcc 0.9025	TestAcc 0.7663
Version 41	TrainAcc 0.9120	ValidAcc 0.9040	TestAcc 0.7667
Version 42	TrainAcc 0.9125	ValidAcc 0.9035	TestAcc 0.7666
Version 43	TrainAcc 0.9120	ValidAcc 0.9034	TestAcc 0.7663
Version 44	TrainAcc 0.9134	ValidAcc 0.9033	TestAcc 0.7656
Version 45	TrainAcc 0.9136	ValidAcc 0.9038	TestAcc 0.7662
Version 46	TrainAcc 0.9131	ValidAcc 0.9041	TestAcc 0.7639
Version 47	TrainAcc 0.9140	ValidAcc 0.9043	TestAcc 0.7673
Version 48	TrainAcc 0.9139	ValidAcc 0.9049	TestAcc 0.7664
Version 49	TrainAcc 0.9141	ValidAcc 0.9045	TestAcc 0.7673
Version 50	TrainAcc 0.9148	ValidAcc 0.9047	TestAcc 0.7686
Version 51	TrainAcc 0.9148	ValidAcc 0.9052	TestAcc 0.7679
Version 52	TrainAcc 0.9146	ValidAcc 0.9049	TestAcc 0.7666
Version 53	TrainAcc 0.9151	ValidAcc 0.9043	TestAcc 0.7685
Version 54	TrainAcc 0.9154	ValidAcc 0.9048	TestAcc 0.7660
Version 55	TrainAcc 0.9154	ValidAcc 0.9059	TestAcc 0.7673
Version 56	TrainAcc 0.9153	ValidAcc 0.9049	TestAcc 0.7681
Version 57	TrainAcc 0.9158	ValidAcc 0.9063	TestAcc 0.7666
Version 58	TrainAcc 0.9157	ValidAcc 0.9054	TestAcc 0.7674
Version 59	TrainAcc 0.9164	ValidAcc 0.9050	TestAcc 0.7665
Version 60	TrainAcc 0.9161	ValidAcc 0.9056	TestAcc 0.7681
Version 61	TrainAcc 0.9164	ValidAcc 0.9054	TestAcc 0.7673
Version 62	TrainAcc 0.9165	ValidAcc 0.9058	TestAcc 0.7680
Version 63	TrainAcc 0.9168	ValidAcc 0.9057	TestAcc 0.7677
Version 64	TrainAcc 0.9174	ValidAcc 0.9062	TestAcc 0.7692
Version 65	TrainAcc 0.9175	ValidAcc 0.9064	TestAcc 0.7686
Version 66	TrainAcc 0.9176	ValidAcc 0.9063	TestAcc 0.7689
Version 67	TrainAcc 0.9170	ValidAcc 0.9065	TestAcc 0.7694
Version 68	TrainAcc 0.9177	ValidAcc 0.9063	TestAcc 0.7671
Version 69	TrainAcc 0.9176	ValidAcc 0.9066	TestAcc 0.7673
Version 70	TrainAcc 0.9177	ValidAcc 0.9075	TestAcc 0.7683
Version 71	TrainAcc 0.9180	ValidAcc 0.9074	TestAcc 0.7675
Version 72	TrainAcc 0.9185	ValidAcc 0.9072	TestAcc 0.7678
Version 73	TrainAcc 0.9185	ValidAcc 0.9075	TestAcc 0.7683
Version 74	TrainAcc 0.9184	ValidAcc 0.9066	TestAcc 0.7687
Version 75	TrainAcc 0.9189	ValidAcc 0.9082	TestAcc 0.7669
Version 76	TrainAcc 0.9185	ValidAcc 0.9080	TestAcc 0.7677
Version 77	TrainAcc 0.9189	ValidAcc 0.9081	TestAcc 0.7692
Version 78	TrainAcc 0.9189	ValidAcc 0.9081	TestAcc 0.7661
Version 79	TrainAcc 0.9195	ValidAcc 0.9081	TestAcc 0.7681
Version 80	TrainAcc 0.9192	ValidAcc 0.9083	TestAcc 0.7692
Version 81	TrainAcc 0.9195	ValidAcc 0.9084	TestAcc 0.7678
Version 82	TrainAcc 0.9181	ValidAcc 0.9074	TestAcc 0.7672
Version 83	TrainAcc 0.9197	ValidAcc 0.9088	TestAcc 0.7688
Version 84	TrainAcc 0.9199	ValidAcc 0.9081	TestAcc 0.7686
Version 85	TrainAcc 0.9194	ValidAcc 0.9088	TestAcc 0.7700
Version 86	TrainAcc 0.9199	ValidAcc 0.9084	TestAcc 0.7675
Version 87	TrainAcc 0.9203	ValidAcc 0.9091	TestAcc 0.7661
Version 88	TrainAcc 0.9194	ValidAcc 0.9078	TestAcc 0.7685
Version 89	TrainAcc 0.9204	ValidAcc 0.9088	TestAcc 0.7665
Version 90	TrainAcc 0.9196	ValidAcc 0.9086	TestAcc 0.7653
Version 91	TrainAcc 0.9208	ValidAcc 0.9092	TestAcc 0.7667
Version 92	TrainAcc 0.9210	ValidAcc 0.9089	TestAcc 0.7661
Version 93	TrainAcc 0.9204	ValidAcc 0.9091	TestAcc 0.7670
Version 94	TrainAcc 0.9211	ValidAcc 0.9092	TestAcc 0.7661
Version 95	TrainAcc 0.9207	ValidAcc 0.9095	TestAcc 0.7665
Version 96	TrainAcc 0.9210	ValidAcc 0.9092	TestAcc 0.7658
Version 97	TrainAcc 0.9211	ValidAcc 0.9090	TestAcc 0.7681
Version 98	TrainAcc 0.9213	ValidAcc 0.9093	TestAcc 0.7658
Version 99	TrainAcc 0.9212	ValidAcc 0.9090	TestAcc 0.7681
Version 100	TrainAcc 0.9215	ValidAcc 0.9094	TestAcc 0.7650
Version 101	TrainAcc 0.9211	ValidAcc 0.9088	TestAcc 0.7666
Version 102	TrainAcc 0.9213	ValidAcc 0.9092	TestAcc 0.7690
Version 103	TrainAcc 0.9212	ValidAcc 0.9091	TestAcc 0.7692
Version 104	TrainAcc 0.9214	ValidAcc 0.9094	TestAcc 0.7668
Version 105	TrainAcc 0.9222	ValidAcc 0.9100	TestAcc 0.7663
Version 106	TrainAcc 0.9220	ValidAcc 0.9097	TestAcc 0.7683
Version 107	TrainAcc 0.9215	ValidAcc 0.9092	TestAcc 0.7681
Version 108	TrainAcc 0.9216	ValidAcc 0.9098	TestAcc 0.7649
Version 109	TrainAcc 0.9218	ValidAcc 0.9096	TestAcc 0.7659
Version 110	TrainAcc 0.9216	ValidAcc 0.9091	TestAcc 0.7671
Version 111	TrainAcc 0.9222	ValidAcc 0.9101	TestAcc 0.7672
Version 112	TrainAcc 0.9219	ValidAcc 0.9096	TestAcc 0.7652
Version 113	TrainAcc 0.9227	ValidAcc 0.9102	TestAcc 0.7656
Version 114	TrainAcc 0.9219	ValidAcc 0.9101	TestAcc 0.7676
Version 115	TrainAcc 0.9222	ValidAcc 0.9101	TestAcc 0.7663
Version 116	TrainAcc 0.9227	ValidAcc 0.9100	TestAcc 0.7665
Version 117	TrainAcc 0.9223	ValidAcc 0.9097	TestAcc 0.7670
Version 118	TrainAcc 0.9228	ValidAcc 0.9100	TestAcc 0.7678
Version 119	TrainAcc 0.9226	ValidAcc 0.9101	TestAcc 0.7687
Version 120	TrainAcc 0.9229	ValidAcc 0.9104	TestAcc 0.7683
Version 121	TrainAcc 0.9228	ValidAcc 0.9095	TestAcc 0.7679
Version 122	TrainAcc 0.9227	ValidAcc 0.9105	TestAcc 0.7685
Version 123	TrainAcc 0.9224	ValidAcc 0.9103	TestAcc 0.7648
Version 124	TrainAcc 0.9233	ValidAcc 0.9111	TestAcc 0.7637
Version 125	TrainAcc 0.9233	ValidAcc 0.9103	TestAcc 0.7656
Version 126	TrainAcc 0.9232	ValidAcc 0.9116	TestAcc 0.7669
Version 127	TrainAcc 0.9229	ValidAcc 0.9104	TestAcc 0.7664
Version 128	TrainAcc 0.9236	ValidAcc 0.9109	TestAcc 0.7676
Version 129	TrainAcc 0.9236	ValidAcc 0.9102	TestAcc 0.7671
Version 130	TrainAcc 0.9235	ValidAcc 0.9108	TestAcc 0.7661
Version 131	TrainAcc 0.9235	ValidAcc 0.9103	TestAcc 0.7662
Version 132	TrainAcc 0.9235	ValidAcc 0.9113	TestAcc 0.7661
Version 133	TrainAcc 0.9233	ValidAcc 0.9105	TestAcc 0.7657
Version 134	TrainAcc 0.9232	ValidAcc 0.9101	TestAcc 0.7668
Version 135	TrainAcc 0.9240	ValidAcc 0.9110	TestAcc 0.7670
Version 136	TrainAcc 0.9239	ValidAcc 0.9111	TestAcc 0.7686
Version 137	TrainAcc 0.9237	ValidAcc 0.9108	TestAcc 0.7663
Version 138	TrainAcc 0.9235	ValidAcc 0.9107	TestAcc 0.7669
Version 139	TrainAcc 0.9238	ValidAcc 0.9114	TestAcc 0.7667
Version 140	TrainAcc 0.9238	ValidAcc 0.9111	TestAcc 0.7670
Version 141	TrainAcc 0.9236	ValidAcc 0.9109	TestAcc 0.7663
Version 142	TrainAcc 0.9240	ValidAcc 0.9112	TestAcc 0.7669
Version 143	TrainAcc 0.9235	ValidAcc 0.9111	TestAcc 0.7665
Version 144	TrainAcc 0.9239	ValidAcc 0.9106	TestAcc 0.7679
Version 145	TrainAcc 0.9239	ValidAcc 0.9108	TestAcc 0.7682
Version 146	TrainAcc 0.9247	ValidAcc 0.9114	TestAcc 0.7662
Version 147	TrainAcc 0.9242	ValidAcc 0.9113	TestAcc 0.7671
Version 148	TrainAcc 0.9243	ValidAcc 0.9110	TestAcc 0.7670
Version 149	TrainAcc 0.9237	ValidAcc 0.9109	TestAcc 0.7668
Version 126 achieved the highest validation accuracy 0.9116 (test accuracy: 0.7669)
