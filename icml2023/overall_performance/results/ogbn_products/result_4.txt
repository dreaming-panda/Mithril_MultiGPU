The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
Initialized node 1 on machine g001.anvil.rcac.purdue.edu
Initialized node 0 on machine g000.anvil.rcac.purdue.edu
Initialized node 2 on machine g004.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.915 seconds.
Building the CSC structure...
        It takes 1.946 seconds.
Building the CSC structure...
        It takes 1.936 seconds.
Building the CSC structure...
        It takes 1.817 seconds.
        It takes 1.887 seconds.
        It takes 1.901 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.656 seconds.
Building the Label Vector...
        It takes 0.620 seconds.
Building the Label Vector...
        It takes 0.578 seconds.
Building the Label Vector...
        It takes 0.309 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.402 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.405 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 3
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 30
0 2449029 0 11
0 2449029 11 21
0 2449029 21 30
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 11) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_WEIGHT, output tensors: 21
    Op 22: type OPERATOR_MATMUL, output tensors: 22
    Op 23: type OPERATOR_AGGREGATION, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_WEIGHT, output tensors: 26
    Op 27: type OPERATOR_MATMUL, output tensors: 27
    Op 28: type OPERATOR_AGGREGATION, output tensors: 28
    Op 29: type OPERATOR_SOFTMAX, output tensors: 29
Boundaries: 0 0 0 2449029 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 12): 0-[0, 204086) 1-[204086, 408172) 2-[408172, 612258) 3-[612258, 816344) 4-[816344, 1020430) 5-[1020430, 1224516) 6-[1224516, 1428602) 7-[1428602, 1632688) 8-[1632688, 1836774) ... 11-[2244946, 2449029)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 10)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 3
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
*** Node 1, starting model training...
Number of operators: 30
0 2449029 0 11
0 2449029 11 21
0 2449029 21 30
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
WARNING: the current version only applies to linear GNN models!
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [11, 21) x [0, 2449029)
*** Node 1, constructing the helper classes...
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 3
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 2, starting model training...
Number of operators: 30
0 2449029 0 11
0 2449029 11 21
0 2449029 21 30
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the partition [21, 30) x [0, 2449029)
*** Node 2, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 10)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 20)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 20)
(Backwarding) Node 2 (fragment 0) depends on nodes:
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
2449029, 126167053, 126167053
Number of vertices per chunk: 204086
2449029, 126167053, 126167053
Number of vertices per chunk: 204086
2449029, 126167053, 126167053
Number of vertices per chunk: 204086
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 2, starting the helper threads...
*** Node 1, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 11)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 0, mapping weight op 6
+++++++++ Node 1 initializing the weights for op[11, 21)...
+++++++++ Node 1, mapping weight op 11
+++++++++ Node 1, mapping weight op 16
+++++++++ Node 2 initializing the weights for op[21, 30)...
+++++++++ Node 2, mapping weight op 21
+++++++++ Node 2, mapping weight op 26
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.003000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.003000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 2.67846	TrainAcc 0.3508	ValidAcc 0.3511	TestAcc 0.2808
    Epoch 19:	Loss 1.52772	TrainAcc 0.6373	ValidAcc 0.6319	TestAcc 0.4745
    Epoch 29:	Loss 1.05023	TrainAcc 0.7574	ValidAcc 0.7548	TestAcc 0.5702
    Epoch 39:	Loss 0.80083	TrainAcc 0.8220	ValidAcc 0.8161	TestAcc 0.6164
    Epoch 49:	Loss 0.66800	TrainAcc 0.8486	ValidAcc 0.8408	TestAcc 0.6490
    Epoch 59:	Loss 0.59583	TrainAcc 0.8628	ValidAcc 0.8561	TestAcc 0.6743
    Epoch 69:	Loss 0.55197	TrainAcc 0.8700	ValidAcc 0.8660	TestAcc 0.6881
    Epoch 79:	Loss 0.52139	TrainAcc 0.8756	ValidAcc 0.8719	TestAcc 0.6941
    Epoch 89:	Loss 0.49911	TrainAcc 0.8790	ValidAcc 0.8734	TestAcc 0.7011
    Epoch 99:	Loss 0.47968	TrainAcc 0.8833	ValidAcc 0.8784	TestAcc 0.7088
    Epoch 109:	Loss 0.46374	TrainAcc 0.8858	ValidAcc 0.8795	TestAcc 0.7166
    Epoch 119:	Loss 0.45159	TrainAcc 0.8882	ValidAcc 0.8817	TestAcc 0.7219
    Epoch 129:	Loss 0.44154	TrainAcc 0.8904	ValidAcc 0.8830	TestAcc 0.7264
    Epoch 139:	Loss 0.43219	TrainAcc 0.8912	ValidAcc 0.8856	TestAcc 0.7289
    Epoch 149:	Loss 0.42359	TrainAcc 0.8928	ValidAcc 0.8872	TestAcc 0.7316
    Epoch 159:	Loss 0.41705	TrainAcc 0.8943	ValidAcc 0.8882	TestAcc 0.7325
    Epoch 169:	Loss 0.41142	TrainAcc 0.8965	ValidAcc 0.8897	TestAcc 0.7337
    Epoch 179:	Loss 0.40483	TrainAcc 0.8969	ValidAcc 0.8905	TestAcc 0.7319
    Epoch 189:	Loss 0.39816	TrainAcc 0.8994	ValidAcc 0.8923	TestAcc 0.7368
    Epoch 199:	Loss 0.39351	TrainAcc 0.9004	ValidAcc 0.8933	TestAcc 0.7379
    Epoch 209:	Loss 0.38868	TrainAcc 0.9018	ValidAcc 0.8941	TestAcc 0.7408
    Epoch 219:	Loss 0.38660	TrainAcc 0.9015	ValidAcc 0.8931	TestAcc 0.7400
    Epoch 229:	Loss 0.38207	TrainAcc 0.9028	ValidAcc 0.8954	TestAcc 0.7411
    Epoch 239:	Loss 0.37901	TrainAcc 0.9034	ValidAcc 0.8962	TestAcc 0.7434
    Epoch 249:	Loss 0.37471	TrainAcc 0.9048	ValidAcc 0.8966	TestAcc 0.7449
    Epoch 259:	Loss 0.37187	TrainAcc 0.9054	ValidAcc 0.8975	TestAcc 0.7428
    Epoch 269:	Loss 0.36917	TrainAcc 0.9060	ValidAcc 0.8985	TestAcc 0.7456
    Epoch 279:	Loss 0.36682	TrainAcc 0.9066	ValidAcc 0.8972	TestAcc 0.7450
    Epoch 289:	Loss 0.36511	TrainAcc 0.9068	ValidAcc 0.8984	TestAcc 0.7473
    Epoch 299:	Loss 0.36198	TrainAcc 0.9076	ValidAcc 0.9000	TestAcc 0.7481
    Epoch 309:	Loss 0.35992	TrainAcc 0.9074	ValidAcc 0.8979	TestAcc 0.7476
    Epoch 319:	Loss 0.35773	TrainAcc 0.9087	ValidAcc 0.9005	TestAcc 0.7480
    Epoch 329:	Loss 0.35608	TrainAcc 0.9086	ValidAcc 0.8993	TestAcc 0.7489
    Epoch 339:	Loss 0.35486	TrainAcc 0.9081	ValidAcc 0.9002	TestAcc 0.7501
    Epoch 349:	Loss 0.35195	TrainAcc 0.9096	ValidAcc 0.9016	TestAcc 0.7505
    Epoch 359:	Loss 0.35101	TrainAcc 0.9097	ValidAcc 0.9001	TestAcc 0.7506
    Epoch 369:	Loss 0.34875	TrainAcc 0.9101	ValidAcc 0.9012	TestAcc 0.7504
    Epoch 379:	Loss 0.34711	TrainAcc 0.9100	ValidAcc 0.9012	TestAcc 0.7502
    Epoch 389:	Loss 0.34644	TrainAcc 0.9107	ValidAcc 0.9011	TestAcc 0.7521
    Epoch 399:	Loss 0.34355	TrainAcc 0.9117	ValidAcc 0.9033	TestAcc 0.7528
    Epoch 409:	Loss 0.34372	TrainAcc 0.9113	ValidAcc 0.9012	TestAcc 0.7480
    Epoch 419:	Loss 0.34315	TrainAcc 0.9118	ValidAcc 0.9024	TestAcc 0.7494
    Epoch 429:	Loss 0.34156	TrainAcc 0.9111	ValidAcc 0.9021	TestAcc 0.7496
    Epoch 439:	Loss 0.34023	TrainAcc 0.9121	ValidAcc 0.9030	TestAcc 0.7512
    Epoch 449:	Loss 0.33951	TrainAcc 0.9121	ValidAcc 0.9025	TestAcc 0.7539
    Epoch 459:	Loss 0.33773	TrainAcc 0.9129	ValidAcc 0.9039	TestAcc 0.7526
    Epoch 469:	Loss 0.33649	TrainAcc 0.9129	ValidAcc 0.9035	TestAcc 0.7523
    Epoch 479:	Loss 0.33542	TrainAcc 0.9127	ValidAcc 0.9041	TestAcc 0.7526
    Epoch 489:	Loss 0.33400	TrainAcc 0.9134	ValidAcc 0.9043	TestAcc 0.7513
    Epoch 499:	Loss 0.33332	TrainAcc 0.9137	ValidAcc 0.9040	TestAcc 0.7524
    Epoch 509:	Loss 0.33141	TrainAcc 0.9135	ValidAcc 0.9040	TestAcc 0.7529
    Epoch 519:	Loss 0.33092	TrainAcc 0.9136	ValidAcc 0.9043	TestAcc 0.7535
    Epoch 529:	Loss 0.33049	TrainAcc 0.9141	ValidAcc 0.9039	TestAcc 0.7522
    Epoch 539:	Loss 0.32851	TrainAcc 0.9143	ValidAcc 0.9047	TestAcc 0.7521
    Epoch 549:	Loss 0.32878	TrainAcc 0.9147	ValidAcc 0.9039	TestAcc 0.7497
    Epoch 559:	Loss 0.32825	TrainAcc 0.9150	ValidAcc 0.9049	TestAcc 0.7510
    Epoch 569:	Loss 0.32695	TrainAcc 0.9148	ValidAcc 0.9060	TestAcc 0.7509
    Epoch 579:	Loss 0.32605	TrainAcc 0.9152	ValidAcc 0.9045	TestAcc 0.7504
    Epoch 589:	Loss 0.32520	TrainAcc 0.9154	ValidAcc 0.9047	TestAcc 0.7501
    Epoch 599:	Loss 0.32548	TrainAcc 0.9151	ValidAcc 0.9047	TestAcc 0.7502
    Epoch 609:	Loss 0.32424	TrainAcc 0.9159	ValidAcc 0.9069	TestAcc 0.7517
    Epoch 619:	Loss 0.32265	TrainAcc 0.9159	ValidAcc 0.9045	TestAcc 0.7517
    Epoch 629:	Loss 0.32169	TrainAcc 0.9157	ValidAcc 0.9047	TestAcc 0.7518
    Epoch 639:	Loss 0.32059	TrainAcc 0.9170	ValidAcc 0.9059	TestAcc 0.7506
    Epoch 649:	Loss 0.32113	TrainAcc 0.9165	ValidAcc 0.9063	TestAcc 0.7507
    Epoch 659:	Loss 0.32026	TrainAcc 0.9162	ValidAcc 0.9068	TestAcc 0.7501
    Epoch 669:	Loss 0.31918	TrainAcc 0.9169	ValidAcc 0.9077	TestAcc 0.7521
    Epoch 679:	Loss 0.31780	TrainAcc 0.9167	ValidAcc 0.9065	TestAcc 0.7520
    Epoch 689:	Loss 0.31897	TrainAcc 0.9159	ValidAcc 0.9063	TestAcc 0.7525
    Epoch 699:	Loss 0.31789	TrainAcc 0.9164	ValidAcc 0.9061	TestAcc 0.7528
    Epoch 709:	Loss 0.31651	TrainAcc 0.9168	ValidAcc 0.9067	TestAcc 0.7533
    Epoch 719:	Loss 0.31612	TrainAcc 0.9171	ValidAcc 0.9064	TestAcc 0.7508
    Epoch 729:	Loss 0.31578	TrainAcc 0.9171	ValidAcc 0.9064	TestAcc 0.7504
    Epoch 739:	Loss 0.31576	TrainAcc 0.9172	ValidAcc 0.9060	TestAcc 0.7515
    Epoch 749:	Loss 0.31354	TrainAcc 0.9180	ValidAcc 0.9073	TestAcc 0.7521
    Epoch 759:	Loss 0.31363	TrainAcc 0.9175	ValidAcc 0.9065	TestAcc 0.7512
    Epoch 769:	Loss 0.31262	TrainAcc 0.9186	ValidAcc 0.9083	TestAcc 0.7500
    Epoch 779:	Loss 0.31278	TrainAcc 0.9186	ValidAcc 0.9063	TestAcc 0.7505
    Epoch 789:	Loss 0.31156	TrainAcc 0.9184	ValidAcc 0.9061	TestAcc 0.7519
    Epoch 799:	Loss 0.31271	TrainAcc 0.9179	ValidAcc 0.9072	TestAcc 0.7494
    Epoch 809:	Loss 0.31176	TrainAcc 0.9179	ValidAcc 0.9080	TestAcc 0.7519
    Epoch 819:	Loss 0.31111	TrainAcc 0.9178	ValidAcc 0.9072	TestAcc 0.7517
    Epoch 829:	Loss 0.31035	TrainAcc 0.9186	ValidAcc 0.9079	TestAcc 0.7508
    Epoch 839:	Loss 0.30966	TrainAcc 0.9186	ValidAcc 0.9083	TestAcc 0.7512
    Epoch 849:	Loss 0.30877	TrainAcc 0.9187	ValidAcc 0.9062	TestAcc 0.7519
    Epoch 859:	Loss 0.30851	TrainAcc 0.9190	ValidAcc 0.9070	TestAcc 0.7504
    Epoch 869:	Loss 0.30849	TrainAcc 0.9192	ValidAcc 0.9067	TestAcc 0.7526
    Epoch 879:	Loss 0.30795	TrainAcc 0.9193	ValidAcc 0.9072	TestAcc 0.7536
    Epoch 889:	Loss 0.30704	TrainAcc 0.9193	ValidAcc 0.9082	TestAcc 0.7523
    Epoch 899:	Loss 0.30671	TrainAcc 0.9197	ValidAcc 0.9088	TestAcc 0.7522
    Epoch 909:	Loss 0.30639	TrainAcc 0.9186	ValidAcc 0.9081	TestAcc 0.7527
    Epoch 919:	Loss 0.30634	TrainAcc 0.9195	ValidAcc 0.9087	TestAcc 0.7524
    Epoch 929:	Loss 0.30684	TrainAcc 0.9190	ValidAcc 0.9076	TestAcc 0.7501
    Epoch 939:	Loss 0.30584	TrainAcc 0.9193	ValidAcc 0.9077	TestAcc 0.7505
    Epoch 949:	Loss 0.30670	TrainAcc 0.9192	ValidAcc 0.9082	TestAcc 0.7498
    Epoch 959:	Loss 0.30519	TrainAcc 0.9190	ValidAcc 0.9085	TestAcc 0.7517
    Epoch 969:	Loss 0.30394	TrainAcc 0.9200	ValidAcc 0.9077	TestAcc 0.7504
    Epoch 979:	Loss 0.30336	TrainAcc 0.9206	ValidAcc 0.9081	TestAcc 0.7501
    Epoch 989:	Loss 0.30347	TrainAcc 0.9200	ValidAcc 0.9079	TestAcc 0.7511
    Epoch 999:	Loss 0.30263	TrainAcc 0.9194	ValidAcc 0.9092	TestAcc 0.7496
    Epoch 1009:	Loss 0.30168	TrainAcc 0.9209	ValidAcc 0.9089	TestAcc 0.7503
    Epoch 1019:	Loss 0.30209	TrainAcc 0.9199	ValidAcc 0.9076	TestAcc 0.7526
    Epoch 1029:	Loss 0.30108	TrainAcc 0.9206	ValidAcc 0.9088	TestAcc 0.7522
    Epoch 1039:	Loss 0.30281	TrainAcc 0.9200	ValidAcc 0.9092	TestAcc 0.7506
    Epoch 1049:	Loss 0.30138	TrainAcc 0.9207	ValidAcc 0.9080	TestAcc 0.7518
    Epoch 1059:	Loss 0.30207	TrainAcc 0.9205	ValidAcc 0.9087	TestAcc 0.7507
    Epoch 1069:	Loss 0.30058	TrainAcc 0.9205	ValidAcc 0.9091	TestAcc 0.7506
    Epoch 1079:	Loss 0.29938	TrainAcc 0.9212	ValidAcc 0.9082	TestAcc 0.7504
    Epoch 1089:	Loss 0.29962	TrainAcc 0.9212	ValidAcc 0.9086	TestAcc 0.7509
    Epoch 1099:	Loss 0.29952	TrainAcc 0.9208	ValidAcc 0.9076	TestAcc 0.7522
    Epoch 1109:	Loss 0.29964	TrainAcc 0.9208	ValidAcc 0.9089	TestAcc 0.7502
    Epoch 1119:	Loss 0.29847	TrainAcc 0.9215	ValidAcc 0.9090	TestAcc 0.7508
    Epoch 1129:	Loss 0.29772	TrainAcc 0.9210	ValidAcc 0.9097	TestAcc 0.7503
    Epoch 1139:	Loss 0.29854	TrainAcc 0.9207	ValidAcc 0.9088	TestAcc 0.7486
    Epoch 1149:	Loss 0.29828	TrainAcc 0.9215	ValidAcc 0.9085	TestAcc 0.7517
    Epoch 1159:	Loss 0.29881	TrainAcc 0.9205	ValidAcc 0.9093	TestAcc 0.7515
    Epoch 1169:	Loss 0.29686	TrainAcc 0.9217	ValidAcc 0.9094	TestAcc 0.7522
    Epoch 1179:	Loss 0.29713	TrainAcc 0.9217	ValidAcc 0.9095	TestAcc 0.7502
    Epoch 1189:	Loss 0.29621	TrainAcc 0.9216	ValidAcc 0.9104	TestAcc 0.7504
    Epoch 1199:	Loss 0.29613	TrainAcc 0.9216	ValidAcc 0.9098	TestAcc 0.7516
    Epoch 1209:	Loss 0.29575	TrainAcc 0.9216	ValidAcc 0.9089	TestAcc 0.7507
    Epoch 1219:	Loss 0.29558	TrainAcc 0.9216	ValidAcc 0.9085	TestAcc 0.7487
    Epoch 1229:	Loss 0.29472	TrainAcc 0.9215	ValidAcc 0.9095	TestAcc 0.7499
    Epoch 1239:	Loss 0.29486	TrainAcc 0.9215	ValidAcc 0.9096	TestAcc 0.7508
    Epoch 1249:	Loss 0.29513	TrainAcc 0.9215	ValidAcc 0.9083	TestAcc 0.7494
    Epoch 1259:	Loss 0.29534	TrainAcc 0.9217	ValidAcc 0.9087	TestAcc 0.7486
    Epoch 1269:	Loss 0.29466	TrainAcc 0.9221	ValidAcc 0.9100	TestAcc 0.7494
    Epoch 1279:	Loss 0.29507	TrainAcc 0.9220	ValidAcc 0.9092	TestAcc 0.7510
    Epoch 1289:	Loss 0.29317	TrainAcc 0.9223	ValidAcc 0.9090	TestAcc 0.7501
    Epoch 1299:	Loss 0.29264	TrainAcc 0.9224	ValidAcc 0.9090	TestAcc 0.7513
    Epoch 1309:	Loss 0.29229	TrainAcc 0.9228	ValidAcc 0.9100	TestAcc 0.7490
    Epoch 1319:	Loss 0.29347	TrainAcc 0.9220	ValidAcc 0.9081	TestAcc 0.7502
    Epoch 1329:	Loss 0.29250	TrainAcc 0.9223	ValidAcc 0.9087	TestAcc 0.7502
    Epoch 1339:	Loss 0.29141	TrainAcc 0.9225	ValidAcc 0.9093	TestAcc 0.7502
    Epoch 1349:	Loss 0.29216	TrainAcc 0.9221	ValidAcc 0.9095	TestAcc 0.7506
    Epoch 1359:	Loss 0.29336	TrainAcc 0.9221	ValidAcc 0.9098	TestAcc 0.7496
    Epoch 1369:	Loss 0.29195	TrainAcc 0.9222	ValidAcc 0.9097	TestAcc 0.7488
    Epoch 1379:	Loss 0.29037	TrainAcc 0.9230	ValidAcc 0.9102	TestAcc 0.7505
    Epoch 1389:	Loss 0.29128	TrainAcc 0.9223	ValidAcc 0.9108	TestAcc 0.7506
    Epoch 1399:	Loss 0.29079	TrainAcc 0.9223	ValidAcc 0.9079	TestAcc 0.7488
    Epoch 1409:	Loss 0.29089	TrainAcc 0.9219	ValidAcc 0.9089	TestAcc 0.7485
    Epoch 1419:	Loss 0.29008	TrainAcc 0.9227	ValidAcc 0.9108	TestAcc 0.7480
    Epoch 1429:	Loss 0.28949	TrainAcc 0.9223	ValidAcc 0.9098	TestAcc 0.7505
    Epoch 1439:	Loss 0.28971	TrainAcc 0.9228	ValidAcc 0.9095	TestAcc 0.7508
    Epoch 1449:	Loss 0.29001	TrainAcc 0.9226	ValidAcc 0.9088	TestAcc 0.7461
    Epoch 1459:	Loss 0.29005	TrainAcc 0.9228	ValidAcc 0.9081	TestAcc 0.7494
    Epoch 1469:	Loss 0.29023	TrainAcc 0.9229	ValidAcc 0.9085	TestAcc 0.7475
    Epoch 1479:	Loss 0.29034	TrainAcc 0.9230	ValidAcc 0.9088	TestAcc 0.7464
    Epoch 1489:	Loss 0.28937	TrainAcc 0.9230	ValidAcc 0.9088	TestAcc 0.7490
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 11.320 GBps
Node 2, Layer-level comm throughput (act): 11.058 GBps
Node 2, Layer-level comm throughput (grad): -nan GBps
Node 1, Layer-level comm throughput (grad): 11.305 GBps
Node 0, Layer-level comm throughput (grad): 11.214 GBps
    Epoch 1499:	Loss 0.28801	TrainAcc 0.9231	ValidAcc 0.9095	TestAcc 0.7478
Node 0, compression time: 3.537s, compression size: 875.841GB, throughput: 247.651GBps
Node 0, decompression time: 18.430s, compression size: 875.841GB, throughput: 47.522GBps
Node 0, pure compute time: 142.363 s, total compute time: 164.330 s
Node 0, wait_for_task_time: 65.443 s, wait_for_other_gpus_time: 0.008 s
------------------------node id 0,  per-epoch time: 0.161549 s---------------
Node 1, compression time: 8.774s, compression size: 1751.682GB, throughput: 199.639GBps
Node 1, decompression time: 50.686s, compression size: 1751.682GB, throughput: 34.560GBps
Node 2, compression time: 5.404s, compression size: 875.841GB, throughput: 162.084GBps
Node 2, decompression time: 16.953s, compression size: 875.841GB, throughput: 51.663GBps
Node 2, pure compute time: 135.026 s, total compute time: 157.382 s
Node 2, wait_for_task_time: 28.038 s, wait_for_other_gpus_time: 0.019 s
------------------------node id 2,  per-epoch time: 0.161549 s---------------
Node 1, pure compute time: 119.854 s, total compute time: 179.314 s
Node 1, wait_for_task_time: 37.621 s, wait_for_other_gpus_time: 0.018 s
------------------------node id 1,  per-epoch time: 0.161549 s---------------
************ Profiling Results ************
	Bubble: 36.885311 (s) (15.21 percentage)
	Compute: 180.643613 (s) (74.49 percentage)
	GradSync: 1.768006 (s) (0.73 percentage)
	GraphComm: 0.050922 (s) (0.02 percentage)
	Imbalance: 14.435591 (s) (5.95 percentage)
	LayerComm: 8.715769 (s) (3.59 percentage)
	Layer-level communication (cluster-wide, per epoch): 1.114 GB
Highest valid_acc: 0.9108
Target test_acc: 0.7506
Epoch to reach the target acc: 1390
[MPI Rank 0] Success 
[MPI Rank 2] Success 
[MPI Rank 1] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g000.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.959 seconds.
Building the CSC structure...
        It takes 1.898 seconds.
Building the Feature Vector...
        It takes 0.585 seconds.
Building the Label Vector...
        It takes 0.312 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.000 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.4252	ValidAcc 0.4316	TestAcc 0.3610
Version 1	TrainAcc 0.6714	ValidAcc 0.6637	TestAcc 0.5083
Version 2	TrainAcc 0.7765	ValidAcc 0.7743	TestAcc 0.5979
Version 3	TrainAcc 0.8311	ValidAcc 0.8263	TestAcc 0.6438
Version 4	TrainAcc 0.8539	ValidAcc 0.8494	TestAcc 0.6747
Version 5	TrainAcc 0.8668	ValidAcc 0.8636	TestAcc 0.6970
Version 6	TrainAcc 0.8739	ValidAcc 0.8713	TestAcc 0.7075
Version 7	TrainAcc 0.8800	ValidAcc 0.8762	TestAcc 0.7113
Version 8	TrainAcc 0.8826	ValidAcc 0.8788	TestAcc 0.7186
Version 9	TrainAcc 0.8862	ValidAcc 0.8819	TestAcc 0.7279
Version 10	TrainAcc 0.8887	ValidAcc 0.8836	TestAcc 0.7334
Version 11	TrainAcc 0.8906	ValidAcc 0.8853	TestAcc 0.7405
Version 12	TrainAcc 0.8927	ValidAcc 0.8873	TestAcc 0.7457
Version 13	TrainAcc 0.8936	ValidAcc 0.8881	TestAcc 0.7459
Version 14	TrainAcc 0.8954	ValidAcc 0.8904	TestAcc 0.7501
Version 15	TrainAcc 0.8968	ValidAcc 0.8912	TestAcc 0.7505
Version 16	TrainAcc 0.8982	ValidAcc 0.8933	TestAcc 0.7514
Version 17	TrainAcc 0.8994	ValidAcc 0.8925	TestAcc 0.7532
Version 18	TrainAcc 0.9009	ValidAcc 0.8950	TestAcc 0.7565
Version 19	TrainAcc 0.9022	ValidAcc 0.8957	TestAcc 0.7562
Version 20	TrainAcc 0.9030	ValidAcc 0.8963	TestAcc 0.7576
Version 21	TrainAcc 0.9036	ValidAcc 0.8970	TestAcc 0.7590
Version 22	TrainAcc 0.9047	ValidAcc 0.8979	TestAcc 0.7613
Version 23	TrainAcc 0.9057	ValidAcc 0.8997	TestAcc 0.7631
Version 24	TrainAcc 0.9062	ValidAcc 0.8995	TestAcc 0.7614
Version 25	TrainAcc 0.9067	ValidAcc 0.8996	TestAcc 0.7603
Version 26	TrainAcc 0.9066	ValidAcc 0.9006	TestAcc 0.7659
Version 27	TrainAcc 0.9076	ValidAcc 0.9009	TestAcc 0.7646
Version 28	TrainAcc 0.9080	ValidAcc 0.9004	TestAcc 0.7668
Version 29	TrainAcc 0.9092	ValidAcc 0.9021	TestAcc 0.7656
Version 30	TrainAcc 0.9090	ValidAcc 0.9016	TestAcc 0.7673
Version 31	TrainAcc 0.9099	ValidAcc 0.9019	TestAcc 0.7671
Version 32	TrainAcc 0.9104	ValidAcc 0.9026	TestAcc 0.7666
Version 33	TrainAcc 0.9109	ValidAcc 0.9033	TestAcc 0.7674
Version 34	TrainAcc 0.9111	ValidAcc 0.9033	TestAcc 0.7675
Version 35	TrainAcc 0.9116	ValidAcc 0.9038	TestAcc 0.7665
Version 36	TrainAcc 0.9119	ValidAcc 0.9041	TestAcc 0.7692
Version 37	TrainAcc 0.9121	ValidAcc 0.9043	TestAcc 0.7702
Version 38	TrainAcc 0.9126	ValidAcc 0.9050	TestAcc 0.7714
Version 39	TrainAcc 0.9128	ValidAcc 0.9051	TestAcc 0.7684
Version 40	TrainAcc 0.9133	ValidAcc 0.9047	TestAcc 0.7688
Version 41	TrainAcc 0.9131	ValidAcc 0.9053	TestAcc 0.7709
Version 42	TrainAcc 0.9128	ValidAcc 0.9046	TestAcc 0.7679
Version 43	TrainAcc 0.9134	ValidAcc 0.9047	TestAcc 0.7721
Version 44	TrainAcc 0.9135	ValidAcc 0.9054	TestAcc 0.7719
Version 45	TrainAcc 0.9143	ValidAcc 0.9063	TestAcc 0.7703
Version 46	TrainAcc 0.9145	ValidAcc 0.9061	TestAcc 0.7710
Version 47	TrainAcc 0.9145	ValidAcc 0.9061	TestAcc 0.7704
Version 48	TrainAcc 0.9150	ValidAcc 0.9065	TestAcc 0.7700
Version 49	TrainAcc 0.9154	ValidAcc 0.9071	TestAcc 0.7714
Version 50	TrainAcc 0.9160	ValidAcc 0.9070	TestAcc 0.7703
Version 51	TrainAcc 0.9156	ValidAcc 0.9071	TestAcc 0.7695
Version 52	TrainAcc 0.9160	ValidAcc 0.9068	TestAcc 0.7708
Version 53	TrainAcc 0.9167	ValidAcc 0.9086	TestAcc 0.7710
Version 54	TrainAcc 0.9158	ValidAcc 0.9073	TestAcc 0.7687
Version 55	TrainAcc 0.9161	ValidAcc 0.9076	TestAcc 0.7707
Version 56	TrainAcc 0.9162	ValidAcc 0.9080	TestAcc 0.7683
Version 57	TrainAcc 0.9168	ValidAcc 0.9085	TestAcc 0.7712
Version 58	TrainAcc 0.9166	ValidAcc 0.9074	TestAcc 0.7709
Version 59	TrainAcc 0.9174	ValidAcc 0.9084	TestAcc 0.7704
Version 60	TrainAcc 0.9176	ValidAcc 0.9082	TestAcc 0.7701
Version 61	TrainAcc 0.9181	ValidAcc 0.9092	TestAcc 0.7711
Version 62	TrainAcc 0.9181	ValidAcc 0.9091	TestAcc 0.7700
Version 63	TrainAcc 0.9183	ValidAcc 0.9085	TestAcc 0.7687
Version 64	TrainAcc 0.9180	ValidAcc 0.9092	TestAcc 0.7712
Version 65	TrainAcc 0.9180	ValidAcc 0.9088	TestAcc 0.7720
Version 66	TrainAcc 0.9179	ValidAcc 0.9084	TestAcc 0.7718
Version 67	TrainAcc 0.9182	ValidAcc 0.9090	TestAcc 0.7714
Version 68	TrainAcc 0.9182	ValidAcc 0.9093	TestAcc 0.7721
Version 69	TrainAcc 0.9189	ValidAcc 0.9096	TestAcc 0.7714
Version 70	TrainAcc 0.9188	ValidAcc 0.9097	TestAcc 0.7703
Version 71	TrainAcc 0.9192	ValidAcc 0.9094	TestAcc 0.7691
Version 72	TrainAcc 0.9193	ValidAcc 0.9099	TestAcc 0.7700
Version 73	TrainAcc 0.9189	ValidAcc 0.9093	TestAcc 0.7699
Version 74	TrainAcc 0.9193	ValidAcc 0.9097	TestAcc 0.7695
Version 75	TrainAcc 0.9200	ValidAcc 0.9100	TestAcc 0.7704
Version 76	TrainAcc 0.9197	ValidAcc 0.9098	TestAcc 0.7708
Version 77	TrainAcc 0.9206	ValidAcc 0.9100	TestAcc 0.7701
Version 78	TrainAcc 0.9203	ValidAcc 0.9096	TestAcc 0.7721
Version 79	TrainAcc 0.9201	ValidAcc 0.9104	TestAcc 0.7710
Version 80	TrainAcc 0.9204	ValidAcc 0.9111	TestAcc 0.7705
Version 81	TrainAcc 0.9205	ValidAcc 0.9108	TestAcc 0.7727
Version 82	TrainAcc 0.9205	ValidAcc 0.9098	TestAcc 0.7720
Version 83	TrainAcc 0.9210	ValidAcc 0.9114	TestAcc 0.7703
Version 84	TrainAcc 0.9211	ValidAcc 0.9109	TestAcc 0.7712
Version 85	TrainAcc 0.9213	ValidAcc 0.9110	TestAcc 0.7715
Version 86	TrainAcc 0.9211	ValidAcc 0.9104	TestAcc 0.7718
Version 87	TrainAcc 0.9214	ValidAcc 0.9112	TestAcc 0.7719
Version 88	TrainAcc 0.9213	ValidAcc 0.9106	TestAcc 0.7711
Version 89	TrainAcc 0.9205	ValidAcc 0.9107	TestAcc 0.7697
Version 90	TrainAcc 0.9213	ValidAcc 0.9108	TestAcc 0.7692
Version 91	TrainAcc 0.9210	ValidAcc 0.9110	TestAcc 0.7680
Version 92	TrainAcc 0.9216	ValidAcc 0.9109	TestAcc 0.7689
Version 93	TrainAcc 0.9213	ValidAcc 0.9108	TestAcc 0.7709
Version 94	TrainAcc 0.9208	ValidAcc 0.9094	TestAcc 0.7693
Version 95	TrainAcc 0.9210	ValidAcc 0.9107	TestAcc 0.7734
Version 96	TrainAcc 0.9217	ValidAcc 0.9103	TestAcc 0.7694
Version 97	TrainAcc 0.9218	ValidAcc 0.9114	TestAcc 0.7715
Version 98	TrainAcc 0.9224	ValidAcc 0.9108	TestAcc 0.7682
Version 99	TrainAcc 0.9223	ValidAcc 0.9116	TestAcc 0.7706
Version 100	TrainAcc 0.9226	ValidAcc 0.9114	TestAcc 0.7690
Version 101	TrainAcc 0.9225	ValidAcc 0.9117	TestAcc 0.7720
Version 102	TrainAcc 0.9225	ValidAcc 0.9118	TestAcc 0.7712
Version 103	TrainAcc 0.9230	ValidAcc 0.9108	TestAcc 0.7715
Version 104	TrainAcc 0.9219	ValidAcc 0.9117	TestAcc 0.7713
Version 105	TrainAcc 0.9230	ValidAcc 0.9117	TestAcc 0.7729
Version 106	TrainAcc 0.9224	ValidAcc 0.9112	TestAcc 0.7718
Version 107	TrainAcc 0.9230	ValidAcc 0.9113	TestAcc 0.7704
Version 108	TrainAcc 0.9221	ValidAcc 0.9107	TestAcc 0.7722
Version 109	TrainAcc 0.9229	ValidAcc 0.9116	TestAcc 0.7725
Version 110	TrainAcc 0.9225	ValidAcc 0.9113	TestAcc 0.7714
Version 111	TrainAcc 0.9237	ValidAcc 0.9120	TestAcc 0.7709
Version 112	TrainAcc 0.9233	ValidAcc 0.9121	TestAcc 0.7705
Version 113	TrainAcc 0.9235	ValidAcc 0.9116	TestAcc 0.7703
Version 114	TrainAcc 0.9236	ValidAcc 0.9123	TestAcc 0.7720
Version 115	TrainAcc 0.9231	ValidAcc 0.9124	TestAcc 0.7727
Version 116	TrainAcc 0.9232	ValidAcc 0.9116	TestAcc 0.7733
Version 117	TrainAcc 0.9237	ValidAcc 0.9118	TestAcc 0.7705
Version 118	TrainAcc 0.9238	ValidAcc 0.9126	TestAcc 0.7704
Version 119	TrainAcc 0.9227	ValidAcc 0.9106	TestAcc 0.7690
Version 120	TrainAcc 0.9237	ValidAcc 0.9119	TestAcc 0.7725
Version 121	TrainAcc 0.9239	ValidAcc 0.9114	TestAcc 0.7714
Version 122	TrainAcc 0.9244	ValidAcc 0.9121	TestAcc 0.7704
Version 123	TrainAcc 0.9243	ValidAcc 0.9122	TestAcc 0.7697
Version 124	TrainAcc 0.9240	ValidAcc 0.9121	TestAcc 0.7711
Version 125	TrainAcc 0.9237	ValidAcc 0.9116	TestAcc 0.7702
Version 126	TrainAcc 0.9241	ValidAcc 0.9130	TestAcc 0.7696
Version 127	TrainAcc 0.9245	ValidAcc 0.9126	TestAcc 0.7702
Version 128	TrainAcc 0.9246	ValidAcc 0.9122	TestAcc 0.7702
Version 129	TrainAcc 0.9245	ValidAcc 0.9130	TestAcc 0.7710
Version 130	TrainAcc 0.9247	ValidAcc 0.9127	TestAcc 0.7705
Version 131	TrainAcc 0.9249	ValidAcc 0.9126	TestAcc 0.7714
Version 132	TrainAcc 0.9246	ValidAcc 0.9128	TestAcc 0.7704
Version 133	TrainAcc 0.9245	ValidAcc 0.9112	TestAcc 0.7703
Version 134	TrainAcc 0.9242	ValidAcc 0.9127	TestAcc 0.7711
Version 135	TrainAcc 0.9246	ValidAcc 0.9116	TestAcc 0.7694
Version 136	TrainAcc 0.9248	ValidAcc 0.9125	TestAcc 0.7701
Version 137	TrainAcc 0.9244	ValidAcc 0.9129	TestAcc 0.7701
Version 138	TrainAcc 0.9243	ValidAcc 0.9122	TestAcc 0.7687
Version 139	TrainAcc 0.9246	ValidAcc 0.9121	TestAcc 0.7702
Version 140	TrainAcc 0.9252	ValidAcc 0.9130	TestAcc 0.7703
Version 141	TrainAcc 0.9248	ValidAcc 0.9126	TestAcc 0.7688
Version 142	TrainAcc 0.9251	ValidAcc 0.9132	TestAcc 0.7713
Version 143	TrainAcc 0.9253	ValidAcc 0.9128	TestAcc 0.7687
Version 144	TrainAcc 0.9249	ValidAcc 0.9128	TestAcc 0.7679
Version 145	TrainAcc 0.9258	ValidAcc 0.9130	TestAcc 0.7686
Version 146	TrainAcc 0.9250	ValidAcc 0.9125	TestAcc 0.7684
Version 147	TrainAcc 0.9253	ValidAcc 0.9133	TestAcc 0.7680
Version 148	TrainAcc 0.9254	ValidAcc 0.9125	TestAcc 0.7707
Version 149	TrainAcc 0.9251	ValidAcc 0.9125	TestAcc 0.7694
Version 147 achieved the highest validation accuracy 0.9133 (test accuracy: 0.7680)
