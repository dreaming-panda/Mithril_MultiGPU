The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1500
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.300
The checkpointed weight file: /anvil/projects/x-cis220117/checkpointed_weights/checkpointed_weights_ogbn_products
The random seed: 5
The scaling down factor of out-of-chunk gradients: 0.100000
Initialized node 1 on machine g001.anvil.rcac.purdue.edu
Initialized node 0 on machine g000.anvil.rcac.purdue.edu
Initialized node 2 on machine g004.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.936 seconds.
Building the CSC structure...
        It takes 1.920 seconds.
Building the CSC structure...
        It takes 1.946 seconds.
Building the CSC structure...
        It takes 1.895 seconds.
        It takes 1.878 seconds.
        It takes 1.897 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.618 seconds.
Building the Label Vector...
        It takes 0.687 seconds.
Building the Label Vector...
        It takes 0.668 seconds.
Building the Label Vector...
        It takes 0.310 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.391 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.402 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 3
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 30
0 2449029 0 11
0 2449029 11 21
0 2449029 21 30
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 11) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_WEIGHT, output tensors: 21
    Op 22: type OPERATOR_MATMUL, output tensors: 22
    Op 23: type OPERATOR_AGGREGATION, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_WEIGHT, output tensors: 26
    Op 27: type OPERATOR_MATMUL, output tensors: 27
    Op 28: type OPERATOR_AGGREGATION, output tensors: 28
    Op 29: type OPERATOR_SOFTMAX, output tensors: 29
Boundaries: 0 0 0 2449029 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 12): 0-[0, 204086) 1-[204086, 408172) 2-[408172, 612258) 3-[612258, 816344) 4-[816344, 1020430) 5-[1020430, 1224516) 6-[1224516, 1428602) 7-[1428602, 1632688) 8-[1632688, 1836774) ... 11-[2244946, 2449029)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 10)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 3
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 1, starting model training...
Number of operators: 30
0 2449029 0 11
0 2449029 11 21
0 2449029 21 30
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [11, 21) x [0, 2449029)
*** Node 1, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 10)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 20)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 3
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
WARNING: the current version only applies to linear GNN models!
*** Node 2, starting model training...
Number of operators: 30
0 2449029 0 11
0 2449029 11 21
0 2449029 21 30
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the partition [21, 30) x [0, 2449029)
*** Node 2, constructing the helper classes...
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 20)
(Backwarding) Node 2 (fragment 0) depends on nodes:
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
2449029, 126167053, 126167053
Number of vertices per chunk: 204086
2449029, 126167053, 126167053
Number of vertices per chunk: 204086
2449029, 126167053, 126167053
Number of vertices per chunk: 204086
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 2, starting the helper threads...
*** Node 1, starting the helper threads...
+++++++++ Node 2 initializing the weights for op[21, 30)...
+++++++++ Node 2, mapping weight op 21
+++++++++ Node 1 initializing the weights for op[11, 21)...
+++++++++ Node 1, mapping weight op 11
+++++++++ Node 2, mapping weight op 26
+++++++++ Node 1, mapping weight op 16
+++++++++ Node 0 initializing the weights for op[0, 11)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 0, mapping weight op 6
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.003000000
*** Node 2, starting task scheduling...
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 2.67846	TrainAcc 0.3508	ValidAcc 0.3511	TestAcc 0.2808
    Epoch 19:	Loss 1.52772	TrainAcc 0.6373	ValidAcc 0.6319	TestAcc 0.4745
    Epoch 29:	Loss 1.05023	TrainAcc 0.7574	ValidAcc 0.7548	TestAcc 0.5702
    Epoch 39:	Loss 0.80083	TrainAcc 0.8220	ValidAcc 0.8161	TestAcc 0.6164
    Epoch 49:	Loss 0.66799	TrainAcc 0.8486	ValidAcc 0.8408	TestAcc 0.6490
    Epoch 59:	Loss 0.59580	TrainAcc 0.8628	ValidAcc 0.8562	TestAcc 0.6744
    Epoch 69:	Loss 0.55195	TrainAcc 0.8701	ValidAcc 0.8660	TestAcc 0.6881
    Epoch 79:	Loss 0.52136	TrainAcc 0.8756	ValidAcc 0.8719	TestAcc 0.6941
    Epoch 89:	Loss 0.49910	TrainAcc 0.8790	ValidAcc 0.8734	TestAcc 0.7011
    Epoch 99:	Loss 0.47967	TrainAcc 0.8833	ValidAcc 0.8784	TestAcc 0.7087
    Epoch 109:	Loss 0.46370	TrainAcc 0.8858	ValidAcc 0.8793	TestAcc 0.7162
    Epoch 119:	Loss 0.45149	TrainAcc 0.8882	ValidAcc 0.8817	TestAcc 0.7215
    Epoch 129:	Loss 0.44145	TrainAcc 0.8905	ValidAcc 0.8832	TestAcc 0.7262
    Epoch 139:	Loss 0.43218	TrainAcc 0.8912	ValidAcc 0.8857	TestAcc 0.7287
    Epoch 149:	Loss 0.42359	TrainAcc 0.8928	ValidAcc 0.8872	TestAcc 0.7314
    Epoch 159:	Loss 0.41697	TrainAcc 0.8943	ValidAcc 0.8882	TestAcc 0.7324
    Epoch 169:	Loss 0.41137	TrainAcc 0.8965	ValidAcc 0.8896	TestAcc 0.7337
    Epoch 179:	Loss 0.40485	TrainAcc 0.8969	ValidAcc 0.8903	TestAcc 0.7320
    Epoch 189:	Loss 0.39816	TrainAcc 0.8993	ValidAcc 0.8925	TestAcc 0.7369
    Epoch 199:	Loss 0.39354	TrainAcc 0.9005	ValidAcc 0.8933	TestAcc 0.7379
    Epoch 209:	Loss 0.38869	TrainAcc 0.9017	ValidAcc 0.8943	TestAcc 0.7408
    Epoch 219:	Loss 0.38668	TrainAcc 0.9016	ValidAcc 0.8935	TestAcc 0.7405
    Epoch 229:	Loss 0.38229	TrainAcc 0.9028	ValidAcc 0.8955	TestAcc 0.7412
    Epoch 239:	Loss 0.37918	TrainAcc 0.9035	ValidAcc 0.8963	TestAcc 0.7432
    Epoch 249:	Loss 0.37487	TrainAcc 0.9048	ValidAcc 0.8967	TestAcc 0.7451
    Epoch 259:	Loss 0.37203	TrainAcc 0.9054	ValidAcc 0.8976	TestAcc 0.7432
    Epoch 269:	Loss 0.36939	TrainAcc 0.9061	ValidAcc 0.8984	TestAcc 0.7454
    Epoch 279:	Loss 0.36694	TrainAcc 0.9067	ValidAcc 0.8972	TestAcc 0.7452
    Epoch 289:	Loss 0.36524	TrainAcc 0.9067	ValidAcc 0.8987	TestAcc 0.7472
    Epoch 299:	Loss 0.36222	TrainAcc 0.9076	ValidAcc 0.9000	TestAcc 0.7480
    Epoch 309:	Loss 0.36002	TrainAcc 0.9075	ValidAcc 0.8985	TestAcc 0.7476
    Epoch 319:	Loss 0.35795	TrainAcc 0.9088	ValidAcc 0.9003	TestAcc 0.7480
    Epoch 329:	Loss 0.35629	TrainAcc 0.9085	ValidAcc 0.8994	TestAcc 0.7491
    Epoch 339:	Loss 0.35501	TrainAcc 0.9080	ValidAcc 0.8999	TestAcc 0.7503
    Epoch 349:	Loss 0.35222	TrainAcc 0.9098	ValidAcc 0.9012	TestAcc 0.7506
    Epoch 359:	Loss 0.35128	TrainAcc 0.9098	ValidAcc 0.8998	TestAcc 0.7513
    Epoch 369:	Loss 0.34876	TrainAcc 0.9101	ValidAcc 0.9015	TestAcc 0.7501
    Epoch 379:	Loss 0.34725	TrainAcc 0.9101	ValidAcc 0.9013	TestAcc 0.7514
    Epoch 389:	Loss 0.34655	TrainAcc 0.9106	ValidAcc 0.9011	TestAcc 0.7525
    Epoch 399:	Loss 0.34387	TrainAcc 0.9119	ValidAcc 0.9028	TestAcc 0.7535
    Epoch 409:	Loss 0.34300	TrainAcc 0.9117	ValidAcc 0.9017	TestAcc 0.7509
    Epoch 419:	Loss 0.34266	TrainAcc 0.9121	ValidAcc 0.9026	TestAcc 0.7497
    Epoch 429:	Loss 0.34147	TrainAcc 0.9113	ValidAcc 0.9018	TestAcc 0.7515
    Epoch 439:	Loss 0.34012	TrainAcc 0.9124	ValidAcc 0.9028	TestAcc 0.7518
    Epoch 449:	Loss 0.33927	TrainAcc 0.9124	ValidAcc 0.9025	TestAcc 0.7544
    Epoch 459:	Loss 0.33765	TrainAcc 0.9133	ValidAcc 0.9038	TestAcc 0.7534
    Epoch 469:	Loss 0.33646	TrainAcc 0.9131	ValidAcc 0.9032	TestAcc 0.7530
    Epoch 479:	Loss 0.33560	TrainAcc 0.9129	ValidAcc 0.9034	TestAcc 0.7540
    Epoch 489:	Loss 0.33407	TrainAcc 0.9134	ValidAcc 0.9042	TestAcc 0.7530
    Epoch 499:	Loss 0.33337	TrainAcc 0.9139	ValidAcc 0.9043	TestAcc 0.7532
    Epoch 509:	Loss 0.33123	TrainAcc 0.9137	ValidAcc 0.9046	TestAcc 0.7538
    Epoch 519:	Loss 0.33066	TrainAcc 0.9140	ValidAcc 0.9039	TestAcc 0.7535
    Epoch 529:	Loss 0.33041	TrainAcc 0.9146	ValidAcc 0.9033	TestAcc 0.7532
    Epoch 539:	Loss 0.32838	TrainAcc 0.9143	ValidAcc 0.9048	TestAcc 0.7527
    Epoch 549:	Loss 0.32881	TrainAcc 0.9147	ValidAcc 0.9043	TestAcc 0.7496
    Epoch 559:	Loss 0.32781	TrainAcc 0.9150	ValidAcc 0.9053	TestAcc 0.7515
    Epoch 569:	Loss 0.32738	TrainAcc 0.9148	ValidAcc 0.9065	TestAcc 0.7521
    Epoch 579:	Loss 0.32570	TrainAcc 0.9154	ValidAcc 0.9043	TestAcc 0.7515
    Epoch 589:	Loss 0.32524	TrainAcc 0.9154	ValidAcc 0.9043	TestAcc 0.7510
    Epoch 599:	Loss 0.32483	TrainAcc 0.9154	ValidAcc 0.9051	TestAcc 0.7518
    Epoch 609:	Loss 0.32398	TrainAcc 0.9159	ValidAcc 0.9073	TestAcc 0.7530
    Epoch 619:	Loss 0.32262	TrainAcc 0.9160	ValidAcc 0.9049	TestAcc 0.7526
    Epoch 629:	Loss 0.32140	TrainAcc 0.9157	ValidAcc 0.9048	TestAcc 0.7524
    Epoch 639:	Loss 0.32033	TrainAcc 0.9168	ValidAcc 0.9058	TestAcc 0.7511
    Epoch 649:	Loss 0.32070	TrainAcc 0.9165	ValidAcc 0.9068	TestAcc 0.7509
    Epoch 659:	Loss 0.32024	TrainAcc 0.9160	ValidAcc 0.9064	TestAcc 0.7506
    Epoch 669:	Loss 0.31907	TrainAcc 0.9170	ValidAcc 0.9084	TestAcc 0.7523
    Epoch 679:	Loss 0.31763	TrainAcc 0.9169	ValidAcc 0.9066	TestAcc 0.7528
    Epoch 689:	Loss 0.31933	TrainAcc 0.9158	ValidAcc 0.9063	TestAcc 0.7530
    Epoch 699:	Loss 0.31806	TrainAcc 0.9164	ValidAcc 0.9060	TestAcc 0.7538
    Epoch 709:	Loss 0.31657	TrainAcc 0.9169	ValidAcc 0.9063	TestAcc 0.7545
    Epoch 719:	Loss 0.31555	TrainAcc 0.9172	ValidAcc 0.9062	TestAcc 0.7517
    Epoch 729:	Loss 0.31575	TrainAcc 0.9173	ValidAcc 0.9065	TestAcc 0.7509
    Epoch 739:	Loss 0.31541	TrainAcc 0.9174	ValidAcc 0.9062	TestAcc 0.7523
    Epoch 749:	Loss 0.31330	TrainAcc 0.9182	ValidAcc 0.9073	TestAcc 0.7524
    Epoch 759:	Loss 0.31355	TrainAcc 0.9176	ValidAcc 0.9068	TestAcc 0.7511
    Epoch 769:	Loss 0.31220	TrainAcc 0.9186	ValidAcc 0.9083	TestAcc 0.7502
    Epoch 779:	Loss 0.31237	TrainAcc 0.9186	ValidAcc 0.9062	TestAcc 0.7511
    Epoch 789:	Loss 0.31107	TrainAcc 0.9186	ValidAcc 0.9065	TestAcc 0.7527
    Epoch 799:	Loss 0.31217	TrainAcc 0.9181	ValidAcc 0.9077	TestAcc 0.7503
    Epoch 809:	Loss 0.31142	TrainAcc 0.9183	ValidAcc 0.9077	TestAcc 0.7522
    Epoch 819:	Loss 0.31092	TrainAcc 0.9180	ValidAcc 0.9073	TestAcc 0.7524
    Epoch 829:	Loss 0.31021	TrainAcc 0.9186	ValidAcc 0.9074	TestAcc 0.7510
    Epoch 839:	Loss 0.30916	TrainAcc 0.9190	ValidAcc 0.9087	TestAcc 0.7519
    Epoch 849:	Loss 0.30808	TrainAcc 0.9186	ValidAcc 0.9061	TestAcc 0.7532
    Epoch 859:	Loss 0.30794	TrainAcc 0.9192	ValidAcc 0.9073	TestAcc 0.7512
    Epoch 869:	Loss 0.30786	TrainAcc 0.9192	ValidAcc 0.9076	TestAcc 0.7533
    Epoch 879:	Loss 0.30762	TrainAcc 0.9195	ValidAcc 0.9070	TestAcc 0.7539
    Epoch 889:	Loss 0.30635	TrainAcc 0.9192	ValidAcc 0.9087	TestAcc 0.7533
    Epoch 899:	Loss 0.30610	TrainAcc 0.9196	ValidAcc 0.9088	TestAcc 0.7529
    Epoch 909:	Loss 0.30562	TrainAcc 0.9188	ValidAcc 0.9093	TestAcc 0.7530
    Epoch 919:	Loss 0.30566	TrainAcc 0.9197	ValidAcc 0.9079	TestAcc 0.7530
    Epoch 929:	Loss 0.30650	TrainAcc 0.9191	ValidAcc 0.9078	TestAcc 0.7511
    Epoch 939:	Loss 0.30527	TrainAcc 0.9192	ValidAcc 0.9077	TestAcc 0.7502
    Epoch 949:	Loss 0.30614	TrainAcc 0.9191	ValidAcc 0.9083	TestAcc 0.7498
    Epoch 959:	Loss 0.30454	TrainAcc 0.9192	ValidAcc 0.9090	TestAcc 0.7515
    Epoch 969:	Loss 0.30359	TrainAcc 0.9200	ValidAcc 0.9085	TestAcc 0.7500
    Epoch 979:	Loss 0.30270	TrainAcc 0.9205	ValidAcc 0.9084	TestAcc 0.7511
    Epoch 989:	Loss 0.30295	TrainAcc 0.9201	ValidAcc 0.9076	TestAcc 0.7508
    Epoch 999:	Loss 0.30232	TrainAcc 0.9195	ValidAcc 0.9088	TestAcc 0.7508
    Epoch 1009:	Loss 0.30129	TrainAcc 0.9209	ValidAcc 0.9082	TestAcc 0.7506
    Epoch 1019:	Loss 0.30176	TrainAcc 0.9198	ValidAcc 0.9085	TestAcc 0.7526
    Epoch 1029:	Loss 0.30041	TrainAcc 0.9206	ValidAcc 0.9085	TestAcc 0.7521
    Epoch 1039:	Loss 0.30247	TrainAcc 0.9200	ValidAcc 0.9083	TestAcc 0.7517
    Epoch 1049:	Loss 0.30110	TrainAcc 0.9206	ValidAcc 0.9078	TestAcc 0.7527
    Epoch 1059:	Loss 0.30139	TrainAcc 0.9207	ValidAcc 0.9083	TestAcc 0.7511
    Epoch 1069:	Loss 0.30002	TrainAcc 0.9202	ValidAcc 0.9093	TestAcc 0.7521
    Epoch 1079:	Loss 0.29871	TrainAcc 0.9209	ValidAcc 0.9084	TestAcc 0.7515
    Epoch 1089:	Loss 0.29870	TrainAcc 0.9211	ValidAcc 0.9091	TestAcc 0.7521
    Epoch 1099:	Loss 0.29849	TrainAcc 0.9212	ValidAcc 0.9082	TestAcc 0.7521
    Epoch 1109:	Loss 0.29873	TrainAcc 0.9206	ValidAcc 0.9097	TestAcc 0.7514
    Epoch 1119:	Loss 0.29832	TrainAcc 0.9214	ValidAcc 0.9092	TestAcc 0.7507
    Epoch 1129:	Loss 0.29714	TrainAcc 0.9210	ValidAcc 0.9091	TestAcc 0.7505
    Epoch 1139:	Loss 0.29797	TrainAcc 0.9209	ValidAcc 0.9095	TestAcc 0.7487
    Epoch 1149:	Loss 0.29750	TrainAcc 0.9213	ValidAcc 0.9086	TestAcc 0.7521
    Epoch 1159:	Loss 0.29911	TrainAcc 0.9199	ValidAcc 0.9086	TestAcc 0.7521
    Epoch 1169:	Loss 0.29671	TrainAcc 0.9220	ValidAcc 0.9098	TestAcc 0.7536
    Epoch 1179:	Loss 0.29692	TrainAcc 0.9216	ValidAcc 0.9091	TestAcc 0.7513
    Epoch 1189:	Loss 0.29565	TrainAcc 0.9216	ValidAcc 0.9106	TestAcc 0.7516
    Epoch 1199:	Loss 0.29559	TrainAcc 0.9216	ValidAcc 0.9100	TestAcc 0.7523
    Epoch 1209:	Loss 0.29496	TrainAcc 0.9216	ValidAcc 0.9086	TestAcc 0.7518
    Epoch 1219:	Loss 0.29515	TrainAcc 0.9218	ValidAcc 0.9082	TestAcc 0.7491
    Epoch 1229:	Loss 0.29433	TrainAcc 0.9214	ValidAcc 0.9091	TestAcc 0.7510
    Epoch 1239:	Loss 0.29401	TrainAcc 0.9218	ValidAcc 0.9097	TestAcc 0.7520
    Epoch 1249:	Loss 0.29475	TrainAcc 0.9218	ValidAcc 0.9085	TestAcc 0.7507
    Epoch 1259:	Loss 0.29468	TrainAcc 0.9220	ValidAcc 0.9079	TestAcc 0.7493
    Epoch 1269:	Loss 0.29384	TrainAcc 0.9221	ValidAcc 0.9096	TestAcc 0.7503
    Epoch 1279:	Loss 0.29424	TrainAcc 0.9223	ValidAcc 0.9097	TestAcc 0.7508
    Epoch 1289:	Loss 0.29250	TrainAcc 0.9224	ValidAcc 0.9093	TestAcc 0.7510
    Epoch 1299:	Loss 0.29222	TrainAcc 0.9224	ValidAcc 0.9094	TestAcc 0.7518
    Epoch 1309:	Loss 0.29180	TrainAcc 0.9227	ValidAcc 0.9097	TestAcc 0.7502
    Epoch 1319:	Loss 0.29279	TrainAcc 0.9220	ValidAcc 0.9083	TestAcc 0.7511
    Epoch 1329:	Loss 0.29199	TrainAcc 0.9219	ValidAcc 0.9092	TestAcc 0.7513
    Epoch 1339:	Loss 0.29109	TrainAcc 0.9227	ValidAcc 0.9095	TestAcc 0.7514
    Epoch 1349:	Loss 0.29163	TrainAcc 0.9222	ValidAcc 0.9095	TestAcc 0.7509
    Epoch 1359:	Loss 0.29282	TrainAcc 0.9224	ValidAcc 0.9098	TestAcc 0.7509
    Epoch 1369:	Loss 0.29090	TrainAcc 0.9224	ValidAcc 0.9105	TestAcc 0.7506
    Epoch 1379:	Loss 0.28990	TrainAcc 0.9231	ValidAcc 0.9096	TestAcc 0.7512
    Epoch 1389:	Loss 0.29011	TrainAcc 0.9228	ValidAcc 0.9108	TestAcc 0.7517
    Epoch 1399:	Loss 0.29031	TrainAcc 0.9222	ValidAcc 0.9084	TestAcc 0.7498
    Epoch 1409:	Loss 0.29047	TrainAcc 0.9221	ValidAcc 0.9089	TestAcc 0.7514
    Epoch 1419:	Loss 0.28968	TrainAcc 0.9225	ValidAcc 0.9105	TestAcc 0.7489
    Epoch 1429:	Loss 0.28944	TrainAcc 0.9225	ValidAcc 0.9094	TestAcc 0.7530
    Epoch 1439:	Loss 0.28960	TrainAcc 0.9223	ValidAcc 0.9087	TestAcc 0.7522
    Epoch 1449:	Loss 0.28980	TrainAcc 0.9229	ValidAcc 0.9094	TestAcc 0.7480
    Epoch 1459:	Loss 0.28969	TrainAcc 0.9229	ValidAcc 0.9087	TestAcc 0.7514
    Epoch 1469:	Loss 0.29002	TrainAcc 0.9230	ValidAcc 0.9098	TestAcc 0.7493
    Epoch 1479:	Loss 0.28970	TrainAcc 0.9232	ValidAcc 0.9080	TestAcc 0.7481
    Epoch 1489:	Loss 0.28847	TrainAcc 0.9230	ValidAcc 0.9085	TestAcc 0.7507
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 11.313 GBps
Node 2, Layer-level comm throughput (act): 11.059 GBps
Node 2, Layer-level comm throughput (grad): -nan GBps
Node 1, Layer-level comm throughput (grad): 11.307 GBps
Node 0, Layer-level comm throughput (grad): 11.230 GBps
    Epoch 1499:	Loss 0.28774	TrainAcc 0.9229	ValidAcc 0.9088	TestAcc 0.7496
Node 0, compression time: 3.560s, compression size: 875.841GB, throughput: 246.041GBps
Node 0, decompression time: 20.457s, compression size: 875.841GB, throughput: 42.814GBps
Node 0, pure compute time: 142.503 s, total compute time: 166.519 s
Node 0, wait_for_task_time: 63.630 s, wait_for_other_gpus_time: 0.007 s
------------------------node id 0,  per-epoch time: 0.161812 s---------------
Node 2, compression time: 5.418s, compression size: 875.841GB, throughput: 161.667GBps
Node 2, decompression time: 16.944s, compression size: 875.841GB, throughput: 51.690GBps
Node 2, pure compute time: 135.197 s, total compute time: 157.558 s
Node 2, wait_for_task_time: 28.239 s, wait_for_other_gpus_time: 0.018 s
------------------------node id 2,  per-epoch time: 0.161812 s---------------
Node 1, compression time: 8.797s, compression size: 1751.682GB, throughput: 199.117GBps
Node 1, decompression time: 50.739s, compression size: 1751.682GB, throughput: 34.523GBps
Node 1, pure compute time: 119.881 s, total compute time: 179.418 s
Node 1, wait_for_task_time: 37.770 s, wait_for_other_gpus_time: 0.013 s
------------------------node id 1,  per-epoch time: 0.161812 s---------------
************ Profiling Results ************
	Bubble: 36.986973 (s) (15.23 percentage)
	Compute: 181.467125 (s) (74.70 percentage)
	GradSync: 1.749925 (s) (0.72 percentage)
	GraphComm: 0.066488 (s) (0.03 percentage)
	Imbalance: 14.507891 (s) (5.97 percentage)
	LayerComm: 8.138233 (s) (3.35 percentage)
	Layer-level communication (cluster-wide, per epoch): 1.114 GB
Highest valid_acc: 0.9108
Target test_acc: 0.7517
Epoch to reach the target acc: 1390
[MPI Rank 2] Success 
[MPI Rank 0] Success 
[MPI Rank 1] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g000.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.893 seconds.
Building the CSC structure...
        It takes 1.857 seconds.
Building the Feature Vector...
        It takes 0.590 seconds.
Building the Label Vector...
        It takes 0.311 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.000 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.4252	ValidAcc 0.4316	TestAcc 0.3610
Version 1	TrainAcc 0.6714	ValidAcc 0.6637	TestAcc 0.5083
Version 2	TrainAcc 0.7765	ValidAcc 0.7743	TestAcc 0.5979
Version 3	TrainAcc 0.8311	ValidAcc 0.8263	TestAcc 0.6438
Version 4	TrainAcc 0.8539	ValidAcc 0.8494	TestAcc 0.6747
Version 5	TrainAcc 0.8668	ValidAcc 0.8636	TestAcc 0.6970
Version 6	TrainAcc 0.8738	ValidAcc 0.8712	TestAcc 0.7074
Version 7	TrainAcc 0.8802	ValidAcc 0.8760	TestAcc 0.7113
Version 8	TrainAcc 0.8826	ValidAcc 0.8789	TestAcc 0.7186
Version 9	TrainAcc 0.8861	ValidAcc 0.8817	TestAcc 0.7278
Version 10	TrainAcc 0.8885	ValidAcc 0.8836	TestAcc 0.7330
Version 11	TrainAcc 0.8907	ValidAcc 0.8853	TestAcc 0.7399
Version 12	TrainAcc 0.8927	ValidAcc 0.8875	TestAcc 0.7455
Version 13	TrainAcc 0.8936	ValidAcc 0.8882	TestAcc 0.7460
Version 14	TrainAcc 0.8952	ValidAcc 0.8905	TestAcc 0.7500
Version 15	TrainAcc 0.8967	ValidAcc 0.8913	TestAcc 0.7505
Version 16	TrainAcc 0.8981	ValidAcc 0.8933	TestAcc 0.7515
Version 17	TrainAcc 0.8993	ValidAcc 0.8925	TestAcc 0.7533
Version 18	TrainAcc 0.9010	ValidAcc 0.8952	TestAcc 0.7567
Version 19	TrainAcc 0.9022	ValidAcc 0.8957	TestAcc 0.7561
Version 20	TrainAcc 0.9030	ValidAcc 0.8966	TestAcc 0.7580
Version 21	TrainAcc 0.9036	ValidAcc 0.8973	TestAcc 0.7590
Version 22	TrainAcc 0.9048	ValidAcc 0.8981	TestAcc 0.7608
Version 23	TrainAcc 0.9059	ValidAcc 0.8998	TestAcc 0.7624
Version 24	TrainAcc 0.9063	ValidAcc 0.9000	TestAcc 0.7618
Version 25	TrainAcc 0.9069	ValidAcc 0.9000	TestAcc 0.7599
Version 26	TrainAcc 0.9066	ValidAcc 0.9007	TestAcc 0.7655
Version 27	TrainAcc 0.9077	ValidAcc 0.9006	TestAcc 0.7647
Version 28	TrainAcc 0.9082	ValidAcc 0.9009	TestAcc 0.7671
Version 29	TrainAcc 0.9091	ValidAcc 0.9019	TestAcc 0.7659
Version 30	TrainAcc 0.9092	ValidAcc 0.9020	TestAcc 0.7672
Version 31	TrainAcc 0.9099	ValidAcc 0.9019	TestAcc 0.7673
Version 32	TrainAcc 0.9106	ValidAcc 0.9028	TestAcc 0.7674
Version 33	TrainAcc 0.9111	ValidAcc 0.9032	TestAcc 0.7679
Version 34	TrainAcc 0.9114	ValidAcc 0.9034	TestAcc 0.7675
Version 35	TrainAcc 0.9116	ValidAcc 0.9041	TestAcc 0.7677
Version 36	TrainAcc 0.9119	ValidAcc 0.9037	TestAcc 0.7693
Version 37	TrainAcc 0.9120	ValidAcc 0.9039	TestAcc 0.7719
Version 38	TrainAcc 0.9125	ValidAcc 0.9043	TestAcc 0.7714
Version 39	TrainAcc 0.9121	ValidAcc 0.9042	TestAcc 0.7708
Version 40	TrainAcc 0.9129	ValidAcc 0.9047	TestAcc 0.7677
Version 41	TrainAcc 0.9133	ValidAcc 0.9050	TestAcc 0.7702
Version 42	TrainAcc 0.9132	ValidAcc 0.9052	TestAcc 0.7708
Version 43	TrainAcc 0.9138	ValidAcc 0.9054	TestAcc 0.7712
Version 44	TrainAcc 0.9140	ValidAcc 0.9059	TestAcc 0.7733
Version 45	TrainAcc 0.9148	ValidAcc 0.9061	TestAcc 0.7707
Version 46	TrainAcc 0.9147	ValidAcc 0.9061	TestAcc 0.7720
Version 47	TrainAcc 0.9146	ValidAcc 0.9060	TestAcc 0.7722
Version 48	TrainAcc 0.9149	ValidAcc 0.9062	TestAcc 0.7714
Version 49	TrainAcc 0.9156	ValidAcc 0.9072	TestAcc 0.7720
Version 50	TrainAcc 0.9160	ValidAcc 0.9073	TestAcc 0.7712
Version 51	TrainAcc 0.9160	ValidAcc 0.9068	TestAcc 0.7697
Version 52	TrainAcc 0.9159	ValidAcc 0.9080	TestAcc 0.7718
Version 53	TrainAcc 0.9171	ValidAcc 0.9085	TestAcc 0.7715
Version 54	TrainAcc 0.9160	ValidAcc 0.9072	TestAcc 0.7707
Version 55	TrainAcc 0.9158	ValidAcc 0.9072	TestAcc 0.7716
Version 56	TrainAcc 0.9163	ValidAcc 0.9079	TestAcc 0.7697
Version 57	TrainAcc 0.9166	ValidAcc 0.9078	TestAcc 0.7714
Version 58	TrainAcc 0.9168	ValidAcc 0.9079	TestAcc 0.7721
Version 59	TrainAcc 0.9173	ValidAcc 0.9080	TestAcc 0.7714
Version 60	TrainAcc 0.9175	ValidAcc 0.9079	TestAcc 0.7711
Version 61	TrainAcc 0.9183	ValidAcc 0.9091	TestAcc 0.7723
Version 62	TrainAcc 0.9183	ValidAcc 0.9096	TestAcc 0.7703
Version 63	TrainAcc 0.9187	ValidAcc 0.9089	TestAcc 0.7696
Version 64	TrainAcc 0.9177	ValidAcc 0.9086	TestAcc 0.7712
Version 65	TrainAcc 0.9186	ValidAcc 0.9089	TestAcc 0.7726
Version 66	TrainAcc 0.9179	ValidAcc 0.9082	TestAcc 0.7732
Version 67	TrainAcc 0.9182	ValidAcc 0.9095	TestAcc 0.7722
Version 68	TrainAcc 0.9183	ValidAcc 0.9094	TestAcc 0.7734
Version 69	TrainAcc 0.9187	ValidAcc 0.9094	TestAcc 0.7729
Version 70	TrainAcc 0.9187	ValidAcc 0.9094	TestAcc 0.7714
Version 71	TrainAcc 0.9188	ValidAcc 0.9093	TestAcc 0.7692
Version 72	TrainAcc 0.9191	ValidAcc 0.9092	TestAcc 0.7706
Version 73	TrainAcc 0.9192	ValidAcc 0.9092	TestAcc 0.7714
Version 74	TrainAcc 0.9196	ValidAcc 0.9104	TestAcc 0.7706
Version 75	TrainAcc 0.9198	ValidAcc 0.9100	TestAcc 0.7703
Version 76	TrainAcc 0.9202	ValidAcc 0.9106	TestAcc 0.7711
Version 77	TrainAcc 0.9208	ValidAcc 0.9094	TestAcc 0.7710
Version 78	TrainAcc 0.9200	ValidAcc 0.9099	TestAcc 0.7729
Version 79	TrainAcc 0.9206	ValidAcc 0.9104	TestAcc 0.7719
Version 80	TrainAcc 0.9204	ValidAcc 0.9104	TestAcc 0.7710
Version 81	TrainAcc 0.9207	ValidAcc 0.9102	TestAcc 0.7734
Version 82	TrainAcc 0.9210	ValidAcc 0.9098	TestAcc 0.7725
Version 83	TrainAcc 0.9211	ValidAcc 0.9109	TestAcc 0.7707
Version 84	TrainAcc 0.9210	ValidAcc 0.9111	TestAcc 0.7726
Version 85	TrainAcc 0.9213	ValidAcc 0.9110	TestAcc 0.7718
Version 86	TrainAcc 0.9210	ValidAcc 0.9103	TestAcc 0.7721
Version 87	TrainAcc 0.9211	ValidAcc 0.9110	TestAcc 0.7723
Version 88	TrainAcc 0.9212	ValidAcc 0.9103	TestAcc 0.7728
Version 89	TrainAcc 0.9206	ValidAcc 0.9103	TestAcc 0.7715
Version 90	TrainAcc 0.9213	ValidAcc 0.9107	TestAcc 0.7696
Version 91	TrainAcc 0.9214	ValidAcc 0.9107	TestAcc 0.7700
Version 92	TrainAcc 0.9219	ValidAcc 0.9109	TestAcc 0.7702
Version 93	TrainAcc 0.9217	ValidAcc 0.9115	TestAcc 0.7708
Version 94	TrainAcc 0.9213	ValidAcc 0.9102	TestAcc 0.7711
Version 95	TrainAcc 0.9215	ValidAcc 0.9108	TestAcc 0.7742
Version 96	TrainAcc 0.9218	ValidAcc 0.9105	TestAcc 0.7698
Version 97	TrainAcc 0.9217	ValidAcc 0.9113	TestAcc 0.7723
Version 98	TrainAcc 0.9222	ValidAcc 0.9108	TestAcc 0.7682
Version 99	TrainAcc 0.9221	ValidAcc 0.9112	TestAcc 0.7731
Version 100	TrainAcc 0.9225	ValidAcc 0.9110	TestAcc 0.7694
Version 101	TrainAcc 0.9226	ValidAcc 0.9113	TestAcc 0.7728
Version 102	TrainAcc 0.9226	ValidAcc 0.9116	TestAcc 0.7717
Version 103	TrainAcc 0.9226	ValidAcc 0.9102	TestAcc 0.7727
Version 104	TrainAcc 0.9218	ValidAcc 0.9108	TestAcc 0.7722
Version 105	TrainAcc 0.9231	ValidAcc 0.9120	TestAcc 0.7738
Version 106	TrainAcc 0.9223	ValidAcc 0.9111	TestAcc 0.7728
Version 107	TrainAcc 0.9232	ValidAcc 0.9117	TestAcc 0.7716
Version 108	TrainAcc 0.9224	ValidAcc 0.9101	TestAcc 0.7730
Version 109	TrainAcc 0.9228	ValidAcc 0.9112	TestAcc 0.7735
Version 110	TrainAcc 0.9229	ValidAcc 0.9113	TestAcc 0.7721
Version 111	TrainAcc 0.9232	ValidAcc 0.9117	TestAcc 0.7706
Version 112	TrainAcc 0.9232	ValidAcc 0.9113	TestAcc 0.7707
Version 113	TrainAcc 0.9236	ValidAcc 0.9119	TestAcc 0.7719
Version 114	TrainAcc 0.9233	ValidAcc 0.9121	TestAcc 0.7727
Version 115	TrainAcc 0.9230	ValidAcc 0.9116	TestAcc 0.7735
Version 116	TrainAcc 0.9228	ValidAcc 0.9111	TestAcc 0.7746
Version 117	TrainAcc 0.9235	ValidAcc 0.9114	TestAcc 0.7713
Version 118	TrainAcc 0.9238	ValidAcc 0.9126	TestAcc 0.7712
Version 119	TrainAcc 0.9230	ValidAcc 0.9110	TestAcc 0.7693
Version 120	TrainAcc 0.9236	ValidAcc 0.9122	TestAcc 0.7741
Version 121	TrainAcc 0.9236	ValidAcc 0.9123	TestAcc 0.7725
Version 122	TrainAcc 0.9242	ValidAcc 0.9119	TestAcc 0.7719
Version 123	TrainAcc 0.9244	ValidAcc 0.9124	TestAcc 0.7715
Version 124	TrainAcc 0.9239	ValidAcc 0.9114	TestAcc 0.7728
Version 125	TrainAcc 0.9234	ValidAcc 0.9111	TestAcc 0.7709
Version 126	TrainAcc 0.9238	ValidAcc 0.9115	TestAcc 0.7707
Version 127	TrainAcc 0.9244	ValidAcc 0.9129	TestAcc 0.7710
Version 128	TrainAcc 0.9245	ValidAcc 0.9117	TestAcc 0.7712
Version 129	TrainAcc 0.9242	ValidAcc 0.9123	TestAcc 0.7712
Version 130	TrainAcc 0.9246	ValidAcc 0.9126	TestAcc 0.7722
Version 131	TrainAcc 0.9245	ValidAcc 0.9127	TestAcc 0.7735
Version 132	TrainAcc 0.9245	ValidAcc 0.9125	TestAcc 0.7711
Version 133	TrainAcc 0.9244	ValidAcc 0.9117	TestAcc 0.7717
Version 134	TrainAcc 0.9245	ValidAcc 0.9121	TestAcc 0.7726
Version 135	TrainAcc 0.9244	ValidAcc 0.9120	TestAcc 0.7717
Version 136	TrainAcc 0.9248	ValidAcc 0.9126	TestAcc 0.7719
Version 137	TrainAcc 0.9249	ValidAcc 0.9129	TestAcc 0.7723
Version 138	TrainAcc 0.9246	ValidAcc 0.9123	TestAcc 0.7698
Version 139	TrainAcc 0.9247	ValidAcc 0.9123	TestAcc 0.7710
Version 140	TrainAcc 0.9249	ValidAcc 0.9125	TestAcc 0.7721
Version 141	TrainAcc 0.9247	ValidAcc 0.9121	TestAcc 0.7709
Version 142	TrainAcc 0.9251	ValidAcc 0.9134	TestAcc 0.7732
Version 143	TrainAcc 0.9246	ValidAcc 0.9111	TestAcc 0.7684
Version 144	TrainAcc 0.9242	ValidAcc 0.9119	TestAcc 0.7699
Version 145	TrainAcc 0.9255	ValidAcc 0.9123	TestAcc 0.7696
Version 146	TrainAcc 0.9250	ValidAcc 0.9124	TestAcc 0.7697
Version 147	TrainAcc 0.9254	ValidAcc 0.9128	TestAcc 0.7706
Version 148	TrainAcc 0.9252	ValidAcc 0.9116	TestAcc 0.7730
Version 149	TrainAcc 0.9253	ValidAcc 0.9119	TestAcc 0.7714
Version 142 achieved the highest validation accuracy 0.9134 (test accuracy: 0.7732)
