Tue Sep 19 17:47:00 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    On   | 00000000:01:00.0 Off |                  Off |
| 30%   40C    P8    18W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    On   | 00000000:25:00.0 Off |                  Off |
| 30%   41C    P8    19W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A5000    On   | 00000000:81:00.0 Off |                  Off |
| 30%   39C    P8    14W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A5000    On   | 00000000:C1:00.0 Off |                  Off |
| 30%   38C    P8    17W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
[ 20%] Built target context
[ 20%] Built target core
[ 70%] Built target cudahelp
[ 77%] Built target OSDI2023_MULTI_NODES_resgcn
[ 90%] Built target OSDI2023_MULTI_NODES_resgcn_plus
[ 90%] Built target estimate_comm_volume
[ 90%] Built target OSDI2023_MULTI_NODES_graphsage
[ 90%] Built target OSDI2023_MULTI_NODES_gcn
[100%] Built target OSDI2023_MULTI_NODES_gcnii
Running experiments...
Starting GNN Training...
Initializing the runtime environment
Starting GNN Training...
Initializing the runtime environment
Starting GNN Training...
Initializing the runtime environment
Starting GNN Training...
Initializing the runtime environment
DONE MPI INIT
DONE MPI INIT
Initialized node 1 on machine gnerv1
DONE MPI INITInitialized node 0 on machine gnerv1
DONE MPI INIT
Initialized node 2 on machine gnerv1

Initialized node 3 on machine gnerv1
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.032 seconds.
Building the CSC structure...
        It takes 0.032 seconds.
Building the CSC structure...
        It takes 0.032 seconds.
Building the CSC structure...
        It takes 0.032 seconds.
Building the CSC structure...
        It takes 0.002 seconds.
        It takes 0.002 seconds.
        It takes 0.002 seconds.
        It takes 0.002 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.112 seconds.
        It takes 0.112 seconds.
        It takes 0.112 seconds.
        It takes 0.112 seconds.
Building the Label Vector...
Building the Label Vector...
Building the Label Vector...
Building the Label Vector...
        It takes 0.008 seconds.
        It takes 0.009 seconds.
        It takes 0.009 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/weighted_shuffled_partitioned_graphs/pubmed/32_parts
The number of GCNII layers: 32
The number of hidden units: 100
The number of training epoches: 100
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 1
GCN hyper-parameter alpha: 0.100000
GCN hyper-parameter lambda: 0.500000
Number of classes: 3
Number of feature dimensions: 500
Number of vertices: 19717
Number of GPUs: 4
        It takes 0.009 seconds.
GPU 0, layer [0, 9)
GPU 1, layer [9, 17)
GPU 2, layer [17, 25)
GPU 3, layer [25, 33)
GPU 0, layer [0, 9)
GPU 1, layer [9, 17)
GPU 2, layer [17, 25)
GPU 3, layer [25, 33)
train nodes 60, valid nodes 500, test nodes 1000
GPU 0, layer [0, 9)
GPU 1, layer [9, 17)
GPU 2, layer [17, 25)
GPU 3, layer [25, 33)
Chunks (number of global chunks: 32): 0-[0, 617) 1-[617, 1213) 2-[1213, 1827) 3-[1827, 2464) 4-[2464, 3089) 5-[3089, 3719) 6-[3719, 4332) 7-[4332, 4956) 8-[4956, 5572) ... 31-[19096, 19717)
19717, 108365, 108365
19717, 108365, 108365
Number of vertices per chunk: 617
Number of vertices per chunk: 617
19717, 108365, 108365
Number of vertices per chunk: 617
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
***** Start profiling the layer-level communication performance *******
csr in-out ready !Start Cost Model Initialization...
GPU 0, layer [0, 9)
GPU 1, layer [9, 17)
GPU 2, layer [17, 25)
GPU 3, layer [25, 33)
19717, 108365, 108365
Number of vertices per chunk: 617
csr in-out ready !Start Cost Model Initialization...
The layer-level communication performance: 117.230 Gbps (per GPU), 468.919 Gbps (aggregated)
The layer-level communication performance: 117.079 Gbps (per GPU), 468.317 Gbps (aggregated)
The layer-level communication performance: 116.914 Gbps (per GPU), 467.656 Gbps (aggregated)
The layer-level communication performance: 116.909 Gbps (per GPU), 467.637 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The graph-level communication performance (supernode = 2): 160.726 Gbps (per GPU), 642.904 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.680 Gbps (per GPU), 642.719 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.732 Gbps (per GPU), 642.928 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.677 Gbps (per GPU), 642.707 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
The graph-level communication performance (supernode = 4): 103.565 Gbps (per GPU), 414.259 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 103.566 Gbps (per GPU), 414.262 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 103.543 Gbps (per GPU), 414.173 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 103.546 Gbps (per GPU), 414.184 Gbps (aggregated, cluster-wide)
 LType   LT0   LT1   LT2 Ratio  VSum  ESum
 chk_0  0.23ms  0.25ms  0.37ms  1.59  0.62K  0.00M
 chk_1  0.23ms  0.25ms  0.37ms  1.59  0.60K  0.00M
 chk_2  0.23ms  0.26ms  0.37ms  1.60  0.61K  0.00M
 chk_3  0.23ms  0.26ms  0.37ms  1.60  0.64K  0.00M
 chk_4  0.23ms  0.26ms  0.37ms  1.60  0.62K  0.00M
 chk_5  0.23ms  0.25ms  0.37ms  1.59  0.63K  0.00M
 chk_6  0.23ms  0.26ms  0.37ms  1.60  0.61K  0.00M
 chk_7  0.23ms  0.25ms  0.37ms  1.60  0.62K  0.00M
 chk_8  0.23ms  0.26ms  0.37ms  1.60  0.62K  0.00M
 chk_9  0.23ms  0.26ms  0.37ms  1.60  0.60K  0.00M
chk_10  0.36ms  0.26ms  0.37ms  1.44  0.61K  0.00M
chk_11  0.23ms  0.26ms  0.37ms  1.60  0.61K  0.00M
chk_12  0.24ms  0.26ms  0.37ms  1.58  0.62K  0.00M
chk_13  0.23ms  0.25ms  0.37ms  1.59  0.61K  0.00M
chk_14  0.23ms  0.26ms  0.38ms  1.60  0.62K  0.00M
chk_15  0.23ms  0.25ms  0.37ms  1.60  0.62K  0.00M
chk_16  0.23ms  0.25ms  0.37ms  1.59  0.60K  0.00M
chk_17  0.23ms  0.26ms  0.37ms  1.59  0.60K  0.00M
chk_18  0.23ms  0.25ms  0.37ms  1.60  0.62K  0.00M
chk_19  0.23ms  0.26ms  0.37ms  1.59  0.63K  0.00M
chk_20  0.23ms  0.26ms  0.37ms  1.61  0.61K  0.00M
chk_21  0.23ms  0.26ms  0.37ms  1.59  0.60K  0.00M
chk_22  0.23ms  0.26ms  0.37ms  1.58  0.60K  0.00M
chk_23  0.23ms  0.31ms  0.37ms  1.59  0.62K  0.00M
chk_24  0.24ms  0.25ms  0.37ms  1.58  0.62K  0.00M
chk_25  0.23ms  0.25ms  0.37ms  1.58  0.62K  0.00M
chk_26  0.24ms  0.25ms  0.37ms  1.58  0.62K  0.00M
chk_27  0.23ms  0.26ms  0.37ms  1.60  0.62K  0.00M
chk_28  0.23ms  0.25ms  0.37ms  1.58  0.62K  0.00M
chk_29  0.23ms  0.25ms  0.37ms  1.59  0.61K  0.00M
chk_30  0.23ms  0.25ms  0.37ms  1.59  0.62K  0.00M
chk_31  0.23ms  0.25ms  0.37ms  1.59  0.62K  0.00M
   Avg  0.24  0.26  0.37
   Max  0.36  0.31  0.38
   Min  0.23  0.25  0.37
 Ratio  1.54  1.23  1.02
   Var  0.00  0.00  0.00
Profiling takes 0.444 s
*** Node 0, starting model training...
Num Stages: 4 / 4
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the model-level partition [0, 62)
*** Node 0, constructing the helper classes...
Node 0, Local Vertex Begin: 0, Num Local Vertices: 19717
*** Node 1, starting model training...
Num Stages: 4 / 4
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the model-level partition [62, 118)
*** Node 1, constructing the helper classes...
Node 1, Local Vertex Begin: 0, Num Local Vertices: 19717
*** Node 3, starting model training...
Num Stages: 4 / 4
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [174, 233)
*** Node 3, constructing the helper classes...
*** Node 2, starting model training...
Num Stages: 4 / 4
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the model-level partition [118, 174)
*** Node 2, constructing the helper classes...
Node 2, Local Vertex Begin: 0, Num Local Vertices: 19717
Node 3, Local Vertex Begin: 0, Num Local Vertices: 19717
*** Node 3, setting up some other necessary information...
*** Node 1, setting up some other necessary information...
*** Node 0, setting up some other necessary information...
*** Node 2, setting up some other necessary information...
+++++++++ Node 2 initializing the weights for op[118, 174)...
+++++++++ Node 0 initializing the weights for op[0, 62)...
+++++++++ Node 3 initializing the weights for op[174, 233)...
+++++++++ Node 1 initializing the weights for op[62, 118)...
Node 0, discovering the vertices that will be sent across graph boundary...
The number of mirror vertices: 0
Node 0, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
Node 1, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
Node 2, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
Node 3, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
*** Node 0, starting task scheduling...
*** Node 1, starting task scheduling...
*** Node 2, starting task scheduling...
*** Node 3, starting task scheduling...



The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
	Epoch 1:	Loss 1.0974	TrainAcc 0.4167	ValidAcc 0.2520	TestAcc 0.2370	BestValid 0.2520
	Epoch 50:	Loss 0.8918	TrainAcc 0.8167	ValidAcc 0.6300	TestAcc 0.6190	BestValid 0.6300
	Epoch 100:	Loss 0.6792	TrainAcc 0.8667	ValidAcc 0.6920	TestAcc 0.6750	BestValid 0.6920
****** Epoch Time (Excluding Evaluation Cost): 0.108 s ******
****** Breakdown Analysis ******
Cluster-Wide Average, Bubble-Pipeline: 8.926 ms (Max: 9.294, Min: 8.410, Sum: 35.702)
Cluster-Wide Average, Compute: 83.362 ms (Max: 89.245, Min: 76.203, Sum: 333.447)
Cluster-Wide Average, Communication-Layer: 5.985 ms (Max: 6.392, Min: 5.535, Sum: 23.941)
Cluster-Wide Average, Bubble-Imbalance: 7.199 ms (Max: 14.114, Min: 1.772, Sum: 28.794)
Cluster-Wide Average, Communication-Graph: 1.203 ms (Max: 1.369, Min: 0.966, Sum: 4.813)
Cluster-Wide Average, Optimization: 0.185 ms (Max: 0.198, Min: 0.174, Sum: 0.742)
Cluster-Wide Average, Others: 0.873 ms (Max: 1.653, Min: 0.573, Sum: 3.490)
****** Breakdown Sum: 107.732 ms ******
Cluster-Wide Average, GPU Memory Consumption: 3.647 GB (Max: 4.460, Min: 3.350, Sum: 14.588)
Cluster-Wide Average, Graph-Level Communication Throughput: -nan Gbps (Max: -nan, Min: -nan, Sum: -nan)
Cluster-Wide Average, Layer-Level Communication Throughput: 31.067 Gbps (Max: 39.645, Min: 22.345, Sum: 124.267)
Layer-level communication (cluster-wide, per-epoch): 0.088 GB
Graph-level communication (cluster-wide, per-epoch): 0.000 GB
Weight-sync communication (cluster-wide, per-epoch): 0.000 GB
Total communication (cluster-wide, per-epoch): 0.088 GB
****** Accuracy Results ******
Highest valid_acc: 0.6920
Target test_acc: 0.6750
Epoch to reach the target acc: 99
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 3] Success 
[MPI Rank 2] Success 
