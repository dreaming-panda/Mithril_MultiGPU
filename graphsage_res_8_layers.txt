gnerv1
Wed Aug 23 21:13:08 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    On   | 00000000:01:00.0 Off |                  Off |
| 30%   32C    P8    25W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    On   | 00000000:25:00.0 Off |                  Off |
| 30%   30C    P8    24W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A5000    On   | 00000000:81:00.0 Off |                  Off |
| 30%   29C    P8    19W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A5000    On   | 00000000:C1:00.0 Off |                  Off |
| 30%   28C    P8    23W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
[  9%] Built target context
[ 30%] Built target core
[ 66%] Built target cudahelp
[ 83%] Built target estimate_comm_volume
[ 83%] Built target OSDI2023_MULTI_NODES_gcn_res
[ 83%] Built target OSDI2023_MULTI_NODES_gin
[ 83%] Built target OSDI2023_MULTI_NODES_gcnii
[ 83%] Built target OSDI2023_MULTI_NODES_graphsage_res
[ 83%] Built target OSDI2023_MULTI_NODES_gcn
[ 83%] Built target OSDI2023_MULTI_NODES_graphsage
Running experiments...
Initialized node 1 on machine gnerv1
Initialized node 3 on machine gnerv1
Initialized node 0 on machine gnerv1
Initialized node 2 on machine gnerv1
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 6.227 seconds.
Building the CSC structure...
        It takes 6.230 seconds.
Building the CSC structure...
        It takes 6.232 seconds.
Building the CSC structure...
        It takes 6.236 seconds.
Building the CSC structure...
        It takes 2.653 seconds.
        It takes 2.660 seconds.
        It takes 2.657 seconds.
        It takes 2.663 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.993 seconds.
Building the Label Vector...
        It takes 0.443 seconds.
Building the Label Vector...
        It takes 0.279 seconds.
Building the Label Vector...
        It takes 0.101 seconds.
        It takes 0.077 seconds.
        It takes 0.085 seconds.
        It takes 0.289 seconds.
Building the Label Vector...
        It takes 0.032 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/weighted_shuffled_partitioned_graphs/reddit/16_parts
The number of GCNII layers: 8
The number of hidden units: 384
The number of training epoches: 5000
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 1
Number of classes: 41
Number of feature dimensions: 602
Number of vertices: 232965
Number of GPUs: 4
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
train nodes 153431, valid nodes 23831, test nodes 55703
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
Chunks (number of global chunks: 16): 0-[0, 11535) 1-[11535, 24519) 2-[24519, 37414) 3-[37414, 51612) 4-[51612, 65245) 5-[65245, 83917) 6-[83917, 97464) 7-[97464, 115111) 8-[115111, 130823) ... 15-[222758, 232965)
232965, 114848857, 114848857
Number of vertices per chunk: 14561
232965, 114848857, 114848857
Number of vertices per chunk: 14561
232965, 114848857, 114848857
Number of vertices per chunk: 14561
232965, 114848857, 114848857
Number of vertices per chunk: 14561
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
***** Start profiling the layer-level communication performance *******
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
The layer-level communication performance: 116.210 Gbps (per GPU), 464.838 Gbps (aggregated)
The layer-level communication performance: 116.045 Gbps (per GPU), 464.178 Gbps (aggregated)
The layer-level communication performance: 115.914 Gbps (per GPU), 463.658 Gbps (aggregated)
The layer-level communication performance: 115.904 Gbps (per GPU), 463.617 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The graph-level communication performance (supernode = 2): 160.244 Gbps (per GPU), 640.975 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.293 Gbps (per GPU), 641.172 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.256 Gbps (per GPU), 641.025 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.195 Gbps (per GPU), 640.780 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
The graph-level communication performance (supernode = 4): 108.431 Gbps (per GPU), 433.725 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 108.432 Gbps (per GPU), 433.729 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 108.432 Gbps (per GPU), 433.729 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 108.433 Gbps (per GPU), 433.733 Gbps (aggregated, cluster-wide)
 LType   LT0   LT1   LT2 Ratio  VSum  ESum
 chk_0 21.36ms 19.46ms 19.81ms  1.10 11.54K  7.20M
 chk_1 22.66ms 20.54ms 21.15ms  1.10 12.98K  7.36M
 chk_2 22.30ms 20.23ms 20.84ms  1.10 12.89K  7.48M
 chk_3 22.56ms 20.25ms 20.78ms  1.11 14.20K  7.29M
 chk_4 22.14ms 20.04ms 20.51ms  1.10 13.63K  7.10M
 chk_5 23.49ms 20.60ms 21.37ms  1.14 18.67K  7.08M
 chk_6 22.16ms 20.00ms 20.57ms  1.11 13.55K  7.21M
 chk_7 23.41ms 20.49ms 21.25ms  1.14 17.65K  6.90M
 chk_8 22.77ms 20.58ms 21.06ms  1.11 15.71K  7.11M
 chk_9 21.79ms 19.28ms 19.99ms  1.13 14.32K  7.22M
chk_10 22.75ms 20.21ms 20.90ms  1.13 16.22K  7.08M
chk_11 22.27ms 19.97ms 20.49ms  1.12 12.83K  7.26M
chk_12 21.64ms 20.04ms 20.52ms  1.08 11.33K  7.30M
chk_13 22.90ms 20.63ms 21.17ms  1.11 15.01K  7.14M
chk_14 25.11ms 21.62ms 22.44ms  1.16 22.23K  6.67M
chk_15 20.82ms 19.18ms 19.44ms  1.09 10.21K  7.22M
   Avg 22.51 20.19 20.77
   Max 25.11 21.62 22.44
   Min 20.82 19.18 19.44
 Ratio  1.21  1.13  1.15
   Var  0.92  0.33  0.46
Profiling takes 11.380 s
*** Node 0, starting model training...
Num Stages: 4 / 4
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_ADD
*** Node 0 owns the model-level partition [0, 23)
*** Node 0, constructing the helper classes...
Node 0, Local Vertex Begin: 0, Num Local Vertices: 232965
*** Node 1, starting model training...
Num Stages: 4 / 4
Node 1, Pipeline Input Tensor: OPERATOR_ADD
Node 1, Pipeline Output Tensor: OPERATOR_ADD
*** Node 1 owns the model-level partition [23, 41)
*** Node 1, constructing the helper classes...
Node 1, Local Vertex Begin: 0, Num Local Vertices: 232965
*** Node 2, starting model training...
Num Stages: 4 / 4
Node 2, Pipeline Input Tensor: OPERATOR_ADD
Node 2, Pipeline Output Tensor: OPERATOR_ADD
*** Node 2 owns the model-level partition [41, 59)
*** Node 2, constructing the helper classes...
Node 2, Local Vertex Begin: 0, Num Local Vertices: 232965
*** Node 3, starting model training...
Num Stages: 4 / 4
Node 3, Pipeline Input Tensor: OPERATOR_ADD
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [59, 80)
*** Node 3, constructing the helper classes...
Node 3, Local Vertex Begin: 0, Num Local Vertices: 232965
*** Node 2, setting up some other necessary information...
*** Node 3, setting up some other necessary information...
*** Node 1, setting up some other necessary information...
*** Node 0, setting up some other necessary information...
+++++++++ Node 1 initializing the weights for op[23, 41)...
+++++++++ Node 2 initializing the weights for op[41, 59)...
+++++++++ Node 3 initializing the weights for op[59, 80)...
+++++++++ Node 0 initializing the weights for op[0, 23)...
Node 0, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be received across the graph boundary.
The number of mirror vertices: 0
Node 0, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
Node 2, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.001000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.001000000
	Epoch 1:	Loss 3.9765	TrainAcc 0.1218	ValidAcc 0.1127	TestAcc 0.1104	BestValid 0.1127
	Epoch 50:	Loss 0.4294	TrainAcc 0.9214	ValidAcc 0.9251	TestAcc 0.9244	BestValid 0.9251
	Epoch 100:	Loss 0.2453	TrainAcc 0.9516	ValidAcc 0.9525	TestAcc 0.9518	BestValid 0.9525
	Epoch 150:	Loss 0.2041	TrainAcc 0.9581	ValidAcc 0.9574	TestAcc 0.9573	BestValid 0.9574
	Epoch 200:	Loss 0.1825	TrainAcc 0.9620	ValidAcc 0.9599	TestAcc 0.9592	BestValid 0.9599
	Epoch 250:	Loss 0.1704	TrainAcc 0.9649	ValidAcc 0.9614	TestAcc 0.9605	BestValid 0.9614
	Epoch 300:	Loss 0.1588	TrainAcc 0.9675	ValidAcc 0.9631	TestAcc 0.9614	BestValid 0.9631
	Epoch 350:	Loss 0.1491	TrainAcc 0.9693	ValidAcc 0.9632	TestAcc 0.9622	BestValid 0.9632
	Epoch 400:	Loss 0.1403	TrainAcc 0.9711	ValidAcc 0.9641	TestAcc 0.9629	BestValid 0.9641
	Epoch 450:	Loss 0.1344	TrainAcc 0.9728	ValidAcc 0.9643	TestAcc 0.9629	BestValid 0.9643
	Epoch 500:	Loss 0.1288	TrainAcc 0.9748	ValidAcc 0.9650	TestAcc 0.9638	BestValid 0.9650
	Epoch 550:	Loss 0.1218	TrainAcc 0.9762	ValidAcc 0.9650	TestAcc 0.9646	BestValid 0.9650
	Epoch 600:	Loss 0.1171	TrainAcc 0.9774	ValidAcc 0.9659	TestAcc 0.9647	BestValid 0.9659
	Epoch 650:	Loss 0.1126	TrainAcc 0.9789	ValidAcc 0.9658	TestAcc 0.9649	BestValid 0.9659
	Epoch 700:	Loss 0.1065	TrainAcc 0.9799	ValidAcc 0.9658	TestAcc 0.9647	BestValid 0.9659
	Epoch 750:	Loss 0.1026	TrainAcc 0.9813	ValidAcc 0.9663	TestAcc 0.9648	BestValid 0.9663
	Epoch 800:	Loss 0.0986	TrainAcc 0.9828	ValidAcc 0.9668	TestAcc 0.9654	BestValid 0.9668
	Epoch 850:	Loss 0.0948	TrainAcc 0.9838	ValidAcc 0.9668	TestAcc 0.9654	BestValid 0.9668
	Epoch 900:	Loss 0.0893	TrainAcc 0.9849	ValidAcc 0.9675	TestAcc 0.9662	BestValid 0.9675
	Epoch 950:	Loss 0.0874	TrainAcc 0.9858	ValidAcc 0.9671	TestAcc 0.9660	BestValid 0.9675
	Epoch 1000:	Loss 0.0848	TrainAcc 0.9869	ValidAcc 0.9670	TestAcc 0.9659	BestValid 0.9675
	Epoch 1050:	Loss 0.0803	TrainAcc 0.9884	ValidAcc 0.9677	TestAcc 0.9662	BestValid 0.9677
	Epoch 1100:	Loss 0.0788	TrainAcc 0.9889	ValidAcc 0.9678	TestAcc 0.9662	BestValid 0.9678
	Epoch 1150:	Loss 0.0748	TrainAcc 0.9899	ValidAcc 0.9677	TestAcc 0.9662	BestValid 0.9678
	Epoch 1200:	Loss 0.0713	TrainAcc 0.9906	ValidAcc 0.9678	TestAcc 0.9663	BestValid 0.9678
	Epoch 1250:	Loss 0.0695	TrainAcc 0.9912	ValidAcc 0.9678	TestAcc 0.9662	BestValid 0.9678
	Epoch 1300:	Loss 0.0679	TrainAcc 0.9918	ValidAcc 0.9675	TestAcc 0.9659	BestValid 0.9678
	Epoch 1350:	Loss 0.0649	TrainAcc 0.9924	ValidAcc 0.9675	TestAcc 0.9659	BestValid 0.9678
	Epoch 1400:	Loss 0.0629	TrainAcc 0.9932	ValidAcc 0.9674	TestAcc 0.9659	BestValid 0.9678
	Epoch 1450:	Loss 0.0606	TrainAcc 0.9938	ValidAcc 0.9684	TestAcc 0.9664	BestValid 0.9684
	Epoch 1500:	Loss 0.0583	TrainAcc 0.9944	ValidAcc 0.9680	TestAcc 0.9662	BestValid 0.9684
	Epoch 1550:	Loss 0.0563	TrainAcc 0.9947	ValidAcc 0.9678	TestAcc 0.9661	BestValid 0.9684
	Epoch 1600:	Loss 0.0542	TrainAcc 0.9952	ValidAcc 0.9680	TestAcc 0.9664	BestValid 0.9684
	Epoch 1650:	Loss 0.0522	TrainAcc 0.9958	ValidAcc 0.9684	TestAcc 0.9666	BestValid 0.9684
	Epoch 1700:	Loss 0.0507	TrainAcc 0.9958	ValidAcc 0.9682	TestAcc 0.9661	BestValid 0.9684
	Epoch 1750:	Loss 0.0493	TrainAcc 0.9961	ValidAcc 0.9676	TestAcc 0.9665	BestValid 0.9684
	Epoch 1800:	Loss 0.0475	TrainAcc 0.9964	ValidAcc 0.9676	TestAcc 0.9662	BestValid 0.9684
	Epoch 1850:	Loss 0.0466	TrainAcc 0.9966	ValidAcc 0.9679	TestAcc 0.9661	BestValid 0.9684
	Epoch 1900:	Loss 0.0448	TrainAcc 0.9975	ValidAcc 0.9679	TestAcc 0.9666	BestValid 0.9684
	Epoch 1950:	Loss 0.0432	TrainAcc 0.9972	ValidAcc 0.9677	TestAcc 0.9662	BestValid 0.9684
	Epoch 2000:	Loss 0.0419	TrainAcc 0.9975	ValidAcc 0.9676	TestAcc 0.9662	BestValid 0.9684
	Epoch 2050:	Loss 0.0415	TrainAcc 0.9980	ValidAcc 0.9680	TestAcc 0.9666	BestValid 0.9684
	Epoch 2100:	Loss 0.0405	TrainAcc 0.9978	ValidAcc 0.9672	TestAcc 0.9661	BestValid 0.9684
	Epoch 2150:	Loss 0.0384	TrainAcc 0.9978	ValidAcc 0.9674	TestAcc 0.9659	BestValid 0.9684
	Epoch 2200:	Loss 0.0379	TrainAcc 0.9985	ValidAcc 0.9678	TestAcc 0.9668	BestValid 0.9684
	Epoch 2250:	Loss 0.0368	TrainAcc 0.9986	ValidAcc 0.9676	TestAcc 0.9664	BestValid 0.9684
	Epoch 2300:	Loss 0.0351	TrainAcc 0.9987	ValidAcc 0.9679	TestAcc 0.9666	BestValid 0.9684
	Epoch 2350:	Loss 0.0342	TrainAcc 0.9988	ValidAcc 0.9676	TestAcc 0.9668	BestValid 0.9684
	Epoch 2400:	Loss 0.0332	TrainAcc 0.9989	ValidAcc 0.9679	TestAcc 0.9668	BestValid 0.9684
	Epoch 2450:	Loss 0.0321	TrainAcc 0.9991	ValidAcc 0.9674	TestAcc 0.9670	BestValid 0.9684
	Epoch 2500:	Loss 0.0316	TrainAcc 0.9991	ValidAcc 0.9679	TestAcc 0.9665	BestValid 0.9684
	Epoch 2550:	Loss 0.0309	TrainAcc 0.9991	ValidAcc 0.9675	TestAcc 0.9662	BestValid 0.9684
	Epoch 2600:	Loss 0.0309	TrainAcc 0.9992	ValidAcc 0.9677	TestAcc 0.9665	BestValid 0.9684
	Epoch 2650:	Loss 0.0297	TrainAcc 0.9991	ValidAcc 0.9679	TestAcc 0.9666	BestValid 0.9684
	Epoch 2700:	Loss 0.0288	TrainAcc 0.9993	ValidAcc 0.9684	TestAcc 0.9668	BestValid 0.9684
	Epoch 2750:	Loss 0.0286	TrainAcc 0.9992	ValidAcc 0.9680	TestAcc 0.9664	BestValid 0.9684
	Epoch 2800:	Loss 0.0272	TrainAcc 0.9996	ValidAcc 0.9680	TestAcc 0.9666	BestValid 0.9684
	Epoch 2850:	Loss 0.0271	TrainAcc 0.9992	ValidAcc 0.9677	TestAcc 0.9663	BestValid 0.9684
	Epoch 2900:	Loss 0.0265	TrainAcc 0.9997	ValidAcc 0.9679	TestAcc 0.9675	BestValid 0.9684
	Epoch 2950:	Loss 0.0266	TrainAcc 0.9994	ValidAcc 0.9677	TestAcc 0.9666	BestValid 0.9684
	Epoch 3000:	Loss 0.0260	TrainAcc 0.9995	ValidAcc 0.9680	TestAcc 0.9671	BestValid 0.9684
	Epoch 3050:	Loss 0.0250	TrainAcc 0.9996	ValidAcc 0.9680	TestAcc 0.9670	BestValid 0.9684
	Epoch 3100:	Loss 0.0248	TrainAcc 0.9995	ValidAcc 0.9674	TestAcc 0.9668	BestValid 0.9684
	Epoch 3150:	Loss 0.0238	TrainAcc 0.9996	ValidAcc 0.9681	TestAcc 0.9673	BestValid 0.9684
	Epoch 3200:	Loss 0.0243	TrainAcc 0.9996	ValidAcc 0.9678	TestAcc 0.9662	BestValid 0.9684
	Epoch 3250:	Loss 0.0229	TrainAcc 0.9994	ValidAcc 0.9668	TestAcc 0.9660	BestValid 0.9684
	Epoch 3300:	Loss 0.0224	TrainAcc 0.9995	ValidAcc 0.9674	TestAcc 0.9664	BestValid 0.9684
	Epoch 3350:	Loss 0.0226	TrainAcc 0.9996	ValidAcc 0.9677	TestAcc 0.9666	BestValid 0.9684
	Epoch 3400:	Loss 0.0220	TrainAcc 0.9995	ValidAcc 0.9675	TestAcc 0.9662	BestValid 0.9684
	Epoch 3450:	Loss 0.0221	TrainAcc 0.9997	ValidAcc 0.9678	TestAcc 0.9666	BestValid 0.9684
	Epoch 3500:	Loss 0.0201	TrainAcc 0.9997	ValidAcc 0.9678	TestAcc 0.9670	BestValid 0.9684
	Epoch 3550:	Loss 0.0209	TrainAcc 0.9997	ValidAcc 0.9676	TestAcc 0.9667	BestValid 0.9684
	Epoch 3600:	Loss 0.0202	TrainAcc 0.9996	ValidAcc 0.9677	TestAcc 0.9666	BestValid 0.9684
	Epoch 3650:	Loss 0.0201	TrainAcc 0.9995	ValidAcc 0.9675	TestAcc 0.9665	BestValid 0.9684
	Epoch 3700:	Loss 0.0201	TrainAcc 0.9997	ValidAcc 0.9680	TestAcc 0.9665	BestValid 0.9684
	Epoch 3750:	Loss 0.0192	TrainAcc 0.9996	ValidAcc 0.9668	TestAcc 0.9664	BestValid 0.9684
	Epoch 3800:	Loss 0.0189	TrainAcc 0.9996	ValidAcc 0.9673	TestAcc 0.9664	BestValid 0.9684
	Epoch 3850:	Loss 0.0184	TrainAcc 0.9997	ValidAcc 0.9674	TestAcc 0.9667	BestValid 0.9684
	Epoch 3900:	Loss 0.0188	TrainAcc 0.9999	ValidAcc 0.9676	TestAcc 0.9670	BestValid 0.9684
	Epoch 3950:	Loss 0.0178	TrainAcc 0.9999	ValidAcc 0.9685	TestAcc 0.9672	BestValid 0.9685
	Epoch 4000:	Loss 0.0179	TrainAcc 0.9995	ValidAcc 0.9677	TestAcc 0.9664	BestValid 0.9685
	Epoch 4050:	Loss 0.0174	TrainAcc 0.9997	ValidAcc 0.9673	TestAcc 0.9667	BestValid 0.9685
	Epoch 4100:	Loss 0.0176	TrainAcc 0.9998	ValidAcc 0.9674	TestAcc 0.9670	BestValid 0.9685
	Epoch 4150:	Loss 0.0170	TrainAcc 0.9997	ValidAcc 0.9679	TestAcc 0.9669	BestValid 0.9685
	Epoch 4200:	Loss 0.0175	TrainAcc 0.9997	ValidAcc 0.9673	TestAcc 0.9671	BestValid 0.9685
	Epoch 4250:	Loss 0.0165	TrainAcc 0.9997	ValidAcc 0.9672	TestAcc 0.9668	BestValid 0.9685
	Epoch 4300:	Loss 0.0156	TrainAcc 0.9999	ValidAcc 0.9678	TestAcc 0.9673	BestValid 0.9685
	Epoch 4350:	Loss 0.0162	TrainAcc 0.9996	ValidAcc 0.9673	TestAcc 0.9664	BestValid 0.9685
	Epoch 4400:	Loss 0.0161	TrainAcc 0.9997	ValidAcc 0.9670	TestAcc 0.9669	BestValid 0.9685
	Epoch 4450:	Loss 0.0148	TrainAcc 0.9999	ValidAcc 0.9675	TestAcc 0.9669	BestValid 0.9685
	Epoch 4500:	Loss 0.0154	TrainAcc 0.9998	ValidAcc 0.9678	TestAcc 0.9669	BestValid 0.9685
	Epoch 4550:	Loss 0.0152	TrainAcc 0.9999	ValidAcc 0.9676	TestAcc 0.9673	BestValid 0.9685
	Epoch 4600:	Loss 0.0150	TrainAcc 0.9998	ValidAcc 0.9673	TestAcc 0.9672	BestValid 0.9685
	Epoch 4650:	Loss 0.0145	TrainAcc 0.9998	ValidAcc 0.9674	TestAcc 0.9673	BestValid 0.9685
	Epoch 4700:	Loss 0.0143	TrainAcc 0.9998	ValidAcc 0.9670	TestAcc 0.9665	BestValid 0.9685
	Epoch 4750:	Loss 0.0143	TrainAcc 0.9997	ValidAcc 0.9673	TestAcc 0.9667	BestValid 0.9685
	Epoch 4800:	Loss 0.0146	TrainAcc 0.9997	ValidAcc 0.9668	TestAcc 0.9667	BestValid 0.9685
	Epoch 4850:	Loss 0.0136	TrainAcc 0.9999	ValidAcc 0.9679	TestAcc 0.9673	BestValid 0.9685
	Epoch 4900:	Loss 0.0138	TrainAcc 0.9991	ValidAcc 0.9666	TestAcc 0.9653	BestValid 0.9685
	Epoch 4950:	Loss 0.0133	TrainAcc 0.9998	ValidAcc 0.9674	TestAcc 0.9670	BestValid 0.9685
	Epoch 5000:	Loss 0.0133	TrainAcc 0.9998	ValidAcc 0.9673	TestAcc 0.9667	BestValid 0.9685
****** Epoch Time (Excluding Evaluation Cost): 0.994 s ******
****** Breakdown Analysis ******
Cluster-Wide Average, Bubble-Pipeline: 153.642 ms (Max: 158.790, Min: 150.229, Sum: 614.568)
Cluster-Wide Average, Compute: 738.840 ms (Max: 773.330, Min: 704.445, Sum: 2955.360)
Cluster-Wide Average, Communication-Layer: 64.667 ms (Max: 76.234, Min: 53.821, Sum: 258.668)
Cluster-Wide Average, Bubble-Imbalance: 33.262 ms (Max: 55.795, Min: 12.347, Sum: 133.046)
Cluster-Wide Average, Communication-Graph: 0.138 ms (Max: 0.161, Min: 0.128, Sum: 0.551)
Cluster-Wide Average, Optimization: 0.310 ms (Max: 0.407, Min: 0.261, Sum: 1.239)
Cluster-Wide Average, Others: 5.185 ms (Max: 11.084, Min: 3.211, Sum: 20.741)
****** Breakdown Sum: 996.044 ms ******
Cluster-Wide Average, GPU Memory Consumption: 6.673 GB (Max: 7.878, Min: 6.233, Sum: 26.694)
Cluster-Wide Average, Graph-Level Communication Throughput: -nan Gbps (Max: -nan, Min: -nan, Sum: -nan)
Cluster-Wide Average, Layer-Level Communication Throughput: 64.515 Gbps (Max: 77.157, Min: 52.613, Sum: 258.062)
Layer-level communication (cluster-wide, per-epoch): 2.000 GB
Graph-level communication (cluster-wide, per-epoch): 0.000 GB
Weight-sync communication (cluster-wide, per-epoch): 0.000 GB
Total communication (cluster-wide, per-epoch): 2.000 GB
****** Accuracy Results ******
Highest valid_acc: 0.9685
Target test_acc: 0.9672
Epoch to reach the target acc: 3949
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 2] Success 
[MPI Rank 3] Success 
