g005.anvil.rcac.purdue.edu
Fri May 19 18:51:53 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   28C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

Consolidate compiler generated dependencies of target cudahelp
[ 11%] Built target context
[ 36%] Built target core
[ 77%] Built target cudahelp
Consolidate compiler generated dependencies of target OSDI2023_MULTI_NODES_graphsage
Consolidate compiler generated dependencies of target OSDI2023_MULTI_NODES_gcnii
Consolidate compiler generated dependencies of target OSDI2023_MULTI_NODES_gcn
[ 83%] Built target estimate_comm_volume
[100%] Built target OSDI2023_MULTI_NODES_gcnii
[100%] Built target OSDI2023_MULTI_NODES_graphsage
[100%] Built target OSDI2023_MULTI_NODES_gcn
Initialized node 3 on machine g008.anvil.rcac.purdue.edu
Initialized node 0 on machine g005.anvil.rcac.purdue.edu
Initialized node 1 on machine g006.anvil.rcac.purdue.edu
Initialized node 2 on machine g007.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.080 seconds.
Building the CSC structure...
        It takes 0.068 seconds.
Building the CSC structure...
        It takes 0.071 seconds.
Building the CSC structure...
        It takes 0.087 seconds.
Building the CSC structure...
        It takes 0.038 seconds.
        It takes 0.039 seconds.
        It takes 0.038 seconds.
        It takes 0.046 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.130 seconds.
        It takes 0.129 seconds.
        It takes 0.128 seconds.
Building the Label Vector...
Building the Label Vector...
Building the Label Vector...
        It takes 0.133 seconds.
Building the Label Vector...
        It takes 0.058 seconds.
        It takes 0.059 seconds.
        It takes 0.061 seconds.
        It takes 0.052 seconds.
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCNII layers: 8
The number of hidden units: 256
The number of training epoches: 3000
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /anvil/projects/x-cis220117/saved_weights_pipe
The random seed: 1
GCN hyper-parameter alpha: 0.100000
GCN hyper-parameter lambda: 0.000000
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
Number of GPUs: 4
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
*** Node 2, starting model training...
Node 2, Pipeline Input Tensor: NULL
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the model-level partition [0, 34)
*** Node 2, constructing the helper classes...
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
*** Node 3, starting model training...
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [34, 65)
*** Node 3, constructing the helper classes...
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
*** Node 1, starting model training...
WARNING: the current version only applies to linear GNN models!
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [34, 65)
*** Node 1, constructing the helper classes...
169343, 2484941, 2484941
Number of vertices per chunk: 10584
169343, 2484941, 2484941
Number of vertices per chunk: 10584
169343, 2484941, 2484941
Number of vertices per chunk: 10584
train nodes 90941, valid nodes 29799, test nodes 48603
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
*** Node 0, starting model training...
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the model-level partition [0, 34)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_DROPOUT, output tensors: 1
    Op 2: type OPERATOR_WEIGHT, output tensors: 2
    Op 3: type OPERATOR_MATMUL, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_AGGREGATION, output tensors: 6
    Op 7: type OPERATOR_ADD, output tensors: 7
    Op 8: type OPERATOR_WEIGHT, output tensors: 8
    Op 9: type OPERATOR_MATMUL, output tensors: 9
    Op 10: type OPERATOR_ADD, output tensors: 10
    Op 11: type OPERATOR_RELU, output tensors: 11
    Op 12: type OPERATOR_DROPOUT, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_ADD, output tensors: 14
    Op 15: type OPERATOR_WEIGHT, output tensors: 15
    Op 16: type OPERATOR_MATMUL, output tensors: 16
    Op 17: type OPERATOR_ADD, output tensors: 17
    Op 18: type OPERATOR_RELU, output tensors: 18
    Op 19: type OPERATOR_DROPOUT, output tensors: 19
    Op 20: type OPERATOR_AGGREGATION, output tensors: 20
    Op 21: type OPERATOR_ADD, output tensors: 21
    Op 22: type OPERATOR_WEIGHT, output tensors: 22
    Op 23: type OPERATOR_MATMUL, output tensors: 23
    Op 24: type OPERATOR_ADD, output tensors: 24
    Op 25: type OPERATOR_RELU, output tensors: 25
    Op 26: type OPERATOR_DROPOUT, output tensors: 26
    Op 27: type OPERATOR_AGGREGATION, output tensors: 27
    Op 28: type OPERATOR_ADD, output tensors: 28
    Op 29: type OPERATOR_WEIGHT, output tensors: 29
    Op 30: type OPERATOR_MATMUL, output tensors: 30
    Op 31: type OPERATOR_ADD, output tensors: 31
    Op 32: type OPERATOR_RELU, output tensors: 32
    Op 33: type OPERATOR_DROPOUT, output tensors: 33
    Op 34: type OPERATOR_AGGREGATION, output tensors: 34
    Op 35: type OPERATOR_ADD, output tensors: 35
    Op 36: type OPERATOR_WEIGHT, output tensors: 36
    Op 37: type OPERATOR_MATMUL, output tensors: 37
    Op 38: type OPERATOR_ADD, output tensors: 38
    Op 39: type OPERATOR_RELU, output tensors: 39
    Op 40: type OPERATOR_DROPOUT, output tensors: 40
    Op 41: type OPERATOR_AGGREGATION, output tensors: 41
    Op 42: type OPERATOR_ADD, output tensors: 42
    Op 43: type OPERATOR_WEIGHT, output tensors: 43
    Op 44: type OPERATOR_MATMUL, output tensors: 44
    Op 45: type OPERATOR_ADD, output tensors: 45
    Op 46: type OPERATOR_RELU, output tensors: 46
    Op 47: type OPERATOR_DROPOUT, output tensors: 47
    Op 48: type OPERATOR_AGGREGATION, output tensors: 48
    Op 49: type OPERATOR_ADD, output tensors: 49
    Op 50: type OPERATOR_WEIGHT, output tensors: 50
    Op 51: type OPERATOR_MATMUL, output tensors: 51
    Op 52: type OPERATOR_ADD, output tensors: 52
    Op 53: type OPERATOR_RELU, output tensors: 53
    Op 54: type OPERATOR_DROPOUT, output tensors: 54
    Op 55: type OPERATOR_AGGREGATION, output tensors: 55
    Op 56: type OPERATOR_ADD, output tensors: 56
    Op 57: type OPERATOR_WEIGHT, output tensors: 57
    Op 58: type OPERATOR_MATMUL, output tensors: 58
    Op 59: type OPERATOR_ADD, output tensors: 59
    Op 60: type OPERATOR_RELU, output tensors: 60
    Op 61: type OPERATOR_DROPOUT, output tensors: 61
    Op 62: type OPERATOR_WEIGHT, output tensors: 62
    Op 63: type OPERATOR_MATMUL, output tensors: 63
    Op 64: type OPERATOR_SOFTMAX, output tensors: 64
Boundaries: 0 0 0 0 169343 169343 169343 169343
Fragments: [0, 169343)
Chunks (number of global chunks: 16): 0-[0, 10584) 1-[10584, 21168) 2-[21168, 31752) 3-[31752, 42336) 4-[42336, 52920) 5-[52920, 63504) 6-[63504, 74088) 7-[74088, 84672) 8-[84672, 95256) ... 15-[158760, 169343)
169343, 2484941, 2484941
Number of vertices per chunk: 10584
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 3, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
*** Node 3, starting the helper threads...
*** Node 2, starting the helper threads...
+++++++++ Node 3 initializing the weights for op[34, 65)...
+++++++++ Node 2 initializing the weights for op[0, 34)...
+++++++++ Node 2, mapping weight op 2
+++++++++ Node 3, mapping weight op 36
+++++++++ Node 2, mapping weight op 8
+++++++++ Node 2, mapping weight op 15
+++++++++ Node 3, mapping weight op 43
*** Node 0, starting the helper threads...
+++++++++ Node 3, mapping weight op 50
+++++++++ Node 2, mapping weight op 22
+++++++++ Node 3, mapping weight op 57
+++++++++ Node 2, mapping weight op 29
+++++++++ Node 3, mapping weight op 62
+++++++++ Node 0 initializing the weights for op[0, 34)...
+++++++++ Node 0, mapping weight op 2
+++++++++ Node 0, mapping weight op 8
+++++++++ Node 0, mapping weight op 15
+++++++++ Node 0, mapping weight op 22
+++++++++ Node 0, mapping weight op 29
*** Node 1, starting the helper threads...
+++++++++ Node 1 initializing the weights for op[34, 65)...
+++++++++ Node 1, mapping weight op 36
+++++++++ Node 1, mapping weight op 43
+++++++++ Node 1, mapping weight op 50
+++++++++ Node 1, mapping weight op 57
+++++++++ Node 1, mapping weight op 62
Node 0, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be sent across graph boundary...
Node 0, discovering the vertices that will be received across the graph boundary.
Node 3, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
Node 2, discovering the vertices that will be received across the graph boundary.
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.001000000
*** Node 3, starting task scheduling...
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.001000000
	Epoch 10:	Loss 3.2752	TrainAcc 0.1791	ValidAcc 0.0763	BestValid 0.0763
	Epoch 20:	Loss 3.0761	TrainAcc 0.2729	ValidAcc 0.2925	BestValid 0.2925
	Epoch 30:	Loss 2.8823	TrainAcc 0.2906	ValidAcc 0.2989	BestValid 0.2989
	Epoch 40:	Loss 2.6665	TrainAcc 0.3625	ValidAcc 0.3475	BestValid 0.3475
	Epoch 50:	Loss 2.5396	TrainAcc 0.4168	ValidAcc 0.3925	BestValid 0.3925
	Epoch 60:	Loss 2.3873	TrainAcc 0.4591	ValidAcc 0.4386	BestValid 0.4386
	Epoch 70:	Loss 2.3048	TrainAcc 0.4875	ValidAcc 0.4724	BestValid 0.4724
	Epoch 80:	Loss 2.2193	TrainAcc 0.5067	ValidAcc 0.4946	BestValid 0.4946
	Epoch 90:	Loss 2.1505	TrainAcc 0.5243	ValidAcc 0.5146	BestValid 0.5146
	Epoch 100:	Loss 2.0873	TrainAcc 0.5407	ValidAcc 0.5329	BestValid 0.5329
	Epoch 110:	Loss 2.0532	TrainAcc 0.5523	ValidAcc 0.5431	BestValid 0.5431
	Epoch 120:	Loss 2.0047	TrainAcc 0.5588	ValidAcc 0.5495	BestValid 0.5495
	Epoch 130:	Loss 1.9735	TrainAcc 0.5656	ValidAcc 0.5567	BestValid 0.5567
	Epoch 140:	Loss 1.9390	TrainAcc 0.5722	ValidAcc 0.5646	BestValid 0.5646
	Epoch 150:	Loss 1.9080	TrainAcc 0.5770	ValidAcc 0.5689	BestValid 0.5689
	Epoch 160:	Loss 1.8774	TrainAcc 0.5813	ValidAcc 0.5726	BestValid 0.5726
	Epoch 170:	Loss 1.8587	TrainAcc 0.5874	ValidAcc 0.5844	BestValid 0.5844
	Epoch 180:	Loss 1.8373	TrainAcc 0.5889	ValidAcc 0.5827	BestValid 0.5844
	Epoch 190:	Loss 1.8239	TrainAcc 0.5939	ValidAcc 0.5904	BestValid 0.5904
	Epoch 200:	Loss 1.8046	TrainAcc 0.5966	ValidAcc 0.5961	BestValid 0.5961
	Epoch 210:	Loss 1.7862	TrainAcc 0.5982	ValidAcc 0.5950	BestValid 0.5961
	Epoch 220:	Loss 1.7764	TrainAcc 0.6008	ValidAcc 0.5984	BestValid 0.5984
	Epoch 230:	Loss 1.7609	TrainAcc 0.6034	ValidAcc 0.6013	BestValid 0.6013
	Epoch 240:	Loss 1.7417	TrainAcc 0.6048	ValidAcc 0.6037	BestValid 0.6037
	Epoch 250:	Loss 1.7399	TrainAcc 0.6079	ValidAcc 0.6083	BestValid 0.6083
	Epoch 260:	Loss 1.7254	TrainAcc 0.6100	ValidAcc 0.6101	BestValid 0.6101
	Epoch 270:	Loss 1.7129	TrainAcc 0.6111	ValidAcc 0.6109	BestValid 0.6109
	Epoch 280:	Loss 1.7058	TrainAcc 0.6126	ValidAcc 0.6115	BestValid 0.6115
	Epoch 290:	Loss 1.6937	TrainAcc 0.6142	ValidAcc 0.6162	BestValid 0.6162
	Epoch 300:	Loss 1.6837	TrainAcc 0.6162	ValidAcc 0.6179	BestValid 0.6179
	Epoch 310:	Loss 1.6789	TrainAcc 0.6174	ValidAcc 0.6198	BestValid 0.6198
	Epoch 320:	Loss 1.6712	TrainAcc 0.6183	ValidAcc 0.6200	BestValid 0.6200
	Epoch 330:	Loss 1.6608	TrainAcc 0.6192	ValidAcc 0.6207	BestValid 0.6207
	Epoch 340:	Loss 1.6536	TrainAcc 0.6203	ValidAcc 0.6219	BestValid 0.6219
	Epoch 350:	Loss 1.6526	TrainAcc 0.6216	ValidAcc 0.6237	BestValid 0.6237
	Epoch 360:	Loss 1.6433	TrainAcc 0.6224	ValidAcc 0.6230	BestValid 0.6237
	Epoch 370:	Loss 1.6410	TrainAcc 0.6239	ValidAcc 0.6275	BestValid 0.6275
	Epoch 380:	Loss 1.6360	TrainAcc 0.6249	ValidAcc 0.6256	BestValid 0.6275
	Epoch 390:	Loss 1.6261	TrainAcc 0.6254	ValidAcc 0.6274	BestValid 0.6275
	Epoch 400:	Loss 1.6274	TrainAcc 0.6262	ValidAcc 0.6286	BestValid 0.6286
	Epoch 410:	Loss 1.6228	TrainAcc 0.6273	ValidAcc 0.6282	BestValid 0.6286
	Epoch 420:	Loss 1.6155	TrainAcc 0.6282	ValidAcc 0.6316	BestValid 0.6316
	Epoch 430:	Loss 1.6060	TrainAcc 0.6287	ValidAcc 0.6301	BestValid 0.6316
	Epoch 440:	Loss 1.6042	TrainAcc 0.6301	ValidAcc 0.6326	BestValid 0.6326
	Epoch 450:	Loss 1.6001	TrainAcc 0.6301	ValidAcc 0.6322	BestValid 0.6326
	Epoch 460:	Loss 1.5949	TrainAcc 0.6309	ValidAcc 0.6326	BestValid 0.6326
	Epoch 470:	Loss 1.5939	TrainAcc 0.6321	ValidAcc 0.6341	BestValid 0.6341
	Epoch 480:	Loss 1.5867	TrainAcc 0.6325	ValidAcc 0.6333	BestValid 0.6341
	Epoch 490:	Loss 1.5897	TrainAcc 0.6336	ValidAcc 0.6360	BestValid 0.6360
	Epoch 500:	Loss 1.5848	TrainAcc 0.6338	ValidAcc 0.6350	BestValid 0.6360
	Epoch 510:	Loss 1.5759	TrainAcc 0.6342	ValidAcc 0.6359	BestValid 0.6360
	Epoch 520:	Loss 1.5746	TrainAcc 0.6346	ValidAcc 0.6355	BestValid 0.6360
	Epoch 530:	Loss 1.5742	TrainAcc 0.6359	ValidAcc 0.6390	BestValid 0.6390
	Epoch 540:	Loss 1.5671	TrainAcc 0.6359	ValidAcc 0.6374	BestValid 0.6390
	Epoch 550:	Loss 1.5642	TrainAcc 0.6375	ValidAcc 0.6399	BestValid 0.6399
	Epoch 560:	Loss 1.5644	TrainAcc 0.6372	ValidAcc 0.6387	BestValid 0.6399
	Epoch 570:	Loss 1.5601	TrainAcc 0.6384	ValidAcc 0.6412	BestValid 0.6412
	Epoch 580:	Loss 1.5551	TrainAcc 0.6386	ValidAcc 0.6395	BestValid 0.6412
	Epoch 590:	Loss 1.5543	TrainAcc 0.6390	ValidAcc 0.6400	BestValid 0.6412
	Epoch 600:	Loss 1.5534	TrainAcc 0.6400	ValidAcc 0.6412	BestValid 0.6412
	Epoch 610:	Loss 1.5510	TrainAcc 0.6408	ValidAcc 0.6421	BestValid 0.6421
	Epoch 620:	Loss 1.5490	TrainAcc 0.6413	ValidAcc 0.6424	BestValid 0.6424
	Epoch 630:	Loss 1.5460	TrainAcc 0.6416	ValidAcc 0.6404	BestValid 0.6424
	Epoch 640:	Loss 1.5439	TrainAcc 0.6427	ValidAcc 0.6442	BestValid 0.6442
	Epoch 650:	Loss 1.5421	TrainAcc 0.6427	ValidAcc 0.6404	BestValid 0.6442
	Epoch 660:	Loss 1.5397	TrainAcc 0.6434	ValidAcc 0.6436	BestValid 0.6442
	Epoch 670:	Loss 1.5440	TrainAcc 0.6442	ValidAcc 0.6426	BestValid 0.6442
	Epoch 680:	Loss 1.5325	TrainAcc 0.6443	ValidAcc 0.6440	BestValid 0.6442
	Epoch 690:	Loss 1.5368	TrainAcc 0.6453	ValidAcc 0.6460	BestValid 0.6460
	Epoch 700:	Loss 1.5382	TrainAcc 0.6454	ValidAcc 0.6439	BestValid 0.6460
	Epoch 710:	Loss 1.5330	TrainAcc 0.6463	ValidAcc 0.6474	BestValid 0.6474
	Epoch 720:	Loss 1.5268	TrainAcc 0.6467	ValidAcc 0.6457	BestValid 0.6474
	Epoch 730:	Loss 1.5276	TrainAcc 0.6468	ValidAcc 0.6468	BestValid 0.6474
	Epoch 740:	Loss 1.5226	TrainAcc 0.6472	ValidAcc 0.6470	BestValid 0.6474
	Epoch 750:	Loss 1.5242	TrainAcc 0.6483	ValidAcc 0.6475	BestValid 0.6475
	Epoch 760:	Loss 1.5180	TrainAcc 0.6483	ValidAcc 0.6474	BestValid 0.6475
	Epoch 770:	Loss 1.5147	TrainAcc 0.6489	ValidAcc 0.6473	BestValid 0.6475
	Epoch 780:	Loss 1.5155	TrainAcc 0.6492	ValidAcc 0.6478	BestValid 0.6478
	Epoch 790:	Loss 1.5166	TrainAcc 0.6497	ValidAcc 0.6492	BestValid 0.6492
	Epoch 800:	Loss 1.5157	TrainAcc 0.6499	ValidAcc 0.6486	BestValid 0.6492
	Epoch 810:	Loss 1.5123	TrainAcc 0.6503	ValidAcc 0.6492	BestValid 0.6492
	Epoch 820:	Loss 1.5070	TrainAcc 0.6506	ValidAcc 0.6486	BestValid 0.6492
	Epoch 830:	Loss 1.5054	TrainAcc 0.6513	ValidAcc 0.6497	BestValid 0.6497
	Epoch 840:	Loss 1.5158	TrainAcc 0.6516	ValidAcc 0.6486	BestValid 0.6497
	Epoch 850:	Loss 1.5062	TrainAcc 0.6526	ValidAcc 0.6508	BestValid 0.6508
	Epoch 860:	Loss 1.5037	TrainAcc 0.6525	ValidAcc 0.6502	BestValid 0.6508
	Epoch 870:	Loss 1.5024	TrainAcc 0.6531	ValidAcc 0.6501	BestValid 0.6508
	Epoch 880:	Loss 1.5015	TrainAcc 0.6528	ValidAcc 0.6503	BestValid 0.6508
	Epoch 890:	Loss 1.5013	TrainAcc 0.6537	ValidAcc 0.6508	BestValid 0.6508
	Epoch 900:	Loss 1.4990	TrainAcc 0.6534	ValidAcc 0.6503	BestValid 0.6508
	Epoch 910:	Loss 1.4952	TrainAcc 0.6538	ValidAcc 0.6514	BestValid 0.6514
	Epoch 920:	Loss 1.4942	TrainAcc 0.6535	ValidAcc 0.6505	BestValid 0.6514
	Epoch 930:	Loss 1.4955	TrainAcc 0.6548	ValidAcc 0.6531	BestValid 0.6531
	Epoch 940:	Loss 1.4895	TrainAcc 0.6541	ValidAcc 0.6506	BestValid 0.6531
	Epoch 950:	Loss 1.4899	TrainAcc 0.6546	ValidAcc 0.6522	BestValid 0.6531
	Epoch 960:	Loss 1.4893	TrainAcc 0.6544	ValidAcc 0.6504	BestValid 0.6531
	Epoch 970:	Loss 1.4889	TrainAcc 0.6560	ValidAcc 0.6554	BestValid 0.6554
	Epoch 980:	Loss 1.4850	TrainAcc 0.6552	ValidAcc 0.6520	BestValid 0.6554
	Epoch 990:	Loss 1.4903	TrainAcc 0.6558	ValidAcc 0.6533	BestValid 0.6554
	Epoch 1000:	Loss 1.4835	TrainAcc 0.6557	ValidAcc 0.6528	BestValid 0.6554
	Epoch 1010:	Loss 1.4870	TrainAcc 0.6564	ValidAcc 0.6535	BestValid 0.6554
	Epoch 1020:	Loss 1.4827	TrainAcc 0.6562	ValidAcc 0.6525	BestValid 0.6554
	Epoch 1030:	Loss 1.4812	TrainAcc 0.6565	ValidAcc 0.6537	BestValid 0.6554
	Epoch 1040:	Loss 1.4836	TrainAcc 0.6569	ValidAcc 0.6537	BestValid 0.6554
	Epoch 1050:	Loss 1.4762	TrainAcc 0.6572	ValidAcc 0.6547	BestValid 0.6554
	Epoch 1060:	Loss 1.4701	TrainAcc 0.6571	ValidAcc 0.6536	BestValid 0.6554
	Epoch 1070:	Loss 1.4745	TrainAcc 0.6579	ValidAcc 0.6548	BestValid 0.6554
	Epoch 1080:	Loss 1.4795	TrainAcc 0.6572	ValidAcc 0.6533	BestValid 0.6554
	Epoch 1090:	Loss 1.4760	TrainAcc 0.6584	ValidAcc 0.6552	BestValid 0.6554
	Epoch 1100:	Loss 1.4702	TrainAcc 0.6577	ValidAcc 0.6536	BestValid 0.6554
	Epoch 1110:	Loss 1.4715	TrainAcc 0.6584	ValidAcc 0.6554	BestValid 0.6554
	Epoch 1120:	Loss 1.4693	TrainAcc 0.6582	ValidAcc 0.6546	BestValid 0.6554
	Epoch 1130:	Loss 1.4765	TrainAcc 0.6591	ValidAcc 0.6558	BestValid 0.6558
	Epoch 1140:	Loss 1.4740	TrainAcc 0.6585	ValidAcc 0.6542	BestValid 0.6558
	Epoch 1150:	Loss 1.4676	TrainAcc 0.6596	ValidAcc 0.6562	BestValid 0.6562
	Epoch 1160:	Loss 1.4687	TrainAcc 0.6596	ValidAcc 0.6551	BestValid 0.6562
	Epoch 1170:	Loss 1.4709	TrainAcc 0.6596	ValidAcc 0.6578	BestValid 0.6578
	Epoch 1180:	Loss 1.4692	TrainAcc 0.6604	ValidAcc 0.6565	BestValid 0.6578
	Epoch 1190:	Loss 1.4697	TrainAcc 0.6597	ValidAcc 0.6566	BestValid 0.6578
	Epoch 1200:	Loss 1.4639	TrainAcc 0.6602	ValidAcc 0.6555	BestValid 0.6578
	Epoch 1210:	Loss 1.4683	TrainAcc 0.6604	ValidAcc 0.6573	BestValid 0.6578
	Epoch 1220:	Loss 1.4637	TrainAcc 0.6607	ValidAcc 0.6564	BestValid 0.6578
	Epoch 1230:	Loss 1.4626	TrainAcc 0.6607	ValidAcc 0.6561	BestValid 0.6578
	Epoch 1240:	Loss 1.4617	TrainAcc 0.6605	ValidAcc 0.6563	BestValid 0.6578
	Epoch 1250:	Loss 1.4649	TrainAcc 0.6616	ValidAcc 0.6584	BestValid 0.6584
	Epoch 1260:	Loss 1.4606	TrainAcc 0.6612	ValidAcc 0.6580	BestValid 0.6584
	Epoch 1270:	Loss 1.4662	TrainAcc 0.6621	ValidAcc 0.6584	BestValid 0.6584
	Epoch 1280:	Loss 1.4619	TrainAcc 0.6618	ValidAcc 0.6573	BestValid 0.6584
	Epoch 1290:	Loss 1.4544	TrainAcc 0.6621	ValidAcc 0.6583	BestValid 0.6584
	Epoch 1300:	Loss 1.4558	TrainAcc 0.6623	ValidAcc 0.6584	BestValid 0.6584
	Epoch 1310:	Loss 1.4558	TrainAcc 0.6624	ValidAcc 0.6579	BestValid 0.6584
	Epoch 1320:	Loss 1.4551	TrainAcc 0.6627	ValidAcc 0.6589	BestValid 0.6589
	Epoch 1330:	Loss 1.4571	TrainAcc 0.6628	ValidAcc 0.6587	BestValid 0.6589
	Epoch 1340:	Loss 1.4554	TrainAcc 0.6627	ValidAcc 0.6596	BestValid 0.6596
	Epoch 1350:	Loss 1.4567	TrainAcc 0.6634	ValidAcc 0.6605	BestValid 0.6605
	Epoch 1360:	Loss 1.4467	TrainAcc 0.6628	ValidAcc 0.6583	BestValid 0.6605
	Epoch 1370:	Loss 1.4579	TrainAcc 0.6635	ValidAcc 0.6603	BestValid 0.6605
	Epoch 1380:	Loss 1.4553	TrainAcc 0.6631	ValidAcc 0.6585	BestValid 0.6605
	Epoch 1390:	Loss 1.4553	TrainAcc 0.6636	ValidAcc 0.6605	BestValid 0.6605
	Epoch 1400:	Loss 1.4504	TrainAcc 0.6633	ValidAcc 0.6597	BestValid 0.6605
	Epoch 1410:	Loss 1.4511	TrainAcc 0.6636	ValidAcc 0.6589	BestValid 0.6605
	Epoch 1420:	Loss 1.4494	TrainAcc 0.6633	ValidAcc 0.6588	BestValid 0.6605
	Epoch 1430:	Loss 1.4495	TrainAcc 0.6636	ValidAcc 0.6593	BestValid 0.6605
	Epoch 1440:	Loss 1.4426	TrainAcc 0.6639	ValidAcc 0.6595	BestValid 0.6605
	Epoch 1450:	Loss 1.4510	TrainAcc 0.6642	ValidAcc 0.6607	BestValid 0.6607
	Epoch 1460:	Loss 1.4392	TrainAcc 0.6642	ValidAcc 0.6603	BestValid 0.6607
	Epoch 1470:	Loss 1.4472	TrainAcc 0.6649	ValidAcc 0.6613	BestValid 0.6613
	Epoch 1480:	Loss 1.4503	TrainAcc 0.6643	ValidAcc 0.6605	BestValid 0.6613
	Epoch 1490:	Loss 1.4413	TrainAcc 0.6652	ValidAcc 0.6616	BestValid 0.6616
	Epoch 1500:	Loss 1.4485	TrainAcc 0.6651	ValidAcc 0.6620	BestValid 0.6620
	Epoch 1510:	Loss 1.4498	TrainAcc 0.6654	ValidAcc 0.6616	BestValid 0.6620
	Epoch 1520:	Loss 1.4457	TrainAcc 0.6651	ValidAcc 0.6606	BestValid 0.6620
	Epoch 1530:	Loss 1.4451	TrainAcc 0.6657	ValidAcc 0.6627	BestValid 0.6627
	Epoch 1540:	Loss 1.4457	TrainAcc 0.6652	ValidAcc 0.6609	BestValid 0.6627
	Epoch 1550:	Loss 1.4436	TrainAcc 0.6655	ValidAcc 0.6619	BestValid 0.6627
	Epoch 1560:	Loss 1.4477	TrainAcc 0.6651	ValidAcc 0.6609	BestValid 0.6627
	Epoch 1570:	Loss 1.4377	TrainAcc 0.6659	ValidAcc 0.6622	BestValid 0.6627
	Epoch 1580:	Loss 1.4412	TrainAcc 0.6657	ValidAcc 0.6607	BestValid 0.6627
	Epoch 1590:	Loss 1.4356	TrainAcc 0.6662	ValidAcc 0.6624	BestValid 0.6627
	Epoch 1600:	Loss 1.4408	TrainAcc 0.6659	ValidAcc 0.6617	BestValid 0.6627
	Epoch 1610:	Loss 1.4400	TrainAcc 0.6659	ValidAcc 0.6626	BestValid 0.6627
	Epoch 1620:	Loss 1.4442	TrainAcc 0.6658	ValidAcc 0.6618	BestValid 0.6627
	Epoch 1630:	Loss 1.4389	TrainAcc 0.6663	ValidAcc 0.6620	BestValid 0.6627
	Epoch 1640:	Loss 1.4410	TrainAcc 0.6660	ValidAcc 0.6622	BestValid 0.6627
	Epoch 1650:	Loss 1.4393	TrainAcc 0.6665	ValidAcc 0.6631	BestValid 0.6631
	Epoch 1660:	Loss 1.4395	TrainAcc 0.6665	ValidAcc 0.6622	BestValid 0.6631
	Epoch 1670:	Loss 1.4306	TrainAcc 0.6666	ValidAcc 0.6622	BestValid 0.6631
	Epoch 1680:	Loss 1.4322	TrainAcc 0.6662	ValidAcc 0.6619	BestValid 0.6631
	Epoch 1690:	Loss 1.4426	TrainAcc 0.6671	ValidAcc 0.6628	BestValid 0.6631
	Epoch 1700:	Loss 1.4346	TrainAcc 0.6662	ValidAcc 0.6607	BestValid 0.6631
	Epoch 1710:	Loss 1.4349	TrainAcc 0.6675	ValidAcc 0.6643	BestValid 0.6643
	Epoch 1720:	Loss 1.4270	TrainAcc 0.6666	ValidAcc 0.6619	BestValid 0.6643
	Epoch 1730:	Loss 1.4375	TrainAcc 0.6674	ValidAcc 0.6630	BestValid 0.6643
	Epoch 1740:	Loss 1.4326	TrainAcc 0.6674	ValidAcc 0.6627	BestValid 0.6643
	Epoch 1750:	Loss 1.4308	TrainAcc 0.6677	ValidAcc 0.6635	BestValid 0.6643
	Epoch 1760:	Loss 1.4301	TrainAcc 0.6673	ValidAcc 0.6634	BestValid 0.6643
	Epoch 1770:	Loss 1.4332	TrainAcc 0.6675	ValidAcc 0.6643	BestValid 0.6643
	Epoch 1780:	Loss 1.4341	TrainAcc 0.6676	ValidAcc 0.6633	BestValid 0.6643
	Epoch 1790:	Loss 1.4360	TrainAcc 0.6676	ValidAcc 0.6636	BestValid 0.6643
	Epoch 1800:	Loss 1.4340	TrainAcc 0.6673	ValidAcc 0.6624	BestValid 0.6643
	Epoch 1810:	Loss 1.4323	TrainAcc 0.6686	ValidAcc 0.6655	BestValid 0.6655
	Epoch 1820:	Loss 1.4321	TrainAcc 0.6678	ValidAcc 0.6633	BestValid 0.6655
	Epoch 1830:	Loss 1.4309	TrainAcc 0.6685	ValidAcc 0.6658	BestValid 0.6658
	Epoch 1840:	Loss 1.4303	TrainAcc 0.6680	ValidAcc 0.6636	BestValid 0.6658
	Epoch 1850:	Loss 1.4294	TrainAcc 0.6686	ValidAcc 0.6651	BestValid 0.6658
	Epoch 1860:	Loss 1.4270	TrainAcc 0.6682	ValidAcc 0.6631	BestValid 0.6658
	Epoch 1870:	Loss 1.4265	TrainAcc 0.6687	ValidAcc 0.6650	BestValid 0.6658
	Epoch 1880:	Loss 1.4302	TrainAcc 0.6684	ValidAcc 0.6637	BestValid 0.6658
	Epoch 1890:	Loss 1.4314	TrainAcc 0.6685	ValidAcc 0.6641	BestValid 0.6658
	Epoch 1900:	Loss 1.4307	TrainAcc 0.6686	ValidAcc 0.6637	BestValid 0.6658
	Epoch 1910:	Loss 1.4234	TrainAcc 0.6691	ValidAcc 0.6654	BestValid 0.6658
	Epoch 1920:	Loss 1.4209	TrainAcc 0.6689	ValidAcc 0.6645	BestValid 0.6658
	Epoch 1930:	Loss 1.4292	TrainAcc 0.6698	ValidAcc 0.6660	BestValid 0.6660
	Epoch 1940:	Loss 1.4246	TrainAcc 0.6687	ValidAcc 0.6645	BestValid 0.6660
	Epoch 1950:	Loss 1.4246	TrainAcc 0.6691	ValidAcc 0.6641	BestValid 0.6660
	Epoch 1960:	Loss 1.4271	TrainAcc 0.6689	ValidAcc 0.6635	BestValid 0.6660
	Epoch 1970:	Loss 1.4287	TrainAcc 0.6697	ValidAcc 0.6665	BestValid 0.6665
	Epoch 1980:	Loss 1.4226	TrainAcc 0.6689	ValidAcc 0.6629	BestValid 0.6665
	Epoch 1990:	Loss 1.4239	TrainAcc 0.6701	ValidAcc 0.6656	BestValid 0.6665
	Epoch 2000:	Loss 1.4221	TrainAcc 0.6694	ValidAcc 0.6636	BestValid 0.6665
	Epoch 2010:	Loss 1.4199	TrainAcc 0.6696	ValidAcc 0.6664	BestValid 0.6665
	Epoch 2020:	Loss 1.4278	TrainAcc 0.6693	ValidAcc 0.6647	BestValid 0.6665
	Epoch 2030:	Loss 1.4215	TrainAcc 0.6698	ValidAcc 0.6656	BestValid 0.6665
	Epoch 2040:	Loss 1.4209	TrainAcc 0.6699	ValidAcc 0.6650	BestValid 0.6665
	Epoch 2050:	Loss 1.4171	TrainAcc 0.6700	ValidAcc 0.6655	BestValid 0.6665
	Epoch 2060:	Loss 1.4277	TrainAcc 0.6701	ValidAcc 0.6649	BestValid 0.6665
	Epoch 2070:	Loss 1.4254	TrainAcc 0.6700	ValidAcc 0.6642	BestValid 0.6665
	Epoch 2080:	Loss 1.4190	TrainAcc 0.6702	ValidAcc 0.6647	BestValid 0.6665
	Epoch 2090:	Loss 1.4249	TrainAcc 0.6700	ValidAcc 0.6656	BestValid 0.6665
	Epoch 2100:	Loss 1.4250	TrainAcc 0.6703	ValidAcc 0.6644	BestValid 0.6665
	Epoch 2110:	Loss 1.4221	TrainAcc 0.6708	ValidAcc 0.6659	BestValid 0.6665
	Epoch 2120:	Loss 1.4243	TrainAcc 0.6705	ValidAcc 0.6643	BestValid 0.6665
	Epoch 2130:	Loss 1.4204	TrainAcc 0.6712	ValidAcc 0.6671	BestValid 0.6671
	Epoch 2140:	Loss 1.4208	TrainAcc 0.6704	ValidAcc 0.6644	BestValid 0.6671
	Epoch 2150:	Loss 1.4188	TrainAcc 0.6711	ValidAcc 0.6667	BestValid 0.6671
	Epoch 2160:	Loss 1.4191	TrainAcc 0.6701	ValidAcc 0.6644	BestValid 0.6671
	Epoch 2170:	Loss 1.4225	TrainAcc 0.6716	ValidAcc 0.6683	BestValid 0.6683
	Epoch 2180:	Loss 1.4218	TrainAcc 0.6711	ValidAcc 0.6664	BestValid 0.6683
	Epoch 2190:	Loss 1.4162	TrainAcc 0.6707	ValidAcc 0.6646	BestValid 0.6683
	Epoch 2200:	Loss 1.4163	TrainAcc 0.6706	ValidAcc 0.6659	BestValid 0.6683
	Epoch 2210:	Loss 1.4229	TrainAcc 0.6715	ValidAcc 0.6665	BestValid 0.6683
	Epoch 2220:	Loss 1.4220	TrainAcc 0.6710	ValidAcc 0.6656	BestValid 0.6683
	Epoch 2230:	Loss 1.4274	TrainAcc 0.6712	ValidAcc 0.6669	BestValid 0.6683
	Epoch 2240:	Loss 1.4174	TrainAcc 0.6713	ValidAcc 0.6660	BestValid 0.6683
	Epoch 2250:	Loss 1.4167	TrainAcc 0.6712	ValidAcc 0.6665	BestValid 0.6683
	Epoch 2260:	Loss 1.4162	TrainAcc 0.6715	ValidAcc 0.6660	BestValid 0.6683
	Epoch 2270:	Loss 1.4118	TrainAcc 0.6710	ValidAcc 0.6657	BestValid 0.6683
	Epoch 2280:	Loss 1.4157	TrainAcc 0.6711	ValidAcc 0.6647	BestValid 0.6683
	Epoch 2290:	Loss 1.4161	TrainAcc 0.6717	ValidAcc 0.6665	BestValid 0.6683
	Epoch 2300:	Loss 1.4146	TrainAcc 0.6713	ValidAcc 0.6647	BestValid 0.6683
	Epoch 2310:	Loss 1.4161	TrainAcc 0.6717	ValidAcc 0.6666	BestValid 0.6683
	Epoch 2320:	Loss 1.4162	TrainAcc 0.6711	ValidAcc 0.6651	BestValid 0.6683
	Epoch 2330:	Loss 1.4136	TrainAcc 0.6722	ValidAcc 0.6678	BestValid 0.6683
	Epoch 2340:	Loss 1.4158	TrainAcc 0.6719	ValidAcc 0.6668	BestValid 0.6683
	Epoch 2350:	Loss 1.4147	TrainAcc 0.6720	ValidAcc 0.6672	BestValid 0.6683
	Epoch 2360:	Loss 1.4127	TrainAcc 0.6722	ValidAcc 0.6668	BestValid 0.6683
	Epoch 2370:	Loss 1.4169	TrainAcc 0.6720	ValidAcc 0.6661	BestValid 0.6683
	Epoch 2380:	Loss 1.4160	TrainAcc 0.6717	ValidAcc 0.6658	BestValid 0.6683
	Epoch 2390:	Loss 1.4049	TrainAcc 0.6720	ValidAcc 0.6664	BestValid 0.6683
	Epoch 2400:	Loss 1.4144	TrainAcc 0.6716	ValidAcc 0.6659	BestValid 0.6683
	Epoch 2410:	Loss 1.4126	TrainAcc 0.6724	ValidAcc 0.6680	BestValid 0.6683
	Epoch 2420:	Loss 1.4127	TrainAcc 0.6722	ValidAcc 0.6667	BestValid 0.6683
	Epoch 2430:	Loss 1.4143	TrainAcc 0.6719	ValidAcc 0.6666	BestValid 0.6683
	Epoch 2440:	Loss 1.4047	TrainAcc 0.6727	ValidAcc 0.6665	BestValid 0.6683
	Epoch 2450:	Loss 1.4098	TrainAcc 0.6719	ValidAcc 0.6666	BestValid 0.6683
	Epoch 2460:	Loss 1.4141	TrainAcc 0.6719	ValidAcc 0.6658	BestValid 0.6683
	Epoch 2470:	Loss 1.4063	TrainAcc 0.6727	ValidAcc 0.6674	BestValid 0.6683
	Epoch 2480:	Loss 1.4084	TrainAcc 0.6724	ValidAcc 0.6664	BestValid 0.6683
	Epoch 2490:	Loss 1.4079	TrainAcc 0.6721	ValidAcc 0.6665	BestValid 0.6683
	Epoch 2500:	Loss 1.4155	TrainAcc 0.6729	ValidAcc 0.6677	BestValid 0.6683
	Epoch 2510:	Loss 1.4071	TrainAcc 0.6722	ValidAcc 0.6666	BestValid 0.6683
	Epoch 2520:	Loss 1.4062	TrainAcc 0.6721	ValidAcc 0.6657	BestValid 0.6683
	Epoch 2530:	Loss 1.4095	TrainAcc 0.6728	ValidAcc 0.6679	BestValid 0.6683
	Epoch 2540:	Loss 1.4064	TrainAcc 0.6726	ValidAcc 0.6663	BestValid 0.6683
	Epoch 2550:	Loss 1.4127	TrainAcc 0.6725	ValidAcc 0.6660	BestValid 0.6683
	Epoch 2560:	Loss 1.4026	TrainAcc 0.6720	ValidAcc 0.6653	BestValid 0.6683
	Epoch 2570:	Loss 1.4077	TrainAcc 0.6726	ValidAcc 0.6658	BestValid 0.6683
	Epoch 2580:	Loss 1.4116	TrainAcc 0.6728	ValidAcc 0.6666	BestValid 0.6683
	Epoch 2590:	Loss 1.4091	TrainAcc 0.6728	ValidAcc 0.6664	BestValid 0.6683
	Epoch 2600:	Loss 1.4112	TrainAcc 0.6726	ValidAcc 0.6663	BestValid 0.6683
	Epoch 2610:	Loss 1.4057	TrainAcc 0.6732	ValidAcc 0.6679	BestValid 0.6683
	Epoch 2620:	Loss 1.4040	TrainAcc 0.6735	ValidAcc 0.6674	BestValid 0.6683
	Epoch 2630:	Loss 1.4083	TrainAcc 0.6730	ValidAcc 0.6662	BestValid 0.6683
	Epoch 2640:	Loss 1.4025	TrainAcc 0.6732	ValidAcc 0.6674	BestValid 0.6683
	Epoch 2650:	Loss 1.4081	TrainAcc 0.6728	ValidAcc 0.6673	BestValid 0.6683
	Epoch 2660:	Loss 1.4100	TrainAcc 0.6728	ValidAcc 0.6661	BestValid 0.6683
	Epoch 2670:	Loss 1.4080	TrainAcc 0.6730	ValidAcc 0.6679	BestValid 0.6683
	Epoch 2680:	Loss 1.4113	TrainAcc 0.6734	ValidAcc 0.6670	BestValid 0.6683
	Epoch 2690:	Loss 1.4044	TrainAcc 0.6733	ValidAcc 0.6670	BestValid 0.6683
	Epoch 2700:	Loss 1.4120	TrainAcc 0.6729	ValidAcc 0.6656	BestValid 0.6683
	Epoch 2710:	Loss 1.4010	TrainAcc 0.6738	ValidAcc 0.6684	BestValid 0.6684
	Epoch 2720:	Loss 1.4038	TrainAcc 0.6736	ValidAcc 0.6676	BestValid 0.6684
	Epoch 2730:	Loss 1.4100	TrainAcc 0.6733	ValidAcc 0.6672	BestValid 0.6684
	Epoch 2740:	Loss 1.4111	TrainAcc 0.6733	ValidAcc 0.6661	BestValid 0.6684
	Epoch 2750:	Loss 1.4049	TrainAcc 0.6733	ValidAcc 0.6675	BestValid 0.6684
	Epoch 2760:	Loss 1.4000	TrainAcc 0.6738	ValidAcc 0.6674	BestValid 0.6684
	Epoch 2770:	Loss 1.4033	TrainAcc 0.6737	ValidAcc 0.6674	BestValid 0.6684
	Epoch 2780:	Loss 1.4054	TrainAcc 0.6738	ValidAcc 0.6668	BestValid 0.6684
	Epoch 2790:	Loss 1.4111	TrainAcc 0.6742	ValidAcc 0.6688	BestValid 0.6688
	Epoch 2800:	Loss 1.4014	TrainAcc 0.6734	ValidAcc 0.6677	BestValid 0.6688
	Epoch 2810:	Loss 1.4016	TrainAcc 0.6735	ValidAcc 0.6667	BestValid 0.6688
	Epoch 2820:	Loss 1.4038	TrainAcc 0.6746	ValidAcc 0.6687	BestValid 0.6688
	Epoch 2830:	Loss 1.4070	TrainAcc 0.6733	ValidAcc 0.6670	BestValid 0.6688
	Epoch 2840:	Loss 1.4009	TrainAcc 0.6739	ValidAcc 0.6663	BestValid 0.6688
	Epoch 2850:	Loss 1.4032	TrainAcc 0.6746	ValidAcc 0.6689	BestValid 0.6689
	Epoch 2860:	Loss 1.4003	TrainAcc 0.6736	ValidAcc 0.6659	BestValid 0.6689
	Epoch 2870:	Loss 1.4097	TrainAcc 0.6743	ValidAcc 0.6686	BestValid 0.6689
	Epoch 2880:	Loss 1.4081	TrainAcc 0.6738	ValidAcc 0.6673	BestValid 0.6689
	Epoch 2890:	Loss 1.4011	TrainAcc 0.6739	ValidAcc 0.6676	BestValid 0.6689
	Epoch 2900:	Loss 1.4041	TrainAcc 0.6743	ValidAcc 0.6678	BestValid 0.6689
	Epoch 2910:	Loss 1.4009	TrainAcc 0.6743	ValidAcc 0.6665	BestValid 0.6689
	Epoch 2920:	Loss 1.4063	TrainAcc 0.6741	ValidAcc 0.6668	BestValid 0.6689
	Epoch 2930:	Loss 1.4036	TrainAcc 0.6740	ValidAcc 0.6665	BestValid 0.6689
	Epoch 2940:	Loss 1.4030	TrainAcc 0.6744	ValidAcc 0.6682	BestValid 0.6689
	Epoch 2950:	Loss 1.4044	TrainAcc 0.6745	ValidAcc 0.6659	BestValid 0.6689
	Epoch 2960:	Loss 1.4036	TrainAcc 0.6748	ValidAcc 0.6676	BestValid 0.6689
	Epoch 2970:	Loss 1.4029	TrainAcc 0.6739	ValidAcc 0.6675	BestValid 0.6689
	Epoch 2980:	Loss 1.3978	TrainAcc 0.6744	ValidAcc 0.6665	BestValid 0.6689
	Epoch 2990:	Loss 1.4006	TrainAcc 0.6749	ValidAcc 0.6681	BestValid 0.6689
Node 0, Layer-level comm throughput (grad): 9.837 GBps
Node 0, Layer-level comm throughput (act): -nan GBps
Node 3, Layer-level comm throughput (grad): -nan GBps
Node 1, Layer-level comm throughput (grad): -nan GBps
Node 2, Layer-level comm throughput (grad): 10.006 GBps
Node 2, Layer-level comm throughput (act): -nan GBps
Node 3, Layer-level comm throughput (act): 9.385 GBps
Node 1, Layer-level comm throughput (act): 8.706 GBps
	Epoch 3000:	Loss 1.4008	TrainAcc 0.6747	ValidAcc 0.6670	BestValid 0.6689
Node 0, GPU memory consumption: 4.689 GB
Node 0, compression time: 2.892s, compression size: 314.923GB, throughput: 108.880GBps
Node 0, decompression time: 25.743s, compression size: 314.923GB, throughput: 9.410GBps
Node 0, pure compute time: 494.024 s, total compute time: 522.659 s
Node 0, wait_for_task_time: 58.382 s, wait_for_other_gpus_time: 0.021 s
------------------------node id 0,  per-epoch time: 0.213865 s---------------
Node 3, GPU memory consumption: 4.365 GB
Node 3, compression time: 2.766s, compression size: 242.246GB, throughput: 87.576GBps
Node 3, decompression time: 23.914s, compression size: 242.246GB, throughput: 13.169GBps
Node 3, pure compute time: 396.016 s, total compute time: 422.696 s
Node 3, wait_for_task_time: 82.702 s, wait_for_other_gpus_time: 0.190 s
------------------------node id 3,  per-epoch time: 0.213865 s---------------
Node 1, GPU memory consumption: 4.365 GB
Node 1, compression time: 2.686s, compression size: 242.249GB, throughput: 90.191GBps
Node 1, decompression time: 23.814s, compression size: 242.249GB, throughput: 13.224GBps
Node 1, pure compute time: 372.403 s, total compute time: 398.903 s
Node 1, wait_for_task_time: 106.916 s, wait_for_other_gpus_time: 0.190 s
------------------------node id 1,  per-epoch time: 0.213865 s---------------
Node 2, GPU memory consumption: 4.499 GB
Node 2, compression time: 2.595s, compression size: 314.919GB, throughput: 121.368GBps
Node 2, decompression time: 15.610s, compression size: 314.919GB, throughput: 15.519GBps
Node 2, pure compute time: 510.609 s, total compute time: 528.813 s
Node 2, wait_for_task_time: 60.005 s, wait_for_other_gpus_time: 0.136 s
------------------------node id 2,  per-epoch time: 0.213865 s---------------
************ Profiling Results ************
	Bubble: 63.257627 (s) (9.79 percentage)
	Compute: 504.220119 (s) (78.00 percentage)
	GradSync: 7.598351 (s) (1.18 percentage)
	GraphComm: 0.245839 (s) (0.04 percentage)
	Imbalance: 49.970135 (s) (7.73 percentage)
	LayerComm: 21.107599 (s) (3.27 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.578 GB
Highest valid_acc: 0.6689
Target test_acc: 0.6541
Epoch to reach the target acc: 2850
Node 2, sent 1143868.936 MB data
Node 3, sent 1143868.936 MB data
Node 1, sent 1026973.233 MB data
Node 0, sent 1026973.233 MB data
[MPI Rank 2] Success 
[MPI Rank 3] Success 
[MPI Rank 1] Success 
[MPI Rank 0] Success 
