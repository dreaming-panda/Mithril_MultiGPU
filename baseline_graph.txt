gnerv2
Mon Jul  3 11:55:49 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    On   | 00000000:01:00.0 Off |                  Off |
| 30%   37C    P8    16W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    On   | 00000000:25:00.0 Off |                  Off |
| 30%   39C    P8    24W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A5000    On   | 00000000:81:00.0 Off |                  Off |
| 30%   39C    P8    22W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A5000    On   | 00000000:C1:00.0 Off |                  Off |
| 30%   39C    P8    15W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
[ 11%] Built target context
[ 36%] Built target core
[ 77%] Built target cudahelp
[ 88%] Built target OSDI2023_MULTI_NODES_gcnii
[ 88%] Built target estimate_comm_volume
[ 94%] Built target OSDI2023_MULTI_NODES_gcn
[100%] Built target OSDI2023_MULTI_NODES_graphsage
Initialized node 4 on machine gnerv1
Initialized node 7 on machine gnerv1
Initialized node 5 on machine gnerv1
Initialized node 6 on machine gnerv1
Initialized node 1 on machine gnerv2
Initialized node 2 on machine gnerv2
Initialized node 0 on machine gnerv2
Initialized node 3 on machine gnerv2
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 2.265 seconds.
Building the CSC structure...
        It takes 2.278 seconds.
Building the CSC structure...
        It takes 2.396 seconds.
Building the CSC structure...
        It takes 2.621 seconds.
Building the CSC structure...
        It takes 3.130 seconds.
Building the CSC structure...
        It takes 3.130 seconds.
Building the CSC structure...
        It takes 3.130 seconds.
Building the CSC structure...
        It takes 3.130 seconds.
Building the CSC structure...
        It takes 2.186 seconds.
        It takes 2.173 seconds.
        It takes 2.397 seconds.
        It takes 2.349 seconds.
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.577 seconds.
Building the Label Vector...
        It takes 0.049 seconds.
        It takes 3.136 seconds.
        It takes 3.136 seconds.
        It takes 3.137 seconds.
        It takes 3.137 seconds.
        It takes 0.420 seconds.
Building the Label Vector...
        It takes 0.046 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/partitioned_graphs/reddit/8_parts
The number of GCN layers: 16
The number of hidden units: 128
The number of training epoches: 50
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 5
Number of classes: 41
Number of feature dimensions: 602
Number of vertices: 232965
Number of GPUs: 8
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.249 seconds.
Building the Label Vector...
        It takes 0.029 seconds.
        It takes 0.253 seconds.
Building the Label Vector...
        It takes 0.035 seconds.
GPU 0, layer [0, 16)
*** Node 1, starting model training...
Node 1, Pipeline Input Tensor: NULL
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [0, 80)
*** Node 1, constructing the helper classes...
Building the Feature Vector...
Building the Feature Vector...
train nodes 153431, valid nodes 23831, test nodes 55703
GPU 0, layer [0, 16)
*** Node 0, starting model training...
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: NULL
*** Node 0 owns the model-level partition [0, 80)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_AGGREGATION, output tensors: 6
    Op 7: type OPERATOR_WEIGHT, output tensors: 7
    Op 8: type OPERATOR_MATMUL, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_AGGREGATION, output tensors: 11
    Op 12: type OPERATOR_WEIGHT, output tensors: 12
    Op 13: type OPERATOR_MATMUL, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_AGGREGATION, output tensors: 16
    Op 17: type OPERATOR_WEIGHT, output tensors: 17
    Op 18: type OPERATOR_MATMUL, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_AGGREGATION, output tensors: 21
    Op 22: type OPERATOR_WEIGHT, output tensors: 22
    Op 23: type OPERATOR_MATMUL, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_AGGREGATION, output tensors: 26
    Op 27: type OPERATOR_WEIGHT, output tensors: 27
    Op 28: type OPERATOR_MATMUL, output tensors: 28
    Op 29: type OPERATOR_RELU, output tensors: 29
    Op 30: type OPERATOR_DROPOUT, output tensors: 30
    Op 31: type OPERATOR_AGGREGATION, output tensors: 31
    Op 32: type OPERATOR_WEIGHT, output tensors: 32
    Op 33: type OPERATOR_MATMUL, output tensors: 33
    Op 34: type OPERATOR_RELU, output tensors: 34
    Op 35: type OPERATOR_DROPOUT, output tensors: 35
    Op 36: type OPERATOR_AGGREGATION, output tensors: 36
    Op 37: type OPERATOR_WEIGHT, output tensors: 37
    Op 38: type OPERATOR_MATMUL, output tensors: 38
    Op 39: type OPERATOR_RELU, output tensors: 39
    Op 40: type OPERATOR_DROPOUT, output tensors: 40
    Op 41: type OPERATOR_AGGREGATION, output tensors: 41
    Op 42: type OPERATOR_WEIGHT, output tensors: 42
    Op 43: type OPERATOR_MATMUL, output tensors: 43
    Op 44: type OPERATOR_RELU, output tensors: 44
    Op 45: type OPERATOR_DROPOUT, output tensors: 45
    Op 46: type OPERATOR_AGGREGATION, output tensors: 46
    Op 47: type OPERATOR_WEIGHT, output tensors: 47
    Op 48: type OPERATOR_MATMUL, output tensors: 48
    Op 49: type OPERATOR_RELU, output tensors: 49
    Op 50: type OPERATOR_DROPOUT, output tensors: 50
    Op 51: type OPERATOR_AGGREGATION, output tensors: 51
    Op 52: type OPERATOR_WEIGHT, output tensors: 52
    Op 53: type OPERATOR_MATMUL, output tensors: 53
    Op 54: type OPERATOR_RELU, output tensors: 54
    Op 55: type OPERATOR_DROPOUT, output tensors: 55
    Op 56: type OPERATOR_AGGREGATION, output tensors: 56
    Op 57: type OPERATOR_WEIGHT, output tensors: 57
    Op 58: type OPERATOR_MATMUL, output tensors: 58
    Op 59: type OPERATOR_RELU, output tensors: 59
    Op 60: type OPERATOR_DROPOUT, output tensors: 60
    Op 61: type OPERATOR_AGGREGATION, output tensors: 61
    Op 62: type OPERATOR_WEIGHT, output tensors: 62
    Op 63: type OPERATOR_MATMUL, output tensors: 63
    Op 64: type OPERATOR_RELU, output tensors: 64
    Op 65: type OPERATOR_DROPOUT, output tensors: 65
    Op 66: type OPERATOR_AGGREGATION, output tensors: 66
    Op 67: type OPERATOR_WEIGHT, output tensors: 67
    Op 68: type OPERATOR_MATMUL, output tensors: 68
    Op 69: type OPERATOR_RELU, output tensors: 69
    Op 70: type OPERATOR_DROPOUT, output tensors: 70
    Op 71: type OPERATOR_AGGREGATION, output tensors: 71
    Op 72: type OPERATOR_WEIGHT, output tensors: 72
    Op 73: type OPERATOR_MATMUL, output tensors: 73
    Op 74: type OPERATOR_RELU, output tensors: 74
    Op 75: type OPERATOR_DROPOUT, output tensors: 75
    Op 76: type OPERATOR_AGGREGATION, output tensors: 76
    Op 77: type OPERATOR_WEIGHT, output tensors: 77
    Op 78: type OPERATOR_MATMUL, output tensors: 78
    Op 79: type OPERATOR_SOFTMAX, output tensors: 79
Chunks (number of global chunks: 8): 0-[0, 29120) 1-[29120, 58241) 2-[58241, 87362) 3-[87362, 116483) 4-[116483, 145604) 5-[145604, 174724) 6-[174724, 203845) 7-[203845, 232965)
Building the Feature Vector...
232965, 114848857, 114848857
Number of vertices per chunk: 29121
Building the Feature Vector...
GPU 0, layer [0, 16)
*** Node 2, starting model training...
Node 2, Pipeline Input Tensor: NULL
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the model-level partition [0, 80)
*** Node 2, constructing the helper classes...
GPU 0, layer [0, 16)
*** Node 3, starting model training...
Node 3, Pipeline Input Tensor: NULL
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [0, 80)
*** Node 3, constructing the helper classes...
232965, 114848857, 114848857
Number of vertices per chunk: 29121
232965, 114848857, 114848857
Number of vertices per chunk: 29121
        It takes 0.566 seconds.
        It takes 1.042 seconds.
        It takes 0.898 seconds.
        It takes 0.944 seconds.
Building the Label Vector...
Building the Label Vector...
Building the Label Vector...
Building the Label Vector...
232965, 114848857, 114848857
Number of vertices per chunk: 29121
        It takes 0.104 seconds.
        It takes 0.104 seconds.
        It takes 0.104 seconds.
        It takes 0.104 seconds.
GPU 0, layer [0, 16)
*** Node 5, starting model training...
Node 5, Pipeline Input Tensor: NULL
Node 5, Pipeline Output Tensor: NULL
*** Node 5 owns the model-level partition [0, 80)
*** Node 5, constructing the helper classes...
GPU 0, layer [0, 16)
*** Node 6, starting model training...
Node 6, Pipeline Input Tensor: NULL
Node 6, Pipeline Output Tensor: NULL
*** Node 6 owns the model-level partition [0, 80)
*** Node 6, constructing the helper classes...
GPU 0, layer [0, 16)
*** Node 4, starting model training...
Node 4, Pipeline Input Tensor: NULL
Node 4, Pipeline Output Tensor: NULL
*** Node 4 owns the model-level partition [0, 80)
*** Node 4, constructing the helper classes...
GPU 0, layer [0, 16)
*** Node 7, starting model training...
Node 7, Pipeline Input Tensor: NULL
Node 7, Pipeline Output Tensor: NULL
*** Node 7 owns the model-level partition [0, 80)
*** Node 7, constructing the helper classes...
232965, 114848857, 114848857
Number of vertices per chunk: 29121
232965, 114848857, 114848857
Number of vertices per chunk: 29121
csr in-out ready !232965, 114848857, 114848857
Number of vertices per chunk: 29121
csr in-out ready !232965, 114848857, 114848857
Number of vertices per chunk: 29121
csr in-out ready !csr in-out ready !csr in-out ready !csr in-out ready !csr in-out ready !csr in-out ready !*** Node 0, setting up some other necessary information...
*** Node 4, setting up some other necessary information...
*** Node 1, setting up some other necessary information...
*** Node 5, setting up some other necessary information...
*** Node 2, setting up some other necessary information...
*** Node 6, setting up some other necessary information...
*** Node 3, setting up some other necessary information...
*** Node 7, setting up some other necessary information...
+++++++++ Node 2 initializing the weights for op[0, 80)...
+++++++++ Node 2, mapping weight op 1
+++++++++ Node 5 initializing the weights for op[0, 80)...
+++++++++ Node 5, mapping weight op 1
+++++++++ Node 3 initializing the weights for op[0, 80)...
+++++++++ Node 3, mapping weight op 42
+++++++++ Node 7 initializing the weights for op[0, 80)...
+++++++++ Node 7, mapping weight op 1
+++++++++ Node 0 initializing the weights for op[0, 80)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 4 initializing the weights for op[0, 80)...
+++++++++ Node 4, mapping weight op 1
+++++++++ Node 1 initializing the weights for op[0, 80)...
+++++++++ Node 1, mapping weight op 1
+++++++++ Node 6 initializing the weights for op[0, 80)...
+++++++++ Node 6, mapping weight op 1
+++++++++ Node 3, mapping weight op 47
+++++++++ Node 3, mapping weight op 52
+++++++++ Node 3, mapping weight op 57
+++++++++ Node 3, mapping weight op 62
+++++++++ Node 2, mapping weight op 7
+++++++++ Node 2, mapping weight op 12
+++++++++ Node 3, mapping weight op 67
+++++++++ Node 2, mapping weight op 17
+++++++++ Node 2, mapping weight op 22
+++++++++ Node 1, mapping weight op 7
+++++++++ Node 7, mapping weight op 7
+++++++++ Node 3, mapping weight op 72
+++++++++ Node 5, mapping weight op 7
+++++++++ Node 7, mapping weight op 12
+++++++++ Node 5, mapping weight op 12
+++++++++ Node 4, mapping weight op 7
+++++++++ Node 7, mapping weight op 17
+++++++++ Node 4, mapping weight op 12
+++++++++ Node 5, mapping weight op 17
+++++++++ Node 6, mapping weight op 7
+++++++++ Node 0, mapping weight op 7
+++++++++ Node 0, mapping weight op 12
+++++++++ Node 1, mapping weight op 12
+++++++++ Node 1, mapping weight op 17
+++++++++ Node 1, mapping weight op 22
+++++++++ Node 5, mapping weight op 22
+++++++++ Node 2, mapping weight op 27
+++++++++ Node 6, mapping weight op 12
+++++++++ Node 3, mapping weight op 77
+++++++++ Node 3, mapping weight op 1
+++++++++ Node 4, mapping weight op 17
+++++++++ Node 0, mapping weight op 17
+++++++++ Node 7, mapping weight op 22
+++++++++ Node 2, mapping weight op 32
+++++++++ Node 6, mapping weight op 17
+++++++++ Node 1, mapping weight op 27
+++++++++ Node 5, mapping weight op 27
+++++++++ Node 6, mapping weight op 22
+++++++++ Node 7, mapping weight op 27
+++++++++ Node 4, mapping weight op 22
+++++++++ Node 6, mapping weight op 27
+++++++++ Node 5, mapping weight op 32
+++++++++ Node 0, mapping weight op 22
+++++++++ Node 1, mapping weight op 32
+++++++++ Node 4, mapping weight op 27
+++++++++ Node 2, mapping weight op 37
+++++++++ Node 2, mapping weight op 42
+++++++++ Node 7, mapping weight op 32
+++++++++ Node 0, mapping weight op 27
+++++++++ Node 5, mapping weight op 37
+++++++++ Node 6, mapping weight op 32
+++++++++ Node 7, mapping weight op 37
+++++++++ Node 0, mapping weight op 32
+++++++++ Node 4, mapping weight op 32
+++++++++ Node 1, mapping weight op 37
+++++++++ Node 5, mapping weight op 42
+++++++++ Node 2, mapping weight op 47
+++++++++ Node 3, mapping weight op 7
+++++++++ Node 6, mapping weight op 37
+++++++++ Node 0, mapping weight op 37
+++++++++ Node 7, mapping weight op 42
+++++++++ Node 1, mapping weight op 42
+++++++++ Node 4, mapping weight op 37
+++++++++ Node 2, mapping weight op 52
+++++++++ Node 5, mapping weight op 47
+++++++++ Node 3, mapping weight op 12
+++++++++ Node 6, mapping weight op 42
+++++++++ Node 0, mapping weight op 42
+++++++++ Node 7, mapping weight op 47
+++++++++ Node 1, mapping weight op 47
+++++++++ Node 2, mapping weight op 57
+++++++++ Node 4, mapping weight op 42
+++++++++ Node 3, mapping weight op 17
+++++++++ Node 5, mapping weight op 52
+++++++++ Node 0, mapping weight op 47
+++++++++ Node 6, mapping weight op 47
+++++++++ Node 1, mapping weight op 52
+++++++++ Node 7, mapping weight op 52
+++++++++ Node 2, mapping weight op 62
+++++++++ Node 4, mapping weight op 47
+++++++++ Node 3, mapping weight op 22
+++++++++ Node 5, mapping weight op 57
+++++++++ Node 0, mapping weight op 52
+++++++++ Node 6, mapping weight op 52
+++++++++ Node 2, mapping weight op 67
+++++++++ Node 4, mapping weight op 52
+++++++++ Node 1, mapping weight op 57
+++++++++ Node 7, mapping weight op 57
+++++++++ Node 3, mapping weight op 27
+++++++++ Node 5, mapping weight op 62
+++++++++ Node 0, mapping weight op 57
+++++++++ Node 6, mapping weight op 57
+++++++++ Node 1, mapping weight op 62
+++++++++ Node 7, mapping weight op 62
+++++++++ Node 2, mapping weight op 72
+++++++++ Node 4, mapping weight op 57
+++++++++ Node 3, mapping weight op 32
+++++++++ Node 5, mapping weight op 67
+++++++++ Node 0, mapping weight op 62
+++++++++ Node 6, mapping weight op 62
+++++++++ Node 1, mapping weight op 67
+++++++++ Node 7, mapping weight op 67
+++++++++ Node 2, mapping weight op 77
+++++++++ Node 4, mapping weight op 62
+++++++++ Node 3, mapping weight op 37
+++++++++ Node 5, mapping weight op 72
+++++++++ Node 0, mapping weight op 67
+++++++++ Node 6, mapping weight op 67
+++++++++ Node 1, mapping weight op 72
+++++++++ Node 5, mapping weight op 77
+++++++++ Node 0, mapping weight op 72
+++++++++ Node 7, mapping weight op 72
+++++++++ Node 1, mapping weight op 77
+++++++++ Node 4, mapping weight op 67
+++++++++ Node 0, mapping weight op 77
+++++++++ Node 6, mapping weight op 72
+++++++++ Node 4, mapping weight op 72
+++++++++ Node 7, mapping weight op 77
+++++++++ Node 6, mapping weight op 77
+++++++++ Node 4, mapping weight op 77
Node 0, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
Node 4, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be sent across graph boundary...
Node 5, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
Node 6, discovering the vertices that will be sent across graph boundary...
Node 7, discovering the vertices that will be sent across graph boundary...
Node 4, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
Node 6, discovering the vertices that will be received across the graph boundary.
Node 5, discovering the vertices that will be received across the graph boundary.
Node 7, discovering the vertices that will be received across the graph boundary.
Node 0, discovering the vertices that will be received across the graph boundary.
Node 3, discovering the vertices that will be received across the graph boundary.
Node 2, discovering the vertices that will be received across the graph boundary.
*** Node 0, starting task scheduling...
*** Node 1, starting task scheduling...
*** Node 2, starting task scheduling...
*** Node 3, starting task scheduling...



*** Node 4, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 5, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 6, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 7, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
	Epoch 10:	Loss 3.4354	TrainAcc 0.0690	ValidAcc 0.0584	BestValid 0.0584
	Epoch 20:	Loss 3.3073	TrainAcc 0.0690	ValidAcc 0.0584	BestValid 0.0584
	Epoch 30:	Loss 3.1817	TrainAcc 0.0690	ValidAcc 0.0584	BestValid 0.0584
	Epoch 40:	Loss 3.0870	TrainAcc 0.0690	ValidAcc 0.0584	BestValid 0.0584
	Epoch 50:	Loss 3.0180	TrainAcc 0.1140	ValidAcc 0.0972	BestValid 0.0972
Node 0, GPU memory consumption: 13.710 GB
Node 1, GPU memory consumption: 13.503 GB
Node 2, GPU memory consumption: 13.510 GB
Node 3, GPU memory consumption: 13.487 GB
Node 7, GPU memory consumption: 13.483 GB
Node 5, GPU memory consumption: 13.503 GB
Node 6, GPU memory consumption: 13.506 GB
Node 4, GPU memory consumption: 13.477 GB
Node 0, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.004 ms
Node 1, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.003 ms
Node 4, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.003 ms
Node 2, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.003 ms
Node 5, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.003 ms
Node 3, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.003 ms
Node 6, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.003 ms
Node 7, Layer-Level Communication Throughput: 0.000 Gbps, Time 0.003 ms
Node 0, Graph-Level Communication Throughput: 25.458 Gbps, Time: 461.562 ms
Node 4, Graph-Level Communication Throughput: 11.715 Gbps, Time: 528.665 ms
Node 1, Graph-Level Communication Throughput: 24.061 Gbps, Time: 519.442 ms
Node 5, Graph-Level Communication Throughput: 19.371 Gbps, Time: 464.025 ms
Node 2, Graph-Level Communication Throughput: 35.918 Gbps, Time: 362.413 ms
Node 6, Graph-Level Communication Throughput: 26.383 Gbps, Time: 456.968 ms
Node 3, Graph-Level Communication Throughput: 48.704 Gbps, Time: 349.728 ms
Node 7, Graph-Level Communication Throughput: 21.565 Gbps, Time: 464.665 ms
------------------------node id 0,  per-epoch time: 0.639927 s---------------
------------------------node id 1,  per-epoch time: 0.639926 s---------------
------------------------node id 4,  per-epoch time: 0.639926 s---------------
------------------------node id 2,  per-epoch time: 0.639926 s---------------
------------------------node id 5,  per-epoch time: 0.639926 s---------------
------------------------node id 3,  per-epoch time: 0.639926 s---------------
------------------------node id 6,  per-epoch time: 0.639926 s---------------
------------------------node id 7,  per-epoch time: 0.639926 s---------------
************ Profiling Results ************
	Bubble: 1.628510 (ms) (0.26 percentage)
	Compute: 141.446596 (ms) (22.23 percentage)
	GraphCommComputeOverhead: 13.409711 (ms) (2.11 percentage)
	GraphCommNetwork: 450.932656 (ms) (70.86 percentage)
	LayerCommNetwork: 0.003238 (ms) (0.00 percentage)
	Optimization: 6.001554 (ms) (0.94 percentage)
	Other: 22.987231 (ms) (3.61 percentage)
	Layer-level communication (cluster-wide, per-epoch): 0.000 GB
	Graph-level communication (cluster-wide, per-epoch): 10.659 GB
	Weight-sync communication (cluster-wide, per-epoch): 0.009 GB
	Total communication (cluster-wide, per-epoch): 10.668 GB
Highest valid_acc: 0.0972
Target test_acc: 0.0987
Epoch to reach the target acc: 50
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 4] Success 
[MPI Rank 2] Success 
[MPI Rank 5] Success 
[MPI Rank 3] Success 
[MPI Rank 6] Success 
[MPI Rank 7] Success 
