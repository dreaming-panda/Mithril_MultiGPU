gnerv1
Wed Aug  9 19:59:13 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    On   | 00000000:01:00.0 Off |                  Off |
| 30%   28C    P8    24W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    On   | 00000000:25:00.0 Off |                  Off |
| 30%   28C    P8    24W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A5000    On   | 00000000:81:00.0 Off |                  Off |
| 30%   27C    P8    20W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A5000    On   | 00000000:C1:00.0 Off |                  Off |
| 30%   27C    P8    22W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
[ 22%] Built target context
[ 36%] Built target core
[ 77%] Built target cudahelp
[ 97%] Built target OSDI2023_MULTI_NODES_graphsage
[ 97%] Built target OSDI2023_MULTI_NODES_gcn
[ 97%] Built target estimate_comm_volume
[ 97%] Built target OSDI2023_MULTI_NODES_gcnii
Running experiments...
gnerv2
gnerv2
gnerv2
gnerv2
gnerv3
gnerv3
gnerv3
gnerv3
Initialized node 0 on machine gnerv2
Initialized node 1 on machine gnerv2
Initialized node 3 on machine gnerv2
Initialized node 2 on machine gnerv2
Initialized node 4 on machine gnerv3
Initialized node 5 on machine gnerv3
Initialized node 6 on machine gnerv3
Initialized node 7 on machine gnerv3
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.018 seconds.
Building the CSC structure...
        It takes 0.019 seconds.
Building the CSC structure...
        It takes 0.019 seconds.
Building the CSC structure...
        It takes 0.022 seconds.
Building the CSC structure...
        It takes 0.022 seconds.
Building the CSC structure...
        It takes 0.023 seconds.
Building the CSC structure...
        It takes 0.025 seconds.
Building the CSC structure...
        It takes 0.020 seconds.
        It takes 0.039 seconds.
Building the CSC structure...
        It takes 0.021 seconds.
        It takes 0.018 seconds.
        It takes 0.021 seconds.
        It takes 0.020 seconds.
        It takes 0.019 seconds.
        It takes 0.019 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.021 seconds.
Building the Feature Vector...
        It takes 0.104 seconds.
Building the Label Vector...
        It takes 0.102 seconds.
Building the Label Vector...
        It takes 0.101 seconds.
        It takes 0.102 seconds.
Building the Label Vector...
Building the Label Vector...
        It takes 0.007 seconds.
        It takes 0.007 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/weighted_shuffled_partitioned_graphs/flickr/32_parts
The number of GCN layers: 32
The number of hidden units: 100
The number of training epoches: 100
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 1
Number of classes: 7
Number of feature dimensions: 500
Number of vertices: 89250
Number of GPUs: 8
        It takes 0.007 seconds.
        It takes 0.110 seconds.
Building the Label Vector...
        It takes 0.007 seconds.
        It takes 0.108 seconds.
Building the Label Vector...
        It takes 0.107 seconds.
Building the Label Vector...
        It takes 0.008 seconds.
        It takes 0.007 seconds.
        It takes 0.007 seconds.
        It takes 0.104 seconds.
Building the Label Vector...
        It takes 0.007 seconds.
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
89250, 989006, 989006
Number of vertices per chunk: 2790
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
89250, 989006, 989006
Number of vertices per chunk: 2790
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
csr in-out ready !Start Cost Model Initialization...
89250, 989006, 989006
Number of vertices per chunk: 2790
csr in-out ready !Start Cost Model Initialization...
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
csr in-out ready !Start Cost Model Initialization...
89250, 989006, 989006
Number of vertices per chunk: 2790
train nodes 44625, valid nodes 22312, test nodes 22313
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
Chunks (number of global chunks: 32): 0-[0, 2809) 1-[2809, 5626) 2-[5626, 8426) 3-[8426, 11230) 4-[11230, 14047) 5-[14047, 16800) 6-[16800, 19507) 7-[19507, 22266) 8-[22266, 25059) ... 31-[86469, 89250)
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
89250, 989006, 989006
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
Number of vertices per chunk: 2790
89250, 989006, 989006
Number of vertices per chunk: 2790
csr in-out ready !Start Cost Model Initialization...
89250, 989006, 989006
Number of vertices per chunk: 2790
csr in-out ready !Start Cost Model Initialization...
***** Start profiling the layer-level communication performance *******
csr in-out ready !Start Cost Model Initialization...
GPU 0, layer [0, 8)
GPU 1, layer [8, 16)
GPU 2, layer [16, 24)
GPU 3, layer [24, 32)
csr in-out ready !Start Cost Model Initialization...
89250, 989006, 989006
Number of vertices per chunk: 2790
csr in-out ready !Start Cost Model Initialization...
The layer-level communication performance: 60.428 Gbps (per GPU), 483.424 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 60.147 Gbps (per GPU), 481.173 Gbps (aggregated)
The layer-level communication performance: 60.131 Gbps (per GPU), 481.046 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 59.888 Gbps (per GPU), 479.104 Gbps (aggregated)
The layer-level communication performance: 59.856 Gbps (per GPU), 478.846 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 59.651 Gbps (per GPU), 477.205 Gbps (aggregated)
The layer-level communication performance: 59.602 Gbps (per GPU), 476.816 Gbps (aggregated)
The layer-level communication performance: 59.569 Gbps (per GPU), 476.553 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The graph-level communication performance (supernode = 2): 158.111 Gbps (per GPU), 1264.889 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 158.240 Gbps (per GPU), 1265.918 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 158.204 Gbps (per GPU), 1265.630 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 158.225 Gbps (per GPU), 1265.803 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 158.025 Gbps (per GPU), 1264.201 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 158.237 Gbps (per GPU), 1265.894 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 158.103 Gbps (per GPU), 1264.821 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 158.222 Gbps (per GPU), 1265.775 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
The graph-level communication performance (supernode = 4): 100.430 Gbps (per GPU), 803.442 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.403 Gbps (per GPU), 803.224 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.429 Gbps (per GPU), 803.436 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.421 Gbps (per GPU), 803.365 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.430 Gbps (per GPU), 803.441 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.419 Gbps (per GPU), 803.353 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.430 Gbps (per GPU), 803.442 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.421 Gbps (per GPU), 803.372 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
The graph-level communication performance (supernode = 8): 33.246 Gbps (per GPU), 265.971 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.246 Gbps (per GPU), 265.966 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.248 Gbps (per GPU), 265.981 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.247 Gbps (per GPU), 265.972 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.243 Gbps (per GPU), 265.943 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.243 Gbps (per GPU), 265.947 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.242 Gbps (per GPU), 265.938 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.240 Gbps (per GPU), 265.918 Gbps (aggregated, cluster-wide)
 LType   LT0   LT1   LT2 Ratio  VSum  ESum
 chk_0  0.32ms  0.26ms  0.22ms  1.47  2.81K  0.03M
 chk_1  0.32ms  0.26ms  0.22ms  1.44  2.82K  0.03M
 chk_2  0.31ms  0.26ms  0.22ms  1.45  2.80K  0.03M
 chk_3  0.31ms  0.26ms  0.22ms  1.43  2.80K  0.03M
 chk_4  0.32ms  0.26ms  0.22ms  1.44  2.82K  0.03M
 chk_5  0.32ms  0.27ms  0.22ms  1.44  2.75K  0.03M
 chk_6  0.31ms  0.26ms  0.21ms  1.47  2.71K  0.03M
 chk_7  0.31ms  0.26ms  0.21ms  1.47  2.76K  0.03M
 chk_8  0.31ms  0.26ms  0.21ms  1.46  2.79K  0.03M
 chk_9  0.31ms  0.26ms  0.21ms  1.48  2.81K  0.03M
chk_10  0.31ms  0.26ms  0.21ms  1.46  2.81K  0.03M
chk_11  0.32ms  0.27ms  0.22ms  1.43  2.74K  0.03M
chk_12  0.32ms  0.27ms  0.22ms  1.45  2.76K  0.03M
chk_13  0.31ms  0.26ms  0.22ms  1.44  2.75K  0.03M
chk_14  0.31ms  0.26ms  0.22ms  1.45  2.81K  0.03M
chk_15  0.31ms  0.26ms  0.22ms  1.45  2.77K  0.03M
chk_16  0.31ms  0.26ms  0.22ms  1.44  2.78K  0.03M
chk_17  0.31ms  0.26ms  0.22ms  1.44  2.79K  0.03M
chk_18  0.31ms  0.26ms  0.22ms  1.44  2.82K  0.03M
chk_19  0.31ms  0.26ms  0.21ms  1.46  2.81K  0.03M
chk_20  0.32ms  0.26ms  0.22ms  1.44  2.77K  0.03M
chk_21  0.31ms  0.26ms  0.22ms  1.45  2.84K  0.02M
chk_22  0.31ms  0.26ms  0.22ms  1.43  2.78K  0.03M
chk_23  0.31ms  0.26ms  0.22ms  1.43  2.80K  0.03M
chk_24  0.31ms  0.26ms  0.22ms  1.45  2.80K  0.03M
chk_25  0.31ms  0.26ms  0.21ms  1.46  2.81K  0.03M
chk_26  0.31ms  0.26ms  0.21ms  1.45  2.81K  0.03M
chk_27  0.31ms  0.26ms  0.22ms  1.44  2.79K  0.03M
chk_28  0.31ms  0.26ms  0.22ms  1.43  2.77K  0.03M
chk_29  0.31ms  0.26ms  0.22ms  1.44  2.77K  0.03M
chk_30  0.31ms  0.26ms  0.22ms  1.44  2.80K  0.03M
chk_31  0.31ms  0.26ms  0.22ms  1.45  2.78K  0.03M
   Avg  0.31  0.26  0.22
   Max  0.32  0.27  0.22
   Min  0.31  0.26  0.21
 Ratio  1.05  1.04  1.07
   Var  0.00  0.00  0.00
Profiling takes 0.386 s
Evaluating the performance of the pure model-parallel execution plan.
The bottleneck stage in the optimal plan: 35.150 ms
Partition 0 [0, 4) has cost: 35.150 ms
Partition 1 [4, 8) has cost: 33.505 ms
Partition 2 [8, 12) has cost: 33.505 ms
Partition 3 [12, 16) has cost: 33.505 ms
Partition 4 [16, 20) has cost: 33.505 ms
Partition 5 [20, 24) has cost: 33.505 ms
Partition 6 [24, 28) has cost: 33.505 ms
Partition 7 [28, 32) has cost: 32.053 ms
The optimal partitioning:
[0, 4)
[4, 8)
[8, 12)
[12, 16)
[16, 20)
[20, 24)
[24, 28)
[28, 32)
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 21.122 ms
GPU 0, Compute+Comm Time: 17.491 ms, Bubble Time: 3.631 ms, Imbalance Overhead: 0.000 ms
GPU 1, Compute+Comm Time: 16.669 ms, Bubble Time: 3.648 ms, Imbalance Overhead: 0.805 ms
GPU 2, Compute+Comm Time: 16.669 ms, Bubble Time: 3.670 ms, Imbalance Overhead: 0.783 ms
GPU 3, Compute+Comm Time: 16.669 ms, Bubble Time: 3.693 ms, Imbalance Overhead: 0.760 ms
GPU 4, Compute+Comm Time: 16.669 ms, Bubble Time: 3.716 ms, Imbalance Overhead: 0.737 ms
GPU 5, Compute+Comm Time: 16.669 ms, Bubble Time: 3.743 ms, Imbalance Overhead: 0.710 ms
GPU 6, Compute+Comm Time: 16.669 ms, Bubble Time: 3.774 ms, Imbalance Overhead: 0.679 ms
GPU 7, Compute+Comm Time: 15.528 ms, Bubble Time: 3.821 ms, Imbalance Overhead: 1.772 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 32.898 ms
GPU 0, Compute+Comm Time: 25.977 ms, Bubble Time: 5.939 ms, Imbalance Overhead: 0.982 ms
GPU 1, Compute+Comm Time: 26.288 ms, Bubble Time: 5.918 ms, Imbalance Overhead: 0.692 ms
GPU 2, Compute+Comm Time: 26.288 ms, Bubble Time: 5.879 ms, Imbalance Overhead: 0.731 ms
GPU 3, Compute+Comm Time: 26.288 ms, Bubble Time: 5.855 ms, Imbalance Overhead: 0.755 ms
GPU 4, Compute+Comm Time: 26.288 ms, Bubble Time: 5.838 ms, Imbalance Overhead: 0.772 ms
GPU 5, Compute+Comm Time: 26.288 ms, Bubble Time: 5.820 ms, Imbalance Overhead: 0.790 ms
GPU 6, Compute+Comm Time: 26.288 ms, Bubble Time: 5.798 ms, Imbalance Overhead: 0.812 ms
GPU 7, Compute+Comm Time: 27.112 ms, Bubble Time: 5.778 ms, Imbalance Overhead: 0.008 ms
The estimated cost of the whole pipeline: 56.721 ms

Evaluating the hybrid-parallelism execution plan with 2 DP ways.
The bottleneck stage in the optimal plan: 68.655 ms
Partition 0 [0, 8) has cost: 68.655 ms
Partition 1 [8, 16) has cost: 67.010 ms
Partition 2 [16, 24) has cost: 67.010 ms
Partition 3 [24, 32) has cost: 65.558 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 24.558 ms
GPU 0, Compute+Comm Time: 20.785 ms, Bubble Time: 3.773 ms, Imbalance Overhead: 0.000 ms
GPU 1, Compute+Comm Time: 20.376 ms, Bubble Time: 3.791 ms, Imbalance Overhead: 0.392 ms
GPU 2, Compute+Comm Time: 20.376 ms, Bubble Time: 3.829 ms, Imbalance Overhead: 0.353 ms
GPU 3, Compute+Comm Time: 19.805 ms, Bubble Time: 3.897 ms, Imbalance Overhead: 0.856 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 36.061 ms
GPU 0, Compute+Comm Time: 29.853 ms, Bubble Time: 5.704 ms, Imbalance Overhead: 0.504 ms
GPU 1, Compute+Comm Time: 30.002 ms, Bubble Time: 5.666 ms, Imbalance Overhead: 0.392 ms
GPU 2, Compute+Comm Time: 30.002 ms, Bubble Time: 5.634 ms, Imbalance Overhead: 0.424 ms
GPU 3, Compute+Comm Time: 30.421 ms, Bubble Time: 5.620 ms, Imbalance Overhead: 0.019 ms
    The estimated cost with 2 DP ways is 63.650 ms

Evaluating the hybrid-parallelism execution plan with 4 DP ways.
The bottleneck stage in the optimal plan: 135.665 ms
Partition 0 [0, 16) has cost: 135.665 ms
Partition 1 [16, 32) has cost: 132.567 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 38.432 ms
GPU 0, Compute+Comm Time: 34.242 ms, Bubble Time: 4.190 ms, Imbalance Overhead: 0.000 ms
GPU 1, Compute+Comm Time: 33.752 ms, Bubble Time: 4.263 ms, Imbalance Overhead: 0.417 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 49.350 ms
GPU 0, Compute+Comm Time: 43.613 ms, Bubble Time: 5.475 ms, Imbalance Overhead: 0.262 ms
GPU 1, Compute+Comm Time: 43.899 ms, Bubble Time: 5.426 ms, Imbalance Overhead: 0.025 ms
    The estimated cost with 4 DP ways is 92.171 ms

Evaluating the hybrid-parallelism execution plan with 8 DP ways.
The bottleneck stage in the optimal plan: 268.232 ms
Partition 0 [0, 32) has cost: 268.232 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 133.860 ms
GPU 0, Compute+Comm Time: 133.860 ms, Bubble Time: 0.000 ms, Imbalance Overhead: 0.000 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 143.632 ms
GPU 0, Compute+Comm Time: 143.632 ms, Bubble Time: 0.000 ms, Imbalance Overhead: 0.000 ms
    The estimated cost with 8 DP ways is 291.367 ms

*** Node 0, starting model training...
Num Stages: 4 / 4
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the model-level partition [0, 41)
*** Node 0, constructing the helper classes...
Node 0, Local Vertex Begin: 0, Num Local Vertices: 44517
*** Node 4, starting model training...
Num Stages: 4 / 4
Node 4, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 4, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 4 owns the model-level partition [81, 121)
*** Node 4, constructing the helper classes...
Node 4, Local Vertex Begin: 0, Num Local Vertices: 44517
*** Node 1, starting model training...
Num Stages: 4 / 4
Node 1, Pipeline Input Tensor: NULL
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the model-level partition [0, 41)
*** Node 1, constructing the helper classes...
Node 1, Local Vertex Begin: 44517, Num Local Vertices: 44733
*** Node 5, starting model training...
Num Stages: 4 / 4
Node 5, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 5, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 5 owns the model-level partition [81, 121)
*** Node 5, constructing the helper classes...
Node 5, Local Vertex Begin: 44517, Num Local Vertices: 44733
*** Node 3, starting model training...
Num Stages: 4 / 4
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 3 owns the model-level partition [41, 81)
*** Node 3, constructing the helper classes...
Node 3, Local Vertex Begin: 44517, Num Local Vertices: 44733
*** Node 6, starting model training...
Num Stages: 4 / 4
Node 6, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 6, Pipeline Output Tensor: NULL
*** Node 6 owns the model-level partition [121, 160)
*** Node 6, constructing the helper classes...
Node 6, Local Vertex Begin: 0, Num Local Vertices: 44517
*** Node 2, starting model training...
Num Stages: 4 / 4
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the model-level partition [41, 81)
*** Node 2, constructing the helper classes...
Node 2, Local Vertex Begin: 0, Num Local Vertices: 44517
*** Node 7, starting model training...
Num Stages: 4 / 4
Node 7, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 7, Pipeline Output Tensor: NULL
*** Node 7 owns the model-level partition [121, 160)
*** Node 7, constructing the helper classes...
Node 7, Local Vertex Begin: 44517, Num Local Vertices: 44733
*** Node 4, setting up some other necessary information...
*** Node 0, setting up some other necessary information...
*** Node 5, setting up some other necessary information...
*** Node 6, setting up some other necessary information...
*** Node 7, setting up some other necessary information...
*** Node 1, setting up some other necessary information...
*** Node 2, setting up some other necessary information...
*** Node 3, setting up some other necessary information...
+++++++++ Node 0 initializing the weights for op[0, 41)...
+++++++++ Node 5 initializing the weights for op[81, 121)...
+++++++++ Node 1 initializing the weights for op[0, 41)...
+++++++++ Node 6 initializing the weights for op[121, 160)...
+++++++++ Node 2 initializing the weights for op[41, 81)...
+++++++++ Node 7 initializing the weights for op[121, 160)...
+++++++++ Node 3 initializing the weights for op[41, 81)...
+++++++++ Node 4 initializing the weights for op[81, 121)...
Node 4, discovering the vertices that will be sent across graph boundary...
Node 0, discovering the vertices that will be sent across graph boundary...
Node 5, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be sent across graph boundary...
Node 6, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
Node 7, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
The number of mirror vertices: 300780
Node 0, discovering the vertices that will be received across the graph boundary.
Node 4, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
Node 5, discovering the vertices that will be received across the graph boundary.
Node 2, discovering the vertices that will be received across the graph boundary.
Node 6, discovering the vertices that will be received across the graph boundary.
Node 3, discovering the vertices that will be received across the graph boundary.
Node 7, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
*** Node 2, starting task scheduling...
*** Node 1, starting task scheduling...
*** Node 0, starting task scheduling...
*** Node 3, starting task scheduling...



*** Node 4, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 5, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 6, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
*** Node 7, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
	Epoch 50:	Loss 1.6706
	Epoch 100:	Loss 1.6360
****** Epoch Time (Excluding Evaluation Cost): 0.090 s ******
****** Breakdown Analysis ******
Cluster-Wide Average, Bubble-Pipeline: 13.293 ms (Max: 13.638, Min: 12.672, Sum: 106.346)
Cluster-Wide Average, Compute: 37.375 ms (Max: 38.638, Min: 36.031, Sum: 299.004)
Cluster-Wide Average, Communication-Layer: 6.528 ms (Max: 7.654, Min: 5.716, Sum: 52.221)
Cluster-Wide Average, Bubble-Imbalance: 2.771 ms (Max: 4.173, Min: 1.758, Sum: 22.165)
Cluster-Wide Average, Communication-Graph: 26.889 ms (Max: 27.652, Min: 26.195, Sum: 215.114)
Cluster-Wide Average, Optimization: 1.646 ms (Max: 1.962, Min: 1.455, Sum: 13.169)
Cluster-Wide Average, Others: 1.956 ms (Max: 3.252, Min: 1.458, Sum: 15.646)
****** Breakdown Sum: 90.458 ms ******
Cluster-Wide Average, GPU Memory Consumption: 3.266 GB (Max: 3.921, Min: 3.036, Sum: 26.130)
Cluster-Wide Average, Graph-Level Communication Throughput: 98.306 Gbps (Max: 103.309, Min: 93.300, Sum: 786.451)
Cluster-Wide Average, Layer-Level Communication Throughput: 32.026 Gbps (Max: 40.978, Min: 23.721, Sum: 256.209)
Layer-level communication (cluster-wide, per-epoch): 0.199 GB
Graph-level communication (cluster-wide, per-epoch): 1.793 GB
Weight-sync communication (cluster-wide, per-epoch): 0.003 GB
Total communication (cluster-wide, per-epoch): 1.995 GB
[MPI Rank 0] Success 
[MPI Rank 4] Success 
[MPI Rank 1] Success 
[MPI Rank 5] Success 
[MPI Rank 2] Success 
[MPI Rank 6] Success 
[MPI Rank 3] Success 
[MPI Rank 7] Success 
