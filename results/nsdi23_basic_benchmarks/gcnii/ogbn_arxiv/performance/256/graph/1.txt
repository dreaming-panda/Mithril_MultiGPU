Initialized node 4 on machine gnerv2
Initialized node 5 on machine gnerv2
Initialized node 6 on machine gnerv2
Initialized node 7 on machine gnerv2
Initialized node 0 on machine gnerv1
Initialized node 1 on machine gnerv1
Initialized node 2 on machine gnerv1
Initialized node 3 on machine gnerv1
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.043 seconds.
Building the CSC structure...
        It takes 0.049 seconds.
Building the CSC structure...
        It takes 0.054 seconds.
Building the CSC structure...
        It takes 0.056 seconds.
Building the CSC structure...
        It takes 0.055 seconds.
Building the CSC structure...
        It takes 0.056 seconds.
Building the CSC structure...
        It takes 0.062 seconds.
Building the CSC structure...
        It takes 0.065 seconds.
Building the CSC structure...
        It takes 0.044 seconds.
        It takes 0.044 seconds.
        It takes 0.051 seconds.
        It takes 0.051 seconds.
        It takes 0.051 seconds.
        It takes 0.055 seconds.
Building the Feature Vector...
        It takes 0.053 seconds.
Building the Feature Vector...
        It takes 0.057 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.057 seconds.
Building the Label Vector...
        It takes 0.057 seconds.
Building the Label Vector...
        It takes 0.054 seconds.
Building the Label Vector...
        It takes 0.056 seconds.
Building the Label Vector...
        It takes 0.060 seconds.
Building the Label Vector...
        It takes 0.061 seconds.
Building the Label Vector...
        It takes 0.025 seconds.
        It takes 0.024 seconds.
        It takes 0.066 seconds.
Building the Label Vector...
        It takes 0.022 seconds.
        It takes 0.066 seconds.
        It takes 0.024 seconds.
Building the Label Vector...
        It takes 0.024 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/partitioned_graphs/ogbn_arxiv/8_parts
The number of GCNII layers: 128
The number of hidden units: 256
The number of training epoches: 100
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 1
GCN hyper-parameter alpha: 0.100000
GCN hyper-parameter lambda: 0.500000
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
Number of GPUs: 8
        It takes 0.025 seconds.
        It takes 0.026 seconds.
        It takes 0.027 seconds.
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
169343, 2484941, 2484941
Number of vertices per chunk: 21168
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
169343, 2484941, 2484941
Number of vertices per chunk: 21168
169343, 2484941, 2484941
Number of vertices per chunk: 21168
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
csr in-out ready !Start Cost Model Initialization...
169343, 2484941, 2484941
Number of vertices per chunk: 21168
169343, 2484941, 2484941
Number of vertices per chunk: 21168
169343, 2484941, 2484941
Number of vertices per chunk: 21168
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
train nodes 90941, valid nodes 29799, test nodes 48603
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
Chunks (number of global chunks: 8): 0-[0, 21167) 1-[21167, 42335) 2-[42335, 63503) 3-[63503, 84671) 4-[84671, 105839) 5-[105839, 127007) 6-[127007, 148175) 7-[148175, 169343)
csr in-out ready !Start Cost Model Initialization...
GPU 0, layer [0, 129)
WARNING: the current version only applies to linear GNN models!
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
169343, 2484941, 2484941
Number of vertices per chunk: 21168
169343, 2484941, 2484941
Number of vertices per chunk: 21168
csr in-out ready !Start Cost Model Initialization...
***** Start profiling the layer-level communication performance *******
csr in-out ready !Start Cost Model Initialization...
The layer-level communication performance: 64.014 Gbps (per GPU), 512.114 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 63.972 Gbps (per GPU), 511.776 Gbps (aggregated)
The layer-level communication performance: 63.970 Gbps (per GPU), 511.757 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 63.936 Gbps (per GPU), 511.486 Gbps (aggregated)
The layer-level communication performance: 63.930 Gbps (per GPU), 511.440 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 63.899 Gbps (per GPU), 511.194 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 63.893 Gbps (per GPU), 511.142 Gbps (aggregated)
The layer-level communication performance: 63.888 Gbps (per GPU), 511.106 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The graph-level communication performance (supernode = 2): 166.279 Gbps (per GPU), 1330.228 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 166.274 Gbps (per GPU), 1330.196 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 166.275 Gbps (per GPU), 1330.199 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 166.277 Gbps (per GPU), 1330.219 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 166.277 Gbps (per GPU), 1330.219 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 166.271 Gbps (per GPU), 1330.166 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 166.280 Gbps (per GPU), 1330.238 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 166.276 Gbps (per GPU), 1330.205 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
The graph-level communication performance (supernode = 4): 114.088 Gbps (per GPU), 912.707 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 114.089 Gbps (per GPU), 912.711 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 114.086 Gbps (per GPU), 912.686 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 114.078 Gbps (per GPU), 912.625 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 114.083 Gbps (per GPU), 912.664 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 114.082 Gbps (per GPU), 912.660 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 114.081 Gbps (per GPU), 912.651 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 114.083 Gbps (per GPU), 912.661 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.754 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.751 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.753 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.748 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.754 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.752 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.749 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 45.469 Gbps (per GPU), 363.752 Gbps (aggregated, cluster-wide)
 LType   LT0   LT1   LT2 Ratio  VSum  ESum
 chk_0  1.15ms  3.17ms  3.60ms  3.13 21.17K  0.46M
 chk_1  1.15ms  3.39ms  3.82ms  3.33 21.17K  0.55M
 chk_2  1.15ms  3.13ms  3.57ms  3.12 21.17K  0.39M
 chk_3  1.15ms  3.02ms  3.47ms  3.02 21.17K  0.24M
 chk_4  1.15ms  2.91ms  3.35ms  2.92 21.17K  0.17M
 chk_5  1.15ms  2.92ms  3.35ms  2.92 21.17K  0.22M
 chk_6  1.15ms  2.93ms  3.37ms  2.94 21.17K  0.16M
 chk_7  1.15ms  2.89ms  3.33ms  2.90 21.17K  0.12M
   Avg  1.15  3.04  3.48
   Max  1.15  3.39  3.82
   Min  1.15  2.89  3.33
 Ratio  1.00  1.17  1.15
   Var  0.00  0.03  0.03
Profiling takes 0.803 s
Evaluating the performance of the pure model-parallel execution plan.
The bottleneck stage in the optimal plan: 398.796 ms
Partition 0 [0, 17) has cost: 398.796 ms
Partition 1 [17, 33) has cost: 389.618 ms
Partition 2 [33, 49) has cost: 389.618 ms
Partition 3 [49, 65) has cost: 389.618 ms
Partition 4 [65, 81) has cost: 389.618 ms
Partition 5 [81, 97) has cost: 389.618 ms
Partition 6 [97, 113) has cost: 389.618 ms
Partition 7 [113, 129) has cost: 393.125 ms
The optimal partitioning:
[0, 17)
[17, 33)
[33, 49)
[49, 65)
[65, 81)
[81, 97)
[97, 113)
[113, 129)
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 274.810 ms
GPU 0, Compute+Comm Time: 141.633 ms, Bubble Time: 121.595 ms, Imbalance Overhead: 11.582 ms
GPU 1, Compute+Comm Time: 139.051 ms, Bubble Time: 120.690 ms, Imbalance Overhead: 15.070 ms
GPU 2, Compute+Comm Time: 139.051 ms, Bubble Time: 122.280 ms, Imbalance Overhead: 13.480 ms
GPU 3, Compute+Comm Time: 139.051 ms, Bubble Time: 124.143 ms, Imbalance Overhead: 11.617 ms
GPU 4, Compute+Comm Time: 139.051 ms, Bubble Time: 126.599 ms, Imbalance Overhead: 9.161 ms
GPU 5, Compute+Comm Time: 139.051 ms, Bubble Time: 129.012 ms, Imbalance Overhead: 6.748 ms
GPU 6, Compute+Comm Time: 139.051 ms, Bubble Time: 131.412 ms, Imbalance Overhead: 4.348 ms
GPU 7, Compute+Comm Time: 139.755 ms, Bubble Time: 134.001 ms, Imbalance Overhead: 1.054 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 580.576 ms
GPU 0, Compute+Comm Time: 296.712 ms, Bubble Time: 281.902 ms, Imbalance Overhead: 1.962 ms
GPU 1, Compute+Comm Time: 293.909 ms, Bubble Time: 276.978 ms, Imbalance Overhead: 9.688 ms
GPU 2, Compute+Comm Time: 293.909 ms, Bubble Time: 272.499 ms, Imbalance Overhead: 14.167 ms
GPU 3, Compute+Comm Time: 293.909 ms, Bubble Time: 267.857 ms, Imbalance Overhead: 18.810 ms
GPU 4, Compute+Comm Time: 293.909 ms, Bubble Time: 263.154 ms, Imbalance Overhead: 23.513 ms
GPU 5, Compute+Comm Time: 293.909 ms, Bubble Time: 259.688 ms, Imbalance Overhead: 26.979 ms
GPU 6, Compute+Comm Time: 293.909 ms, Bubble Time: 256.482 ms, Imbalance Overhead: 30.184 ms
GPU 7, Compute+Comm Time: 300.505 ms, Bubble Time: 258.308 ms, Imbalance Overhead: 21.762 ms
The estimated cost of the whole pipeline: 898.156 ms

Evaluating the hybrid-parallelism execution plan with 2 DP ways.
The bottleneck stage in the optimal plan: 788.413 ms
Partition 0 [0, 33) has cost: 788.413 ms
Partition 1 [33, 65) has cost: 779.235 ms
Partition 2 [65, 97) has cost: 779.235 ms
Partition 3 [97, 129) has cost: 782.742 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 373.781 ms
GPU 0, Compute+Comm Time: 209.057 ms, Bubble Time: 152.916 ms, Imbalance Overhead: 11.808 ms
GPU 1, Compute+Comm Time: 207.765 ms, Bubble Time: 155.862 ms, Imbalance Overhead: 10.154 ms
GPU 2, Compute+Comm Time: 207.765 ms, Bubble Time: 160.774 ms, Imbalance Overhead: 5.242 ms
GPU 3, Compute+Comm Time: 208.117 ms, Bubble Time: 165.664 ms, Imbalance Overhead: 0.000 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 659.026 ms
GPU 0, Compute+Comm Time: 365.950 ms, Bubble Time: 293.076 ms, Imbalance Overhead: 0.000 ms
GPU 1, Compute+Comm Time: 364.547 ms, Bubble Time: 283.766 ms, Imbalance Overhead: 10.714 ms
GPU 2, Compute+Comm Time: 364.547 ms, Bubble Time: 274.130 ms, Imbalance Overhead: 20.349 ms
GPU 3, Compute+Comm Time: 367.847 ms, Bubble Time: 268.188 ms, Imbalance Overhead: 22.992 ms
    The estimated cost with 2 DP ways is 1084.447 ms

Evaluating the hybrid-parallelism execution plan with 4 DP ways.
The bottleneck stage in the optimal plan: 1567.649 ms
Partition 0 [0, 65) has cost: 1567.649 ms
Partition 1 [65, 129) has cost: 1561.978 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 658.850 ms
GPU 0, Compute+Comm Time: 436.225 ms, Bubble Time: 212.900 ms, Imbalance Overhead: 9.725 ms
GPU 1, Compute+Comm Time: 435.757 ms, Bubble Time: 223.093 ms, Imbalance Overhead: 0.000 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 904.328 ms
GPU 0, Compute+Comm Time: 596.126 ms, Bubble Time: 308.202 ms, Imbalance Overhead: 0.000 ms
GPU 1, Compute+Comm Time: 597.078 ms, Bubble Time: 288.403 ms, Imbalance Overhead: 18.846 ms
    The estimated cost with 4 DP ways is 1641.337 ms

Evaluating the hybrid-parallelism execution plan with 8 DP ways.
The bottleneck stage in the optimal plan: 3129.627 ms
Partition 0 [0, 129) has cost: 3129.627 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 1841.007 ms
GPU 0, Compute+Comm Time: 1841.007 ms, Bubble Time: 0.000 ms, Imbalance Overhead: 0.000 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 2010.981 ms
GPU 0, Compute+Comm Time: 2010.981 ms, Bubble Time: 0.000 ms, Imbalance Overhead: 0.000 ms
    The estimated cost with 8 DP ways is 4044.588 ms

*** Node 0, starting model training...
Num Stages: 1 / 1
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: NULL
*** Node 0 owns the model-level partition [0, 905)
*** Node 0, constructing the helper classes...
*** Node 1, starting model training...
Num Stages: 1 / 1
Node 1, Pipeline Input Tensor: NULL
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [0, 905)
*** Node 1, constructing the helper classes...
*** Node 4, starting model training...
Num Stages: 1 / 1
Node 4, Pipeline Input Tensor: NULL
Node 4, Pipeline Output Tensor: NULL
*** Node 4 owns the model-level partition [0, 905)
*** Node 4, constructing the helper classes...
*** Node 3, starting model training...
Num Stages: 1 / 1
Node 3, Pipeline Input Tensor: NULL
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [0, 905)
*** Node 3, constructing the helper classes...
*** Node 5, starting model training...
Num Stages: 1 / 1
Node 5, Pipeline Input Tensor: NULL
Node 5, Pipeline Output Tensor: NULL
*** Node 5 owns the model-level partition [0, 905)
*** Node 5, constructing the helper classes...
*** Node 2, starting model training...
Num Stages: 1 / 1
Node 2, Pipeline Input Tensor: NULL
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the model-level partition [0, 905)
*** Node 2, constructing the helper classes...
*** Node 6, starting model training...
Num Stages: 1 / 1
Node 6, Pipeline Input Tensor: NULL
Node 6, Pipeline Output Tensor: NULL
*** Node 6 owns the model-level partition [0, 905)
*** Node 6, constructing the helper classes...
*** Node 7, starting model training...
Num Stages: 1 / 1
Node 7, Pipeline Input Tensor: NULL
Node 7, Pipeline Output Tensor: NULL
*** Node 7 owns the model-level partition [0, 905)
*** Node 7, constructing the helper classes...
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2721: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.data != NULL' failed.
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2721: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.data != NULL' failed.
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2734: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.grad != NULL' failed.
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2721: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.data != NULL' failed.
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2721: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.data != NULL' failed.
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2721: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.data != NULL' failed.
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2721: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.data != NULL' failed.
gcnii: /shared_ssd_storage/jingjichen/Mithril_MultiGPU/core/src/cuda/cuda_hybrid_parallel.cc:2721: CUDAVertexTensorDataGradManager::CUDAVertexTensorDataGradManager(CUDAOperatorsAndTensorsManager*, CUDAVertexIdTranslationTable*, int, int, VertexId, Tensor*, Tensor*): Assertion `lvt.data != NULL' failed.

===================================================================================
=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES
=   PID 27550 RUNNING AT gnerv1
=   EXIT CODE: 6
=   CLEANING UP REMAINING PROCESSES
=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES
===================================================================================
YOUR APPLICATION TERMINATED WITH THE EXIT STRING: Aborted (signal 6)
This typically refers to a problem with your application.
Please see the FAQ page for debugging suggestions
