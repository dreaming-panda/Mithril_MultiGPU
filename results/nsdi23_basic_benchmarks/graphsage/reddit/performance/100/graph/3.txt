Initialized node 7 on machine gnerv2
Initialized node 6 on machine gnerv2
Initialized node 4 on machine gnerv2
Initialized node 5 on machine gnerv2
Initialized node 0 on machine gnerv1
Initialized node 1 on machine gnerv1
Initialized node 3 on machine gnerv1
Initialized node 2 on machine gnerv1
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.873 seconds.
Building the CSC structure...
        It takes 1.885 seconds.
Building the CSC structure...
        It takes 2.029 seconds.
Building the CSC structure...
        It takes 2.368 seconds.
Building the CSC structure...
        It takes 2.387 seconds.
Building the CSC structure...
        It takes 2.426 seconds.
Building the CSC structure...
        It takes 2.450 seconds.
Building the CSC structure...
        It takes 2.604 seconds.
Building the CSC structure...
        It takes 1.834 seconds.
        It takes 1.838 seconds.
        It takes 1.855 seconds.
        It takes 2.248 seconds.
Building the Feature Vector...
Building the Feature Vector...
        It takes 2.355 seconds.
        It takes 2.398 seconds.
        It takes 2.373 seconds.
        It takes 2.345 seconds.
        It takes 0.277 seconds.
Building the Label Vector...
        It takes 0.041 seconds.
        It takes 0.310 seconds.
Building the Label Vector...
        It takes 0.047 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.280 seconds.
Building the Label Vector...
        It takes 0.031 seconds.
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
        It takes 0.284 seconds.
Building the Label Vector...
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
Building the Feature Vector...
        It takes 0.033 seconds.
        It takes 0.303 seconds.
Building the Label Vector...
        It takes 0.032 seconds.
        It takes 0.304 seconds.
Building the Label Vector...
        It takes 0.037 seconds.
Building the Feature Vector...
        It takes 0.269 seconds.
Building the Label Vector...
232965, 114848857, 114848857
Number of vertices per chunk: 29121
        It takes 0.032 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/partitioned_graphs/reddit/8_parts
The number of GCNII layers: 32
The number of hidden units: 100
The number of training epoches: 5000
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 3
Number of classes: 41
Number of feature dimensions: 602
Number of vertices: 232965
Number of GPUs: 8
        It takes 0.253 seconds.
Building the Label Vector...
232965, 114848857, 114848857
Number of vertices per chunk: 29121
        It takes 0.032 seconds.
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
train nodes 153431, valid nodes 23831, test nodes 55703
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
Chunks (number of global chunks: 8): 0-[0, 29120) 1-[29120, 58241) 2-[58241, 87362) 3-[87362, 116483) 4-[116483, 145604) 5-[145604, 174724) 6-[174724, 203845) 7-[203845, 232965)
232965, 114848857, 114848857
Number of vertices per chunk: 29121
232965, 114848857, 114848857
Number of vertices per chunk: 29121
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
232965, 114848857, 114848857
Number of vertices per chunk: 29121
232965, 114848857, 114848857
Number of vertices per chunk: 29121
232965, 114848857, 114848857
Number of vertices per chunk: 29121
232965, 114848857, 114848857
Number of vertices per chunk: 29121
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
***** Start profiling the layer-level communication performance *******
csr in-out ready !Start Cost Model Initialization...
The layer-level communication performance: 55.957 Gbps (per GPU), 447.652 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 55.690 Gbps (per GPU), 445.518 Gbps (aggregated)
The layer-level communication performance: 55.798 Gbps (per GPU), 446.384 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 55.477 Gbps (per GPU), 443.820 Gbps (aggregated)
The layer-level communication performance: 55.440 Gbps (per GPU), 443.522 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 55.276 Gbps (per GPU), 442.205 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 55.312 Gbps (per GPU), 442.495 Gbps (aggregated)
The layer-level communication performance: 55.204 Gbps (per GPU), 441.633 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The graph-level communication performance (supernode = 2): 160.800 Gbps (per GPU), 1286.399 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.791 Gbps (per GPU), 1286.325 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.803 Gbps (per GPU), 1286.424 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.791 Gbps (per GPU), 1286.325 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.806 Gbps (per GPU), 1286.448 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.815 Gbps (per GPU), 1286.522 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.806 Gbps (per GPU), 1286.448 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 160.800 Gbps (per GPU), 1286.399 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
The graph-level communication performance (supernode = 4): 98.426 Gbps (per GPU), 787.410 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 98.433 Gbps (per GPU), 787.466 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 98.432 Gbps (per GPU), 787.459 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 98.432 Gbps (per GPU), 787.453 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 98.429 Gbps (per GPU), 787.435 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 98.432 Gbps (per GPU), 787.459 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 98.432 Gbps (per GPU), 787.453 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 98.425 Gbps (per GPU), 787.404 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
The graph-level communication performance (supernode = 8): 34.124 Gbps (per GPU), 272.996 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 34.124 Gbps (per GPU), 272.990 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 34.124 Gbps (per GPU), 272.989 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 34.124 Gbps (per GPU), 272.991 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 34.124 Gbps (per GPU), 272.994 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 34.123 Gbps (per GPU), 272.985 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 34.123 Gbps (per GPU), 272.982 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 34.123 Gbps (per GPU), 272.982 Gbps (aggregated, cluster-wide)
 LType   LT0   LT1   LT2 Ratio  VSum  ESum
 chk_0 12.51ms 10.20ms  9.30ms  1.34 29.12K 14.23M
 chk_1  7.93ms  5.59ms  4.77ms  1.66 29.12K  6.56M
 chk_2 19.74ms 17.58ms 16.79ms  1.18 29.12K 24.68M
 chk_3 19.72ms 17.46ms 16.75ms  1.18 29.12K 22.95M
 chk_4  7.74ms  5.45ms  4.63ms  1.67 29.12K  6.33M
 chk_5 12.06ms  9.77ms  8.76ms  1.38 29.12K 12.05M
 chk_6 13.18ms 10.83ms 10.01ms  1.32 29.12K 14.60M
 chk_7 12.33ms 10.10ms  9.17ms  1.34 29.12K 13.21M
   Avg 13.15 10.87 10.02
   Max 19.74 17.58 16.79
   Min  7.74  5.45  4.63
 Ratio  2.55  3.23  3.63
   Var 18.17 18.49 18.82
Profiling takes 3.106 s
Evaluating the performance of the pure model-parallel execution plan.
The bottleneck stage in the optimal plan: 366.138 ms
Partition 0 [0, 4) has cost: 366.138 ms
Partition 1 [4, 8) has cost: 347.894 ms
Partition 2 [8, 12) has cost: 347.894 ms
Partition 3 [12, 16) has cost: 347.894 ms
Partition 4 [16, 20) has cost: 347.894 ms
Partition 5 [20, 24) has cost: 347.894 ms
Partition 6 [24, 28) has cost: 347.894 ms
Partition 7 [28, 32) has cost: 341.104 ms
The optimal partitioning:
[0, 4)
[4, 8)
[8, 12)
[12, 16)
[16, 20)
[20, 24)
[24, 28)
[28, 32)
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 316.677 ms
GPU 0, Compute+Comm Time: 131.864 ms, Bubble Time: 136.142 ms, Imbalance Overhead: 48.671 ms
GPU 1, Compute+Comm Time: 127.276 ms, Bubble Time: 126.794 ms, Imbalance Overhead: 62.608 ms
GPU 2, Compute+Comm Time: 127.276 ms, Bubble Time: 117.085 ms, Imbalance Overhead: 72.317 ms
GPU 3, Compute+Comm Time: 127.276 ms, Bubble Time: 117.998 ms, Imbalance Overhead: 71.404 ms
GPU 4, Compute+Comm Time: 127.276 ms, Bubble Time: 127.374 ms, Imbalance Overhead: 62.027 ms
GPU 5, Compute+Comm Time: 127.276 ms, Bubble Time: 136.307 ms, Imbalance Overhead: 53.095 ms
GPU 6, Compute+Comm Time: 127.276 ms, Bubble Time: 145.472 ms, Imbalance Overhead: 43.930 ms
GPU 7, Compute+Comm Time: 125.183 ms, Bubble Time: 155.694 ms, Imbalance Overhead: 35.801 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 620.892 ms
GPU 0, Compute+Comm Time: 242.566 ms, Bubble Time: 307.051 ms, Imbalance Overhead: 71.275 ms
GPU 1, Compute+Comm Time: 247.264 ms, Bubble Time: 286.428 ms, Imbalance Overhead: 87.200 ms
GPU 2, Compute+Comm Time: 247.264 ms, Bubble Time: 267.762 ms, Imbalance Overhead: 105.867 ms
GPU 3, Compute+Comm Time: 247.264 ms, Bubble Time: 249.686 ms, Imbalance Overhead: 123.943 ms
GPU 4, Compute+Comm Time: 247.264 ms, Bubble Time: 230.289 ms, Imbalance Overhead: 143.339 ms
GPU 5, Compute+Comm Time: 247.264 ms, Bubble Time: 227.837 ms, Imbalance Overhead: 145.792 ms
GPU 6, Compute+Comm Time: 247.264 ms, Bubble Time: 247.159 ms, Imbalance Overhead: 126.470 ms
GPU 7, Compute+Comm Time: 260.919 ms, Bubble Time: 265.030 ms, Imbalance Overhead: 94.944 ms
The estimated cost of the whole pipeline: 984.448 ms

Evaluating the hybrid-parallelism execution plan with 2 DP ways.
The bottleneck stage in the optimal plan: 714.032 ms
Partition 0 [0, 8) has cost: 714.032 ms
Partition 1 [8, 16) has cost: 695.789 ms
Partition 2 [16, 24) has cost: 695.789 ms
Partition 3 [24, 32) has cost: 688.998 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 325.233 ms
GPU 0, Compute+Comm Time: 169.181 ms, Bubble Time: 155.291 ms, Imbalance Overhead: 0.761 ms
GPU 1, Compute+Comm Time: 166.987 ms, Bubble Time: 136.085 ms, Imbalance Overhead: 22.161 ms
GPU 2, Compute+Comm Time: 166.987 ms, Bubble Time: 116.583 ms, Imbalance Overhead: 41.663 ms
GPU 3, Compute+Comm Time: 165.952 ms, Bubble Time: 117.646 ms, Imbalance Overhead: 41.636 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 623.473 ms
GPU 0, Compute+Comm Time: 315.858 ms, Bubble Time: 224.523 ms, Imbalance Overhead: 83.092 ms
GPU 1, Compute+Comm Time: 318.219 ms, Bubble Time: 221.717 ms, Imbalance Overhead: 83.537 ms
GPU 2, Compute+Comm Time: 318.219 ms, Bubble Time: 260.495 ms, Imbalance Overhead: 44.759 ms
GPU 3, Compute+Comm Time: 325.058 ms, Bubble Time: 298.041 ms, Imbalance Overhead: 0.374 ms
    The estimated cost with 2 DP ways is 996.141 ms

Evaluating the hybrid-parallelism execution plan with 4 DP ways.
The bottleneck stage in the optimal plan: 1409.821 ms
Partition 0 [0, 16) has cost: 1409.821 ms
Partition 1 [16, 32) has cost: 1384.786 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 366.029 ms
GPU 0, Compute+Comm Time: 244.738 ms, Bubble Time: 121.291 ms, Imbalance Overhead: 0.000 ms
GPU 1, Compute+Comm Time: 243.167 ms, Bubble Time: 122.652 ms, Imbalance Overhead: 0.210 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 653.848 ms
GPU 0, Compute+Comm Time: 433.449 ms, Bubble Time: 219.565 ms, Imbalance Overhead: 0.835 ms
GPU 1, Compute+Comm Time: 437.795 ms, Bubble Time: 216.053 ms, Imbalance Overhead: 0.000 ms
    The estimated cost with 4 DP ways is 1070.871 ms

Evaluating the hybrid-parallelism execution plan with 8 DP ways.
The bottleneck stage in the optimal plan: 2794.607 ms
Partition 0 [0, 32) has cost: 2794.607 ms
****** Estimating the Forwarding Pipeline Cost ******
Simulation Results: Total Runtime: 491.611 ms
GPU 0, Compute+Comm Time: 491.611 ms, Bubble Time: 0.000 ms, Imbalance Overhead: 0.000 ms
****** Estimating the Backwarding Pipeline Cost *******
Simulation Results: Total Runtime: 684.042 ms
GPU 0, Compute+Comm Time: 684.042 ms, Bubble Time: 0.000 ms, Imbalance Overhead: 0.000 ms
    The estimated cost with 8 DP ways is 1234.435 ms

*** Node 0, starting model training...
Num Stages: 1 / 1
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: NULL
*** Node 0 owns the model-level partition [0, 287)
*** Node 0, constructing the helper classes...
Node 0, Local Vertex Begin: 0, Num Local Vertices: 29120
*** Node 1, starting model training...
Num Stages: 1 / 1
Node 1, Pipeline Input Tensor: NULL
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [0, 287)
*** Node 1, constructing the helper classes...
Node 1, Local Vertex Begin: 29120, Num Local Vertices: 29121
*** Node 2, starting model training...
Num Stages: 1 / 1
Node 2, Pipeline Input Tensor: NULL
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the model-level partition [0, 287)
*** Node 2, constructing the helper classes...
Node 2, Local Vertex Begin: 58241, Num Local Vertices: 29121
*** Node 3, starting model training...
Num Stages: 1 / 1
Node 3, Pipeline Input Tensor: NULL
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [0, 287)
*** Node 3, constructing the helper classes...
Node 3, Local Vertex Begin: 87362, Num Local Vertices: 29121
*** Node 4, starting model training...
Num Stages: 1 / 1
Node 4, Pipeline Input Tensor: NULL
Node 4, Pipeline Output Tensor: NULL
*** Node 4 owns the model-level partition [0, 287)
*** Node 4, constructing the helper classes...
Node 4, Local Vertex Begin: 116483, Num Local Vertices: 29121
*** Node 5, starting model training...
Num Stages: 1 / 1
Node 5, Pipeline Input Tensor: NULL
Node 5, Pipeline Output Tensor: NULL
*** Node 5 owns the model-level partition [0, 287)
*** Node 5, constructing the helper classes...
Node 5, Local Vertex Begin: 145604, Num Local Vertices: 29120
*** Node 6, starting model training...
Num Stages: 1 / 1
Node 6, Pipeline Input Tensor: NULL
Node 6, Pipeline Output Tensor: NULL
*** Node 6 owns the model-level partition [0, 287)
*** Node 6, constructing the helper classes...
Node 6, Local Vertex Begin: 174724, Num Local Vertices: 29121
*** Node 7, starting model training...
Num Stages: 1 / 1
Node 7, Pipeline Input Tensor: NULL
Node 7, Pipeline Output Tensor: NULL
*** Node 7 owns the model-level partition [0, 287)
*** Node 7, constructing the helper classes...
Node 7, Local Vertex Begin: 203845, Num Local Vertices: 29120
*** Node 5, setting up some other necessary information...
*** Node 7, setting up some other necessary information...
*** Node 3, setting up some other necessary information...
*** Node 4, setting up some other necessary information...
*** Node 0, setting up some other necessary information...
*** Node 6, setting up some other necessary information...
*** Node 2, setting up some other necessary information...
*** Node 1, setting up some other necessary information...
+++++++++ Node 1 initializing the weights for op[0, 287)...
+++++++++ Node 5 initializing the weights for op[0, 287)...
+++++++++ Node 0 initializing the weights for op[0, 287)...
+++++++++ Node 7 initializing the weights for op[0, 287)...
+++++++++ Node 3 initializing the weights for op[0, 287)...
+++++++++ Node 4 initializing the weights for op[0, 287)...
+++++++++ Node 2 initializing the weights for op[0, 287)...
+++++++++ Node 6 initializing the weights for op[0, 287)...
Node 0, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be sent across graph boundary...
Node 4, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
Node 5, discovering the vertices that will be sent across graph boundary...
Node 6, discovering the vertices that will be sent across graph boundary...
Node 7, discovering the vertices that will be sent across graph boundary...
Node 4, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
Node 5, discovering the vertices that will be received across the graph boundary.
Node 6, discovering the vertices that will be received across the graph boundary.
Node 7, discovering the vertices that will be received across the graph boundary.
Node 0, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
Node 3, discovering the vertices that will be received across the graph boundary.
Node 2, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
*** Node 0, starting task scheduling...



*** Node 1, starting task scheduling...
*** Node 4, starting task scheduling...
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 5, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
*** Node 6, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
*** Node 7, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
	Epoch 25:	Loss 3.2398
	Epoch 50:	Loss 3.0606
	Epoch 75:	Loss 2.9893
	Epoch 100:	Loss 2.9456
	Epoch 125:	Loss 2.9232
	Epoch 150:	Loss 2.9049
	Epoch 175:	Loss 2.8922
	Epoch 200:	Loss 2.8814
	Epoch 225:	Loss 2.8689
	Epoch 250:	Loss 2.8468
	Epoch 275:	Loss 2.8342
	Epoch 300:	Loss 2.8160
	Epoch 325:	Loss 2.7839
	Epoch 350:	Loss 2.7728
	Epoch 375:	Loss 2.6753
	Epoch 400:	Loss 2.7395
	Epoch 425:	Loss 2.6221
	Epoch 450:	Loss 2.5460
	Epoch 475:	Loss 2.6329
	Epoch 500:	Loss 2.4691
	Epoch 525:	Loss 2.4218
	Epoch 550:	Loss 2.3663
	Epoch 575:	Loss 2.3611
	Epoch 600:	Loss 2.2477
	Epoch 625:	Loss 2.2791
	Epoch 650:	Loss 2.1626
	Epoch 675:	Loss 2.0781
	Epoch 700:	Loss 2.0387
	Epoch 725:	Loss 2.0116
	Epoch 750:	Loss 1.9347
	Epoch 775:	Loss 1.8743
	Epoch 800:	Loss 1.8845
	Epoch 825:	Loss 1.8220
	Epoch 850:	Loss 1.7759
	Epoch 875:	Loss 1.7464
	Epoch 900:	Loss 1.7271
	Epoch 925:	Loss 1.6564
	Epoch 950:	Loss 1.5971
	Epoch 975:	Loss 1.7052
	Epoch 1000:	Loss 1.6118
	Epoch 1025:	Loss 1.5414
	Epoch 1050:	Loss 1.4549
	Epoch 1075:	Loss 1.4533
	Epoch 1100:	Loss 1.4358
	Epoch 1125:	Loss 1.4166
	Epoch 1150:	Loss 1.4183
	Epoch 1175:	Loss 1.3313
	Epoch 1200:	Loss 1.4684
	Epoch 1225:	Loss 1.2270
	Epoch 1250:	Loss 1.2611
	Epoch 1275:	Loss 1.1922
	Epoch 1300:	Loss 1.2645
	Epoch 1325:	Loss 1.1849
	Epoch 1350:	Loss 1.1651
	Epoch 1375:	Loss 1.1172
	Epoch 1400:	Loss 1.9477
	Epoch 1425:	Loss 1.1124
	Epoch 1450:	Loss 1.1435
	Epoch 1475:	Loss 1.3395
	Epoch 1500:	Loss 1.0658
	Epoch 1525:	Loss 1.0561
	Epoch 1550:	Loss 1.0685
	Epoch 1575:	Loss 1.0909
	Epoch 1600:	Loss 1.2678
	Epoch 1625:	Loss 1.1104
	Epoch 1650:	Loss 0.9839
	Epoch 1675:	Loss 0.9931
	Epoch 1700:	Loss 0.9470
	Epoch 1725:	Loss 0.9562
	Epoch 1750:	Loss 1.1695
	Epoch 1775:	Loss 1.1803
	Epoch 1800:	Loss 0.9738
	Epoch 1825:	Loss 1.0980
	Epoch 1850:	Loss 0.9798
	Epoch 1875:	Loss 0.8795
	Epoch 1900:	Loss 0.8761
	Epoch 1925:	Loss 0.9471
	Epoch 1950:	Loss 0.9482
	Epoch 1975:	Loss 0.8727
	Epoch 2000:	Loss 1.0928
	Epoch 2025:	Loss 0.9434
	Epoch 2050:	Loss 0.8521
	Epoch 2075:	Loss 0.8396
	Epoch 2100:	Loss 0.8765
	Epoch 2125:	Loss 0.8079
	Epoch 2150:	Loss 1.1392
	Epoch 2175:	Loss 0.8300
	Epoch 2200:	Loss 0.7900
	Epoch 2225:	Loss 0.8186
	Epoch 2250:	Loss 0.7853
	Epoch 2275:	Loss 0.8906
	Epoch 2300:	Loss 0.7859
	Epoch 2325:	Loss 0.9354
	Epoch 2350:	Loss 0.7887
	Epoch 2375:	Loss 0.7877
	Epoch 2400:	Loss 0.7672
	Epoch 2425:	Loss 0.8022
	Epoch 2450:	Loss 0.8586
	Epoch 2475:	Loss 0.7343
	Epoch 2500:	Loss 0.7884
	Epoch 2525:	Loss 0.7419
	Epoch 2550:	Loss 0.8015
	Epoch 2575:	Loss 0.8966
	Epoch 2600:	Loss 0.7655
	Epoch 2625:	Loss 0.7081
	Epoch 2650:	Loss 0.9073
	Epoch 2675:	Loss 0.7896
	Epoch 2700:	Loss 0.7244
	Epoch 2725:	Loss 0.7047
	Epoch 2750:	Loss 0.8009
	Epoch 2775:	Loss 0.7179
	Epoch 2800:	Loss 0.6907
	Epoch 2825:	Loss 0.6989
	Epoch 2850:	Loss 0.6896
	Epoch 2875:	Loss 0.6908
	Epoch 2900:	Loss 0.6766
	Epoch 2925:	Loss 0.6714
	Epoch 2950:	Loss 0.6601
	Epoch 2975:	Loss 0.6836
	Epoch 3000:	Loss 0.7129
	Epoch 3025:	Loss 0.6660
	Epoch 3050:	Loss 0.6754
	Epoch 3075:	Loss 0.6893
	Epoch 3100:	Loss 0.8323
	Epoch 3125:	Loss 0.7603
	Epoch 3150:	Loss 0.6933
	Epoch 3175:	Loss 0.6511
	Epoch 3200:	Loss 0.8008
	Epoch 3225:	Loss 0.6717
	Epoch 3250:	Loss 0.6251
	Epoch 3275:	Loss 0.6356
	Epoch 3300:	Loss 0.6350
	Epoch 3325:	Loss 0.6288
	Epoch 3350:	Loss 0.6806
	Epoch 3375:	Loss 1.2961
	Epoch 3400:	Loss 0.6891
	Epoch 3425:	Loss 0.6440
	Epoch 3450:	Loss 0.9434
	Epoch 3475:	Loss 0.6106
	Epoch 3500:	Loss 0.5939
	Epoch 3525:	Loss 0.6251
	Epoch 3550:	Loss 0.6147
	Epoch 3575:	Loss 0.5873
	Epoch 3600:	Loss 0.5812
	Epoch 3625:	Loss 0.5983
	Epoch 3650:	Loss 0.5928
	Epoch 3675:	Loss 0.5824
	Epoch 3700:	Loss 0.7462
	Epoch 3725:	Loss 0.5856
	Epoch 3750:	Loss 0.6049
	Epoch 3775:	Loss 0.5689
	Epoch 3800:	Loss 0.6797
	Epoch 3825:	Loss 0.5648
	Epoch 3850:	Loss 0.5750
	Epoch 3875:	Loss 0.5829
	Epoch 3900:	Loss 0.5740
	Epoch 3925:	Loss 0.6104
	Epoch 3950:	Loss 0.5546
	Epoch 3975:	Loss 0.5514
	Epoch 4000:	Loss 0.5574
	Epoch 4025:	Loss 0.5591
	Epoch 4050:	Loss 0.5797
	Epoch 4075:	Loss 0.5693
	Epoch 4100:	Loss 0.5645
	Epoch 4125:	Loss 0.5505
	Epoch 4150:	Loss 0.5706
	Epoch 4175:	Loss 0.5552
	Epoch 4200:	Loss 1.1054
	Epoch 4225:	Loss 0.6488
	Epoch 4250:	Loss 0.6328
	Epoch 4275:	Loss 0.5499
	Epoch 4300:	Loss 0.5754
	Epoch 4325:	Loss 0.5289
	Epoch 4350:	Loss 0.5983
	Epoch 4375:	Loss 0.5388
	Epoch 4400:	Loss 0.5685
	Epoch 4425:	Loss 0.5598
	Epoch 4450:	Loss 0.5237
	Epoch 4475:	Loss 0.5278
	Epoch 4500:	Loss 0.5287
	Epoch 4525:	Loss 0.5285
	Epoch 4550:	Loss 0.5293
	Epoch 4575:	Loss 0.5264
	Epoch 4600:	Loss 0.5240
	Epoch 4625:	Loss 0.5234
	Epoch 4650:	Loss 0.5386
	Epoch 4675:	Loss 0.5067
	Epoch 4700:	Loss 0.5109
	Epoch 4725:	Loss 0.5093
	Epoch 4750:	Loss 0.5158
	Epoch 4775:	Loss 0.5162
	Epoch 4800:	Loss 0.5111
	Epoch 4825:	Loss 0.5161
	Epoch 4850:	Loss 0.5108
	Epoch 4875:	Loss 0.5543
	Epoch 4900:	Loss 0.5421
	Epoch 4925:	Loss 0.5806
	Epoch 4950:	Loss 0.6099
	Epoch 4975:	Loss 0.5039
	Epoch 5000:	Loss 0.5674
Node 0, Pre/Post-Pipelining: 8.699 / 24.782 ms, Bubble: 1.199 ms, Compute: 1078.120 ms, Comm: 0.008 ms, Imbalance: 0.016 ms
Node 1, Pre/Post-Pipelining: 8.700 / 24.779 ms, Bubble: 1.121 ms, Compute: 1078.193 ms, Comm: 0.008 ms, Imbalance: 0.016 ms
Node 2, Pre/Post-Pipelining: 8.710 / 24.849 ms, Bubble: 0.415 ms, Compute: 1078.828 ms, Comm: 0.008 ms, Imbalance: 0.016 ms
Node 3, Pre/Post-Pipelining: 8.720 / 24.951 ms, Bubble: 0.047 ms, Compute: 1079.080 ms, Comm: 0.009 ms, Imbalance: 0.019 ms
Node 4, Pre/Post-Pipelining: 8.705 / 24.789 ms, Bubble: 1.285 ms, Compute: 1078.017 ms, Comm: 0.010 ms, Imbalance: 0.018 ms
Node 5, Pre/Post-Pipelining: 8.701 / 24.768 ms, Bubble: 1.229 ms, Compute: 1078.102 ms, Comm: 0.009 ms, Imbalance: 0.017 ms
Node 6, Pre/Post-Pipelining: 8.711 / 24.787 ms, Bubble: 0.766 ms, Compute: 1078.540 ms, Comm: 0.009 ms, Imbalance: 0.016 ms
Node 7, Pre/Post-Pipelining: 8.703 / 24.786 ms, Bubble: 1.181 ms, Compute: 1078.128 ms, Comm: 0.010 ms, Imbalance: 0.018 ms
Cluster-Wide Average, Pre-Pipelining Overhead: 8.699 ms
Cluster-Wide Average, Post-Pipelining Overhead: 24.782 ms
Cluster-Wide Average, Bubble: 1.199 ms
Cluster-Wide Average, Compute: 1078.120 ms
Cluster-Wide Average, Communication: 0.008 ms
Cluster-Wide Average, Imbalance: 0.016 ms
Node 0, GPU memory consumption: 17.618 GB
Node 2, GPU memory consumption: 16.893 GB
Node 3, GPU memory consumption: 16.870 GB
Node 1, GPU memory consumption: 16.885 GB
Node 5, GPU memory consumption: 16.883 GB
Node 6, GPU memory consumption: 16.889 GB
Node 4, GPU memory consumption: 16.860 GB
Node 7, GPU memory consumption: 16.864 GB
Node 0, Graph-Level Communication Throughput: 22.375 Gbps, Time: 713.542 ms
Node 1, Graph-Level Communication Throughput: 19.891 Gbps, Time: 853.714 ms
Node 2, Graph-Level Communication Throughput: 35.872 Gbps, Time: 493.039 ms
Node 3, Graph-Level Communication Throughput: 49.394 Gbps, Time: 468.535 ms
Node 4, Graph-Level Communication Throughput: 9.610 Gbps, Time: 875.636 ms
Node 5, Graph-Level Communication Throughput: 16.639 Gbps, Time: 734.011 ms
Node 6, Graph-Level Communication Throughput: 23.315 Gbps, Time: 702.584 ms
Node 7, Graph-Level Communication Throughput: 18.811 Gbps, Time: 723.764 ms
------------------------node id 0,  per-epoch time: 1.112874 s---------------
------------------------node id 4,  per-epoch time: 1.112874 s---------------
------------------------node id 1,  per-epoch time: 1.112874 s---------------
------------------------node id 5,  per-epoch time: 1.112874 s---------------
------------------------node id 2,  per-epoch time: 1.112874 s---------------
------------------------node id 6,  per-epoch time: 1.112874 s---------------
------------------------node id 3,  per-epoch time: 1.112874 s---------------
------------------------node id 7,  per-epoch time: 1.112874 s---------------
************ Profiling Results ************
	Bubble: 34.773852 (ms) (3.12 percentage)
	Compute: 343.077125 (ms) (30.83 percentage)
	GraphCommComputeOverhead: 19.271810 (ms) (1.73 percentage)
	GraphCommNetwork: 695.601870 (ms) (62.50 percentage)
	LayerCommNetwork: 0.000000 (ms) (0.00 percentage)
	Optimization: 0.000000 (ms) (0.00 percentage)
	Other: 20.160155 (ms) (1.81 percentage)
	Layer-level communication (cluster-wide, per-epoch): 0.000 GB
	Graph-level communication (cluster-wide, per-epoch): 14.482 GB
	Weight-sync communication (cluster-wide, per-epoch): 0.022 GB
	Total communication (cluster-wide, per-epoch): 14.504 GB
	Aggregated layer-level communication throughput: 0.000 Gbps
Highest valid_acc: 0.0000
Target test_acc: 0.0576
Epoch to reach the target acc: 0
[MPI Rank 0] Success 
[MPI Rank 4] Success 
[MPI Rank 1] Success 
[MPI Rank 5] Success 
[MPI Rank 2] Success 
[MPI Rank 6] Success 
[MPI Rank 3] Success 
[MPI Rank 7] Success 
