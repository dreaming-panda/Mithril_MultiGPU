gnerv7
gnerv8
launching jobs on gnerv7, in total 2 nodes
launching jobs on gnerv8, in total 2 nodes
Executing:  'python ./main.py 1 2 gnerv7 4 8' on gnerv8
Executing:  'python ./main.py 1 2 gnerv7 5 8' on gnerv8
Executing:  'python ./main.py 1 2 gnerv7 6 8' on gnerv8
Executing:  'python ./main.py 1 2 gnerv7 7 8' on gnerv8
Executing:  'python ./main.py 0 2 gnerv7 0 8' on gnerv7
Executing:  'python ./main.py 0 2 gnerv7 1 8' on gnerv7
Executing:  'python ./main.py 0 2 gnerv7 2 8' on gnerv7
Executing:  'python ./main.py 0 2 gnerv7 3 8' on gnerv7
['./main.py', '0', '2', 'gnerv7', '0', '8']
Hello World From Process 0, the World Size is 8
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv7', '7', '8']
Hello World From Process 7, the World Size is 8
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv7', '5', '8']
Hello World From Process 5, the World Size is 8
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv7', '4', '8']
Hello World From Process 4, the World Size is 8
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv7', '6', '8']
Hello World From Process 6, the World Size is 8
Downloaded the graph dataset
['./main.py', '0', '2', 'gnerv7', '2', '8']
Hello World From Process 2, the World Size is 8
Downloaded the graph dataset
['./main.py', '0', '2', 'gnerv7', '1', '8']
Hello World From Process 1, the World Size is 8
Downloaded the graph dataset
['./main.py', '0', '2', 'gnerv7', '3', '8']
Hello World From Process 3, the World Size is 8
Downloaded the graph dataset
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=500, out_features=100, bias=False)
      (fc_self): Linear(in_features=500, out_features=100, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=100, bias=False)
      (fc_self): Linear(in_features=100, out_features=100, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=100, out_features=7, bias=False)
      (fc_self): Linear(in_features=100, out_features=7, bias=True)
    )
  )
)
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
	Rank 0, True Batch Size 256, Iteration 0, Loss 20124302.0000
	Rank 0, True Batch Size 256, Iteration 1, Loss 3290204.7500
	Rank 0, True Batch Size 256, Iteration 2, Loss 992031.4375
	Rank 0, True Batch Size 256, Iteration 3, Loss 437966.2500
	Rank 0, True Batch Size 256, Iteration 4, Loss 221352.0938
	Rank 0, True Batch Size 256, Iteration 5, Loss 121164.6250
	Rank 0, True Batch Size 256, Iteration 6, Loss 99142.4297
	Rank 0, True Batch Size 256, Iteration 7, Loss 61489.1445
	Rank 0, True Batch Size 256, Iteration 8, Loss 53193.7500
	Rank 0, True Batch Size 256, Iteration 9, Loss 37453.7109
	Rank 0, True Batch Size 256, Iteration 10, Loss 36130.2305
	Rank 0, True Batch Size 256, Iteration 11, Loss 30835.7383
	Rank 0, True Batch Size 256, Iteration 12, Loss 26338.0469
	Rank 0, True Batch Size 256, Iteration 13, Loss 20561.8008
	Rank 0, True Batch Size 256, Iteration 14, Loss 17043.7715
	Rank 0, True Batch Size 256, Iteration 15, Loss 16746.5859
	Rank 0, True Batch Size 256, Iteration 16, Loss 17060.1543
	Rank 0, True Batch Size 256, Iteration 17, Loss 14839.7275
	Rank 0, True Batch Size 256, Iteration 18, Loss 13458.8896
	Rank 0, True Batch Size 256, Iteration 19, Loss 10567.8818
	Rank 0, True Batch Size 256, Iteration 20, Loss 11478.2246
	Rank 0, True Batch Size 203, Iteration 21, Loss 10666.3594
Epoch 1, Loss 1258894.9756, Train Accuracy 0.3913, Valid Accuracy 0.3917, Test Accuracy 0.3941
	Rank 0, True Batch Size 256, Iteration 0, Loss 9446.0654
	Rank 0, True Batch Size 256, Iteration 1, Loss 8235.8428
	Rank 0, True Batch Size 256, Iteration 2, Loss 7914.9355
	Rank 0, True Batch Size 256, Iteration 3, Loss 8585.5508
	Rank 0, True Batch Size 256, Iteration 4, Loss 7748.8877
	Rank 0, True Batch Size 256, Iteration 5, Loss 7087.4521
	Rank 0, True Batch Size 256, Iteration 6, Loss 6216.3213
	Rank 0, True Batch Size 256, Iteration 7, Loss 6544.7622
	Rank 0, True Batch Size 256, Iteration 8, Loss 5283.6396
	Rank 0, True Batch Size 256, Iteration 9, Loss 6280.5356
	Rank 0, True Batch Size 256, Iteration 10, Loss 5211.8442
	Rank 0, True Batch Size 256, Iteration 11, Loss 5670.1602
	Rank 0, True Batch Size 256, Iteration 12, Loss 4868.7632
	Rank 0, True Batch Size 256, Iteration 13, Loss 5311.6777
	Rank 0, True Batch Size 256, Iteration 14, Loss 4943.8774
	Rank 0, True Batch Size 256, Iteration 15, Loss 4662.5737
	Rank 0, True Batch Size 256, Iteration 16, Loss 4831.4072
	Rank 0, True Batch Size 256, Iteration 17, Loss 4522.6963
	Rank 0, True Batch Size 256, Iteration 18, Loss 4555.8833
	Rank 0, True Batch Size 256, Iteration 19, Loss 3885.3276
	Rank 0, True Batch Size 256, Iteration 20, Loss 4187.9097
	Rank 0, True Batch Size 203, Iteration 21, Loss 4985.6929
Epoch 2, Loss 5935.9330, Train Accuracy 0.3827, Valid Accuracy 0.3847, Test Accuracy 0.3849
	Rank 0, True Batch Size 256, Iteration 0, Loss 4392.1401
	Rank 0, True Batch Size 256, Iteration 1, Loss 4297.9785
	Rank 0, True Batch Size 256, Iteration 2, Loss 3802.6824
	Rank 0, True Batch Size 256, Iteration 3, Loss 3936.7454
	Rank 0, True Batch Size 256, Iteration 4, Loss 3478.5234
	Rank 0, True Batch Size 256, Iteration 5, Loss 3833.0579
	Rank 0, True Batch Size 256, Iteration 6, Loss 3656.3125
	Rank 0, True Batch Size 256, Iteration 7, Loss 3588.7329
	Rank 0, True Batch Size 256, Iteration 8, Loss 3472.7812
	Rank 0, True Batch Size 256, Iteration 9, Loss 3295.6819
	Rank 0, True Batch Size 256, Iteration 10, Loss 3258.5010
	Rank 0, True Batch Size 256, Iteration 11, Loss 3478.8538
	Rank 0, True Batch Size 256, Iteration 12, Loss 3337.2424
	Rank 0, True Batch Size 256, Iteration 13, Loss 2850.0854
	Rank 0, True Batch Size 256, Iteration 14, Loss 3047.0149
	Rank 0, True Batch Size 256, Iteration 15, Loss 3352.7021
	Rank 0, True Batch Size 256, Iteration 16, Loss 3621.3047
	Rank 0, True Batch Size 256, Iteration 17, Loss 2882.3101
	Rank 0, True Batch Size 256, Iteration 18, Loss 3372.6743
	Rank 0, True Batch Size 256, Iteration 19, Loss 2804.5996
	Rank 0, True Batch Size 256, Iteration 20, Loss 3122.9836
	Rank 0, True Batch Size 203, Iteration 21, Loss 2921.7498
Epoch 3, Loss 3372.1500, Train Accuracy 0.3778, Valid Accuracy 0.3770, Test Accuracy 0.3797
	Rank 0, True Batch Size 256, Iteration 0, Loss 3344.0752
	Rank 0, True Batch Size 256, Iteration 1, Loss 2687.6548
	Rank 0, True Batch Size 256, Iteration 2, Loss 3108.1455
	Rank 0, True Batch Size 256, Iteration 3, Loss 3104.1580
	Rank 0, True Batch Size 256, Iteration 4, Loss 2779.0681
	Rank 0, True Batch Size 256, Iteration 5, Loss 2974.7090
	Rank 0, True Batch Size 256, Iteration 6, Loss 2694.1565
	Rank 0, True Batch Size 256, Iteration 7, Loss 2624.6743
	Rank 0, True Batch Size 256, Iteration 8, Loss 2552.8271
	Rank 0, True Batch Size 256, Iteration 9, Loss 2624.6016
	Rank 0, True Batch Size 256, Iteration 10, Loss 2610.8525
	Rank 0, True Batch Size 256, Iteration 11, Loss 2310.4492
	Rank 0, True Batch Size 256, Iteration 12, Loss 2549.6499
	Rank 0, True Batch Size 256, Iteration 13, Loss 2568.2407
	Rank 0, True Batch Size 256, Iteration 14, Loss 2355.1790
	Rank 0, True Batch Size 256, Iteration 15, Loss 2433.7983
	Rank 0, True Batch Size 256, Iteration 16, Loss 2286.7659
	Rank 0, True Batch Size 256, Iteration 17, Loss 2325.5283
	Rank 0, True Batch Size 256, Iteration 18, Loss 2378.8005
	Rank 0, True Batch Size 256, Iteration 19, Loss 2419.2537
	Rank 0, True Batch Size 256, Iteration 20, Loss 2364.2839
	Rank 0, True Batch Size 203, Iteration 21, Loss 2138.5281
Epoch 4, Loss 2582.8157, Train Accuracy 0.3716, Valid Accuracy 0.3754, Test Accuracy 0.3735
	Rank 0, True Batch Size 256, Iteration 0, Loss 2596.9758
	Rank 0, True Batch Size 256, Iteration 1, Loss 2415.4060
	Rank 0, True Batch Size 256, Iteration 2, Loss 2558.9500
	Rank 0, True Batch Size 256, Iteration 3, Loss 2136.2119
	Rank 0, True Batch Size 256, Iteration 4, Loss 2064.7117
	Rank 0, True Batch Size 256, Iteration 5, Loss 2284.9155
	Rank 0, True Batch Size 256, Iteration 6, Loss 2392.0811
	Rank 0, True Batch Size 256, Iteration 7, Loss 2196.0068
	Rank 0, True Batch Size 256, Iteration 8, Loss 2202.6082
	Rank 0, True Batch Size 256, Iteration 9, Loss 1990.1814
	Rank 0, True Batch Size 256, Iteration 10, Loss 2073.4939
	Rank 0, True Batch Size 256, Iteration 11, Loss 1913.5369
	Rank 0, True Batch Size 256, Iteration 12, Loss 2099.7219
	Rank 0, True Batch Size 256, Iteration 13, Loss 2041.3046
	Rank 0, True Batch Size 256, Iteration 14, Loss 1910.4908
	Rank 0, True Batch Size 256, Iteration 15, Loss 1952.4718
	Rank 0, True Batch Size 256, Iteration 16, Loss 1976.0399
	Rank 0, True Batch Size 256, Iteration 17, Loss 2045.9785
	Rank 0, True Batch Size 256, Iteration 18, Loss 2173.7290
	Rank 0, True Batch Size 256, Iteration 19, Loss 1748.4327
	Rank 0, True Batch Size 256, Iteration 20, Loss 1955.3997
	Rank 0, True Batch Size 203, Iteration 21, Loss 1829.5763
Epoch 5, Loss 2127.1275, Train Accuracy 0.3639, Valid Accuracy 0.3628, Test Accuracy 0.3645
	Rank 0, True Batch Size 256, Iteration 0, Loss 1903.4218
	Rank 0, True Batch Size 256, Iteration 1, Loss 1821.8746
	Rank 0, True Batch Size 256, Iteration 2, Loss 1675.5205
	Rank 0, True Batch Size 256, Iteration 3, Loss 2457.0974
	Rank 0, True Batch Size 256, Iteration 4, Loss 1855.9486
	Rank 0, True Batch Size 256, Iteration 5, Loss 1997.8295
	Rank 0, True Batch Size 256, Iteration 6, Loss 1999.7035
	Rank 0, True Batch Size 256, Iteration 7, Loss 1977.0216
	Rank 0, True Batch Size 256, Iteration 8, Loss 1989.4862
	Rank 0, True Batch Size 256, Iteration 9, Loss 1878.7759
	Rank 0, True Batch Size 256, Iteration 10, Loss 1685.1447
	Rank 0, True Batch Size 256, Iteration 11, Loss 1779.9753
	Rank 0, True Batch Size 256, Iteration 12, Loss 2000.1758
	Rank 0, True Batch Size 256, Iteration 13, Loss 1726.2020
	Rank 0, True Batch Size 256, Iteration 14, Loss 1727.3135
	Rank 0, True Batch Size 256, Iteration 15, Loss 1856.6559
	Rank 0, True Batch Size 256, Iteration 16, Loss 1888.5391
	Rank 0, True Batch Size 256, Iteration 17, Loss 1759.8843
	Rank 0, True Batch Size 256, Iteration 18, Loss 1943.8270
	Rank 0, True Batch Size 256, Iteration 19, Loss 1700.7085
	Rank 0, True Batch Size 256, Iteration 20, Loss 1871.0747
	Rank 0, True Batch Size 203, Iteration 21, Loss 1837.1169
Epoch 6, Loss 1848.2832, Train Accuracy 0.3614, Valid Accuracy 0.3558, Test Accuracy 0.3614
	Rank 0, True Batch Size 256, Iteration 0, Loss 1553.2860
	Rank 0, True Batch Size 256, Iteration 1, Loss 1658.1577
	Rank 0, True Batch Size 256, Iteration 2, Loss 1772.8098
	Rank 0, True Batch Size 256, Iteration 3, Loss 1673.7173
	Rank 0, True Batch Size 256, Iteration 4, Loss 1650.9735
	Rank 0, True Batch Size 256, Iteration 5, Loss 1654.2515
	Rank 0, True Batch Size 256, Iteration 6, Loss 1473.6575
	Rank 0, True Batch Size 256, Iteration 7, Loss 1710.0704
	Rank 0, True Batch Size 256, Iteration 8, Loss 1502.1301
	Rank 0, True Batch Size 256, Iteration 9, Loss 1295.8912
	Rank 0, True Batch Size 256, Iteration 10, Loss 1599.6162
	Rank 0, True Batch Size 256, Iteration 11, Loss 1880.8217
	Rank 0, True Batch Size 256, Iteration 12, Loss 1915.4988
	Rank 0, True Batch Size 256, Iteration 13, Loss 1720.9233
	Rank 0, True Batch Size 256, Iteration 14, Loss 1489.6769
	Rank 0, True Batch Size 256, Iteration 15, Loss 1399.5754
	Rank 0, True Batch Size 256, Iteration 16, Loss 1266.4108
	Rank 0, True Batch Size 256, Iteration 17, Loss 1523.3015
	Rank 0, True Batch Size 256, Iteration 18, Loss 1808.6205
	Rank 0, True Batch Size 256, Iteration 19, Loss 1343.4385
	Rank 0, True Batch Size 256, Iteration 20, Loss 1546.7891
	Rank 0, True Batch Size 203, Iteration 21, Loss 1763.5920
Epoch 7, Loss 1602.3264, Train Accuracy 0.3546, Valid Accuracy 0.3565, Test Accuracy 0.3560
	Rank 0, True Batch Size 256, Iteration 0, Loss 1469.1771
	Rank 0, True Batch Size 256, Iteration 1, Loss 1474.3983
	Rank 0, True Batch Size 256, Iteration 2, Loss 1467.1212
	Rank 0, True Batch Size 256, Iteration 3, Loss 1682.3358
	Rank 0, True Batch Size 256, Iteration 4, Loss 1425.9486
	Rank 0, True Batch Size 256, Iteration 5, Loss 1341.2004
	Rank 0, True Batch Size 256, Iteration 6, Loss 1614.1908
	Rank 0, True Batch Size 256, Iteration 7, Loss 1289.3973
	Rank 0, True Batch Size 256, Iteration 8, Loss 1395.1934
	Rank 0, True Batch Size 256, Iteration 9, Loss 1395.0294
	Rank 0, True Batch Size 256, Iteration 10, Loss 1372.8912
	Rank 0, True Batch Size 256, Iteration 11, Loss 1737.0457
	Rank 0, True Batch Size 256, Iteration 12, Loss 1224.6061
	Rank 0, True Batch Size 256, Iteration 13, Loss 1462.4886
	Rank 0, True Batch Size 256, Iteration 14, Loss 1434.3822
	Rank 0, True Batch Size 256, Iteration 15, Loss 1247.8502
	Rank 0, True Batch Size 256, Iteration 16, Loss 1337.4144
	Rank 0, True Batch Size 256, Iteration 17, Loss 1484.3992
	Rank 0, True Batch Size 256, Iteration 18, Loss 1333.3893
	Rank 0, True Batch Size 256, Iteration 19, Loss 1593.7089
	Rank 0, True Batch Size 256, Iteration 20, Loss 1626.1661
	Rank 0, True Batch Size 203, Iteration 21, Loss 1468.0559
Epoch 8, Loss 1431.8545, Train Accuracy 0.3511, Valid Accuracy 0.3490, Test Accuracy 0.3481
	Rank 0, True Batch Size 256, Iteration 0, Loss 1463.2982
	Rank 0, True Batch Size 256, Iteration 1, Loss 1305.9250
	Rank 0, True Batch Size 256, Iteration 2, Loss 1209.8282
	Rank 0, True Batch Size 256, Iteration 3, Loss 1481.2605
	Rank 0, True Batch Size 256, Iteration 4, Loss 1367.7035
	Rank 0, True Batch Size 256, Iteration 5, Loss 1205.7415
	Rank 0, True Batch Size 256, Iteration 6, Loss 1271.7837
	Rank 0, True Batch Size 256, Iteration 7, Loss 1380.9999
	Rank 0, True Batch Size 256, Iteration 8, Loss 1380.8162
	Rank 0, True Batch Size 256, Iteration 9, Loss 1419.1256
	Rank 0, True Batch Size 256, Iteration 10, Loss 1371.3926
	Rank 0, True Batch Size 256, Iteration 11, Loss 1319.6628
	Rank 0, True Batch Size 256, Iteration 12, Loss 1230.9792
	Rank 0, True Batch Size 256, Iteration 13, Loss 1304.7113
	Rank 0, True Batch Size 256, Iteration 14, Loss 1243.8951
	Rank 0, True Batch Size 256, Iteration 15, Loss 1267.1448
	Rank 0, True Batch Size 256, Iteration 16, Loss 1173.1658
	Rank 0, True Batch Size 256, Iteration 17, Loss 1127.6506
	Rank 0, True Batch Size 256, Iteration 18, Loss 1520.5854
	Rank 0, True Batch Size 256, Iteration 19, Loss 1154.4043
	Rank 0, True Batch Size 256, Iteration 20, Loss 1249.9678
	Rank 0, True Batch Size 203, Iteration 21, Loss 1483.8898
Epoch 9, Loss 1277.9254, Train Accuracy 0.3466, Valid Accuracy 0.3511, Test Accuracy 0.3446
	Rank 0, True Batch Size 256, Iteration 0, Loss 1343.1508
	Rank 0, True Batch Size 256, Iteration 1, Loss 1091.1987
	Rank 0, True Batch Size 256, Iteration 2, Loss 1330.9963
	Rank 0, True Batch Size 256, Iteration 3, Loss 1124.9464
	Rank 0, True Batch Size 256, Iteration 4, Loss 1259.4714
	Rank 0, True Batch Size 256, Iteration 5, Loss 1147.1794
	Rank 0, True Batch Size 256, Iteration 6, Loss 1229.2623
	Rank 0, True Batch Size 256, Iteration 7, Loss 1011.1750
	Rank 0, True Batch Size 256, Iteration 8, Loss 980.6299
	Rank 0, True Batch Size 256, Iteration 9, Loss 981.0311
	Rank 0, True Batch Size 256, Iteration 10, Loss 1162.9221
	Rank 0, True Batch Size 256, Iteration 11, Loss 1188.0540
	Rank 0, True Batch Size 256, Iteration 12, Loss 1301.2460
	Rank 0, True Batch Size 256, Iteration 13, Loss 1331.9178
	Rank 0, True Batch Size 256, Iteration 14, Loss 1031.4165
	Rank 0, True Batch Size 256, Iteration 15, Loss 1114.0308
	Rank 0, True Batch Size 256, Iteration 16, Loss 1203.6110
	Rank 0, True Batch Size 256, Iteration 17, Loss 1019.2928
	Rank 0, True Batch Size 256, Iteration 18, Loss 1458.2280
	Rank 0, True Batch Size 256, Iteration 19, Loss 933.9003
	Rank 0, True Batch Size 256, Iteration 20, Loss 1077.8693
	Rank 0, True Batch Size 203, Iteration 21, Loss 991.5708
Epoch 10, Loss 1168.1241, Train Accuracy 0.3394, Valid Accuracy 0.3443, Test Accuracy 0.3439
	Rank 0, True Batch Size 256, Iteration 0, Loss 1058.6957
	Rank 0, True Batch Size 256, Iteration 1, Loss 1061.0332
	Rank 0, True Batch Size 256, Iteration 2, Loss 1084.0905
	Rank 0, True Batch Size 256, Iteration 3, Loss 1126.1821
	Rank 0, True Batch Size 256, Iteration 4, Loss 1104.1439
	Rank 0, True Batch Size 256, Iteration 5, Loss 1276.8976
	Rank 0, True Batch Size 256, Iteration 6, Loss 1228.4972
	Rank 0, True Batch Size 256, Iteration 7, Loss 1065.5358
	Rank 0, True Batch Size 256, Iteration 8, Loss 887.0152
	Rank 0, True Batch Size 256, Iteration 9, Loss 1002.9686
	Rank 0, True Batch Size 256, Iteration 10, Loss 1069.1194
	Rank 0, True Batch Size 256, Iteration 11, Loss 1215.7212
	Rank 0, True Batch Size 256, Iteration 12, Loss 1135.9648
	Rank 0, True Batch Size 256, Iteration 13, Loss 983.4653
	Rank 0, True Batch Size 256, Iteration 14, Loss 1030.8691
	Rank 0, True Batch Size 256, Iteration 15, Loss 1003.2287
	Rank 0, True Batch Size 256, Iteration 16, Loss 1236.0566
	Rank 0, True Batch Size 256, Iteration 17, Loss 999.1629
	Rank 0, True Batch Size 256, Iteration 18, Loss 1156.0303
	Rank 0, True Batch Size 256, Iteration 19, Loss 1115.1331
	Rank 0, True Batch Size 256, Iteration 20, Loss 1157.0756
	Rank 0, True Batch Size 203, Iteration 21, Loss 883.8337
Epoch 11, Loss 1085.6220, Train Accuracy 0.3354, Valid Accuracy 0.3364, Test Accuracy 0.3384
	Rank 0, True Batch Size 256, Iteration 0, Loss 1029.5094
	Rank 0, True Batch Size 256, Iteration 1, Loss 1136.0747
	Rank 0, True Batch Size 256, Iteration 2, Loss 1031.2253
	Rank 0, True Batch Size 256, Iteration 3, Loss 1023.1866
	Rank 0, True Batch Size 256, Iteration 4, Loss 1046.3831
	Rank 0, True Batch Size 256, Iteration 5, Loss 975.2424
	Rank 0, True Batch Size 256, Iteration 6, Loss 1126.5007
	Rank 0, True Batch Size 256, Iteration 7, Loss 1010.6526
	Rank 0, True Batch Size 256, Iteration 8, Loss 1095.6881
	Rank 0, True Batch Size 256, Iteration 9, Loss 916.0963
	Rank 0, True Batch Size 256, Iteration 10, Loss 1013.6913
	Rank 0, True Batch Size 256, Iteration 11, Loss 873.9500
	Rank 0, True Batch Size 256, Iteration 12, Loss 1079.1986
	Rank 0, True Batch Size 256, Iteration 13, Loss 1033.2601
	Rank 0, True Batch Size 256, Iteration 14, Loss 812.9845
	Rank 0, True Batch Size 256, Iteration 15, Loss 862.3571
	Rank 0, True Batch Size 256, Iteration 16, Loss 914.4028
	Rank 0, True Batch Size 256, Iteration 17, Loss 864.5496
	Rank 0, True Batch Size 256, Iteration 18, Loss 907.2653
	Rank 0, True Batch Size 256, Iteration 19, Loss 953.6907
	Rank 0, True Batch Size 256, Iteration 20, Loss 1096.2318
	Rank 0, True Batch Size 203, Iteration 21, Loss 986.7227
Epoch 12, Loss 976.0012, Train Accuracy 0.3311, Valid Accuracy 0.3352, Test Accuracy 0.3350
	Rank 0, True Batch Size 256, Iteration 0, Loss 843.3126
	Rank 0, True Batch Size 256, Iteration 1, Loss 809.0695
	Rank 0, True Batch Size 256, Iteration 2, Loss 850.7751
	Rank 0, True Batch Size 256, Iteration 3, Loss 1038.3534
	Rank 0, True Batch Size 256, Iteration 4, Loss 875.6607
	Rank 0, True Batch Size 256, Iteration 5, Loss 796.9650
	Rank 0, True Batch Size 256, Iteration 6, Loss 887.6184
	Rank 0, True Batch Size 256, Iteration 7, Loss 1168.5599
	Rank 0, True Batch Size 256, Iteration 8, Loss 979.8605
	Rank 0, True Batch Size 256, Iteration 9, Loss 878.9919
	Rank 0, True Batch Size 256, Iteration 10, Loss 856.4388
	Rank 0, True Batch Size 256, Iteration 11, Loss 868.8212
	Rank 0, True Batch Size 256, Iteration 12, Loss 982.8607
	Rank 0, True Batch Size 256, Iteration 13, Loss 1010.0394
	Rank 0, True Batch Size 256, Iteration 14, Loss 849.5970
	Rank 0, True Batch Size 256, Iteration 15, Loss 833.0966
	Rank 0, True Batch Size 256, Iteration 16, Loss 1014.0107
	Rank 0, True Batch Size 256, Iteration 17, Loss 831.3786
	Rank 0, True Batch Size 256, Iteration 18, Loss 784.3955
	Rank 0, True Batch Size 256, Iteration 19, Loss 934.5208
	Rank 0, True Batch Size 256, Iteration 20, Loss 802.7994
	Rank 0, True Batch Size 203, Iteration 21, Loss 812.3892
Epoch 13, Loss 910.2360, Train Accuracy 0.3252, Valid Accuracy 0.3253, Test Accuracy 0.3264
	Rank 0, True Batch Size 256, Iteration 0, Loss 842.5197
	Rank 0, True Batch Size 256, Iteration 1, Loss 929.8116
	Rank 0, True Batch Size 256, Iteration 2, Loss 832.2012
	Rank 0, True Batch Size 256, Iteration 3, Loss 835.7466
	Rank 0, True Batch Size 256, Iteration 4, Loss 804.6996
	Rank 0, True Batch Size 256, Iteration 5, Loss 798.3371
	Rank 0, True Batch Size 256, Iteration 6, Loss 799.1527
	Rank 0, True Batch Size 256, Iteration 7, Loss 808.2598
	Rank 0, True Batch Size 256, Iteration 8, Loss 948.2689
	Rank 0, True Batch Size 256, Iteration 9, Loss 798.8001
	Rank 0, True Batch Size 256, Iteration 10, Loss 1037.2410
	Rank 0, True Batch Size 256, Iteration 11, Loss 728.5883
	Rank 0, True Batch Size 256, Iteration 12, Loss 879.2423
	Rank 0, True Batch Size 256, Iteration 13, Loss 839.5083
	Rank 0, True Batch Size 256, Iteration 14, Loss 891.5040
	Rank 0, True Batch Size 256, Iteration 15, Loss 804.5214
	Rank 0, True Batch Size 256, Iteration 16, Loss 976.3407
	Rank 0, True Batch Size 256, Iteration 17, Loss 826.5485
	Rank 0, True Batch Size 256, Iteration 18, Loss 896.1888
	Rank 0, True Batch Size 256, Iteration 19, Loss 800.4055
	Rank 0, True Batch Size 256, Iteration 20, Loss 818.7061
	Rank 0, True Batch Size 203, Iteration 21, Loss 798.1855
Epoch 14, Loss 857.8400, Train Accuracy 0.3259, Valid Accuracy 0.3303, Test Accuracy 0.3243
	Rank 0, True Batch Size 256, Iteration 0, Loss 741.8280
	Rank 0, True Batch Size 256, Iteration 1, Loss 917.1530
	Rank 0, True Batch Size 256, Iteration 2, Loss 865.7789
	Rank 0, True Batch Size 256, Iteration 3, Loss 799.3699
	Rank 0, True Batch Size 256, Iteration 4, Loss 778.1353
	Rank 0, True Batch Size 256, Iteration 5, Loss 883.7871
	Rank 0, True Batch Size 256, Iteration 6, Loss 724.8804
	Rank 0, True Batch Size 256, Iteration 7, Loss 784.4266
	Rank 0, True Batch Size 256, Iteration 8, Loss 895.6686
	Rank 0, True Batch Size 256, Iteration 9, Loss 708.4692
	Rank 0, True Batch Size 256, Iteration 10, Loss 778.1887
	Rank 0, True Batch Size 256, Iteration 11, Loss 792.7820
	Rank 0, True Batch Size 256, Iteration 12, Loss 664.2290
	Rank 0, True Batch Size 256, Iteration 13, Loss 800.3264
	Rank 0, True Batch Size 256, Iteration 14, Loss 779.7488
	Rank 0, True Batch Size 256, Iteration 15, Loss 1025.1552
	Rank 0, True Batch Size 256, Iteration 16, Loss 760.6657
	Rank 0, True Batch Size 256, Iteration 17, Loss 764.5283
	Rank 0, True Batch Size 256, Iteration 18, Loss 733.3078
	Rank 0, True Batch Size 256, Iteration 19, Loss 805.8194
	Rank 0, True Batch Size 256, Iteration 20, Loss 795.5550
	Rank 0, True Batch Size 203, Iteration 21, Loss 890.2927
Epoch 15, Loss 790.7430, Train Accuracy 0.3212, Valid Accuracy 0.3240, Test Accuracy 0.3205
	Rank 0, True Batch Size 256, Iteration 0, Loss 713.9572
	Rank 0, True Batch Size 256, Iteration 1, Loss 707.6331
	Rank 0, True Batch Size 256, Iteration 2, Loss 740.8456
	Rank 0, True Batch Size 256, Iteration 3, Loss 681.3160
	Rank 0, True Batch Size 256, Iteration 4, Loss 734.3234
	Rank 0, True Batch Size 256, Iteration 5, Loss 644.9072
	Rank 0, True Batch Size 256, Iteration 6, Loss 778.4261
	Rank 0, True Batch Size 256, Iteration 7, Loss 816.0598
	Rank 0, True Batch Size 256, Iteration 8, Loss 782.6478
	Rank 0, True Batch Size 256, Iteration 9, Loss 690.1750
	Rank 0, True Batch Size 256, Iteration 10, Loss 723.1033
	Rank 0, True Batch Size 256, Iteration 11, Loss 795.3244
	Rank 0, True Batch Size 256, Iteration 12, Loss 625.4244
	Rank 0, True Batch Size 256, Iteration 13, Loss 828.4700
	Rank 0, True Batch Size 256, Iteration 14, Loss 696.1309
	Rank 0, True Batch Size 256, Iteration 15, Loss 719.5472
	Rank 0, True Batch Size 256, Iteration 16, Loss 745.4236
	Rank 0, True Batch Size 256, Iteration 17, Loss 704.1122
	Rank 0, True Batch Size 256, Iteration 18, Loss 691.4634
	Rank 0, True Batch Size 256, Iteration 19, Loss 675.8975
	Rank 0, True Batch Size 256, Iteration 20, Loss 921.7476
	Rank 0, True Batch Size 203, Iteration 21, Loss 728.8149
Epoch 16, Loss 749.7670, Train Accuracy 0.3168, Valid Accuracy 0.3210, Test Accuracy 0.3193
	Rank 0, True Batch Size 256, Iteration 0, Loss 653.1931
	Rank 0, True Batch Size 256, Iteration 1, Loss 551.6155
	Rank 0, True Batch Size 256, Iteration 2, Loss 666.1167
	Rank 0, True Batch Size 256, Iteration 3, Loss 754.7823
	Rank 0, True Batch Size 256, Iteration 4, Loss 738.4611
	Rank 0, True Batch Size 256, Iteration 5, Loss 672.1616
	Rank 0, True Batch Size 256, Iteration 6, Loss 923.6975
	Rank 0, True Batch Size 256, Iteration 7, Loss 749.2097
	Rank 0, True Batch Size 256, Iteration 8, Loss 670.8839
	Rank 0, True Batch Size 256, Iteration 9, Loss 642.9232
	Rank 0, True Batch Size 256, Iteration 10, Loss 679.2396
	Rank 0, True Batch Size 256, Iteration 11, Loss 711.9333
	Rank 0, True Batch Size 256, Iteration 12, Loss 589.5336
	Rank 0, True Batch Size 256, Iteration 13, Loss 662.8808
	Rank 0, True Batch Size 256, Iteration 14, Loss 629.1204
	Rank 0, True Batch Size 256, Iteration 15, Loss 768.6599
	Rank 0, True Batch Size 256, Iteration 16, Loss 802.6769
	Rank 0, True Batch Size 256, Iteration 17, Loss 723.3248
	Rank 0, True Batch Size 256, Iteration 18, Loss 783.8654
	Rank 0, True Batch Size 256, Iteration 19, Loss 836.0403
	Rank 0, True Batch Size 256, Iteration 20, Loss 902.2496
	Rank 0, True Batch Size 203, Iteration 21, Loss 552.9392
Epoch 17, Loss 709.7339, Train Accuracy 0.3139, Valid Accuracy 0.3127, Test Accuracy 0.3131
	Rank 0, True Batch Size 256, Iteration 0, Loss 634.7864
	Rank 0, True Batch Size 256, Iteration 1, Loss 611.7786
	Rank 0, True Batch Size 256, Iteration 2, Loss 704.3917
	Rank 0, True Batch Size 256, Iteration 3, Loss 625.5125
	Rank 0, True Batch Size 256, Iteration 4, Loss 572.7143
	Rank 0, True Batch Size 256, Iteration 5, Loss 630.7255
	Rank 0, True Batch Size 256, Iteration 6, Loss 672.5095
	Rank 0, True Batch Size 256, Iteration 7, Loss 596.2253
	Rank 0, True Batch Size 256, Iteration 8, Loss 650.1364
	Rank 0, True Batch Size 256, Iteration 9, Loss 514.5136
	Rank 0, True Batch Size 256, Iteration 10, Loss 829.1751
	Rank 0, True Batch Size 256, Iteration 11, Loss 782.4421
	Rank 0, True Batch Size 256, Iteration 12, Loss 586.5217
	Rank 0, True Batch Size 256, Iteration 13, Loss 576.2775
	Rank 0, True Batch Size 256, Iteration 14, Loss 572.3630
	Rank 0, True Batch Size 256, Iteration 15, Loss 727.0695
	Rank 0, True Batch Size 256, Iteration 16, Loss 594.9203
	Rank 0, True Batch Size 256, Iteration 17, Loss 708.4398
	Rank 0, True Batch Size 256, Iteration 18, Loss 700.8030
	Rank 0, True Batch Size 256, Iteration 19, Loss 724.3396
	Rank 0, True Batch Size 256, Iteration 20, Loss 894.5286
	Rank 0, True Batch Size 203, Iteration 21, Loss 636.5787
Epoch 18, Loss 661.8630, Train Accuracy 0.3106, Valid Accuracy 0.3139, Test Accuracy 0.3130
	Rank 0, True Batch Size 256, Iteration 0, Loss 721.2862
	Rank 0, True Batch Size 256, Iteration 1, Loss 595.9028
	Rank 0, True Batch Size 256, Iteration 2, Loss 518.1904
	Rank 0, True Batch Size 256, Iteration 3, Loss 584.0720
	Rank 0, True Batch Size 256, Iteration 4, Loss 684.0732
	Rank 0, True Batch Size 256, Iteration 5, Loss 694.3945
	Rank 0, True Batch Size 256, Iteration 6, Loss 668.6323
	Rank 0, True Batch Size 256, Iteration 7, Loss 677.0250
	Rank 0, True Batch Size 256, Iteration 8, Loss 671.1923
	Rank 0, True Batch Size 256, Iteration 9, Loss 670.0373
	Rank 0, True Batch Size 256, Iteration 10, Loss 622.5973
	Rank 0, True Batch Size 256, Iteration 11, Loss 570.5081
	Rank 0, True Batch Size 256, Iteration 12, Loss 597.1656
	Rank 0, True Batch Size 256, Iteration 13, Loss 608.7074
	Rank 0, True Batch Size 256, Iteration 14, Loss 582.2499
	Rank 0, True Batch Size 256, Iteration 15, Loss 510.4017
	Rank 0, True Batch Size 256, Iteration 16, Loss 570.7292
	Rank 0, True Batch Size 256, Iteration 17, Loss 629.8939
	Rank 0, True Batch Size 256, Iteration 18, Loss 586.9503
	Rank 0, True Batch Size 256, Iteration 19, Loss 589.9806
	Rank 0, True Batch Size 256, Iteration 20, Loss 575.3547
	Rank 0, True Batch Size 203, Iteration 21, Loss 545.8842
Epoch 19, Loss 632.1268, Train Accuracy 0.3052, Valid Accuracy 0.3110, Test Accuracy 0.3120
	Rank 0, True Batch Size 256, Iteration 0, Loss 759.1633
	Rank 0, True Batch Size 256, Iteration 1, Loss 580.7249
	Rank 0, True Batch Size 256, Iteration 2, Loss 693.3782
	Rank 0, True Batch Size 256, Iteration 3, Loss 667.0404
	Rank 0, True Batch Size 256, Iteration 4, Loss 676.9800
	Rank 0, True Batch Size 256, Iteration 5, Loss 589.3003
	Rank 0, True Batch Size 256, Iteration 6, Loss 549.0287
	Rank 0, True Batch Size 256, Iteration 7, Loss 640.7665
	Rank 0, True Batch Size 256, Iteration 8, Loss 556.1996
	Rank 0, True Batch Size 256, Iteration 9, Loss 646.3967
	Rank 0, True Batch Size 256, Iteration 10, Loss 501.0991
	Rank 0, True Batch Size 256, Iteration 11, Loss 754.4731
	Rank 0, True Batch Size 256, Iteration 12, Loss 705.2767
	Rank 0, True Batch Size 256, Iteration 13, Loss 537.3775
	Rank 0, True Batch Size 256, Iteration 14, Loss 588.9051
	Rank 0, True Batch Size 256, Iteration 15, Loss 516.3380
	Rank 0, True Batch Size 256, Iteration 16, Loss 610.6486
	Rank 0, True Batch Size 256, Iteration 17, Loss 537.4271
	Rank 0, True Batch Size 256, Iteration 18, Loss 544.9397
	Rank 0, True Batch Size 256, Iteration 19, Loss 550.0889
	Rank 0, True Batch Size 256, Iteration 20, Loss 604.8100
	Rank 0, True Batch Size 203, Iteration 21, Loss 750.5594
Epoch 20, Loss 594.3227, Train Accuracy 0.3052, Valid Accuracy 0.3106, Test Accuracy 0.3072
	Rank 0, True Batch Size 256, Iteration 0, Loss 536.3267
	Rank 0, True Batch Size 256, Iteration 1, Loss 499.1371
	Rank 0, True Batch Size 256, Iteration 2, Loss 612.4407
	Rank 0, True Batch Size 256, Iteration 3, Loss 575.3337
	Rank 0, True Batch Size 256, Iteration 4, Loss 640.6448
	Rank 0, True Batch Size 256, Iteration 5, Loss 493.9155
	Rank 0, True Batch Size 256, Iteration 6, Loss 677.5364
	Rank 0, True Batch Size 256, Iteration 7, Loss 499.4970
	Rank 0, True Batch Size 256, Iteration 8, Loss 575.4566
	Rank 0, True Batch Size 256, Iteration 9, Loss 579.7288
	Rank 0, True Batch Size 256, Iteration 10, Loss 470.3483
	Rank 0, True Batch Size 256, Iteration 11, Loss 519.6874
	Rank 0, True Batch Size 256, Iteration 12, Loss 522.0201
	Rank 0, True Batch Size 256, Iteration 13, Loss 579.9032
	Rank 0, True Batch Size 256, Iteration 14, Loss 505.5787
	Rank 0, True Batch Size 256, Iteration 15, Loss 515.9229
	Rank 0, True Batch Size 256, Iteration 16, Loss 529.9410
	Rank 0, True Batch Size 256, Iteration 17, Loss 653.6179
	Rank 0, True Batch Size 256, Iteration 18, Loss 511.5174
	Rank 0, True Batch Size 256, Iteration 19, Loss 534.0679
	Rank 0, True Batch Size 256, Iteration 20, Loss 543.5314
	Rank 0, True Batch Size 203, Iteration 21, Loss 566.8640
Epoch 21, Loss 563.4800, Train Accuracy 0.3049, Valid Accuracy 0.3040, Test Accuracy 0.3042
	Rank 0, True Batch Size 256, Iteration 0, Loss 680.6432
	Rank 0, True Batch Size 256, Iteration 1, Loss 548.9999
	Rank 0, True Batch Size 256, Iteration 2, Loss 473.9110
	Rank 0, True Batch Size 256, Iteration 3, Loss 620.5355
	Rank 0, True Batch Size 256, Iteration 4, Loss 587.2079
	Rank 0, True Batch Size 256, Iteration 5, Loss 491.4056
	Rank 0, True Batch Size 256, Iteration 6, Loss 513.4350
	Rank 0, True Batch Size 256, Iteration 7, Loss 512.7038
	Rank 0, True Batch Size 256, Iteration 8, Loss 523.8297
	Rank 0, True Batch Size 256, Iteration 9, Loss 477.6765
	Rank 0, True Batch Size 256, Iteration 10, Loss 589.2021
	Rank 0, True Batch Size 256, Iteration 11, Loss 511.7036
	Rank 0, True Batch Size 256, Iteration 12, Loss 510.0390
	Rank 0, True Batch Size 256, Iteration 13, Loss 522.5652
	Rank 0, True Batch Size 256, Iteration 14, Loss 552.0596
	Rank 0, True Batch Size 256, Iteration 15, Loss 531.0524
	Rank 0, True Batch Size 256, Iteration 16, Loss 512.4989
	Rank 0, True Batch Size 256, Iteration 17, Loss 575.0818
	Rank 0, True Batch Size 256, Iteration 18, Loss 462.7714
	Rank 0, True Batch Size 256, Iteration 19, Loss 538.9817
	Rank 0, True Batch Size 256, Iteration 20, Loss 487.1736
	Rank 0, True Batch Size 203, Iteration 21, Loss 543.4272
Epoch 22, Loss 537.8988, Train Accuracy 0.3014, Valid Accuracy 0.3018, Test Accuracy 0.3025
	Rank 0, True Batch Size 256, Iteration 0, Loss 460.4091
	Rank 0, True Batch Size 256, Iteration 1, Loss 478.6030
	Rank 0, True Batch Size 256, Iteration 2, Loss 441.6732
	Rank 0, True Batch Size 256, Iteration 3, Loss 504.2229
	Rank 0, True Batch Size 256, Iteration 4, Loss 534.4202
	Rank 0, True Batch Size 256, Iteration 5, Loss 476.3021
	Rank 0, True Batch Size 256, Iteration 6, Loss 570.0139
	Rank 0, True Batch Size 256, Iteration 7, Loss 523.3896
	Rank 0, True Batch Size 256, Iteration 8, Loss 473.7960
	Rank 0, True Batch Size 256, Iteration 9, Loss 552.4621
	Rank 0, True Batch Size 256, Iteration 10, Loss 547.2845
	Rank 0, True Batch Size 256, Iteration 11, Loss 380.8260
	Rank 0, True Batch Size 256, Iteration 12, Loss 467.3580
	Rank 0, True Batch Size 256, Iteration 13, Loss 580.7165
	Rank 0, True Batch Size 256, Iteration 14, Loss 425.3409
	Rank 0, True Batch Size 256, Iteration 15, Loss 496.7563
	Rank 0, True Batch Size 256, Iteration 16, Loss 634.6699
	Rank 0, True Batch Size 256, Iteration 17, Loss 492.3009
	Rank 0, True Batch Size 256, Iteration 18, Loss 513.4426
	Rank 0, True Batch Size 256, Iteration 19, Loss 480.9508
	Rank 0, True Batch Size 256, Iteration 20, Loss 506.1098
	Rank 0, True Batch Size 203, Iteration 21, Loss 576.2367
Epoch 23, Loss 509.6990, Train Accuracy 0.3003, Valid Accuracy 0.2981, Test Accuracy 0.2950
	Rank 0, True Batch Size 256, Iteration 0, Loss 469.2609
	Rank 0, True Batch Size 256, Iteration 1, Loss 494.9714
	Rank 0, True Batch Size 256, Iteration 2, Loss 518.8533
	Rank 0, True Batch Size 256, Iteration 3, Loss 476.4162
	Rank 0, True Batch Size 256, Iteration 4, Loss 498.1355
	Rank 0, True Batch Size 256, Iteration 5, Loss 628.2310
	Rank 0, True Batch Size 256, Iteration 6, Loss 518.9918
	Rank 0, True Batch Size 256, Iteration 7, Loss 475.0129
	Rank 0, True Batch Size 256, Iteration 8, Loss 494.4759
	Rank 0, True Batch Size 256, Iteration 9, Loss 414.4710
	Rank 0, True Batch Size 256, Iteration 10, Loss 519.4159
	Rank 0, True Batch Size 256, Iteration 11, Loss 422.3693
	Rank 0, True Batch Size 256, Iteration 12, Loss 637.7739
	Rank 0, True Batch Size 256, Iteration 13, Loss 448.2862
	Rank 0, True Batch Size 256, Iteration 14, Loss 413.4387
	Rank 0, True Batch Size 256, Iteration 15, Loss 492.3247
	Rank 0, True Batch Size 256, Iteration 16, Loss 494.3424
	Rank 0, True Batch Size 256, Iteration 17, Loss 483.4555
	Rank 0, True Batch Size 256, Iteration 18, Loss 447.5788
	Rank 0, True Batch Size 256, Iteration 19, Loss 435.3604
	Rank 0, True Batch Size 256, Iteration 20, Loss 485.9890
	Rank 0, True Batch Size 203, Iteration 21, Loss 436.9668
Epoch 24, Loss 498.4525, Train Accuracy 0.2996, Valid Accuracy 0.3029, Test Accuracy 0.3026
	Rank 0, True Batch Size 256, Iteration 0, Loss 551.4894
	Rank 0, True Batch Size 256, Iteration 1, Loss 398.1017
	Rank 0, True Batch Size 256, Iteration 2, Loss 411.0825
	Rank 0, True Batch Size 256, Iteration 3, Loss 453.9919
	Rank 0, True Batch Size 256, Iteration 4, Loss 428.4008
	Rank 0, True Batch Size 256, Iteration 5, Loss 387.7705
	Rank 0, True Batch Size 256, Iteration 6, Loss 442.4644
	Rank 0, True Batch Size 256, Iteration 7, Loss 488.0982
	Rank 0, True Batch Size 256, Iteration 8, Loss 393.2469
	Rank 0, True Batch Size 256, Iteration 9, Loss 424.9441
	Rank 0, True Batch Size 256, Iteration 10, Loss 397.8276
	Rank 0, True Batch Size 256, Iteration 11, Loss 440.8711
	Rank 0, True Batch Size 256, Iteration 12, Loss 427.3760
	Rank 0, True Batch Size 256, Iteration 13, Loss 565.2465
	Rank 0, True Batch Size 256, Iteration 14, Loss 423.0966
	Rank 0, True Batch Size 256, Iteration 15, Loss 517.1963
	Rank 0, True Batch Size 256, Iteration 16, Loss 382.3202
	Rank 0, True Batch Size 256, Iteration 17, Loss 499.3571
	Rank 0, True Batch Size 256, Iteration 18, Loss 400.4907
	Rank 0, True Batch Size 256, Iteration 19, Loss 448.0750
	Rank 0, True Batch Size 256, Iteration 20, Loss 482.8273
	Rank 0, True Batch Size 203, Iteration 21, Loss 417.8802
Epoch 25, Loss 461.0998, Train Accuracy 0.2971, Valid Accuracy 0.3020, Test Accuracy 0.3000
	Rank 0, True Batch Size 256, Iteration 0, Loss 445.2490
	Rank 0, True Batch Size 256, Iteration 1, Loss 423.0945
	Rank 0, True Batch Size 256, Iteration 2, Loss 409.0397
	Rank 0, True Batch Size 256, Iteration 3, Loss 498.9520
	Rank 0, True Batch Size 256, Iteration 4, Loss 470.9759
	Rank 0, True Batch Size 256, Iteration 5, Loss 512.1864
	Rank 0, True Batch Size 256, Iteration 6, Loss 530.1164
	Rank 0, True Batch Size 256, Iteration 7, Loss 417.5982
	Rank 0, True Batch Size 256, Iteration 8, Loss 475.3298
	Rank 0, True Batch Size 256, Iteration 9, Loss 424.1497
	Rank 0, True Batch Size 256, Iteration 10, Loss 394.9321
	Rank 0, True Batch Size 256, Iteration 11, Loss 417.9535
	Rank 0, True Batch Size 256, Iteration 12, Loss 462.5648
	Rank 0, True Batch Size 256, Iteration 13, Loss 405.0305
	Rank 0, True Batch Size 256, Iteration 14, Loss 436.6184
	Rank 0, True Batch Size 256, Iteration 15, Loss 444.6640
	Rank 0, True Batch Size 256, Iteration 16, Loss 345.2022
	Rank 0, True Batch Size 256, Iteration 17, Loss 366.4696
	Rank 0, True Batch Size 256, Iteration 18, Loss 434.0052
	Rank 0, True Batch Size 256, Iteration 19, Loss 423.5683
	Rank 0, True Batch Size 256, Iteration 20, Loss 362.5394
	Rank 0, True Batch Size 203, Iteration 21, Loss 386.0818
Epoch 26, Loss 433.3922, Train Accuracy 0.2990, Valid Accuracy 0.3002, Test Accuracy 0.2934
	Rank 0, True Batch Size 256, Iteration 0, Loss 479.6043
	Rank 0, True Batch Size 256, Iteration 1, Loss 343.9359
	Rank 0, True Batch Size 256, Iteration 2, Loss 378.8480
	Rank 0, True Batch Size 256, Iteration 3, Loss 410.0557
	Rank 0, True Batch Size 256, Iteration 4, Loss 397.5903
	Rank 0, True Batch Size 256, Iteration 5, Loss 387.0175
	Rank 0, True Batch Size 256, Iteration 6, Loss 410.7878
	Rank 0, True Batch Size 256, Iteration 7, Loss 464.1634
	Rank 0, True Batch Size 256, Iteration 8, Loss 394.0069
	Rank 0, True Batch Size 256, Iteration 9, Loss 354.6086
	Rank 0, True Batch Size 256, Iteration 10, Loss 495.2703
	Rank 0, True Batch Size 256, Iteration 11, Loss 420.9960
	Rank 0, True Batch Size 256, Iteration 12, Loss 437.0223
	Rank 0, True Batch Size 256, Iteration 13, Loss 397.7343
	Rank 0, True Batch Size 256, Iteration 14, Loss 419.9171
	Rank 0, True Batch Size 256, Iteration 15, Loss 325.6644
	Rank 0, True Batch Size 256, Iteration 16, Loss 352.8139
	Rank 0, True Batch Size 256, Iteration 17, Loss 377.5807
	Rank 0, True Batch Size 256, Iteration 18, Loss 588.0759
	Rank 0, True Batch Size 256, Iteration 19, Loss 382.6217
	Rank 0, True Batch Size 256, Iteration 20, Loss 398.1114
	Rank 0, True Batch Size 203, Iteration 21, Loss 423.4995
Epoch 27, Loss 416.4823, Train Accuracy 0.2941, Valid Accuracy 0.2955, Test Accuracy 0.2957
	Rank 0, True Batch Size 256, Iteration 0, Loss 381.9665
	Rank 0, True Batch Size 256, Iteration 1, Loss 415.6549
	Rank 0, True Batch Size 256, Iteration 2, Loss 359.8705
	Rank 0, True Batch Size 256, Iteration 3, Loss 339.3675
	Rank 0, True Batch Size 256, Iteration 4, Loss 349.9576
	Rank 0, True Batch Size 256, Iteration 5, Loss 388.1824
	Rank 0, True Batch Size 256, Iteration 6, Loss 391.6530
	Rank 0, True Batch Size 256, Iteration 7, Loss 347.6004
	Rank 0, True Batch Size 256, Iteration 8, Loss 372.9959
	Rank 0, True Batch Size 256, Iteration 9, Loss 398.1565
	Rank 0, True Batch Size 256, Iteration 10, Loss 400.4958
	Rank 0, True Batch Size 256, Iteration 11, Loss 372.8554
	Rank 0, True Batch Size 256, Iteration 12, Loss 467.5739
	Rank 0, True Batch Size 256, Iteration 13, Loss 405.1739
	Rank 0, True Batch Size 256, Iteration 14, Loss 361.2443
	Rank 0, True Batch Size 256, Iteration 15, Loss 395.4574
	Rank 0, True Batch Size 256, Iteration 16, Loss 442.4291
	Rank 0, True Batch Size 256, Iteration 17, Loss 359.7860
	Rank 0, True Batch Size 256, Iteration 18, Loss 349.6930
	Rank 0, True Batch Size 256, Iteration 19, Loss 377.2200
	Rank 0, True Batch Size 256, Iteration 20, Loss 592.2554
	Rank 0, True Batch Size 203, Iteration 21, Loss 372.6932
Epoch 28, Loss 404.6962, Train Accuracy 0.2948, Valid Accuracy 0.2957, Test Accuracy 0.2987
	Rank 0, True Batch Size 256, Iteration 0, Loss 374.4042
	Rank 0, True Batch Size 256, Iteration 1, Loss 349.8214
	Rank 0, True Batch Size 256, Iteration 2, Loss 430.1615
	Rank 0, True Batch Size 256, Iteration 3, Loss 428.8239
	Rank 0, True Batch Size 256, Iteration 4, Loss 485.7453
	Rank 0, True Batch Size 256, Iteration 5, Loss 309.3723
	Rank 0, True Batch Size 256, Iteration 6, Loss 322.1232
	Rank 0, True Batch Size 256, Iteration 7, Loss 371.1077
	Rank 0, True Batch Size 256, Iteration 8, Loss 454.8014
	Rank 0, True Batch Size 256, Iteration 9, Loss 448.1557
	Rank 0, True Batch Size 256, Iteration 10, Loss 369.5696
	Rank 0, True Batch Size 256, Iteration 11, Loss 377.2282
	Rank 0, True Batch Size 256, Iteration 12, Loss 414.6802
	Rank 0, True Batch Size 256, Iteration 13, Loss 331.9307
	Rank 0, True Batch Size 256, Iteration 14, Loss 361.1670
	Rank 0, True Batch Size 256, Iteration 15, Loss 452.6488
	Rank 0, True Batch Size 256, Iteration 16, Loss 377.2916
	Rank 0, True Batch Size 256, Iteration 17, Loss 376.7612
	Rank 0, True Batch Size 256, Iteration 18, Loss 405.5469
	Rank 0, True Batch Size 256, Iteration 19, Loss 519.2989
	Rank 0, True Batch Size 256, Iteration 20, Loss 299.9541
	Rank 0, True Batch Size 203, Iteration 21, Loss 392.8509
Epoch 29, Loss 391.3479, Train Accuracy 0.2938, Valid Accuracy 0.2916, Test Accuracy 0.2921
	Rank 0, True Batch Size 256, Iteration 0, Loss 353.7497
	Rank 0, True Batch Size 256, Iteration 1, Loss 388.4515
	Rank 0, True Batch Size 256, Iteration 2, Loss 415.9390
	Rank 0, True Batch Size 256, Iteration 3, Loss 339.5027
	Rank 0, True Batch Size 256, Iteration 4, Loss 371.0130
	Rank 0, True Batch Size 256, Iteration 5, Loss 389.0153
	Rank 0, True Batch Size 256, Iteration 6, Loss 339.0537
	Rank 0, True Batch Size 256, Iteration 7, Loss 352.3093
	Rank 0, True Batch Size 256, Iteration 8, Loss 306.3611
	Rank 0, True Batch Size 256, Iteration 9, Loss 388.5368
	Rank 0, True Batch Size 256, Iteration 10, Loss 400.3739
	Rank 0, True Batch Size 256, Iteration 11, Loss 439.6965
	Rank 0, True Batch Size 256, Iteration 12, Loss 321.8322
	Rank 0, True Batch Size 256, Iteration 13, Loss 272.3305
	Rank 0, True Batch Size 256, Iteration 14, Loss 471.4116
	Rank 0, True Batch Size 256, Iteration 15, Loss 356.8985
	Rank 0, True Batch Size 256, Iteration 16, Loss 377.6880
	Rank 0, True Batch Size 256, Iteration 17, Loss 389.5313
	Rank 0, True Batch Size 256, Iteration 18, Loss 386.1084
	Rank 0, True Batch Size 256, Iteration 19, Loss 333.5306
	Rank 0, True Batch Size 256, Iteration 20, Loss 400.0878
	Rank 0, True Batch Size 203, Iteration 21, Loss 354.5336
Epoch 30, Loss 372.1125, Train Accuracy 0.2905, Valid Accuracy 0.2927, Test Accuracy 0.2895
	Rank 0, True Batch Size 256, Iteration 0, Loss 300.9737
	Rank 0, True Batch Size 256, Iteration 1, Loss 342.1327
	Rank 0, True Batch Size 256, Iteration 2, Loss 298.5926
	Rank 0, True Batch Size 256, Iteration 3, Loss 371.0102
	Rank 0, True Batch Size 256, Iteration 4, Loss 317.6672
	Rank 0, True Batch Size 256, Iteration 5, Loss 305.0402
	Rank 0, True Batch Size 256, Iteration 6, Loss 338.4572
	Rank 0, True Batch Size 256, Iteration 7, Loss 333.3856
	Rank 0, True Batch Size 256, Iteration 8, Loss 322.6033
	Rank 0, True Batch Size 256, Iteration 9, Loss 350.8445
	Rank 0, True Batch Size 256, Iteration 10, Loss 308.6747
	Rank 0, True Batch Size 256, Iteration 11, Loss 351.6725
	Rank 0, True Batch Size 256, Iteration 12, Loss 316.7718
	Rank 0, True Batch Size 256, Iteration 13, Loss 370.1073
	Rank 0, True Batch Size 256, Iteration 14, Loss 356.2846
	Rank 0, True Batch Size 256, Iteration 15, Loss 411.4875
	Rank 0, True Batch Size 256, Iteration 16, Loss 428.0934
	Rank 0, True Batch Size 256, Iteration 17, Loss 332.3805
	Rank 0, True Batch Size 256, Iteration 18, Loss 334.1353
	Rank 0, True Batch Size 256, Iteration 19, Loss 317.5091
	Rank 0, True Batch Size 256, Iteration 20, Loss 313.4561
	Rank 0, True Batch Size 203, Iteration 21, Loss 301.9916
Epoch 31, Loss 354.3696, Train Accuracy 0.2876, Valid Accuracy 0.2843, Test Accuracy 0.2964
	Rank 0, True Batch Size 256, Iteration 0, Loss 449.9920
	Rank 0, True Batch Size 256, Iteration 1, Loss 356.2758
	Rank 0, True Batch Size 256, Iteration 2, Loss 322.0069
	Rank 0, True Batch Size 256, Iteration 3, Loss 362.1219
	Rank 0, True Batch Size 256, Iteration 4, Loss 315.0320
	Rank 0, True Batch Size 256, Iteration 5, Loss 292.8658
	Rank 0, True Batch Size 256, Iteration 6, Loss 313.4473
	Rank 0, True Batch Size 256, Iteration 7, Loss 287.9336
	Rank 0, True Batch Size 256, Iteration 8, Loss 311.9127
	Rank 0, True Batch Size 256, Iteration 9, Loss 399.4960
	Rank 0, True Batch Size 256, Iteration 10, Loss 300.9224
	Rank 0, True Batch Size 256, Iteration 11, Loss 383.9931
	Rank 0, True Batch Size 256, Iteration 12, Loss 296.1181
	Rank 0, True Batch Size 256, Iteration 13, Loss 298.9260
	Rank 0, True Batch Size 256, Iteration 14, Loss 380.4476
	Rank 0, True Batch Size 256, Iteration 15, Loss 349.0899
	Rank 0, True Batch Size 256, Iteration 16, Loss 262.4673
	Rank 0, True Batch Size 256, Iteration 17, Loss 336.3028
	Rank 0, True Batch Size 256, Iteration 18, Loss 339.5618
	Rank 0, True Batch Size 256, Iteration 19, Loss 274.2283
	Rank 0, True Batch Size 256, Iteration 20, Loss 280.9684
	Rank 0, True Batch Size 203, Iteration 21, Loss 312.6683
Epoch 32, Loss 341.3290, Train Accuracy 0.2875, Valid Accuracy 0.2889, Test Accuracy 0.2879
	Rank 0, True Batch Size 256, Iteration 0, Loss 388.9845
	Rank 0, True Batch Size 256, Iteration 1, Loss 305.2789
	Rank 0, True Batch Size 256, Iteration 2, Loss 315.9735
	Rank 0, True Batch Size 256, Iteration 3, Loss 329.9461
	Rank 0, True Batch Size 256, Iteration 4, Loss 264.4638
	Rank 0, True Batch Size 256, Iteration 5, Loss 306.6989
	Rank 0, True Batch Size 256, Iteration 6, Loss 264.7426
	Rank 0, True Batch Size 256, Iteration 7, Loss 332.0493
	Rank 0, True Batch Size 256, Iteration 8, Loss 418.7214
	Rank 0, True Batch Size 256, Iteration 9, Loss 291.4070
	Rank 0, True Batch Size 256, Iteration 10, Loss 271.0390
	Rank 0, True Batch Size 256, Iteration 11, Loss 331.2076
	Rank 0, True Batch Size 256, Iteration 12, Loss 304.3799
	Rank 0, True Batch Size 256, Iteration 13, Loss 417.5512
	Rank 0, True Batch Size 256, Iteration 14, Loss 269.6249
	Rank 0, True Batch Size 256, Iteration 15, Loss 270.6235
	Rank 0, True Batch Size 256, Iteration 16, Loss 348.0649
	Rank 0, True Batch Size 256, Iteration 17, Loss 298.0001
	Rank 0, True Batch Size 256, Iteration 18, Loss 327.3151
	Rank 0, True Batch Size 256, Iteration 19, Loss 380.7842
	Rank 0, True Batch Size 256, Iteration 20, Loss 300.1841
	Rank 0, True Batch Size 203, Iteration 21, Loss 304.1039
Epoch 33, Loss 324.4086, Train Accuracy 0.2871, Valid Accuracy 0.2928, Test Accuracy 0.2850
	Rank 0, True Batch Size 256, Iteration 0, Loss 374.2611
	Rank 0, True Batch Size 256, Iteration 1, Loss 321.9391
	Rank 0, True Batch Size 256, Iteration 2, Loss 283.8851
	Rank 0, True Batch Size 256, Iteration 3, Loss 321.1058
	Rank 0, True Batch Size 256, Iteration 4, Loss 233.9110
	Rank 0, True Batch Size 256, Iteration 5, Loss 352.3628
	Rank 0, True Batch Size 256, Iteration 6, Loss 266.9498
	Rank 0, True Batch Size 256, Iteration 7, Loss 280.3600
	Rank 0, True Batch Size 256, Iteration 8, Loss 296.1576
	Rank 0, True Batch Size 256, Iteration 9, Loss 264.3682
	Rank 0, True Batch Size 256, Iteration 10, Loss 311.0238
	Rank 0, True Batch Size 256, Iteration 11, Loss 269.7625
	Rank 0, True Batch Size 256, Iteration 12, Loss 400.3444
	Rank 0, True Batch Size 256, Iteration 13, Loss 308.8790
	Rank 0, True Batch Size 256, Iteration 14, Loss 351.2501
	Rank 0, True Batch Size 256, Iteration 15, Loss 305.7581
	Rank 0, True Batch Size 256, Iteration 16, Loss 343.9177
	Rank 0, True Batch Size 256, Iteration 17, Loss 337.1024
	Rank 0, True Batch Size 256, Iteration 18, Loss 319.6118
	Rank 0, True Batch Size 256, Iteration 19, Loss 380.0365
	Rank 0, True Batch Size 256, Iteration 20, Loss 347.3487
	Rank 0, True Batch Size 203, Iteration 21, Loss 316.6849
Epoch 34, Loss 313.6973, Train Accuracy 0.2847, Valid Accuracy 0.2861, Test Accuracy 0.2858
	Rank 0, True Batch Size 256, Iteration 0, Loss 341.5652
	Rank 0, True Batch Size 256, Iteration 1, Loss 257.6799
	Rank 0, True Batch Size 256, Iteration 2, Loss 265.7960
	Rank 0, True Batch Size 256, Iteration 3, Loss 316.9206
	Rank 0, True Batch Size 256, Iteration 4, Loss 258.5103
	Rank 0, True Batch Size 256, Iteration 5, Loss 283.4762
	Rank 0, True Batch Size 256, Iteration 6, Loss 293.0553
	Rank 0, True Batch Size 256, Iteration 7, Loss 264.1091
	Rank 0, True Batch Size 256, Iteration 8, Loss 335.7802
	Rank 0, True Batch Size 256, Iteration 9, Loss 310.9399
	Rank 0, True Batch Size 256, Iteration 10, Loss 306.1150
	Rank 0, True Batch Size 256, Iteration 11, Loss 341.7921
	Rank 0, True Batch Size 256, Iteration 12, Loss 320.8116
	Rank 0, True Batch Size 256, Iteration 13, Loss 277.7168
	Rank 0, True Batch Size 256, Iteration 14, Loss 338.5019
	Rank 0, True Batch Size 256, Iteration 15, Loss 320.1436
	Rank 0, True Batch Size 256, Iteration 16, Loss 272.2921
	Rank 0, True Batch Size 256, Iteration 17, Loss 232.7900
	Rank 0, True Batch Size 256, Iteration 18, Loss 252.2516
	Rank 0, True Batch Size 256, Iteration 19, Loss 267.5493
	Rank 0, True Batch Size 256, Iteration 20, Loss 250.5106
	Rank 0, True Batch Size 203, Iteration 21, Loss 308.0701
Epoch 35, Loss 299.5058, Train Accuracy 0.2829, Valid Accuracy 0.2841, Test Accuracy 0.2842
	Rank 0, True Batch Size 256, Iteration 0, Loss 252.5708
	Rank 0, True Batch Size 256, Iteration 1, Loss 341.9907
	Rank 0, True Batch Size 256, Iteration 2, Loss 271.6902
	Rank 0, True Batch Size 256, Iteration 3, Loss 336.8658
	Rank 0, True Batch Size 256, Iteration 4, Loss 280.2838
	Rank 0, True Batch Size 256, Iteration 5, Loss 287.4802
	Rank 0, True Batch Size 256, Iteration 6, Loss 267.5487
	Rank 0, True Batch Size 256, Iteration 7, Loss 310.1298
	Rank 0, True Batch Size 256, Iteration 8, Loss 249.8198
	Rank 0, True Batch Size 256, Iteration 9, Loss 261.4698
	Rank 0, True Batch Size 256, Iteration 10, Loss 274.1764
	Rank 0, True Batch Size 256, Iteration 11, Loss 259.8135
	Rank 0, True Batch Size 256, Iteration 12, Loss 273.5294
	Rank 0, True Batch Size 256, Iteration 13, Loss 256.2665
	Rank 0, True Batch Size 256, Iteration 14, Loss 183.8929
	Rank 0, True Batch Size 256, Iteration 15, Loss 336.7808
	Rank 0, True Batch Size 256, Iteration 16, Loss 301.7426
	Rank 0, True Batch Size 256, Iteration 17, Loss 287.6897
	Rank 0, True Batch Size 256, Iteration 18, Loss 301.3595
	Rank 0, True Batch Size 256, Iteration 19, Loss 241.5795
	Rank 0, True Batch Size 256, Iteration 20, Loss 230.3965
	Rank 0, True Batch Size 203, Iteration 21, Loss 231.5235
Epoch 36, Loss 284.5148, Train Accuracy 0.2862, Valid Accuracy 0.2880, Test Accuracy 0.2849
	Rank 0, True Batch Size 256, Iteration 0, Loss 290.0163
	Rank 0, True Batch Size 256, Iteration 1, Loss 225.9120
	Rank 0, True Batch Size 256, Iteration 2, Loss 256.7126
	Rank 0, True Batch Size 256, Iteration 3, Loss 265.9515
	Rank 0, True Batch Size 256, Iteration 4, Loss 276.0793
	Rank 0, True Batch Size 256, Iteration 5, Loss 409.9922
	Rank 0, True Batch Size 256, Iteration 6, Loss 283.4058
	Rank 0, True Batch Size 256, Iteration 7, Loss 299.9011
	Rank 0, True Batch Size 256, Iteration 8, Loss 261.9905
	Rank 0, True Batch Size 256, Iteration 9, Loss 237.1128
	Rank 0, True Batch Size 256, Iteration 10, Loss 226.9137
	Rank 0, True Batch Size 256, Iteration 11, Loss 248.3454
	Rank 0, True Batch Size 256, Iteration 12, Loss 229.5601
	Rank 0, True Batch Size 256, Iteration 13, Loss 298.1997
	Rank 0, True Batch Size 256, Iteration 14, Loss 295.6125
	Rank 0, True Batch Size 256, Iteration 15, Loss 240.2294
	Rank 0, True Batch Size 256, Iteration 16, Loss 313.2220
	Rank 0, True Batch Size 256, Iteration 17, Loss 339.4875
	Rank 0, True Batch Size 256, Iteration 18, Loss 264.0796
	Rank 0, True Batch Size 256, Iteration 19, Loss 326.9384
	Rank 0, True Batch Size 256, Iteration 20, Loss 229.2937
	Rank 0, True Batch Size 203, Iteration 21, Loss 330.4055
Epoch 37, Loss 275.4081, Train Accuracy 0.2777, Valid Accuracy 0.2854, Test Accuracy 0.2787
	Rank 0, True Batch Size 256, Iteration 0, Loss 223.3782
	Rank 0, True Batch Size 256, Iteration 1, Loss 228.7950
	Rank 0, True Batch Size 256, Iteration 2, Loss 253.9948
	Rank 0, True Batch Size 256, Iteration 3, Loss 233.0116
	Rank 0, True Batch Size 256, Iteration 4, Loss 240.6470
	Rank 0, True Batch Size 256, Iteration 5, Loss 234.6406
	Rank 0, True Batch Size 256, Iteration 6, Loss 221.5443
	Rank 0, True Batch Size 256, Iteration 7, Loss 294.9732
	Rank 0, True Batch Size 256, Iteration 8, Loss 300.1287
	Rank 0, True Batch Size 256, Iteration 9, Loss 300.8577
	Rank 0, True Batch Size 256, Iteration 10, Loss 253.5880
	Rank 0, True Batch Size 256, Iteration 11, Loss 183.3940
	Rank 0, True Batch Size 256, Iteration 12, Loss 255.9792
	Rank 0, True Batch Size 256, Iteration 13, Loss 277.5825
	Rank 0, True Batch Size 256, Iteration 14, Loss 287.1248
	Rank 0, True Batch Size 256, Iteration 15, Loss 269.8031
	Rank 0, True Batch Size 256, Iteration 16, Loss 286.3144
	Rank 0, True Batch Size 256, Iteration 17, Loss 225.8416
	Rank 0, True Batch Size 256, Iteration 18, Loss 289.5252
	Rank 0, True Batch Size 256, Iteration 19, Loss 253.3606
	Rank 0, True Batch Size 256, Iteration 20, Loss 263.0694
	Rank 0, True Batch Size 203, Iteration 21, Loss 300.1300
Epoch 38, Loss 263.4154, Train Accuracy 0.2825, Valid Accuracy 0.2862, Test Accuracy 0.2845
	Rank 0, True Batch Size 256, Iteration 0, Loss 267.2657
	Rank 0, True Batch Size 256, Iteration 1, Loss 240.8242
	Rank 0, True Batch Size 256, Iteration 2, Loss 194.9996
	Rank 0, True Batch Size 256, Iteration 3, Loss 262.2432
	Rank 0, True Batch Size 256, Iteration 4, Loss 248.5103
	Rank 0, True Batch Size 256, Iteration 5, Loss 244.7092
	Rank 0, True Batch Size 256, Iteration 6, Loss 269.4497
	Rank 0, True Batch Size 256, Iteration 7, Loss 287.4181
	Rank 0, True Batch Size 256, Iteration 8, Loss 230.5523
	Rank 0, True Batch Size 256, Iteration 9, Loss 265.3189
	Rank 0, True Batch Size 256, Iteration 10, Loss 265.2780
	Rank 0, True Batch Size 256, Iteration 11, Loss 271.6117
	Rank 0, True Batch Size 256, Iteration 12, Loss 266.4756
	Rank 0, True Batch Size 256, Iteration 13, Loss 261.8647
	Rank 0, True Batch Size 256, Iteration 14, Loss 269.4033
	Rank 0, True Batch Size 256, Iteration 15, Loss 259.0967
	Rank 0, True Batch Size 256, Iteration 16, Loss 227.6328
	Rank 0, True Batch Size 256, Iteration 17, Loss 234.0647
	Rank 0, True Batch Size 256, Iteration 18, Loss 275.5517
	Rank 0, True Batch Size 256, Iteration 19, Loss 291.2438
	Rank 0, True Batch Size 256, Iteration 20, Loss 243.8101
	Rank 0, True Batch Size 203, Iteration 21, Loss 224.8706
Epoch 39, Loss 252.8038, Train Accuracy 0.2815, Valid Accuracy 0.2792, Test Accuracy 0.2803
	Rank 0, True Batch Size 256, Iteration 0, Loss 205.5708
	Rank 0, True Batch Size 256, Iteration 1, Loss 248.8202
	Rank 0, True Batch Size 256, Iteration 2, Loss 218.1987
	Rank 0, True Batch Size 256, Iteration 3, Loss 238.1396
	Rank 0, True Batch Size 256, Iteration 4, Loss 198.8220
	Rank 0, True Batch Size 256, Iteration 5, Loss 280.2524
	Rank 0, True Batch Size 256, Iteration 6, Loss 179.6648
	Rank 0, True Batch Size 256, Iteration 7, Loss 215.3246
	Rank 0, True Batch Size 256, Iteration 8, Loss 181.4436
	Rank 0, True Batch Size 256, Iteration 9, Loss 293.3058
	Rank 0, True Batch Size 256, Iteration 10, Loss 255.7943
	Rank 0, True Batch Size 256, Iteration 11, Loss 222.7885
	Rank 0, True Batch Size 256, Iteration 12, Loss 226.9123
	Rank 0, True Batch Size 256, Iteration 13, Loss 198.3754
	Rank 0, True Batch Size 256, Iteration 14, Loss 248.5630
	Rank 0, True Batch Size 256, Iteration 15, Loss 250.3303
	Rank 0, True Batch Size 256, Iteration 16, Loss 237.7780
	Rank 0, True Batch Size 256, Iteration 17, Loss 232.5674
	Rank 0, True Batch Size 256, Iteration 18, Loss 199.2085
	Rank 0, True Batch Size 256, Iteration 19, Loss 204.8271
	Rank 0, True Batch Size 256, Iteration 20, Loss 222.4389
	Rank 0, True Batch Size 203, Iteration 21, Loss 230.0784
Epoch 40, Loss 242.6110, Train Accuracy 0.2805, Valid Accuracy 0.2868, Test Accuracy 0.2778
	Rank 0, True Batch Size 256, Iteration 0, Loss 203.3328
	Rank 0, True Batch Size 256, Iteration 1, Loss 217.9401
	Rank 0, True Batch Size 256, Iteration 2, Loss 235.8601
	Rank 0, True Batch Size 256, Iteration 3, Loss 226.4094
	Rank 0, True Batch Size 256, Iteration 4, Loss 241.3294
	Rank 0, True Batch Size 256, Iteration 5, Loss 263.8051
	Rank 0, True Batch Size 256, Iteration 6, Loss 245.3967
	Rank 0, True Batch Size 256, Iteration 7, Loss 199.9490
	Rank 0, True Batch Size 256, Iteration 8, Loss 351.7773
	Rank 0, True Batch Size 256, Iteration 9, Loss 170.5595
	Rank 0, True Batch Size 256, Iteration 10, Loss 181.4296
	Rank 0, True Batch Size 256, Iteration 11, Loss 260.5567
	Rank 0, True Batch Size 256, Iteration 12, Loss 237.9392
	Rank 0, True Batch Size 256, Iteration 13, Loss 268.9879
	Rank 0, True Batch Size 256, Iteration 14, Loss 258.5699
	Rank 0, True Batch Size 256, Iteration 15, Loss 218.9886
	Rank 0, True Batch Size 256, Iteration 16, Loss 257.3529
	Rank 0, True Batch Size 256, Iteration 17, Loss 251.2632
	Rank 0, True Batch Size 256, Iteration 18, Loss 193.1704
	Rank 0, True Batch Size 256, Iteration 19, Loss 242.4421
	Rank 0, True Batch Size 256, Iteration 20, Loss 221.3176
	Rank 0, True Batch Size 203, Iteration 21, Loss 210.6303
Epoch 41, Loss 232.4490, Train Accuracy 0.2781, Valid Accuracy 0.2809, Test Accuracy 0.2773
	Rank 0, True Batch Size 256, Iteration 0, Loss 179.2514
	Rank 0, True Batch Size 256, Iteration 1, Loss 169.8818
	Rank 0, True Batch Size 256, Iteration 2, Loss 222.1273
	Rank 0, True Batch Size 256, Iteration 3, Loss 239.6421
	Rank 0, True Batch Size 256, Iteration 4, Loss 216.1421
	Rank 0, True Batch Size 256, Iteration 5, Loss 193.5504
	Rank 0, True Batch Size 256, Iteration 6, Loss 186.6550
	Rank 0, True Batch Size 256, Iteration 7, Loss 188.5085
	Rank 0, True Batch Size 256, Iteration 8, Loss 240.6231
	Rank 0, True Batch Size 256, Iteration 9, Loss 221.5110
	Rank 0, True Batch Size 256, Iteration 10, Loss 217.4850
	Rank 0, True Batch Size 256, Iteration 11, Loss 218.6735
	Rank 0, True Batch Size 256, Iteration 12, Loss 250.0889
	Rank 0, True Batch Size 256, Iteration 13, Loss 197.3810
	Rank 0, True Batch Size 256, Iteration 14, Loss 185.6303
	Rank 0, True Batch Size 256, Iteration 15, Loss 238.0320
	Rank 0, True Batch Size 256, Iteration 16, Loss 257.6814
	Rank 0, True Batch Size 256, Iteration 17, Loss 223.8705
	Rank 0, True Batch Size 256, Iteration 18, Loss 180.1424
	Rank 0, True Batch Size 256, Iteration 19, Loss 198.6385
	Rank 0, True Batch Size 256, Iteration 20, Loss 195.5940
	Rank 0, True Batch Size 203, Iteration 21, Loss 198.9781
Epoch 42, Loss 220.7994, Train Accuracy 0.2811, Valid Accuracy 0.2822, Test Accuracy 0.2794
	Rank 0, True Batch Size 256, Iteration 0, Loss 223.7804
	Rank 0, True Batch Size 256, Iteration 1, Loss 213.5703
	Rank 0, True Batch Size 256, Iteration 2, Loss 227.4316
	Rank 0, True Batch Size 256, Iteration 3, Loss 290.2636
	Rank 0, True Batch Size 256, Iteration 4, Loss 202.6673
	Rank 0, True Batch Size 256, Iteration 5, Loss 234.7632
	Rank 0, True Batch Size 256, Iteration 6, Loss 202.8329
	Rank 0, True Batch Size 256, Iteration 7, Loss 275.0876
	Rank 0, True Batch Size 256, Iteration 8, Loss 174.6935
	Rank 0, True Batch Size 256, Iteration 9, Loss 174.3050
	Rank 0, True Batch Size 256, Iteration 10, Loss 219.3517
	Rank 0, True Batch Size 256, Iteration 11, Loss 189.2393
	Rank 0, True Batch Size 256, Iteration 12, Loss 195.8032
	Rank 0, True Batch Size 256, Iteration 13, Loss 178.6406
	Rank 0, True Batch Size 256, Iteration 14, Loss 236.4488
	Rank 0, True Batch Size 256, Iteration 15, Loss 249.3313
	Rank 0, True Batch Size 256, Iteration 16, Loss 192.7171
	Rank 0, True Batch Size 256, Iteration 17, Loss 203.5418
	Rank 0, True Batch Size 256, Iteration 18, Loss 225.7712
	Rank 0, True Batch Size 256, Iteration 19, Loss 225.2183
	Rank 0, True Batch Size 256, Iteration 20, Loss 207.9173
	Rank 0, True Batch Size 203, Iteration 21, Loss 329.4510
Epoch 43, Loss 215.8158, Train Accuracy 0.2780, Valid Accuracy 0.2829, Test Accuracy 0.2732
	Rank 0, True Batch Size 256, Iteration 0, Loss 176.3649
	Rank 0, True Batch Size 256, Iteration 1, Loss 210.9963
	Rank 0, True Batch Size 256, Iteration 2, Loss 191.0077
	Rank 0, True Batch Size 256, Iteration 3, Loss 237.5702
	Rank 0, True Batch Size 256, Iteration 4, Loss 171.9473
	Rank 0, True Batch Size 256, Iteration 5, Loss 225.8471
	Rank 0, True Batch Size 256, Iteration 6, Loss 220.3631
	Rank 0, True Batch Size 256, Iteration 7, Loss 188.2930
	Rank 0, True Batch Size 256, Iteration 8, Loss 203.5477
	Rank 0, True Batch Size 256, Iteration 9, Loss 188.2269
	Rank 0, True Batch Size 256, Iteration 10, Loss 168.1008
	Rank 0, True Batch Size 256, Iteration 11, Loss 177.2467
	Rank 0, True Batch Size 256, Iteration 12, Loss 231.9872
	Rank 0, True Batch Size 256, Iteration 13, Loss 202.3902
	Rank 0, True Batch Size 256, Iteration 14, Loss 182.4299
	Rank 0, True Batch Size 256, Iteration 15, Loss 218.0174
	Rank 0, True Batch Size 256, Iteration 16, Loss 185.2453
	Rank 0, True Batch Size 256, Iteration 17, Loss 203.9631
	Rank 0, True Batch Size 256, Iteration 18, Loss 170.6664
	Rank 0, True Batch Size 256, Iteration 19, Loss 192.8607
	Rank 0, True Batch Size 256, Iteration 20, Loss 170.3689
	Rank 0, True Batch Size 203, Iteration 21, Loss 181.7114
Epoch 44, Loss 202.1377, Train Accuracy 0.2777, Valid Accuracy 0.2783, Test Accuracy 0.2760
	Rank 0, True Batch Size 256, Iteration 0, Loss 195.4850
	Rank 0, True Batch Size 256, Iteration 1, Loss 235.3373
	Rank 0, True Batch Size 256, Iteration 2, Loss 208.7362
	Rank 0, True Batch Size 256, Iteration 3, Loss 152.2941
	Rank 0, True Batch Size 256, Iteration 4, Loss 184.6999
	Rank 0, True Batch Size 256, Iteration 5, Loss 188.5980
	Rank 0, True Batch Size 256, Iteration 6, Loss 175.9748
	Rank 0, True Batch Size 256, Iteration 7, Loss 180.4317
	Rank 0, True Batch Size 256, Iteration 8, Loss 171.3252
	Rank 0, True Batch Size 256, Iteration 9, Loss 184.4737
	Rank 0, True Batch Size 256, Iteration 10, Loss 156.8948
	Rank 0, True Batch Size 256, Iteration 11, Loss 201.5180
	Rank 0, True Batch Size 256, Iteration 12, Loss 185.3396
	Rank 0, True Batch Size 256, Iteration 13, Loss 196.4099
	Rank 0, True Batch Size 256, Iteration 14, Loss 156.3031
	Rank 0, True Batch Size 256, Iteration 15, Loss 194.8234
	Rank 0, True Batch Size 256, Iteration 16, Loss 173.9664
	Rank 0, True Batch Size 256, Iteration 17, Loss 185.2970
	Rank 0, True Batch Size 256, Iteration 18, Loss 176.4037
	Rank 0, True Batch Size 256, Iteration 19, Loss 168.3495
	Rank 0, True Batch Size 256, Iteration 20, Loss 164.1186
	Rank 0, True Batch Size 203, Iteration 21, Loss 182.4092
Epoch 45, Loss 196.6592, Train Accuracy 0.2731, Valid Accuracy 0.2710, Test Accuracy 0.2789
	Rank 0, True Batch Size 256, Iteration 0, Loss 199.7210
	Rank 0, True Batch Size 256, Iteration 1, Loss 186.8017
	Rank 0, True Batch Size 256, Iteration 2, Loss 213.6219
	Rank 0, True Batch Size 256, Iteration 3, Loss 170.3496
	Rank 0, True Batch Size 256, Iteration 4, Loss 156.1326
	Rank 0, True Batch Size 256, Iteration 5, Loss 225.9561
	Rank 0, True Batch Size 256, Iteration 6, Loss 190.1698
	Rank 0, True Batch Size 256, Iteration 7, Loss 191.9763
	Rank 0, True Batch Size 256, Iteration 8, Loss 194.3742
	Rank 0, True Batch Size 256, Iteration 9, Loss 192.5722
	Rank 0, True Batch Size 256, Iteration 10, Loss 194.0684
	Rank 0, True Batch Size 256, Iteration 11, Loss 190.5910
	Rank 0, True Batch Size 256, Iteration 12, Loss 157.9101
	Rank 0, True Batch Size 256, Iteration 13, Loss 181.3184
	Rank 0, True Batch Size 256, Iteration 14, Loss 166.4815
	Rank 0, True Batch Size 256, Iteration 15, Loss 170.7778
	Rank 0, True Batch Size 256, Iteration 16, Loss 154.5327
	Rank 0, True Batch Size 256, Iteration 17, Loss 193.7852
	Rank 0, True Batch Size 256, Iteration 18, Loss 176.0185
	Rank 0, True Batch Size 256, Iteration 19, Loss 195.0776
	Rank 0, True Batch Size 256, Iteration 20, Loss 135.0563
	Rank 0, True Batch Size 203, Iteration 21, Loss 174.8016
Epoch 46, Loss 187.7017, Train Accuracy 0.2761, Valid Accuracy 0.2813, Test Accuracy 0.2754
	Rank 0, True Batch Size 256, Iteration 0, Loss 247.3758
	Rank 0, True Batch Size 256, Iteration 1, Loss 158.7592
	Rank 0, True Batch Size 256, Iteration 2, Loss 183.3326
	Rank 0, True Batch Size 256, Iteration 3, Loss 178.7495
	Rank 0, True Batch Size 256, Iteration 4, Loss 169.3041
	Rank 0, True Batch Size 256, Iteration 5, Loss 172.4431
	Rank 0, True Batch Size 256, Iteration 6, Loss 175.3012
	Rank 0, True Batch Size 256, Iteration 7, Loss 185.3469
	Rank 0, True Batch Size 256, Iteration 8, Loss 175.5842
	Rank 0, True Batch Size 256, Iteration 9, Loss 165.6495
	Rank 0, True Batch Size 256, Iteration 10, Loss 233.0248
	Rank 0, True Batch Size 256, Iteration 11, Loss 208.2010
	Rank 0, True Batch Size 256, Iteration 12, Loss 194.3763
	Rank 0, True Batch Size 256, Iteration 13, Loss 181.2811
	Rank 0, True Batch Size 256, Iteration 14, Loss 145.9118
	Rank 0, True Batch Size 256, Iteration 15, Loss 176.4543
	Rank 0, True Batch Size 256, Iteration 16, Loss 178.0990
	Rank 0, True Batch Size 256, Iteration 17, Loss 200.4887
	Rank 0, True Batch Size 256, Iteration 18, Loss 183.8629
	Rank 0, True Batch Size 256, Iteration 19, Loss 200.9338
	Rank 0, True Batch Size 256, Iteration 20, Loss 215.4251
	Rank 0, True Batch Size 203, Iteration 21, Loss 149.2381
Epoch 47, Loss 182.5296, Train Accuracy 0.2808, Valid Accuracy 0.2770, Test Accuracy 0.2710
	Rank 0, True Batch Size 256, Iteration 0, Loss 147.3006
	Rank 0, True Batch Size 256, Iteration 1, Loss 164.1229
	Rank 0, True Batch Size 256, Iteration 2, Loss 171.2395
	Rank 0, True Batch Size 256, Iteration 3, Loss 132.0370
	Rank 0, True Batch Size 256, Iteration 4, Loss 181.8869
	Rank 0, True Batch Size 256, Iteration 5, Loss 193.7193
	Rank 0, True Batch Size 256, Iteration 6, Loss 150.0854
	Rank 0, True Batch Size 256, Iteration 7, Loss 137.0193
	Rank 0, True Batch Size 256, Iteration 8, Loss 154.8156
	Rank 0, True Batch Size 256, Iteration 9, Loss 222.4977
	Rank 0, True Batch Size 256, Iteration 10, Loss 188.5896
	Rank 0, True Batch Size 256, Iteration 11, Loss 224.9442
	Rank 0, True Batch Size 256, Iteration 12, Loss 183.3183
	Rank 0, True Batch Size 256, Iteration 13, Loss 162.8310
	Rank 0, True Batch Size 256, Iteration 14, Loss 140.6852
	Rank 0, True Batch Size 256, Iteration 15, Loss 160.5536
	Rank 0, True Batch Size 256, Iteration 16, Loss 147.6281
	Rank 0, True Batch Size 256, Iteration 17, Loss 155.4949
	Rank 0, True Batch Size 256, Iteration 18, Loss 178.6246
	Rank 0, True Batch Size 256, Iteration 19, Loss 216.6940
	Rank 0, True Batch Size 256, Iteration 20, Loss 182.9248
	Rank 0, True Batch Size 203, Iteration 21, Loss 193.1438
Epoch 48, Loss 172.1569, Train Accuracy 0.2712, Valid Accuracy 0.2702, Test Accuracy 0.2743
	Rank 0, True Batch Size 256, Iteration 0, Loss 145.5465
	Rank 0, True Batch Size 256, Iteration 1, Loss 165.7289
	Rank 0, True Batch Size 256, Iteration 2, Loss 164.2182
	Rank 0, True Batch Size 256, Iteration 3, Loss 147.8754
	Rank 0, True Batch Size 256, Iteration 4, Loss 186.1181
	Rank 0, True Batch Size 256, Iteration 5, Loss 202.6163
	Rank 0, True Batch Size 256, Iteration 6, Loss 142.6845
	Rank 0, True Batch Size 256, Iteration 7, Loss 156.1876
	Rank 0, True Batch Size 256, Iteration 8, Loss 159.4380
	Rank 0, True Batch Size 256, Iteration 9, Loss 125.8019
	Rank 0, True Batch Size 256, Iteration 10, Loss 217.5668
	Rank 0, True Batch Size 256, Iteration 11, Loss 185.5978
	Rank 0, True Batch Size 256, Iteration 12, Loss 158.7961
	Rank 0, True Batch Size 256, Iteration 13, Loss 164.8468
	Rank 0, True Batch Size 256, Iteration 14, Loss 144.1051
	Rank 0, True Batch Size 256, Iteration 15, Loss 179.4250
	Rank 0, True Batch Size 256, Iteration 16, Loss 135.7212
	Rank 0, True Batch Size 256, Iteration 17, Loss 141.6577
	Rank 0, True Batch Size 256, Iteration 18, Loss 146.3052
	Rank 0, True Batch Size 256, Iteration 19, Loss 132.5731
	Rank 0, True Batch Size 256, Iteration 20, Loss 151.1445
	Rank 0, True Batch Size 203, Iteration 21, Loss 176.6409
Epoch 49, Loss 170.4416, Train Accuracy 0.2741, Valid Accuracy 0.2723, Test Accuracy 0.2798
	Rank 0, True Batch Size 256, Iteration 0, Loss 114.3706
	Rank 0, True Batch Size 256, Iteration 1, Loss 142.2858
	Rank 0, True Batch Size 256, Iteration 2, Loss 148.8602
	Rank 0, True Batch Size 256, Iteration 3, Loss 160.3292
	Rank 0, True Batch Size 256, Iteration 4, Loss 178.8187
	Rank 0, True Batch Size 256, Iteration 5, Loss 138.7106
	Rank 0, True Batch Size 256, Iteration 6, Loss 141.5227
	Rank 0, True Batch Size 256, Iteration 7, Loss 166.6102
	Rank 0, True Batch Size 256, Iteration 8, Loss 135.7732
	Rank 0, True Batch Size 256, Iteration 9, Loss 113.0700
	Rank 0, True Batch Size 256, Iteration 10, Loss 140.0348
	Rank 0, True Batch Size 256, Iteration 11, Loss 180.9288
	Rank 0, True Batch Size 256, Iteration 12, Loss 123.6536
	Rank 0, True Batch Size 256, Iteration 13, Loss 133.8333
	Rank 0, True Batch Size 256, Iteration 14, Loss 188.5606
	Rank 0, True Batch Size 256, Iteration 15, Loss 152.4062
	Rank 0, True Batch Size 256, Iteration 16, Loss 134.7558
	Rank 0, True Batch Size 256, Iteration 17, Loss 130.1311
	Rank 0, True Batch Size 256, Iteration 18, Loss 177.7807
	Rank 0, True Batch Size 256, Iteration 19, Loss 149.9810
	Rank 0, True Batch Size 256, Iteration 20, Loss 155.4235
	Rank 0, True Batch Size 203, Iteration 21, Loss 137.4946
Epoch 50, Loss 153.0980, Train Accuracy 0.2710, Valid Accuracy 0.2760, Test Accuracy 0.2784
Per-epoch Time: 3.9808 s
Highest Validation Accuracy: 0.3917
Target Test Accuracy: 0.3941
