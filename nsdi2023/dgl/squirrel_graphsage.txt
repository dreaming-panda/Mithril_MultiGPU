gnerv2
gnerv4
launching jobs on gnerv4, in total 2 nodes
launching jobs on gnerv2, in total 2 nodes
Executing:  'python ./main.py 1 2 gnerv2 4 8' on gnerv4
Executing:  'python ./main.py 1 2 gnerv2 5 8' on gnerv4
Executing:  'python ./main.py 1 2 gnerv2 6 8' on gnerv4
Executing:  'python ./main.py 1 2 gnerv2 7 8' on gnerv4
Executing:  'python ./main.py 0 2 gnerv2 0 8' on gnerv2
Executing:  'python ./main.py 0 2 gnerv2 1 8' on gnerv2
Executing:  'python ./main.py 0 2 gnerv2 2 8' on gnerv2
Executing:  'python ./main.py 0 2 gnerv2 3 8' on gnerv2
['./main.py', '0', '2', 'gnerv2', '0', '8']
Hello World From Process 0, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv2', '6', '8']
Hello World From Process 6, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
['./main.py', '0', '2', 'gnerv2', '2', '8']
Hello World From Process 2, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
['./main.py', '0', '2', 'gnerv2', '3', '8']
Hello World From Process 3, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv2', '7', '8']
Hello World From Process 7, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
['./main.py', '0', '2', 'gnerv2', '1', '8']
Hello World From Process 1, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv2', '4', '8']
Hello World From Process 4, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
['./main.py', '1', '2', 'gnerv2', '5', '8']
Hello World From Process 5, the World Size is 8
Done loading data from cached files.
Downloaded the graph dataset
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
StochasticGraphSage(
  (convs): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=2089, out_features=1000, bias=False)
      (fc_self): Linear(in_features=2089, out_features=1000, bias=True)
    )
    (1-30): 30 x SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=1000, bias=False)
      (fc_self): Linear(in_features=1000, out_features=1000, bias=True)
    )
    (31): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_neigh): Linear(in_features=1000, out_features=5, bias=False)
      (fc_self): Linear(in_features=1000, out_features=5, bias=True)
    )
  )
)
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
Start Distributed GNN Training
	Rank 0, True Batch Size 256, Iteration 0, Loss 26090806.0000
	Rank 0, True Batch Size 56, Iteration 1, Loss 3643836.0000
Epoch 1, Loss 7250328.6154, Train Accuracy 0.2015, Valid Accuracy 0.2031, Test Accuracy 0.2085
	Rank 0, True Batch Size 256, Iteration 0, Loss 1196930.8750
	Rank 0, True Batch Size 56, Iteration 1, Loss 395184.2188
Epoch 2, Loss 1144426.1538, Train Accuracy 0.1871, Valid Accuracy 0.1917, Test Accuracy 0.1998
	Rank 0, True Batch Size 256, Iteration 0, Loss 266941.8125
	Rank 0, True Batch Size 56, Iteration 1, Loss 174010.8750
Epoch 3, Loss 318029.2821, Train Accuracy 0.2119, Valid Accuracy 0.1923, Test Accuracy 0.2085
	Rank 0, True Batch Size 256, Iteration 0, Loss 117678.7109
	Rank 0, True Batch Size 56, Iteration 1, Loss 122872.8672
Epoch 4, Loss 147899.4744, Train Accuracy 0.2055, Valid Accuracy 0.1995, Test Accuracy 0.1950
	Rank 0, True Batch Size 256, Iteration 0, Loss 92229.8125
	Rank 0, True Batch Size 56, Iteration 1, Loss 46544.8711
Epoch 5, Loss 104635.4295, Train Accuracy 0.2019, Valid Accuracy 0.2031, Test Accuracy 0.2017
	Rank 0, True Batch Size 256, Iteration 0, Loss 87839.7344
	Rank 0, True Batch Size 56, Iteration 1, Loss 83132.7500
Epoch 6, Loss 90465.7500, Train Accuracy 0.2079, Valid Accuracy 0.1863, Test Accuracy 0.1931
	Rank 0, True Batch Size 256, Iteration 0, Loss 106578.4453
	Rank 0, True Batch Size 56, Iteration 1, Loss 16602.3398
Epoch 7, Loss 60101.3846, Train Accuracy 0.2051, Valid Accuracy 0.1935, Test Accuracy 0.1825
	Rank 0, True Batch Size 256, Iteration 0, Loss 28532.5586
	Rank 0, True Batch Size 56, Iteration 1, Loss 298035.8438
Epoch 8, Loss 49661.2404, Train Accuracy 0.1887, Valid Accuracy 0.2037, Test Accuracy 0.2133
	Rank 0, True Batch Size 256, Iteration 0, Loss 20738.5137
	Rank 0, True Batch Size 56, Iteration 1, Loss 18908.0527
Epoch 9, Loss 29502.9167, Train Accuracy 0.1983, Valid Accuracy 0.1977, Test Accuracy 0.1979
	Rank 0, True Batch Size 256, Iteration 0, Loss 11606.1826
	Rank 0, True Batch Size 56, Iteration 1, Loss 6693.1436
Epoch 10, Loss 18417.8974, Train Accuracy 0.2007, Valid Accuracy 0.1899, Test Accuracy 0.1854
	Rank 0, True Batch Size 256, Iteration 0, Loss 9863.9473
	Rank 0, True Batch Size 56, Iteration 1, Loss 9433.5156
Epoch 11, Loss 14264.5497, Train Accuracy 0.2075, Valid Accuracy 0.1995, Test Accuracy 0.2113
	Rank 0, True Batch Size 256, Iteration 0, Loss 5652.6675
	Rank 0, True Batch Size 56, Iteration 1, Loss 7326.7915
Epoch 12, Loss 8912.4135, Train Accuracy 0.1995, Valid Accuracy 0.1935, Test Accuracy 0.2123
	Rank 0, True Batch Size 256, Iteration 0, Loss 4825.3145
	Rank 0, True Batch Size 56, Iteration 1, Loss 4730.2515
Epoch 13, Loss 9149.8582, Train Accuracy 0.2095, Valid Accuracy 0.2073, Test Accuracy 0.2046
	Rank 0, True Batch Size 256, Iteration 0, Loss 5266.6157
	Rank 0, True Batch Size 56, Iteration 1, Loss 3015.0532
Epoch 14, Loss 7699.7580, Train Accuracy 0.1923, Valid Accuracy 0.2115, Test Accuracy 0.1950
	Rank 0, True Batch Size 256, Iteration 0, Loss 3658.6853
	Rank 0, True Batch Size 56, Iteration 1, Loss 9904.8594
Epoch 15, Loss 5739.5120, Train Accuracy 0.1971, Valid Accuracy 0.2067, Test Accuracy 0.1883
	Rank 0, True Batch Size 256, Iteration 0, Loss 4756.5122
	Rank 0, True Batch Size 56, Iteration 1, Loss 1145.3575
Epoch 16, Loss 5107.8421, Train Accuracy 0.1979, Valid Accuracy 0.2043, Test Accuracy 0.2056
	Rank 0, True Batch Size 256, Iteration 0, Loss 3840.6982
	Rank 0, True Batch Size 56, Iteration 1, Loss 1398.1234
Epoch 17, Loss 4071.4575, Train Accuracy 0.1967, Valid Accuracy 0.2073, Test Accuracy 0.1998
	Rank 0, True Batch Size 256, Iteration 0, Loss 2508.6396
	Rank 0, True Batch Size 56, Iteration 1, Loss 28983.1582
Epoch 18, Loss 4525.2139, Train Accuracy 0.2027, Valid Accuracy 0.1995, Test Accuracy 0.2123
	Rank 0, True Batch Size 256, Iteration 0, Loss 7199.8643
	Rank 0, True Batch Size 56, Iteration 1, Loss 2575.4163
Epoch 19, Loss 4366.5353, Train Accuracy 0.2007, Valid Accuracy 0.2043, Test Accuracy 0.2152
	Rank 0, True Batch Size 256, Iteration 0, Loss 2571.7268
	Rank 0, True Batch Size 56, Iteration 1, Loss 1575.5173
Epoch 20, Loss 3624.2312, Train Accuracy 0.1947, Valid Accuracy 0.1989, Test Accuracy 0.1979
	Rank 0, True Batch Size 256, Iteration 0, Loss 1561.1659
	Rank 0, True Batch Size 56, Iteration 1, Loss 1700.5071
Epoch 21, Loss 2187.0174, Train Accuracy 0.1727, Valid Accuracy 0.1995, Test Accuracy 0.2161
	Rank 0, True Batch Size 256, Iteration 0, Loss 1239.8981
	Rank 0, True Batch Size 56, Iteration 1, Loss 1169.1906
Epoch 22, Loss 2430.2975, Train Accuracy 0.2083, Valid Accuracy 0.1935, Test Accuracy 0.2142
	Rank 0, True Batch Size 256, Iteration 0, Loss 1419.6061
	Rank 0, True Batch Size 56, Iteration 1, Loss 895.4113
Epoch 23, Loss 1871.5631, Train Accuracy 0.1887, Valid Accuracy 0.2103, Test Accuracy 0.2277
	Rank 0, True Batch Size 256, Iteration 0, Loss 867.4716
	Rank 0, True Batch Size 56, Iteration 1, Loss 1221.3230
Epoch 24, Loss 1761.5148, Train Accuracy 0.2071, Valid Accuracy 0.2031, Test Accuracy 0.2017
	Rank 0, True Batch Size 256, Iteration 0, Loss 4515.0942
	Rank 0, True Batch Size 56, Iteration 1, Loss 890.8467
Epoch 25, Loss 2050.9327, Train Accuracy 0.2003, Valid Accuracy 0.2169, Test Accuracy 0.2075
	Rank 0, True Batch Size 256, Iteration 0, Loss 1226.3000
	Rank 0, True Batch Size 56, Iteration 1, Loss 12157.9316
Epoch 26, Loss 1974.4331, Train Accuracy 0.2003, Valid Accuracy 0.2061, Test Accuracy 0.2046
	Rank 0, True Batch Size 256, Iteration 0, Loss 1082.5088
	Rank 0, True Batch Size 56, Iteration 1, Loss 460.3727
Epoch 27, Loss 1805.2977, Train Accuracy 0.1995, Valid Accuracy 0.1917, Test Accuracy 0.1940
	Rank 0, True Batch Size 256, Iteration 0, Loss 5801.5522
	Rank 0, True Batch Size 56, Iteration 1, Loss 603.6864
Epoch 28, Loss 2434.4816, Train Accuracy 0.2023, Valid Accuracy 0.2019, Test Accuracy 0.2075
	Rank 0, True Batch Size 256, Iteration 0, Loss 4543.9956
	Rank 0, True Batch Size 56, Iteration 1, Loss 556.8514
Epoch 29, Loss 1782.3409, Train Accuracy 0.2011, Valid Accuracy 0.2121, Test Accuracy 0.2104
	Rank 0, True Batch Size 256, Iteration 0, Loss 1121.6606
	Rank 0, True Batch Size 56, Iteration 1, Loss 355.6535
Epoch 30, Loss 1805.8600, Train Accuracy 0.2035, Valid Accuracy 0.2025, Test Accuracy 0.2123
	Rank 0, True Batch Size 256, Iteration 0, Loss 2239.6775
	Rank 0, True Batch Size 56, Iteration 1, Loss 401.5122
Epoch 31, Loss 1714.8888, Train Accuracy 0.2023, Valid Accuracy 0.1929, Test Accuracy 0.1998
	Rank 0, True Batch Size 256, Iteration 0, Loss 8764.9648
	Rank 0, True Batch Size 56, Iteration 1, Loss 652.9590
Epoch 32, Loss 2418.0601, Train Accuracy 0.1947, Valid Accuracy 0.2019, Test Accuracy 0.2027
	Rank 0, True Batch Size 256, Iteration 0, Loss 1162.7407
	Rank 0, True Batch Size 56, Iteration 1, Loss 170.7208
Epoch 33, Loss 1510.1655, Train Accuracy 0.1959, Valid Accuracy 0.2067, Test Accuracy 0.2181
	Rank 0, True Batch Size 256, Iteration 0, Loss 3944.1536
	Rank 0, True Batch Size 56, Iteration 1, Loss 434.8135
Epoch 34, Loss 1942.3916, Train Accuracy 0.1911, Valid Accuracy 0.1905, Test Accuracy 0.1998
	Rank 0, True Batch Size 256, Iteration 0, Loss 788.4160
	Rank 0, True Batch Size 56, Iteration 1, Loss 264.4205
Epoch 35, Loss 1210.1871, Train Accuracy 0.1915, Valid Accuracy 0.1917, Test Accuracy 0.2037
	Rank 0, True Batch Size 256, Iteration 0, Loss 406.4031
	Rank 0, True Batch Size 56, Iteration 1, Loss 709.1787
Epoch 36, Loss 1143.6413, Train Accuracy 0.2035, Valid Accuracy 0.1989, Test Accuracy 0.2113
	Rank 0, True Batch Size 256, Iteration 0, Loss 1287.3947
	Rank 0, True Batch Size 56, Iteration 1, Loss 710.4086
Epoch 37, Loss 1335.6423, Train Accuracy 0.1899, Valid Accuracy 0.1977, Test Accuracy 0.2171
	Rank 0, True Batch Size 256, Iteration 0, Loss 416.7436
	Rank 0, True Batch Size 56, Iteration 1, Loss 630.1330
Epoch 38, Loss 1232.0667, Train Accuracy 0.2103, Valid Accuracy 0.2037, Test Accuracy 0.2104
	Rank 0, True Batch Size 256, Iteration 0, Loss 337.3764
	Rank 0, True Batch Size 56, Iteration 1, Loss 563.4304
Epoch 39, Loss 1070.4540, Train Accuracy 0.2147, Valid Accuracy 0.1995, Test Accuracy 0.1988
	Rank 0, True Batch Size 256, Iteration 0, Loss 445.6584
	Rank 0, True Batch Size 56, Iteration 1, Loss 368.6446
Epoch 40, Loss 1434.1503, Train Accuracy 0.1955, Valid Accuracy 0.1953, Test Accuracy 0.1950
	Rank 0, True Batch Size 256, Iteration 0, Loss 414.2090
	Rank 0, True Batch Size 56, Iteration 1, Loss 949.7745
Epoch 41, Loss 948.6733, Train Accuracy 0.2059, Valid Accuracy 0.1875, Test Accuracy 0.1979
	Rank 0, True Batch Size 256, Iteration 0, Loss 456.6270
	Rank 0, True Batch Size 56, Iteration 1, Loss 386.5478
Epoch 42, Loss 1109.4962, Train Accuracy 0.2059, Valid Accuracy 0.1989, Test Accuracy 0.1969
	Rank 0, True Batch Size 256, Iteration 0, Loss 764.6887
	Rank 0, True Batch Size 56, Iteration 1, Loss 754.7501
Epoch 43, Loss 1037.8237, Train Accuracy 0.2019, Valid Accuracy 0.1905, Test Accuracy 0.2181
	Rank 0, True Batch Size 256, Iteration 0, Loss 2325.5559
	Rank 0, True Batch Size 56, Iteration 1, Loss 503.1687
Epoch 44, Loss 1099.6562, Train Accuracy 0.1935, Valid Accuracy 0.2266, Test Accuracy 0.2315
	Rank 0, True Batch Size 256, Iteration 0, Loss 511.0702
	Rank 0, True Batch Size 56, Iteration 1, Loss 802.8860
Epoch 45, Loss 862.2696, Train Accuracy 0.2163, Valid Accuracy 0.1989, Test Accuracy 0.2257
	Rank 0, True Batch Size 256, Iteration 0, Loss 1909.7844
	Rank 0, True Batch Size 56, Iteration 1, Loss 571.5275
Epoch 46, Loss 997.6675, Train Accuracy 0.2103, Valid Accuracy 0.1983, Test Accuracy 0.2027
	Rank 0, True Batch Size 256, Iteration 0, Loss 1304.8176
	Rank 0, True Batch Size 56, Iteration 1, Loss 192.5951
Epoch 47, Loss 1197.0649, Train Accuracy 0.2087, Valid Accuracy 0.1875, Test Accuracy 0.1950
	Rank 0, True Batch Size 256, Iteration 0, Loss 349.9307
	Rank 0, True Batch Size 56, Iteration 1, Loss 909.1218
Epoch 48, Loss 903.3903, Train Accuracy 0.2027, Valid Accuracy 0.2145, Test Accuracy 0.2027
	Rank 0, True Batch Size 256, Iteration 0, Loss 4691.0591
	Rank 0, True Batch Size 56, Iteration 1, Loss 619.6467
Epoch 49, Loss 1192.2678, Train Accuracy 0.1963, Valid Accuracy 0.1983, Test Accuracy 0.2037
	Rank 0, True Batch Size 256, Iteration 0, Loss 756.8756
	Rank 0, True Batch Size 56, Iteration 1, Loss 476.3580
Epoch 50, Loss 829.9838, Train Accuracy 0.2099, Valid Accuracy 0.1911, Test Accuracy 0.2008
Per-epoch Time: 1.5679 s
Highest Validation Accuracy: 0.2266
Target Test Accuracy: 0.2315
