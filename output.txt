g002.anvil.rcac.purdue.edu
Sun Jan 22 19:03:41 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:C1:00.0 Off |                    0 |
| N/A   26C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  5%] Built target context
[ 13%] Built target core
[ 14%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_single_cpu_engine.cc.o
[ 20%] Built target parallel
[ 21%] Linking CXX static library libcudahelp.a
[ 40%] Built target cudahelp
[ 42%] Linking CXX executable test_mpi_gpu_hybrid
[ 42%] Linking CXX executable test_cuda_graph
[ 43%] Linking CXX executable test_mpi_gpu_pipelined_model_parallel
[ 44%] Linking CXX executable test_cuda_model_parallel
[ 45%] Linking CXX executable test_trivial
[ 48%] Linking CXX executable test_cuda_pipeline_parallel
[ 48%] Linking CXX executable test_mpi_gpu_model_parallel
[ 49%] Linking CXX executable test_mpi_combined
[ 48%] Linking CXX executable test_cuda
[ 51%] Linking CXX executable gcn_graph_parallel
[ 51%] Linking CXX executable gcn
[ 54%] Linking CXX executable test_two_layer_hybrid_parallelism_designer
[ 54%] Linking CXX executable gcn
[ 54%] Linking CXX executable gcn_inference
[ 55%] Linking CXX executable test_graph
[ 57%] Linking CXX executable test_single_node_fullgpu_training
[ 57%] Linking CXX executable test_mpi_structual_graph
[ 58%] Linking CXX executable test_full_non_structual_graph
[ 59%] Linking CXX executable test_mpi_non_structual_graph
[ 61%] Linking CXX executable test_hello_world
[ 61%] Linking CXX executable test_nccl_thread
[ 65%] Linking CXX executable test_mpi_pipelined_model_parallel
[ 65%] Linking CXX executable test_full_structual_graph
[ 68%] Linking CXX executable test_mpi_loader
[ 68%] Linking CXX executable test_single_node_training
[ 69%] Linking CXX executable estimate_comm_volume
[ 68%] Linking CXX executable test_single_node_gpu_training
[ 69%] Linking CXX executable test_nccl_mpi
[ 70%] Linking CXX executable test_mpi_model_parallel
[ 73%] Built target test_mpi_non_structual_graph
[ 73%] Built target test_full_non_structual_graph
[ 73%] Built target test_graph
[ 74%] Built target test_full_structual_graph
[ 75%] Built target test_cuda
[ 76%] Built target test_cuda_graph
[ 79%] Built target test_mpi_gpu_hybrid
[ 79%] Built target test_mpi_gpu_model_parallel
[ 79%] Built target test_trivial
[ 80%] Built target test_mpi_combined
[ 83%] Built target test_cuda_pipeline_parallel
[ 83%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[ 83%] Built target test_two_layer_hybrid_parallelism_designer
[ 85%] Built target OSDI2023_MULTI_NODES_gcn
[ 85%] Built target test_single_node_fullgpu_training
[ 93%] Built target test_mpi_loader
[ 93%] Built target test_mpi_model_parallel
[ 93%] Built target test_mpi_pipelined_model_parallel
[ 93%] Built target estimate_comm_volume
[ 93%] Built target test_single_node_training
[ 93%] Built target test_single_node_gpu_training
[ 93%] Built target test_mpi_structual_graph
[ 93%] Built target test_hello_world
[ 94%] Built target test_mpi_gpu_pipelined_model_parallel
[ 95%] Built target OSDI2023_SINGLE_NODE_gcn
[ 97%] Built target test_nccl_thread
[ 97%] Built target test_nccl_mpi
[ 98%] Built target test_cuda_model_parallel
[100%] Built target OSDI2023_MULTI_NODES_gcn_graph_parallel
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 3
The number of hidden units: 128
The number of training epoches: 100
Learning rate: 0.003000
Initialized node g002.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.896 seconds.
Building the CSC structure...
        It takes 1.946 seconds.
Building the Feature Vector...
        It takes 0.703 seconds.
Building the Label Vector...
        It takes 0.414 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.300 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
    Epoch 9:	Loss 1.55486	TrainAcc 0.7042	ValidAcc 0.6980	TestAcc 0.5285
    Epoch 19:	Loss 0.87481	TrainAcc 0.8226	ValidAcc 0.8173	TestAcc 0.6496
    Epoch 29:	Loss 0.66867	TrainAcc 0.8591	ValidAcc 0.8528	TestAcc 0.6865
    Epoch 39:	Loss 0.58305	TrainAcc 0.8735	ValidAcc 0.8677	TestAcc 0.6955
    Epoch 49:	Loss 0.52748	TrainAcc 0.8817	ValidAcc 0.8752	TestAcc 0.7045
    Epoch 59:	Loss 0.49329	TrainAcc 0.8852	ValidAcc 0.8797	TestAcc 0.7142
    Epoch 69:	Loss 0.47016	TrainAcc 0.8886	ValidAcc 0.8822	TestAcc 0.7158
    Epoch 79:	Loss 0.45287	TrainAcc 0.8920	ValidAcc 0.8846	TestAcc 0.7204
    Epoch 89:	Loss 0.43978	TrainAcc 0.8937	ValidAcc 0.8874	TestAcc 0.7234
    Epoch 99:	Loss 0.42880	TrainAcc 0.8959	ValidAcc 0.8889	TestAcc 0.7270

Average per-epoch runtime: 0.176 (s)
Total Time: 16.942(s)
loss Time: 0.066(s)
calacc Time: 0.582(s)
calgra Time: 0.471(s)
cf Time: 7.463(s)
cb Time: 9.346(s)
Highest validation acc: 0.8894
Target test acc: 0.7256
Epochs to reach the target acc: 95
The runtime of each operator:
	Op 0 (OPERATOR_INPUT),	Rumtime: 0.000000 s
	Op 1 (OPERATOR_WEIGHT),	Rumtime: 0.000000 s
	Op 2 (OPERATOR_MATMUL),	Rumtime: 1.224218 s
	Op 3 (OPERATOR_AGGREGATION),	Rumtime: 3.353679 s
	Op 4 (OPERATOR_RELU),	Rumtime: 0.553576 s
	Op 5 (OPERATOR_DROPOUT),	Rumtime: 0.412701 s
	Op 6 (OPERATOR_WEIGHT),	Rumtime: 0.000010 s
	Op 7 (OPERATOR_MATMUL),	Rumtime: 1.301511 s
	Op 8 (OPERATOR_AGGREGATION),	Rumtime: 3.351366 s
	Op 9 (OPERATOR_RELU),	Rumtime: 0.552960 s
	Op 10 (OPERATOR_DROPOUT),	Rumtime: 0.413218 s
	Op 11 (OPERATOR_WEIGHT),	Rumtime: 0.000010 s
	Op 12 (OPERATOR_MATMUL),	Rumtime: 0.635221 s
	Op 13 (OPERATOR_AGGREGATION),	Rumtime: 2.745264 s
	Op 14 (OPERATOR_SOFTMAX),	Rumtime: 1.483147 s
