g001.anvil.rcac.purdue.edu
Mon Feb 13 15:57:01 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   30C    P0    70W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  4%] Built target context
[ 17%] Built target parallel
[ 19%] Built target core
[ 40%] Built target cudahelp
[ 45%] Built target test_mpi_gpu_hybrid
[ 53%] Built target test_cuda_graph
[ 53%] Built target test_mpi_gpu_pipelined_model_parallel
[ 72%] Built target test_cuda_model_parallel
[ 72%] Built target test_mpi_loader
[ 72%] Built target test_mpi_pipelined_model_parallel
[ 72%] Built target test_hello_world
[ 72%] Built target test_mpi_gpu_model_parallel
[ 72%] Built target test_cuda_pipeline_parallel
[ 72%] Built target test_mpi_combined
[ 75%] Built target test_trivial
[ 77%] Built target test_cuda
[ 85%] Built target test_graph
[ 85%] Built target test_single_node_fullgpu_training
[ 85%] Built target test_mpi_non_structual_graph
[ 85%] Built target test_single_node_training
[ 85%] Built target test_full_non_structual_graph
[ 85%] Built target test_nccl_thread
[ 89%] Built target test_full_structual_graph
[ 89%] Built target test_single_node_gpu_training
[ 89%] Built target test_mpi_structual_graph
[ 89%] Built target test_mpi_model_parallel
[ 89%] Built target estimate_comm_volume
[ 89%] Built target test_nccl_mpi
[ 95%] Built target OSDI2023_MULTI_NODES_gcn
[ 95%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[ 95%] Built target test_two_layer_hybrid_parallelism_designer
[100%] Built target OSDI2023_MULTI_NODES_gcn_graph_parallel
[100%] Built target OSDI2023_SINGLE_NODE_gcn
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/metis_3_gpu/ogbn_products/reorder/bin
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: hybrid
The dropout rate: 0.300
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/metis_3_gpu/ogbn_products/reorder/bin
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: hybrid
The dropout rate: 0.300
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/metis_3_gpu/ogbn_products/reorder/bin
The number of GCN layers: 6
The number of hidden units: 64
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: hybrid
The dropout rate: 0.300
Initialized node g014.anvil.rcac.purdue.edu
Initialized node g015.anvil.rcac.purdue.edu
Initialized node g001.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.899 seconds.
Building the CSC structure...
        It takes 1.919 seconds.
Building the CSC structure...
        It takes 1.966 seconds.
Building the CSC structure...
        It takes 1.820 seconds.
        It takes 1.829 seconds.
        It takes 1.887 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.733 seconds.
Building the Label Vector...
        It takes 0.699 seconds.
Building the Label Vector...
        It takes 0.617 seconds.
Building the Label Vector...
        It takes 0.397 seconds.
        It takes 0.392 seconds.
        It takes 0.395 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
start[0]: 0, end[0]: 828262start[1]: 828262, end[1]: 1630846start[2]: 1630846, end[2]: 2449029[Node 0]: distributed graph prepared: start: 0, end: 828262 , send vertices: 317730.
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
[Node 2]: distributed graph prepared: start: 1630846, end: 2449029 , send vertices: 527720.
[Node 1]: distributed graph prepared: start: 828262, end: 1630846 , send vertices: 600934.
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_SOFTMAX
    OP_TYPE: OPERATOR_DROPOUT
*** Done allocating resource.
*** Preparing the input tensor...
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
2449029
2449029
2449029
    Epoch 9:	Loss 2.30952	TrainAcc 0.4514	ValidAcc 0.4483	TestAcc 0.3501
    Epoch 19:	Loss 1.42196	TrainAcc 0.6084	ValidAcc 0.5986	TestAcc 0.4530
    Epoch 29:	Loss 1.02486	TrainAcc 0.7818	ValidAcc 0.7729	TestAcc 0.5988
    Epoch 39:	Loss 0.75489	TrainAcc 0.8292	ValidAcc 0.8237	TestAcc 0.6573
    Epoch 49:	Loss 0.63674	TrainAcc 0.8544	ValidAcc 0.8476	TestAcc 0.6777
    Epoch 59:	Loss 0.57407	TrainAcc 0.8688	ValidAcc 0.8614	TestAcc 0.6920
    Epoch 69:	Loss 0.53153	TrainAcc 0.8752	ValidAcc 0.8688	TestAcc 0.6997
    Epoch 79:	Loss 0.50393	TrainAcc 0.8802	ValidAcc 0.8727	TestAcc 0.7064
    Epoch 89:	Loss 0.48234	TrainAcc 0.8835	ValidAcc 0.8768	TestAcc 0.7100
    Epoch 99:	Loss 0.46546	TrainAcc 0.8869	ValidAcc 0.8808	TestAcc 0.7169
    Epoch 109:	Loss 0.45351	TrainAcc 0.8878	ValidAcc 0.8807	TestAcc 0.7202
    Epoch 119:	Loss 0.44055	TrainAcc 0.8920	ValidAcc 0.8836	TestAcc 0.7269
    Epoch 129:	Loss 0.43007	TrainAcc 0.8935	ValidAcc 0.8862	TestAcc 0.7314
    Epoch 139:	Loss 0.42191	TrainAcc 0.8947	ValidAcc 0.8881	TestAcc 0.7327
    Epoch 149:	Loss 0.41549	TrainAcc 0.8965	ValidAcc 0.8893	TestAcc 0.7360
    Epoch 159:	Loss 0.40922	TrainAcc 0.8977	ValidAcc 0.8914	TestAcc 0.7387
    Epoch 169:	Loss 0.40321	TrainAcc 0.8987	ValidAcc 0.8923	TestAcc 0.7398
    Epoch 179:	Loss 0.39835	TrainAcc 0.9002	ValidAcc 0.8933	TestAcc 0.7415
    Epoch 189:	Loss 0.39402	TrainAcc 0.9008	ValidAcc 0.8916	TestAcc 0.7442
    Epoch 199:	Loss 0.38841	TrainAcc 0.9029	ValidAcc 0.8944	TestAcc 0.7444
    Epoch 209:	Loss 0.38631	TrainAcc 0.9029	ValidAcc 0.8945	TestAcc 0.7458
    Epoch 219:	Loss 0.38255	TrainAcc 0.9039	ValidAcc 0.8953	TestAcc 0.7448
    Epoch 229:	Loss 0.37799	TrainAcc 0.9046	ValidAcc 0.8958	TestAcc 0.7452
    Epoch 239:	Loss 0.37614	TrainAcc 0.9050	ValidAcc 0.8964	TestAcc 0.7485
    Epoch 249:	Loss 0.37339	TrainAcc 0.9051	ValidAcc 0.8968	TestAcc 0.7478
    Epoch 259:	Loss 0.37061	TrainAcc 0.9064	ValidAcc 0.8978	TestAcc 0.7482
    Epoch 269:	Loss 0.36960	TrainAcc 0.9070	ValidAcc 0.8972	TestAcc 0.7492
    Epoch 279:	Loss 0.36650	TrainAcc 0.9075	ValidAcc 0.8985	TestAcc 0.7480
    Epoch 289:	Loss 0.36286	TrainAcc 0.9086	ValidAcc 0.8992	TestAcc 0.7493
    Epoch 299:	Loss 0.36251	TrainAcc 0.9083	ValidAcc 0.8987	TestAcc 0.7483
    Epoch 309:	Loss 0.36022	TrainAcc 0.9086	ValidAcc 0.8987	TestAcc 0.7475
    Epoch 319:	Loss 0.35757	TrainAcc 0.9095	ValidAcc 0.8982	TestAcc 0.7496
    Epoch 329:	Loss 0.35507	TrainAcc 0.9091	ValidAcc 0.9003	TestAcc 0.7487
    Epoch 339:	Loss 0.35394	TrainAcc 0.9095	ValidAcc 0.9003	TestAcc 0.7493
    Epoch 349:	Loss 0.35380	TrainAcc 0.9096	ValidAcc 0.8998	TestAcc 0.7501
    Epoch 359:	Loss 0.35215	TrainAcc 0.9104	ValidAcc 0.9004	TestAcc 0.7484
    Epoch 369:	Loss 0.34967	TrainAcc 0.9103	ValidAcc 0.8997	TestAcc 0.7513
    Epoch 379:	Loss 0.34800	TrainAcc 0.9107	ValidAcc 0.9028	TestAcc 0.7492
    Epoch 389:	Loss 0.34699	TrainAcc 0.9116	ValidAcc 0.9000	TestAcc 0.7470
    Epoch 399:	Loss 0.34549	TrainAcc 0.9115	ValidAcc 0.9013	TestAcc 0.7478
    Epoch 409:	Loss 0.34357	TrainAcc 0.9121	ValidAcc 0.9022	TestAcc 0.7495
    Epoch 419:	Loss 0.34157	TrainAcc 0.9122	ValidAcc 0.9016	TestAcc 0.7471
    Epoch 429:	Loss 0.34155	TrainAcc 0.9123	ValidAcc 0.9006	TestAcc 0.7466
    Epoch 439:	Loss 0.34162	TrainAcc 0.9130	ValidAcc 0.9012	TestAcc 0.7500
    Epoch 449:	Loss 0.33995	TrainAcc 0.9125	ValidAcc 0.9049	TestAcc 0.7504
    Epoch 459:	Loss 0.33824	TrainAcc 0.9130	ValidAcc 0.9031	TestAcc 0.7488
    Epoch 469:	Loss 0.33820	TrainAcc 0.9125	ValidAcc 0.9038	TestAcc 0.7498
    Epoch 479:	Loss 0.33628	TrainAcc 0.9138	ValidAcc 0.9036	TestAcc 0.7481
    Epoch 489:	Loss 0.33381	TrainAcc 0.9139	ValidAcc 0.9031	TestAcc 0.7509
slurmstepd: error: *** JOB 1136523 ON g001 CANCELLED AT 2023-02-13T16:00:00 ***
