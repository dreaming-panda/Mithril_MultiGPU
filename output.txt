g001.anvil.rcac.purdue.edu
Fri May  5 13:25:41 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   30C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[ 11%] Built target context
[ 36%] Built target core
[ 77%] Built target cudahelp
[ 83%] Built target estimate_comm_volume
[ 94%] Built target OSDI2023_MULTI_NODES_gcnii
[ 94%] Built target OSDI2023_MULTI_NODES_graphsage
[100%] Built target OSDI2023_MULTI_NODES_gcn
Initialized node 0 on machine g001.anvil.rcac.purdue.edu
Initialized node 1 on machine g004.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
        It takes 1.895 seconds.
Building the CSC structure...
        It takes 1.954 seconds.
Building the CSC structure...
        It takes 1.868 seconds.
        It takes 1.879 seconds.
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.657 seconds.
Building the Label Vector...
        It takes 0.710 seconds.
Building the Label Vector...
        It takes 0.608 seconds.
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCNII layers: 8
The number of hidden units: 64
The number of training epoches: 2000
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /anvil/projects/x-cis220117/saved_weights_pipe
The random seed: 1
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
Number of GPUs: 2
        It takes 0.615 seconds.
train nodes 196615, valid nodes 39323, test nodes 2213091
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 4)
GPU 1, layer [4, 8)
*** Node 1, starting model training...
Number of operators: 40
0 2449029 0 21
0 2449029 21 40
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the partition [21, 40) x [0, 2449029)
*** Node 1, constructing the helper classes...
GPU 0, layer [0, 4)
GPU 1, layer [4, 8)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 40
0 2449029 0 21
0 2449029 21 40
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 21) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_AGGREGATION, output tensors: 6
    Op 7: type OPERATOR_WEIGHT, output tensors: 7
    Op 8: type OPERATOR_MATMUL, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_AGGREGATION, output tensors: 11
    Op 12: type OPERATOR_WEIGHT, output tensors: 12
    Op 13: type OPERATOR_MATMUL, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_AGGREGATION, output tensors: 16
    Op 17: type OPERATOR_WEIGHT, output tensors: 17
    Op 18: type OPERATOR_MATMUL, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_AGGREGATION, output tensors: 21
    Op 22: type OPERATOR_WEIGHT, output tensors: 22
    Op 23: type OPERATOR_MATMUL, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_AGGREGATION, output tensors: 26
    Op 27: type OPERATOR_WEIGHT, output tensors: 27
    Op 28: type OPERATOR_MATMUL, output tensors: 28
    Op 29: type OPERATOR_RELU, output tensors: 29
    Op 30: type OPERATOR_DROPOUT, output tensors: 30
    Op 31: type OPERATOR_AGGREGATION, output tensors: 31
    Op 32: type OPERATOR_WEIGHT, output tensors: 32
    Op 33: type OPERATOR_MATMUL, output tensors: 33
    Op 34: type OPERATOR_RELU, output tensors: 34
    Op 35: type OPERATOR_DROPOUT, output tensors: 35
    Op 36: type OPERATOR_AGGREGATION, output tensors: 36
    Op 37: type OPERATOR_WEIGHT, output tensors: 37
    Op 38: type OPERATOR_MATMUL, output tensors: 38
    Op 39: type OPERATOR_SOFTMAX, output tensors: 39
Boundaries: 0 0 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 8): 0-[0, 306129) 1-[306129, 612258) 2-[612258, 918387) 3-[918387, 1224516) 4-[1224516, 1530645) 5-[1530645, 1836774) 6-[1836774, 2142903) 7-[2142903, 2449029)
2449029, 126167053, 126167053
2449029, 126167053, 126167053
Number of vertices per chunk: 306129
Number of vertices per chunk: 306129
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 1, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 21)...
+++++++++ Node 0, mapping weight op 1
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 7
using the Pytorch initialization method.
+++++++++ Node 1 initializing the weights for op[21, 40)...
+++++++++ Node 1, mapping weight op 22
+++++++++ Node 0, mapping weight op 12
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 17
using the Pytorch initialization method.
using the Pytorch initialization method.
+++++++++ Node 1, mapping weight op 27
using the Pytorch initialization method.
+++++++++ Node 1, mapping weight op 32
using the Pytorch initialization method.
+++++++++ Node 1, mapping weight op 37
using the Pytorch initialization method.
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.003000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 2.85719	TrainAcc 0.1026	ValidAcc 0.1152	TestAcc 0.1044
    Epoch 19:	Loss 1.91045	TrainAcc 0.4925	ValidAcc 0.4852	TestAcc 0.3661
    Epoch 29:	Loss 1.34966	TrainAcc 0.6514	ValidAcc 0.6390	TestAcc 0.4642
    Epoch 39:	Loss 1.06630	TrainAcc 0.7232	ValidAcc 0.7189	TestAcc 0.5378
    Epoch 49:	Loss 0.87589	TrainAcc 0.7715	ValidAcc 0.7650	TestAcc 0.5751
    Epoch 59:	Loss 0.79259	TrainAcc 0.8016	ValidAcc 0.7964	TestAcc 0.6107
    Epoch 69:	Loss 0.71539	TrainAcc 0.8220	ValidAcc 0.8147	TestAcc 0.6326
    Epoch 79:	Loss 0.67420	TrainAcc 0.8379	ValidAcc 0.8302	TestAcc 0.6393
    Epoch 89:	Loss 0.62565	TrainAcc 0.8556	ValidAcc 0.8459	TestAcc 0.6527
    Epoch 99:	Loss 0.59374	TrainAcc 0.8614	ValidAcc 0.8541	TestAcc 0.6597
    Epoch 109:	Loss 0.55697	TrainAcc 0.8672	ValidAcc 0.8594	TestAcc 0.6729
    Epoch 119:	Loss 0.53979	TrainAcc 0.8711	ValidAcc 0.8626	TestAcc 0.6781
    Epoch 129:	Loss 0.52081	TrainAcc 0.8752	ValidAcc 0.8683	TestAcc 0.6871
    Epoch 139:	Loss 0.51051	TrainAcc 0.8776	ValidAcc 0.8708	TestAcc 0.6890
    Epoch 149:	Loss 0.49559	TrainAcc 0.8809	ValidAcc 0.8733	TestAcc 0.6958
    Epoch 159:	Loss 0.48647	TrainAcc 0.8819	ValidAcc 0.8731	TestAcc 0.6985
    Epoch 169:	Loss 0.47873	TrainAcc 0.8831	ValidAcc 0.8777	TestAcc 0.7039
    Epoch 179:	Loss 0.47277	TrainAcc 0.8851	ValidAcc 0.8783	TestAcc 0.7046
    Epoch 189:	Loss 0.46318	TrainAcc 0.8873	ValidAcc 0.8796	TestAcc 0.7078
    Epoch 199:	Loss 0.45939	TrainAcc 0.8870	ValidAcc 0.8799	TestAcc 0.7095
    Epoch 209:	Loss 0.45288	TrainAcc 0.8884	ValidAcc 0.8827	TestAcc 0.7102
    Epoch 219:	Loss 0.44810	TrainAcc 0.8898	ValidAcc 0.8824	TestAcc 0.7125
    Epoch 229:	Loss 0.44315	TrainAcc 0.8901	ValidAcc 0.8829	TestAcc 0.7150
    Epoch 239:	Loss 0.43809	TrainAcc 0.8914	ValidAcc 0.8836	TestAcc 0.7127
    Epoch 249:	Loss 0.43339	TrainAcc 0.8928	ValidAcc 0.8847	TestAcc 0.7175
    Epoch 259:	Loss 0.42981	TrainAcc 0.8937	ValidAcc 0.8863	TestAcc 0.7162
    Epoch 269:	Loss 0.42467	TrainAcc 0.8949	ValidAcc 0.8856	TestAcc 0.7179
    Epoch 279:	Loss 0.42317	TrainAcc 0.8955	ValidAcc 0.8861	TestAcc 0.7170
    Epoch 289:	Loss 0.41904	TrainAcc 0.8960	ValidAcc 0.8861	TestAcc 0.7249
    Epoch 299:	Loss 0.41695	TrainAcc 0.8962	ValidAcc 0.8875	TestAcc 0.7220
    Epoch 309:	Loss 0.41432	TrainAcc 0.8970	ValidAcc 0.8881	TestAcc 0.7241
    Epoch 319:	Loss 0.41267	TrainAcc 0.8973	ValidAcc 0.8885	TestAcc 0.7241
    Epoch 329:	Loss 0.40840	TrainAcc 0.8985	ValidAcc 0.8896	TestAcc 0.7256
    Epoch 339:	Loss 0.40755	TrainAcc 0.8993	ValidAcc 0.8906	TestAcc 0.7297
    Epoch 349:	Loss 0.40154	TrainAcc 0.8999	ValidAcc 0.8910	TestAcc 0.7283
    Epoch 359:	Loss 0.40245	TrainAcc 0.8997	ValidAcc 0.8932	TestAcc 0.7288
    Epoch 369:	Loss 0.39869	TrainAcc 0.9018	ValidAcc 0.8919	TestAcc 0.7271
    Epoch 379:	Loss 0.39670	TrainAcc 0.9008	ValidAcc 0.8918	TestAcc 0.7300
    Epoch 389:	Loss 0.39443	TrainAcc 0.9014	ValidAcc 0.8937	TestAcc 0.7319
    Epoch 399:	Loss 0.39449	TrainAcc 0.9023	ValidAcc 0.8914	TestAcc 0.7302
    Epoch 409:	Loss 0.39239	TrainAcc 0.9014	ValidAcc 0.8920	TestAcc 0.7320
    Epoch 419:	Loss 0.39084	TrainAcc 0.9017	ValidAcc 0.8915	TestAcc 0.7311
    Epoch 429:	Loss 0.38902	TrainAcc 0.9015	ValidAcc 0.8947	TestAcc 0.7315
    Epoch 439:	Loss 0.38871	TrainAcc 0.9026	ValidAcc 0.8932	TestAcc 0.7324
    Epoch 449:	Loss 0.38489	TrainAcc 0.9032	ValidAcc 0.8936	TestAcc 0.7337
    Epoch 459:	Loss 0.38349	TrainAcc 0.9039	ValidAcc 0.8935	TestAcc 0.7365
    Epoch 469:	Loss 0.38187	TrainAcc 0.9038	ValidAcc 0.8944	TestAcc 0.7360
    Epoch 479:	Loss 0.38132	TrainAcc 0.9041	ValidAcc 0.8949	TestAcc 0.7340
    Epoch 489:	Loss 0.37879	TrainAcc 0.9048	ValidAcc 0.8948	TestAcc 0.7376
    Epoch 499:	Loss 0.37849	TrainAcc 0.9040	ValidAcc 0.8940	TestAcc 0.7339
    Epoch 509:	Loss 0.37537	TrainAcc 0.9051	ValidAcc 0.8955	TestAcc 0.7359
    Epoch 519:	Loss 0.37572	TrainAcc 0.9053	ValidAcc 0.8951	TestAcc 0.7374
    Epoch 529:	Loss 0.37553	TrainAcc 0.9052	ValidAcc 0.8945	TestAcc 0.7354
    Epoch 539:	Loss 0.37365	TrainAcc 0.9055	ValidAcc 0.8949	TestAcc 0.7344
    Epoch 549:	Loss 0.37308	TrainAcc 0.9061	ValidAcc 0.8969	TestAcc 0.7382
    Epoch 559:	Loss 0.37108	TrainAcc 0.9056	ValidAcc 0.8963	TestAcc 0.7369
    Epoch 569:	Loss 0.37138	TrainAcc 0.9061	ValidAcc 0.8968	TestAcc 0.7355
    Epoch 579:	Loss 0.36915	TrainAcc 0.9059	ValidAcc 0.8963	TestAcc 0.7373
    Epoch 589:	Loss 0.36913	TrainAcc 0.9062	ValidAcc 0.8943	TestAcc 0.7352
    Epoch 599:	Loss 0.36890	TrainAcc 0.9064	ValidAcc 0.8957	TestAcc 0.7359
    Epoch 609:	Loss 0.36809	TrainAcc 0.9063	ValidAcc 0.8955	TestAcc 0.7382
    Epoch 619:	Loss 0.36605	TrainAcc 0.9070	ValidAcc 0.8972	TestAcc 0.7361
    Epoch 629:	Loss 0.36360	TrainAcc 0.9085	ValidAcc 0.8985	TestAcc 0.7378
    Epoch 639:	Loss 0.36569	TrainAcc 0.9070	ValidAcc 0.8976	TestAcc 0.7331
    Epoch 649:	Loss 0.36432	TrainAcc 0.9081	ValidAcc 0.8977	TestAcc 0.7388
    Epoch 659:	Loss 0.36183	TrainAcc 0.9085	ValidAcc 0.8982	TestAcc 0.7387
    Epoch 669:	Loss 0.36170	TrainAcc 0.9076	ValidAcc 0.8982	TestAcc 0.7389
    Epoch 679:	Loss 0.35930	TrainAcc 0.9089	ValidAcc 0.8964	TestAcc 0.7404
    Epoch 689:	Loss 0.36193	TrainAcc 0.9088	ValidAcc 0.8991	TestAcc 0.7397
    Epoch 699:	Loss 0.35815	TrainAcc 0.9088	ValidAcc 0.8984	TestAcc 0.7375
    Epoch 709:	Loss 0.36066	TrainAcc 0.9079	ValidAcc 0.8990	TestAcc 0.7377
    Epoch 719:	Loss 0.35948	TrainAcc 0.9087	ValidAcc 0.8990	TestAcc 0.7376
    Epoch 729:	Loss 0.35668	TrainAcc 0.9094	ValidAcc 0.8988	TestAcc 0.7389
    Epoch 739:	Loss 0.35619	TrainAcc 0.9094	ValidAcc 0.8987	TestAcc 0.7386
    Epoch 749:	Loss 0.35664	TrainAcc 0.9091	ValidAcc 0.8967	TestAcc 0.7379
    Epoch 759:	Loss 0.35622	TrainAcc 0.9093	ValidAcc 0.8980	TestAcc 0.7386
    Epoch 769:	Loss 0.35472	TrainAcc 0.9090	ValidAcc 0.8987	TestAcc 0.7411
    Epoch 779:	Loss 0.35399	TrainAcc 0.9100	ValidAcc 0.8991	TestAcc 0.7393
    Epoch 789:	Loss 0.35481	TrainAcc 0.9094	ValidAcc 0.8972	TestAcc 0.7401
    Epoch 799:	Loss 0.35173	TrainAcc 0.9098	ValidAcc 0.8977	TestAcc 0.7404
    Epoch 809:	Loss 0.35138	TrainAcc 0.9106	ValidAcc 0.8987	TestAcc 0.7408
    Epoch 819:	Loss 0.35063	TrainAcc 0.9100	ValidAcc 0.8994	TestAcc 0.7384
    Epoch 829:	Loss 0.35209	TrainAcc 0.9101	ValidAcc 0.8977	TestAcc 0.7400
    Epoch 839:	Loss 0.35025	TrainAcc 0.9109	ValidAcc 0.9018	TestAcc 0.7361
    Epoch 849:	Loss 0.35010	TrainAcc 0.9105	ValidAcc 0.8990	TestAcc 0.7405
    Epoch 859:	Loss 0.34883	TrainAcc 0.9112	ValidAcc 0.9015	TestAcc 0.7400
    Epoch 869:	Loss 0.34995	TrainAcc 0.9105	ValidAcc 0.8998	TestAcc 0.7400
    Epoch 879:	Loss 0.34698	TrainAcc 0.9113	ValidAcc 0.9008	TestAcc 0.7400
    Epoch 889:	Loss 0.35115	TrainAcc 0.9103	ValidAcc 0.8989	TestAcc 0.7389
    Epoch 899:	Loss 0.34693	TrainAcc 0.9106	ValidAcc 0.8990	TestAcc 0.7384
    Epoch 909:	Loss 0.34691	TrainAcc 0.9116	ValidAcc 0.8985	TestAcc 0.7396
    Epoch 919:	Loss 0.34703	TrainAcc 0.9117	ValidAcc 0.8992	TestAcc 0.7384
    Epoch 929:	Loss 0.34439	TrainAcc 0.9123	ValidAcc 0.8992	TestAcc 0.7385
    Epoch 939:	Loss 0.34765	TrainAcc 0.9112	ValidAcc 0.9005	TestAcc 0.7383
    Epoch 949:	Loss 0.34433	TrainAcc 0.9118	ValidAcc 0.9000	TestAcc 0.7389
    Epoch 959:	Loss 0.34572	TrainAcc 0.9115	ValidAcc 0.9004	TestAcc 0.7389
    Epoch 969:	Loss 0.34425	TrainAcc 0.9115	ValidAcc 0.9005	TestAcc 0.7407
    Epoch 979:	Loss 0.34522	TrainAcc 0.9115	ValidAcc 0.9004	TestAcc 0.7392
    Epoch 989:	Loss 0.34417	TrainAcc 0.9116	ValidAcc 0.9007	TestAcc 0.7403
    Epoch 999:	Loss 0.34335	TrainAcc 0.9121	ValidAcc 0.8992	TestAcc 0.7387
    Epoch 1009:	Loss 0.34360	TrainAcc 0.9116	ValidAcc 0.9004	TestAcc 0.7401
    Epoch 1019:	Loss 0.34322	TrainAcc 0.9121	ValidAcc 0.9020	TestAcc 0.7411
    Epoch 1029:	Loss 0.34248	TrainAcc 0.9115	ValidAcc 0.9000	TestAcc 0.7399
    Epoch 1039:	Loss 0.34091	TrainAcc 0.9126	ValidAcc 0.9008	TestAcc 0.7388
    Epoch 1049:	Loss 0.34101	TrainAcc 0.9119	ValidAcc 0.9026	TestAcc 0.7365
    Epoch 1059:	Loss 0.34079	TrainAcc 0.9120	ValidAcc 0.9004	TestAcc 0.7377
    Epoch 1069:	Loss 0.34160	TrainAcc 0.9127	ValidAcc 0.9020	TestAcc 0.7412
    Epoch 1079:	Loss 0.34089	TrainAcc 0.9124	ValidAcc 0.9009	TestAcc 0.7408
    Epoch 1089:	Loss 0.34017	TrainAcc 0.9125	ValidAcc 0.9000	TestAcc 0.7384
    Epoch 1099:	Loss 0.33954	TrainAcc 0.9129	ValidAcc 0.9008	TestAcc 0.7405
    Epoch 1109:	Loss 0.33729	TrainAcc 0.9131	ValidAcc 0.9004	TestAcc 0.7386
    Epoch 1119:	Loss 0.33734	TrainAcc 0.9127	ValidAcc 0.9022	TestAcc 0.7425
    Epoch 1129:	Loss 0.33928	TrainAcc 0.9133	ValidAcc 0.9018	TestAcc 0.7414
    Epoch 1139:	Loss 0.33733	TrainAcc 0.9136	ValidAcc 0.9008	TestAcc 0.7375
    Epoch 1149:	Loss 0.33861	TrainAcc 0.9124	ValidAcc 0.9021	TestAcc 0.7407
    Epoch 1159:	Loss 0.33847	TrainAcc 0.9132	ValidAcc 0.9017	TestAcc 0.7421
    Epoch 1169:	Loss 0.33705	TrainAcc 0.9132	ValidAcc 0.9023	TestAcc 0.7408
    Epoch 1179:	Loss 0.33456	TrainAcc 0.9138	ValidAcc 0.9016	TestAcc 0.7397
    Epoch 1189:	Loss 0.33638	TrainAcc 0.9131	ValidAcc 0.9019	TestAcc 0.7439
    Epoch 1199:	Loss 0.33777	TrainAcc 0.9125	ValidAcc 0.9008	TestAcc 0.7379
    Epoch 1209:	Loss 0.33502	TrainAcc 0.9134	ValidAcc 0.9022	TestAcc 0.7407
    Epoch 1219:	Loss 0.33391	TrainAcc 0.9141	ValidAcc 0.9012	TestAcc 0.7401
    Epoch 1229:	Loss 0.33617	TrainAcc 0.9131	ValidAcc 0.9023	TestAcc 0.7403
    Epoch 1239:	Loss 0.33301	TrainAcc 0.9142	ValidAcc 0.9027	TestAcc 0.7417
    Epoch 1249:	Loss 0.33383	TrainAcc 0.9138	ValidAcc 0.9013	TestAcc 0.7401
    Epoch 1259:	Loss 0.33232	TrainAcc 0.9140	ValidAcc 0.9022	TestAcc 0.7392
    Epoch 1269:	Loss 0.33226	TrainAcc 0.9143	ValidAcc 0.9028	TestAcc 0.7404
    Epoch 1279:	Loss 0.33163	TrainAcc 0.9141	ValidAcc 0.9028	TestAcc 0.7427
    Epoch 1289:	Loss 0.33066	TrainAcc 0.9143	ValidAcc 0.9020	TestAcc 0.7407
    Epoch 1299:	Loss 0.33205	TrainAcc 0.9148	ValidAcc 0.9008	TestAcc 0.7408
    Epoch 1309:	Loss 0.33027	TrainAcc 0.9141	ValidAcc 0.9018	TestAcc 0.7410
    Epoch 1319:	Loss 0.32914	TrainAcc 0.9147	ValidAcc 0.9026	TestAcc 0.7388
    Epoch 1329:	Loss 0.33205	TrainAcc 0.9142	ValidAcc 0.9039	TestAcc 0.7385
    Epoch 1339:	Loss 0.33206	TrainAcc 0.9143	ValidAcc 0.9018	TestAcc 0.7393
    Epoch 1349:	Loss 0.33209	TrainAcc 0.9140	ValidAcc 0.9019	TestAcc 0.7389
    Epoch 1359:	Loss 0.33001	TrainAcc 0.9152	ValidAcc 0.9005	TestAcc 0.7396
    Epoch 1369:	Loss 0.33012	TrainAcc 0.9149	ValidAcc 0.9018	TestAcc 0.7421
    Epoch 1379:	Loss 0.33124	TrainAcc 0.9146	ValidAcc 0.9015	TestAcc 0.7393
    Epoch 1389:	Loss 0.32915	TrainAcc 0.9151	ValidAcc 0.9012	TestAcc 0.7388
    Epoch 1399:	Loss 0.32931	TrainAcc 0.9148	ValidAcc 0.9028	TestAcc 0.7407
    Epoch 1409:	Loss 0.33000	TrainAcc 0.9149	ValidAcc 0.9037	TestAcc 0.7427
    Epoch 1419:	Loss 0.32813	TrainAcc 0.9157	ValidAcc 0.9026	TestAcc 0.7411
    Epoch 1429:	Loss 0.32753	TrainAcc 0.9150	ValidAcc 0.9018	TestAcc 0.7415
    Epoch 1439:	Loss 0.32626	TrainAcc 0.9154	ValidAcc 0.9037	TestAcc 0.7402
    Epoch 1449:	Loss 0.32719	TrainAcc 0.9154	ValidAcc 0.9018	TestAcc 0.7394
    Epoch 1459:	Loss 0.32595	TrainAcc 0.9157	ValidAcc 0.9039	TestAcc 0.7409
    Epoch 1469:	Loss 0.32768	TrainAcc 0.9148	ValidAcc 0.9040	TestAcc 0.7399
    Epoch 1479:	Loss 0.32643	TrainAcc 0.9153	ValidAcc 0.9033	TestAcc 0.7391
    Epoch 1489:	Loss 0.32691	TrainAcc 0.9153	ValidAcc 0.9037	TestAcc 0.7403
    Epoch 1499:	Loss 0.32647	TrainAcc 0.9155	ValidAcc 0.9038	TestAcc 0.7403
    Epoch 1509:	Loss 0.32690	TrainAcc 0.9154	ValidAcc 0.9044	TestAcc 0.7406
    Epoch 1519:	Loss 0.32660	TrainAcc 0.9151	ValidAcc 0.9000	TestAcc 0.7396
    Epoch 1529:	Loss 0.32623	TrainAcc 0.9147	ValidAcc 0.9027	TestAcc 0.7404
    Epoch 1539:	Loss 0.32554	TrainAcc 0.9157	ValidAcc 0.9036	TestAcc 0.7393
    Epoch 1549:	Loss 0.32606	TrainAcc 0.9155	ValidAcc 0.9044	TestAcc 0.7416
    Epoch 1559:	Loss 0.32438	TrainAcc 0.9155	ValidAcc 0.9018	TestAcc 0.7409
    Epoch 1569:	Loss 0.32484	TrainAcc 0.9158	ValidAcc 0.9037	TestAcc 0.7403
    Epoch 1579:	Loss 0.32360	TrainAcc 0.9160	ValidAcc 0.9028	TestAcc 0.7411
    Epoch 1589:	Loss 0.32448	TrainAcc 0.9156	ValidAcc 0.9042	TestAcc 0.7415
    Epoch 1599:	Loss 0.32379	TrainAcc 0.9162	ValidAcc 0.9023	TestAcc 0.7404
    Epoch 1609:	Loss 0.32314	TrainAcc 0.9164	ValidAcc 0.9047	TestAcc 0.7422
    Epoch 1619:	Loss 0.32330	TrainAcc 0.9155	ValidAcc 0.9055	TestAcc 0.7402
    Epoch 1629:	Loss 0.32188	TrainAcc 0.9166	ValidAcc 0.9050	TestAcc 0.7398
    Epoch 1639:	Loss 0.32347	TrainAcc 0.9154	ValidAcc 0.9034	TestAcc 0.7401
    Epoch 1649:	Loss 0.32220	TrainAcc 0.9169	ValidAcc 0.9020	TestAcc 0.7394
    Epoch 1659:	Loss 0.32186	TrainAcc 0.9170	ValidAcc 0.9022	TestAcc 0.7404
    Epoch 1669:	Loss 0.32095	TrainAcc 0.9174	ValidAcc 0.9040	TestAcc 0.7425
    Epoch 1679:	Loss 0.32158	TrainAcc 0.9169	ValidAcc 0.9029	TestAcc 0.7415
    Epoch 1689:	Loss 0.32247	TrainAcc 0.9160	ValidAcc 0.9027	TestAcc 0.7381
    Epoch 1699:	Loss 0.32049	TrainAcc 0.9160	ValidAcc 0.9026	TestAcc 0.7415
    Epoch 1709:	Loss 0.32157	TrainAcc 0.9161	ValidAcc 0.9042	TestAcc 0.7400
    Epoch 1719:	Loss 0.32193	TrainAcc 0.9166	ValidAcc 0.9045	TestAcc 0.7371
    Epoch 1729:	Loss 0.32103	TrainAcc 0.9165	ValidAcc 0.9048	TestAcc 0.7417
    Epoch 1739:	Loss 0.32126	TrainAcc 0.9165	ValidAcc 0.9054	TestAcc 0.7382
    Epoch 1749:	Loss 0.32122	TrainAcc 0.9162	ValidAcc 0.9033	TestAcc 0.7398
    Epoch 1759:	Loss 0.32208	TrainAcc 0.9160	ValidAcc 0.9025	TestAcc 0.7414
    Epoch 1769:	Loss 0.32056	TrainAcc 0.9164	ValidAcc 0.9037	TestAcc 0.7394
    Epoch 1779:	Loss 0.31918	TrainAcc 0.9170	ValidAcc 0.9045	TestAcc 0.7406
    Epoch 1789:	Loss 0.32065	TrainAcc 0.9163	ValidAcc 0.9038	TestAcc 0.7390
    Epoch 1799:	Loss 0.32007	TrainAcc 0.9165	ValidAcc 0.9049	TestAcc 0.7404
    Epoch 1809:	Loss 0.31902	TrainAcc 0.9172	ValidAcc 0.9046	TestAcc 0.7402
    Epoch 1819:	Loss 0.31944	TrainAcc 0.9174	ValidAcc 0.9046	TestAcc 0.7382
    Epoch 1829:	Loss 0.32016	TrainAcc 0.9169	ValidAcc 0.9040	TestAcc 0.7403
    Epoch 1839:	Loss 0.31804	TrainAcc 0.9167	ValidAcc 0.9047	TestAcc 0.7428
    Epoch 1849:	Loss 0.31729	TrainAcc 0.9170	ValidAcc 0.9034	TestAcc 0.7399
    Epoch 1859:	Loss 0.31949	TrainAcc 0.9162	ValidAcc 0.9042	TestAcc 0.7419
    Epoch 1869:	Loss 0.31837	TrainAcc 0.9169	ValidAcc 0.9042	TestAcc 0.7393
    Epoch 1879:	Loss 0.31939	TrainAcc 0.9169	ValidAcc 0.9045	TestAcc 0.7399
    Epoch 1889:	Loss 0.31818	TrainAcc 0.9170	ValidAcc 0.9037	TestAcc 0.7405
    Epoch 1899:	Loss 0.31815	TrainAcc 0.9168	ValidAcc 0.9037	TestAcc 0.7401
    Epoch 1909:	Loss 0.31645	TrainAcc 0.9166	ValidAcc 0.9052	TestAcc 0.7432
    Epoch 1919:	Loss 0.31643	TrainAcc 0.9175	ValidAcc 0.9035	TestAcc 0.7398
    Epoch 1929:	Loss 0.31647	TrainAcc 0.9169	ValidAcc 0.9032	TestAcc 0.7410
    Epoch 1939:	Loss 0.31576	TrainAcc 0.9177	ValidAcc 0.9043	TestAcc 0.7415
    Epoch 1949:	Loss 0.31584	TrainAcc 0.9177	ValidAcc 0.9045	TestAcc 0.7417
    Epoch 1959:	Loss 0.31629	TrainAcc 0.9176	ValidAcc 0.9053	TestAcc 0.7397
    Epoch 1969:	Loss 0.31603	TrainAcc 0.9181	ValidAcc 0.9058	TestAcc 0.7381
    Epoch 1979:	Loss 0.31593	TrainAcc 0.9175	ValidAcc 0.9060	TestAcc 0.7387
    Epoch 1989:	Loss 0.31514	TrainAcc 0.9173	ValidAcc 0.9044	TestAcc 0.7410
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 11.354 GBps
Node 1, Layer-level comm throughput (grad): -nan GBps
Node 0, Layer-level comm throughput (grad): 11.364 GBps
    Epoch 1999:	Loss 0.31490	TrainAcc 0.9179	ValidAcc 0.9046	TestAcc 0.7402
Node 1, GPU memory consumption: 18.005 GB
Node 1, compression time: 6.765s, compression size: 1167.788GB, throughput: 172.631GBps
Node 1, decompression time: 18.233s, compression size: 1167.788GB, throughput: 64.050GBps
Node 1, pure compute time: 341.564 s, total compute time: 366.561 s
Node 1, wait_for_task_time: 33.351 s, wait_for_other_gpus_time: 0.010 s
------------------------node id 1,  per-epoch time: 0.237859 s---------------
Node 0, GPU memory consumption: 17.628 GB
Node 0, compression time: 4.091s, compression size: 1167.788GB, throughput: 285.428GBps
Node 0, decompression time: 17.756s, compression size: 1167.788GB, throughput: 65.767GBps
Node 0, pure compute time: 355.583 s, total compute time: 377.431 s
Node 0, wait_for_task_time: 72.939 s, wait_for_other_gpus_time: 0.003 s
------------------------node id 0,  per-epoch time: 0.237859 s---------------
************ Profiling Results ************
	Bubble: 51.692166 (s) (10.86 percentage)
	Compute: 398.231678 (s) (83.68 percentage)
	GradSync: 3.991549 (s) (0.84 percentage)
	GraphComm: 0.047763 (s) (0.01 percentage)
	Imbalance: 16.864781 (s) (3.54 percentage)
	LayerComm: 5.055352 (s) (1.06 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.382 GB
Highest valid_acc: 0.9060
Target test_acc: 0.7387
Epoch to reach the target acc: 1980
[MPI Rank 1] Success 
[MPI Rank 0] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 8
The number of hidden units: 64
The number of training epoches: 0
Learning rate: 0.000000
gcn_inference: /home/x-jchen5/baseline/Mithril_MultiGPU/core/src/cuda/cuda_resource.cc:25: virtual void TensorResourceGPU::map(): Assertion `gpu_data_ != nullptr' failed.
[g001:1122825] *** Process received signal ***
[g001:1122825] Signal: Aborted (6)
[g001:1122825] Signal code:  (-6)
[g001:1122825] [ 0] /lib64/libc.so.6(+0x4eb80)[0x149cd5dc1b80]
[g001:1122825] [ 1] /lib64/libc.so.6(gsignal+0x10f)[0x149cd5dc1aff]
[g001:1122825] [ 2] /lib64/libc.so.6(abort+0x127)[0x149cd5d94ea5]
[g001:1122825] [ 3] /lib64/libc.so.6(+0x21d79)[0x149cd5d94d79]
[g001:1122825] [ 4] /lib64/libc.so.6(+0x47456)[0x149cd5dba456]
[g001:1122825] [ 5] /home/x-jchen5/baseline/Mithril_MultiGPU/build/applications/single_gpu/gcn_inference(_ZN17TensorResourceGPU3mapEv+0x42a)[0x45896a]
[g001:1122825] [ 6] /home/x-jchen5/baseline/Mithril_MultiGPU/build/applications/single_gpu/gcn_inference(_ZN28SingleNodeExecutionEngineGPU15model_inferenceEP19AbstractApplicationNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x16b)[0x45519b]
[g001:1122825] [ 7] /home/x-jchen5/baseline/Mithril_MultiGPU/build/applications/single_gpu/gcn_inference(main+0x118e)[0x42278e]
[g001:1122825] [ 8] /lib64/libc.so.6(__libc_start_main+0xe5)[0x149cd5dadd85]
[g001:1122825] [ 9] /home/x-jchen5/baseline/Mithril_MultiGPU/build/applications/single_gpu/gcn_inference(_start+0x2e)[0x422d0e]
[g001:1122825] *** End of error message ***
/var/spool/slurm/job1678293/slurm_script: line 36: 1122825 Aborted                 $HOME/baseline/Mithril_MultiGPU/build/applications/single_gpu/gcn_inference --graph $PROJECT/gnn_datasets/reordered/$graph --layers $num_layers --hunits $hunits --weight_file $PROJECT/saved_weights_pipe
