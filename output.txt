Mon Sep 18 11:03:08 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    On   | 00000000:01:00.0 Off |                  Off |
| 30%   34C    P8    16W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    On   | 00000000:25:00.0 Off |                  Off |
| 30%   35C    P8    24W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A5000    On   | 00000000:81:00.0 Off |                  Off |
| 30%   36C    P8    21W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A5000    On   | 00000000:C1:00.0 Off |                  Off |
| 30%   35C    P8    14W / 230W |      1MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
[ 26%] Built target core
[ 26%] Built target context
[ 73%] Built target cudahelp
Scanning dependencies of target OSDI2023_MULTI_NODES_resgcn
[ 78%] Built target OSDI2023_MULTI_NODES_graphsage
[ 78%] Built target OSDI2023_MULTI_NODES_gcnii
[ 97%] Built target OSDI2023_MULTI_NODES_gcn
[ 97%] Building CXX object applications/async_multi_gpus/CMakeFiles/OSDI2023_MULTI_NODES_resgcn.dir/resgcn.cc.o
[ 97%] Built target estimate_comm_volume
[100%] Linking CXX executable resgcn
[100%] Built target OSDI2023_MULTI_NODES_resgcn
Running experiments...
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
DONE MPI INITDONE MPI INIT
Initialized node 3 on machine gnerv2
DONE MPI INIT
Initialized node 1 on machine gnerv2

Initialized node 0 on machine gnerv2
DONE MPI INIT
Initialized node 2 on machine gnerv2
DONE MPI INIT
Initialized node 4 on machine gnerv3
DONE MPI INIT
Initialized node 5 on machine gnerv3
DONE MPI INITDONE MPI INIT
Initialized node 6 on machine gnerv3

Initialized node 7 on machine gnerv3
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.243 seconds.
Building the CSC structure...
        It takes 0.283 seconds.
Building the CSC structure...
        It takes 0.282 seconds.
Building the CSC structure...
        It takes 0.287 seconds.
Building the CSC structure...
        It takes 0.289 seconds.
Building the CSC structure...
        It takes 0.291 seconds.
Building the CSC structure...
        It takes 0.294 seconds.
Building the CSC structure...
        It takes 0.314 seconds.
Building the CSC structure...
        It takes 0.239 seconds.
        It takes 0.262 seconds.
        It takes 0.280 seconds.
        It takes 0.282 seconds.
        It takes 0.291 seconds.
        It takes 0.283 seconds.
        It takes 0.295 seconds.
        It takes 0.311 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.475 seconds.
Building the Label Vector...
        It takes 0.480 seconds.
Building the Label Vector...
        It takes 0.474 seconds.
Building the Label Vector...
        It takes 0.493 seconds.
Building the Label Vector...
        It takes 0.504 seconds.
Building the Label Vector...
        It takes 0.491 seconds.
Building the Label Vector...
        It takes 0.500 seconds.
Building the Label Vector...
        It takes 0.500 seconds.
Building the Label Vector...
        It takes 0.182 seconds.
        It takes 0.178 seconds.
        It takes 0.189 seconds.
        It takes 0.192 seconds.
        It takes 0.195 seconds.
        It takes 0.200 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/partitioned_graphs/yelp/8_parts
The number of GCNII layers: 32
The number of hidden units: 100
The number of training epoches: 100
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 1
Number of classes: 100
Number of feature dimensions: 300
Number of vertices: 716847
Number of GPUs: 8
        It takes 0.195 seconds.
        It takes 0.194 seconds.
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
716847, 13954819, 13954819
Number of vertices per chunk: 89606
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
716847, 13954819, 13954819
Number of vertices per chunk: 89606
train nodes 537635, valid nodes 107527, test nodes 71685
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
Chunks (number of global chunks: 8): 0-[0, 89605) 1-[89605, 179211) 2-[179211, 268818) 3-[268818, 358423) 4-[358423, 448029) 5-[448029, 537635) 6-[537635, 627242) 7-[627242, 716847)
716847, 13954819, 13954819
Number of vertices per chunk: 89606
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
716847, 13954819, 13954819
Number of vertices per chunk: 89606
716847, 13954819, 13954819
716847, 13954819, 13954819
Number of vertices per chunk: 89606
Number of vertices per chunk: 89606
716847, 13954819, 13954819
Number of vertices per chunk: 89606
716847, 13954819, 13954819
Number of vertices per chunk: 89606
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
***** Start profiling the layer-level communication performance *******
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
The layer-level communication performance: 56.855 Gbps (per GPU), 454.841 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 56.601 Gbps (per GPU), 452.811 Gbps (aggregated)
The layer-level communication performance: 56.584 Gbps (per GPU), 452.672 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 56.365 Gbps (per GPU), 450.921 Gbps (aggregated)
The layer-level communication performance: 56.323 Gbps (per GPU), 450.586 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The layer-level communication performance: 56.140 Gbps (per GPU), 449.116 Gbps (aggregated)
The layer-level communication performance: 56.101 Gbps (per GPU), 448.807 Gbps (aggregated)
The layer-level communication performance: 56.071 Gbps (per GPU), 448.571 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The graph-level communication performance (supernode = 2): 156.484 Gbps (per GPU), 1251.870 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 156.472 Gbps (per GPU), 1251.774 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 156.481 Gbps (per GPU), 1251.845 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 156.472 Gbps (per GPU), 1251.774 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 156.475 Gbps (per GPU), 1251.797 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 156.472 Gbps (per GPU), 1251.774 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 156.390 Gbps (per GPU), 1251.121 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 156.472 Gbps (per GPU), 1251.774 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
The graph-level communication performance (supernode = 4): 100.914 Gbps (per GPU), 807.315 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.915 Gbps (per GPU), 807.321 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.916 Gbps (per GPU), 807.328 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.914 Gbps (per GPU), 807.315 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.916 Gbps (per GPU), 807.327 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.915 Gbps (per GPU), 807.321 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.917 Gbps (per GPU), 807.334 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 100.914 Gbps (per GPU), 807.315 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
****** Start profiling the graph-level communication performance with supernodesize = 8 ******
The graph-level communication performance (supernode = 8): 33.051 Gbps (per GPU), 264.407 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.050 Gbps (per GPU), 264.402 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.051 Gbps (per GPU), 264.406 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.049 Gbps (per GPU), 264.394 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.050 Gbps (per GPU), 264.398 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.049 Gbps (per GPU), 264.396 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.051 Gbps (per GPU), 264.406 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 8): 33.050 Gbps (per GPU), 264.401 Gbps (aggregated, cluster-wide)
 LType   LT0   LT1   LT2 Ratio  VSum  ESum
 chk_0 10.17ms  8.36ms  9.08ms  1.22 89.61K  0.73M
 chk_1 10.11ms  8.28ms  9.02ms  1.22 89.61K  0.74M
 chk_2 12.80ms 10.98ms 11.68ms  1.17 89.61K  3.52M
 chk_3 12.22ms 10.41ms 11.07ms  1.17 89.61K  2.76M
 chk_4 11.37ms  9.80ms 10.30ms  1.16 89.61K  1.50M
 chk_5 10.68ms  8.85ms  9.58ms  1.21 89.61K  1.19M
 chk_6 12.31ms 10.47ms 11.19ms  1.18 89.61K  2.34M
 chk_7  9.91ms  8.10ms  8.80ms  1.22 89.61K  0.47M
   Avg 11.20  9.41 10.09
   Max 12.80 10.98 11.68
   Min  9.91  8.10  8.80
 Ratio  1.29  1.36  1.33
   Var  1.13  1.15  1.10
Profiling takes 2.870 s
*** Node 0, starting model training...
*** Node 1, starting model training...
*** Node 2, starting model training...
*** Node 3, starting model training...
*** Node 4, starting model training...
*** Node 5, starting model training...
*** Node 6, starting model training...
*** Node 7, starting model training...
Num Stages: 1 / 1
Node 5, Pipeline Input Tensor: NULL
Node 5, Pipeline Output Tensor: NULL
*** Node 5 owns the model-level partition [0, 261)
*** Node 5, constructing the helper classes...
Node 5, Local Vertex Begin: 448029, Num Local Vertices: 89606
Num Stages: 1 / 1
Node 4, Pipeline Input Tensor: NULL
Node 4, Pipeline Output Tensor: NULL
*** Node 4 owns the model-level partition [0, 261)
*** Node 4, constructing the helper classes...
Node 4, Local Vertex Begin: 358423, Num Local Vertices: 89606
Num Stages: 1 / 1
Node 6, Pipeline Input Tensor: NULL
Node 6, Pipeline Output Tensor: NULL
*** Node 6 owns the model-level partition [0, 261)
*** Node 6, constructing the helper classes...
Node 6, Local Vertex Begin: 537635, Num Local Vertices: 89607
Num Stages: 1 / 1
Node 7, Pipeline Input Tensor: NULL
Node 7, Pipeline Output Tensor: NULL
*** Node 7 owns the model-level partition [0, 261)
*** Node 7, constructing the helper classes...
Node 7, Local Vertex Begin: 627242, Num Local Vertices: 89605
Num Stages: 1 / 1
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: NULL
*** Node 0 owns the model-level partition [0, 261)
*** Node 0, constructing the helper classes...
Node 0, Local Vertex Begin: 0, Num Local Vertices: 89605
Num Stages: 1 / 1
Node 1, Pipeline Input Tensor: NULL
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [0, 261)
*** Node 1, constructing the helper classes...
Node 1, Local Vertex Begin: 89605, Num Local Vertices: 89606
Num Stages: 1 / 1
Node 3, Pipeline Input Tensor: NULL
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [0, 261)
*** Node 3, constructing the helper classes...
Node 3, Local Vertex Begin: 268818, Num Local Vertices: 89605
Num Stages: 1 / 1
Node 2, Pipeline Input Tensor: NULL
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the model-level partition [0, 261)
*** Node 2, constructing the helper classes...
Node 2, Local Vertex Begin: 179211, Num Local Vertices: 89607
*** Node 5, setting up some other necessary information...
*** Node 7, setting up some other necessary information...
*** Node 6, setting up some other necessary information...
*** Node 4, setting up some other necessary information...
*** Node 0, setting up some other necessary information...
*** Node 3, setting up some other necessary information...
*** Node 1, setting up some other necessary information...
*** Node 2, setting up some other necessary information...
+++++++++ Node 7 initializing the weights for op[0, 261)...
+++++++++ Node 1 initializing the weights for op[0, 261)...
+++++++++ Node 5 initializing the weights for op[0, 261)...
+++++++++ Node 0 initializing the weights for op[0, 261)...
+++++++++ Node 2 initializing the weights for op[0, 261)...
+++++++++ Node 3 initializing the weights for op[0, 261)...
+++++++++ Node 4 initializing the weights for op[0, 261)...
+++++++++ Node 6 initializing the weights for op[0, 261)...
Node 0, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
Node 4, discovering the vertices that will be sent across graph boundary...
Node 5, discovering the vertices that will be sent across graph boundary...
Node 6, discovering the vertices that will be sent across graph boundary...
Node 7, discovering the vertices that will be sent across graph boundary...
The number of mirror vertices: 898218
Node 0, discovering the vertices that will be received across the graph boundary.
Node 4, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
Node 5, discovering the vertices that will be received across the graph boundary.
Node 2, discovering the vertices that will be received across the graph boundary.
Node 6, discovering the vertices that will be received across the graph boundary.
Node 3, discovering the vertices that will be received across the graph boundary.
Node 7, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
*** Node 0, starting task scheduling...



*** Node 4, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 5, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 6, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 7, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
	Epoch 1:	Loss 0.7938	TrainAcc -nan	ValidAcc -nan	TestAcc -nan	BestValid 0.0000
	Epoch 50:	Loss nan	TrainAcc -nan	ValidAcc -nan	TestAcc -nan	BestValid 0.0000
	Epoch 100:	Loss nan	TrainAcc -nan	ValidAcc -nan	TestAcc -nan	BestValid 0.0000
****** Epoch Time (Excluding Evaluation Cost): 0.911 s ******
****** Breakdown Analysis ******
Cluster-Wide Average, Bubble-Pipeline: 1.364 ms (Max: 2.251, Min: 0.037, Sum: 10.909)
Cluster-Wide Average, Compute: 277.417 ms (Max: 312.062, Min: 249.727, Sum: 2219.339)
Cluster-Wide Average, Communication-Layer: 0.008 ms (Max: 0.009, Min: 0.007, Sum: 0.064)
Cluster-Wide Average, Bubble-Imbalance: 0.015 ms (Max: 0.018, Min: 0.014, Sum: 0.122)
Cluster-Wide Average, Communication-Graph: 627.784 ms (Max: 654.797, Min: 594.465, Sum: 5022.270)
Cluster-Wide Average, Optimization: 3.235 ms (Max: 3.251, Min: 3.204, Sum: 25.880)
Cluster-Wide Average, Others: 0.799 ms (Max: 0.827, Min: 0.769, Sum: 6.392)
****** Breakdown Sum: 910.622 ms ******
Cluster-Wide Average, GPU Memory Consumption: 20.038 GB (Max: 21.255, Min: 19.850, Sum: 160.306)
Cluster-Wide Average, Graph-Level Communication Throughput: 38.652 Gbps (Max: 52.129, Min: 24.777, Sum: 309.216)
Cluster-Wide Average, Layer-Level Communication Throughput: 0.000 Gbps (Max: 0.000, Min: 0.000, Sum: 0.000)
Layer-level communication (cluster-wide, per-epoch): 0.000 GB
Graph-level communication (cluster-wide, per-epoch): 21.415 GB
Weight-sync communication (cluster-wide, per-epoch): 0.019 GB
Total communication (cluster-wide, per-epoch): 21.434 GB
****** Accuracy Results ******
Highest valid_acc: 0.0000
Target test_acc: 0.1718
Epoch to reach the target acc: 0
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 4] Success 
[MPI Rank 2] Success 
[MPI Rank 5] Success 
[MPI Rank 3] Success 
[MPI Rank 6] Success 
[MPI Rank 7] Success 
