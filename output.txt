g012.anvil.rcac.purdue.edu
Fri Jan 20 00:08:32 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   28C    P0    49W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  4%] Built target context
[ 17%] Built target parallel
[ 19%] Built target core
Scanning dependencies of target cudahelp
[ 20%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_graph_parallel.cc.o
[ 21%] Linking CXX static library libcudahelp.a
[ 40%] Built target cudahelp
[ 44%] Linking CXX executable test_full_structual_graph
[ 56%] Linking CXX executable test_cuda_model_parallel
[ 60%] Linking CXX executable test_cuda_graph
[ 60%] Linking CXX executable test_mpi_model_parallel
[ 60%] Linking CXX executable test_cuda
[ 60%] Linking CXX executable test_full_non_structual_graph
[ 60%] Linking CXX executable test_graph
[ 60%] Linking CXX executable test_mpi_combined
[ 64%] Linking CXX executable estimate_comm_volume
[ 60%] Linking CXX executable test_single_node_fullgpu_training
[ 64%] Linking CXX executable test_single_node_training
[ 64%] Linking CXX executable test_mpi_gpu_pipelined_model_parallel
[ 60%] Linking CXX executable test_mpi_structual_graph
[ 60%] Linking CXX executable test_single_node_gpu_training
[ 64%] Linking CXX executable test_mpi_pipelined_model_parallel
[ 60%] Linking CXX executable test_cuda_pipeline_parallel
[ 60%] Linking CXX executable test_trivial
[ 64%] Linking CXX executable test_mpi_gpu_model_parallel
[ 60%] Linking CXX executable test_mpi_gpu_hybrid
[ 60%] Linking CXX executable test_mpi_loader
[ 64%] Linking CXX executable test_mpi_non_structual_graph
[ 60%] Linking CXX executable test_hello_world
[ 60%] Linking CXX executable test_nccl_thread
[ 60%] Linking CXX executable test_nccl_mpi
[ 68%] Linking CXX executable gcn_inference
[ 68%] Linking CXX executable gcn_graph_parallel
[ 68%] Linking CXX executable gcn
[ 70%] Linking CXX executable gcn
[ 70%] Linking CXX executable test_two_layer_hybrid_parallelism_designer
[ 71%] Built target test_mpi_combined
[ 77%] Built target test_mpi_loader
[ 77%] Built target estimate_comm_volume
[ 77%] Built target test_cuda
[ 77%] Built target test_full_structual_graph
[ 77%] Built target test_full_non_structual_graph
[ 77%] Built target test_mpi_structual_graph
[ 79%] Built target test_graph
[ 79%] Built target test_trivial
[ 83%] Built target test_mpi_non_structual_graph
[ 83%] Built target test_cuda_graph
[ 83%] Built target test_hello_world
[ 83%] Built target test_mpi_pipelined_model_parallel
[ 84%] Built target test_single_node_training
[ 85%] Built target test_mpi_model_parallel
[ 86%] Built target test_two_layer_hybrid_parallelism_designer
[ 87%] Built target test_mpi_gpu_model_parallel
[ 88%] Built target test_single_node_gpu_training
[ 89%] Built target test_mpi_gpu_pipelined_model_parallel
[ 91%] Built target test_single_node_fullgpu_training
[ 91%] Built target test_mpi_gpu_hybrid
[ 92%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[ 93%] Built target OSDI2023_SINGLE_NODE_gcn
[ 94%] Built target test_cuda_pipeline_parallel
[ 95%] Built target OSDI2023_MULTI_NODES_gcn
[ 97%] Built target test_nccl_thread
[ 97%] Built target test_nccl_mpi
[ 98%] Built target test_cuda_model_parallel
[100%] Built target OSDI2023_MULTI_NODES_gcn_graph_parallel
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
Initialized node g014.anvil.rcac.purdue.edu
Initialized node g013.anvil.rcac.purdue.edu
Initialized node g015.anvil.rcac.purdue.edu
Initialized node g012.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.811 seconds.
Building the CSC structure...
        It takes 1.896 seconds.
Building the CSC structure...
        It takes 1.925 seconds.
Building the CSC structure...
        It takes 1.925 seconds.
Building the CSC structure...
        It takes 1.814 seconds.
        It takes 1.866 seconds.
        It takes 1.895 seconds.
        It takes 1.892 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.571 seconds.
Building the Label Vector...
        It takes 0.590 seconds.
Building the Label Vector...
        It takes 0.561 seconds.
Building the Label Vector...
        It takes 0.604 seconds.
Building the Label Vector...
        It takes 0.310 seconds.
        It takes 0.323 seconds.
        It takes 0.308 seconds.
        It takes 0.330 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
[Node 2]: distributed graph prepared: start: 1224514, end: 1836771 , send vertices: 171315.
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
[Node 0]: distributed graph prepared: start: 0, end: 612257 , send vertices: 219013.
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
[Node 1]: distributed graph prepared: start: 612257, end: 1224514 , send vertices: 199323.
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_SOFTMAX
    OP_TYPE: OPERATOR_DROPOUT
*** Done allocating resource.
*** Preparing the input tensor...
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
[Node 3]: distributed graph prepared: start: 1836771, end: 2449029 , send vertices: 230898.
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the STD tensor.
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
*** Done preparing the weight tensor.

****** Start model training... ******
*** Done preparing the weight tensor.

****** Start model training... ******
*** Done preparing the weight tensor.

****** Start model training... ******
2449029
2449029
2449029
2449029
    Epoch 9:	Loss 2.60615	TrainAcc 0.3637	ValidAcc 0.3606	TestAcc 0.3038
    Epoch 19:	Loss 1.54191	TrainAcc 0.6126	ValidAcc 0.6076	TestAcc 0.4755
    Epoch 29:	Loss 1.06835	TrainAcc 0.7833	ValidAcc 0.7754	TestAcc 0.6050
    Epoch 39:	Loss 0.83627	TrainAcc 0.8206	ValidAcc 0.8172	TestAcc 0.6449
    Epoch 49:	Loss 0.71038	TrainAcc 0.8416	ValidAcc 0.8370	TestAcc 0.6643
    Epoch 59:	Loss 0.64016	TrainAcc 0.8545	ValidAcc 0.8507	TestAcc 0.6786
    Epoch 69:	Loss 0.59269	TrainAcc 0.8641	ValidAcc 0.8589	TestAcc 0.6858
    Epoch 79:	Loss 0.55904	TrainAcc 0.8703	ValidAcc 0.8631	TestAcc 0.6922
    Epoch 89:	Loss 0.53460	TrainAcc 0.8754	ValidAcc 0.8691	TestAcc 0.6955
    Epoch 99:	Loss 0.51605	TrainAcc 0.8780	ValidAcc 0.8720	TestAcc 0.6992
    Epoch 109:	Loss 0.49826	TrainAcc 0.8814	ValidAcc 0.8733	TestAcc 0.7014
    Epoch 119:	Loss 0.48510	TrainAcc 0.8835	ValidAcc 0.8757	TestAcc 0.7041
    Epoch 129:	Loss 0.47220	TrainAcc 0.8862	ValidAcc 0.8783	TestAcc 0.7073
    Epoch 139:	Loss 0.46166	TrainAcc 0.8882	ValidAcc 0.8797	TestAcc 0.7107
    Epoch 149:	Loss 0.45366	TrainAcc 0.8892	ValidAcc 0.8823	TestAcc 0.7124
    Epoch 159:	Loss 0.44690	TrainAcc 0.8904	ValidAcc 0.8818	TestAcc 0.7145
    Epoch 169:	Loss 0.43905	TrainAcc 0.8922	ValidAcc 0.8839	TestAcc 0.7177
    Epoch 179:	Loss 0.43315	TrainAcc 0.8930	ValidAcc 0.8855	TestAcc 0.7192
    Epoch 189:	Loss 0.42744	TrainAcc 0.8950	ValidAcc 0.8861	TestAcc 0.7212
    Epoch 199:	Loss 0.42221	TrainAcc 0.8956	ValidAcc 0.8872	TestAcc 0.7219
    Epoch 209:	Loss 0.41811	TrainAcc 0.8965	ValidAcc 0.8885	TestAcc 0.7240
    Epoch 219:	Loss 0.41439	TrainAcc 0.8968	ValidAcc 0.8887	TestAcc 0.7259
    Epoch 229:	Loss 0.41033	TrainAcc 0.8974	ValidAcc 0.8899	TestAcc 0.7265
    Epoch 239:	Loss 0.40712	TrainAcc 0.8984	ValidAcc 0.8907	TestAcc 0.7271
    Epoch 249:	Loss 0.40244	TrainAcc 0.8991	ValidAcc 0.8924	TestAcc 0.7310
    Epoch 259:	Loss 0.39984	TrainAcc 0.9001	ValidAcc 0.8923	TestAcc 0.7322
    Epoch 269:	Loss 0.39747	TrainAcc 0.9003	ValidAcc 0.8919	TestAcc 0.7330
    Epoch 279:	Loss 0.39344	TrainAcc 0.9013	ValidAcc 0.8938	TestAcc 0.7333
    Epoch 289:	Loss 0.39044	TrainAcc 0.9020	ValidAcc 0.8937	TestAcc 0.7347
    Epoch 299:	Loss 0.38899	TrainAcc 0.9018	ValidAcc 0.8949	TestAcc 0.7336
    Epoch 309:	Loss 0.38603	TrainAcc 0.9029	ValidAcc 0.8947	TestAcc 0.7356
    Epoch 319:	Loss 0.38369	TrainAcc 0.9035	ValidAcc 0.8953	TestAcc 0.7372
    Epoch 329:	Loss 0.38150	TrainAcc 0.9039	ValidAcc 0.8950	TestAcc 0.7368
    Epoch 339:	Loss 0.37905	TrainAcc 0.9039	ValidAcc 0.8956	TestAcc 0.7372
    Epoch 349:	Loss 0.37698	TrainAcc 0.9057	ValidAcc 0.8960	TestAcc 0.7389
    Epoch 359:	Loss 0.37450	TrainAcc 0.9049	ValidAcc 0.8961	TestAcc 0.7377
    Epoch 369:	Loss 0.37231	TrainAcc 0.9057	ValidAcc 0.8965	TestAcc 0.7391
    Epoch 379:	Loss 0.37170	TrainAcc 0.9059	ValidAcc 0.8966	TestAcc 0.7409
    Epoch 389:	Loss 0.36929	TrainAcc 0.9062	ValidAcc 0.8988	TestAcc 0.7395
    Epoch 399:	Loss 0.36859	TrainAcc 0.9068	ValidAcc 0.8980	TestAcc 0.7388
    Epoch 409:	Loss 0.36615	TrainAcc 0.9072	ValidAcc 0.8987	TestAcc 0.7419
    Epoch 419:	Loss 0.36309	TrainAcc 0.9081	ValidAcc 0.8974	TestAcc 0.7417
    Epoch 429:	Loss 0.36266	TrainAcc 0.9080	ValidAcc 0.8992	TestAcc 0.7413
    Epoch 439:	Loss 0.36187	TrainAcc 0.9083	ValidAcc 0.8987	TestAcc 0.7411
    Epoch 449:	Loss 0.36090	TrainAcc 0.9080	ValidAcc 0.8995	TestAcc 0.7430
    Epoch 459:	Loss 0.35873	TrainAcc 0.9080	ValidAcc 0.8999	TestAcc 0.7426
    Epoch 469:	Loss 0.35687	TrainAcc 0.9088	ValidAcc 0.9009	TestAcc 0.7425
    Epoch 479:	Loss 0.35662	TrainAcc 0.9096	ValidAcc 0.8999	TestAcc 0.7422
    Epoch 489:	Loss 0.35476	TrainAcc 0.9098	ValidAcc 0.9000	TestAcc 0.7431
    Epoch 499:	Loss 0.35295	TrainAcc 0.9100	ValidAcc 0.9012	TestAcc 0.7437
    Epoch 509:	Loss 0.35244	TrainAcc 0.9094	ValidAcc 0.9005	TestAcc 0.7432
    Epoch 519:	Loss 0.34965	TrainAcc 0.9111	ValidAcc 0.9009	TestAcc 0.7439
    Epoch 529:	Loss 0.34998	TrainAcc 0.9107	ValidAcc 0.9010	TestAcc 0.7454
    Epoch 539:	Loss 0.34870	TrainAcc 0.9112	ValidAcc 0.9006	TestAcc 0.7456
    Epoch 549:	Loss 0.34804	TrainAcc 0.9109	ValidAcc 0.9010	TestAcc 0.7458
    Epoch 559:	Loss 0.34662	TrainAcc 0.9115	ValidAcc 0.9023	TestAcc 0.7445
    Epoch 569:	Loss 0.34504	TrainAcc 0.9121	ValidAcc 0.9030	TestAcc 0.7467
    Epoch 579:	Loss 0.34478	TrainAcc 0.9120	ValidAcc 0.9017	TestAcc 0.7441
    Epoch 589:	Loss 0.34355	TrainAcc 0.9119	ValidAcc 0.9019	TestAcc 0.7455
    Epoch 599:	Loss 0.34248	TrainAcc 0.9128	ValidAcc 0.9016	TestAcc 0.7456
    Epoch 609:	Loss 0.34147	TrainAcc 0.9127	ValidAcc 0.9019	TestAcc 0.7449
    Epoch 619:	Loss 0.33929	TrainAcc 0.9128	ValidAcc 0.9023	TestAcc 0.7461
    Epoch 629:	Loss 0.33930	TrainAcc 0.9130	ValidAcc 0.9026	TestAcc 0.7464
    Epoch 639:	Loss 0.33877	TrainAcc 0.9137	ValidAcc 0.9015	TestAcc 0.7463
    Epoch 649:	Loss 0.33815	TrainAcc 0.9133	ValidAcc 0.9032	TestAcc 0.7488
    Epoch 659:	Loss 0.33792	TrainAcc 0.9132	ValidAcc 0.9026	TestAcc 0.7471
    Epoch 669:	Loss 0.33675	TrainAcc 0.9140	ValidAcc 0.9025	TestAcc 0.7473
    Epoch 679:	Loss 0.33495	TrainAcc 0.9136	ValidAcc 0.9042	TestAcc 0.7468
    Epoch 689:	Loss 0.33418	TrainAcc 0.9145	ValidAcc 0.9033	TestAcc 0.7471
    Epoch 699:	Loss 0.33244	TrainAcc 0.9145	ValidAcc 0.9047	TestAcc 0.7466
    Epoch 709:	Loss 0.33238	TrainAcc 0.9146	ValidAcc 0.9055	TestAcc 0.7473
    Epoch 719:	Loss 0.33181	TrainAcc 0.9146	ValidAcc 0.9047	TestAcc 0.7477
    Epoch 729:	Loss 0.33091	TrainAcc 0.9148	ValidAcc 0.9036	TestAcc 0.7486
    Epoch 739:	Loss 0.33078	TrainAcc 0.9149	ValidAcc 0.9034	TestAcc 0.7474
    Epoch 749:	Loss 0.32929	TrainAcc 0.9150	ValidAcc 0.9037	TestAcc 0.7487
    Epoch 759:	Loss 0.32901	TrainAcc 0.9145	ValidAcc 0.9046	TestAcc 0.7480
    Epoch 769:	Loss 0.32805	TrainAcc 0.9158	ValidAcc 0.9052	TestAcc 0.7490
    Epoch 779:	Loss 0.32683	TrainAcc 0.9156	ValidAcc 0.9045	TestAcc 0.7481
    Epoch 789:	Loss 0.32589	TrainAcc 0.9156	ValidAcc 0.9039	TestAcc 0.7478
    Epoch 799:	Loss 0.32548	TrainAcc 0.9164	ValidAcc 0.9055	TestAcc 0.7484
    Epoch 809:	Loss 0.32436	TrainAcc 0.9156	ValidAcc 0.9039	TestAcc 0.7476
    Epoch 819:	Loss 0.32448	TrainAcc 0.9162	ValidAcc 0.9053	TestAcc 0.7472
    Epoch 829:	Loss 0.32354	TrainAcc 0.9167	ValidAcc 0.9048	TestAcc 0.7487
    Epoch 839:	Loss 0.32336	TrainAcc 0.9164	ValidAcc 0.9052	TestAcc 0.7473
    Epoch 849:	Loss 0.32219	TrainAcc 0.9173	ValidAcc 0.9057	TestAcc 0.7487
    Epoch 859:	Loss 0.32133	TrainAcc 0.9172	ValidAcc 0.9058	TestAcc 0.7491
    Epoch 869:	Loss 0.32149	TrainAcc 0.9162	ValidAcc 0.9051	TestAcc 0.7471
    Epoch 879:	Loss 0.31992	TrainAcc 0.9173	ValidAcc 0.9065	TestAcc 0.7458
    Epoch 889:	Loss 0.31958	TrainAcc 0.9177	ValidAcc 0.9055	TestAcc 0.7476
    Epoch 899:	Loss 0.31937	TrainAcc 0.9169	ValidAcc 0.9057	TestAcc 0.7474
    Epoch 909:	Loss 0.31898	TrainAcc 0.9174	ValidAcc 0.9049	TestAcc 0.7468
    Epoch 919:	Loss 0.31791	TrainAcc 0.9181	ValidAcc 0.9075	TestAcc 0.7479
    Epoch 929:	Loss 0.31778	TrainAcc 0.9184	ValidAcc 0.9051	TestAcc 0.7474
    Epoch 939:	Loss 0.31539	TrainAcc 0.9185	ValidAcc 0.9050	TestAcc 0.7472
    Epoch 949:	Loss 0.31630	TrainAcc 0.9177	ValidAcc 0.9068	TestAcc 0.7480
    Epoch 959:	Loss 0.31599	TrainAcc 0.9182	ValidAcc 0.9067	TestAcc 0.7493
    Epoch 969:	Loss 0.31534	TrainAcc 0.9184	ValidAcc 0.9063	TestAcc 0.7473
    Epoch 979:	Loss 0.31419	TrainAcc 0.9181	ValidAcc 0.9060	TestAcc 0.7472
    Epoch 989:	Loss 0.31359	TrainAcc 0.9181	ValidAcc 0.9069	TestAcc 0.7475
    Epoch 999:	Loss 0.31417	TrainAcc 0.9183	ValidAcc 0.9073	TestAcc 0.7487

Average per-epoch runtime: 0.554 (s)

Average per-epoch runtime: 0.554 (s)

Average per-epoch runtime: 0.554 (s)

Average per-epoch runtime: 0.554 (s)
[MPI Rank 3] Success 
[MPI Rank 2] Success 
[MPI Rank 0] Success 
[MPI Rank 1] Success 
