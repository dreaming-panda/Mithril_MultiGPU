amadeus-MS-7B86
Thu May 18 22:03:06 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:29:00.0 Off |                  N/A |
| 42%   42C    P8     9W / 120W |    321MiB /  6144MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1319      G   /usr/lib/xorg/Xorg                101MiB |
|    0   N/A  N/A      2403      G   /usr/lib/xorg/Xorg                166MiB |
|    0   N/A  N/A      2528      G   /usr/bin/gnome-shell               42MiB |
+-----------------------------------------------------------------------------+
[ 11%] Built target context
[ 36%] Built target core
Consolidate compiler generated dependencies of target cudahelp
[ 77%] Built target cudahelp
[ 83%] Built target estimate_comm_volume
[ 88%] Built target OSDI2023_MULTI_NODES_gcn
[ 94%] Built target OSDI2023_MULTI_NODES_gcnii
[100%] Built target OSDI2023_MULTI_NODES_graphsage
Initialized node 0 on machine amadeus-MS-7B86
Initialized node 2 on machine amadeus-MS-7B86
Initialized node 3 on machine amadeus-MS-7B86
Initialized node 1 on machine amadeus-MS-7B86
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.038 seconds.
Building the CSC structure...
        It takes 0.039 seconds.
Building the CSC structure...
        It takes 0.049 seconds.
Building the CSC structure...
        It takes 0.048 seconds.
Building the CSC structure...
        It takes 0.039 seconds.
        It takes 0.036 seconds.
        It takes 0.040 seconds.
        It takes 0.035 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.044 seconds.
Building the Label Vector...
        It takes 0.044 seconds.
Building the Label Vector...
        It takes 0.043 seconds.
Building the Label Vector...
        It takes 0.043 seconds.
Building the Label Vector...
        It takes 0.018 seconds.
        It takes 0.018 seconds.
        It takes 0.018 seconds.
        It takes 0.018 seconds.
The graph dataset locates at /home/amadeus/ssd512/gnn_datasets/reordered/ogbn_arxiv
The number of GCNII layers: 8
The number of hidden units: 16
The number of training epoches: 100
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 5
GCN hyper-parameter alpha: 0.100000
GCN hyper-parameter lambda: 0.500000
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
Number of GPUs: 4
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
*** Node 1, starting model training...
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [34, 65)
*** Node 1, constructing the helper classes...
train nodes 90941, valid nodes 29799, test nodes 48603
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
*** Node 0, starting model training...
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the model-level partition [0, 34)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_DROPOUT, output tensors: 1
    Op 2: type OPERATOR_WEIGHT, output tensors: 2
    Op 3: type OPERATOR_MATMUL, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_AGGREGATION, output tensors: 6
    Op 7: type OPERATOR_ADD, output tensors: 7
    Op 8: type OPERATOR_WEIGHT, output tensors: 8
    Op 9: type OPERATOR_MATMUL, output tensors: 9
    Op 10: type OPERATOR_ADD, output tensors: 10
    Op 11: type OPERATOR_RELU, output tensors: 11
    Op 12: type OPERATOR_DROPOUT, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_ADD, output tensors: 14
    Op 15: type OPERATOR_WEIGHT, output tensors: 15
    Op 16: type OPERATOR_MATMUL, output tensors: 16
    Op 17: type OPERATOR_ADD, output tensors: 17
    Op 18: type OPERATOR_RELU, output tensors: 18
    Op 19: type OPERATOR_DROPOUT, output tensors: 19
    Op 20: type OPERATOR_AGGREGATION, output tensors: 20
    Op 21: type OPERATOR_ADD, output tensors: 21
    Op 22: type OPERATOR_WEIGHT, output tensors: 22
    Op 23: type OPERATOR_MATMUL, output tensors: 23
    Op 24: type OPERATOR_ADD, output tensors: 24
    Op 25: type OPERATOR_RELU, output tensors: 25
    Op 26: type OPERATOR_DROPOUT, output tensors: 26
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
    Op 27: type OPERATOR_AGGREGATION, output tensors: 27
    Op 28: type OPERATOR_ADD, output tensors: 28
    Op 29: type OPERATOR_WEIGHT, output tensors: 29
    Op 30: type OPERATOR_MATMUL, output tensors: 30
    Op 31: type OPERATOR_ADD, output tensors: 31
    Op 32: type OPERATOR_RELU, output tensors: 32
    Op 33: type OPERATOR_DROPOUT, output tensors: 33
    Op 34: type OPERATOR_AGGREGATION, output tensors: 34
    Op 35: type OPERATOR_ADD, output tensors: 35
    Op 36: type OPERATOR_WEIGHT, output tensors: 36
*** Node 2, starting model training...
Node 2, Pipeline Input Tensor: NULL
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the model-level partition [0, 34)
*** Node 2, constructing the helper classes...
    Op 37: type OPERATOR_MATMUL, output tensors: 37
    Op 38: type OPERATOR_ADD, output tensors: 38
    Op 39: type OPERATOR_RELU, output tensors: 39
    Op 40: type OPERATOR_DROPOUT, output tensors: 40
    Op 41: type OPERATOR_AGGREGATION, output tensors: 41
    Op 42: type OPERATOR_ADD, output tensors: 42
    Op 43: type OPERATOR_WEIGHT, output tensors: 43
    Op 44: type OPERATOR_MATMUL, output tensors: 44
    Op 45: type OPERATOR_ADD, output tensors: 45
    Op 46: type OPERATOR_RELU, output tensors: 46
    Op 47: type OPERATOR_DROPOUT, output tensors: 47
    Op 48: type OPERATOR_AGGREGATION, output tensors: 48
    Op 49: type OPERATOR_ADD, output tensors: 49
    Op 50: type OPERATOR_WEIGHT, output tensors: 50
    Op 51: type OPERATOR_MATMUL, output tensors: 51
    Op 52: type OPERATOR_ADD, output tensors: 52
    Op 53: type OPERATOR_RELU, output tensors: 53
    Op 54: type OPERATOR_DROPOUT, output tensors: 54
    Op 55: type OPERATOR_AGGREGATION, output tensors: 55
    Op 56: type OPERATOR_ADD, output tensors: 56
    Op 57: type OPERATOR_WEIGHT, output tensors: 57
    Op 58: type OPERATOR_MATMUL, output tensors: 58
    Op 59: type OPERATOR_ADD, output tensors: 59
    Op 60: type OPERATOR_RELU, output tensors: 60
    Op 61: type OPERATOR_DROPOUT, output tensors: 61
    Op 62: type OPERATOR_WEIGHT, output tensors: 62
    Op 63: type OPERATOR_MATMUL, output tensors: 63
    Op 64: type OPERATOR_SOFTMAX, output tensors: 64
GPU 0, layer [0, 5)
GPU 1, layer [5, 10)
*** Node 3, starting model training...
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [34, 65)
*** Node 3, constructing the helper classes...
169343, 2484941, 2484941
Number of vertices per chunk: 5292
Boundaries: 0 0 0 0 169343 169343 169343 169343
Fragments: [0, 169343)
Chunks (number of global chunks: 32): 0-[0, 5292) 1-[5292, 10584) 2-[10584, 15876) 3-[15876, 21168) 4-[21168, 26460) 5-[26460, 31752) 6-[31752, 37044) 7-[37044, 42336) 8-[42336, 47628) ... 31-[164052, 169343)
169343, 2484941, 2484941
169343, 2484941, 2484941
Number of vertices per chunk: 5292
Number of vertices per chunk: 5292
169343, 2484941, 2484941
Number of vertices per chunk: 5292
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
csr in-out ready !*** Node 3, setting up some other necessary information...
*** Node 1, starting the helper threads...
*** Node 3, starting the helper threads...
*** Node 0, starting the helper threads...
*** Node 2, starting the helper threads...
+++++++++ Node 1 initializing the weights for op[34, 65)...
+++++++++ Node 1, mapping weight op 36
+++++++++ Node 0 initializing the weights for op[0, 34)...
+++++++++ Node 0, mapping weight op 2
+++++++++ Node 2 initializing the weights for op[0, 34)...
+++++++++ Node 2, mapping weight op 2
+++++++++ Node 3 initializing the weights for op[34, 65)...
+++++++++ Node 3, mapping weight op 36
+++++++++ Node 1, mapping weight op 43
+++++++++ Node 0, mapping weight op 8
+++++++++ Node 2, mapping weight op 8
+++++++++ Node 3, mapping weight op 43
+++++++++ Node 1, mapping weight op 50
+++++++++ Node 0, mapping weight op 15
+++++++++ Node 2, mapping weight op 15
+++++++++ Node 3, mapping weight op 50
+++++++++ Node 1, mapping weight op 57
+++++++++ Node 0, mapping weight op 22
+++++++++ Node 2, mapping weight op 22
+++++++++ Node 3, mapping weight op 57
+++++++++ Node 1, mapping weight op 62
+++++++++ Node 0, mapping weight op 29
+++++++++ Node 2, mapping weight op 29
+++++++++ Node 3, mapping weight op 62
Node 2, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
Node 0, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be received across the graph boundary.
Node 3, discovering the vertices that will be received across the graph boundary.
Node 0, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
*** Node 3, starting task scheduling...
*** Node 0, starting task scheduling...
*** Node 1, starting task scheduling...



The learning rate specified by the user: 0.003000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
The learning rate specified by the user: 0.003000000
	Epoch 10:	Loss 3.5246	TrainAcc 0.1791	ValidAcc 0.0763	BestValid 0.0763
	Epoch 20:	Loss 3.3172	TrainAcc 0.1791	ValidAcc 0.0763	BestValid 0.0763
	Epoch 30:	Loss 3.1917	TrainAcc 0.1791	ValidAcc 0.0763	BestValid 0.0763
	Epoch 40:	Loss 3.1134	TrainAcc 0.1791	ValidAcc 0.0763	BestValid 0.0763
	Epoch 50:	Loss 3.0582	TrainAcc 0.1793	ValidAcc 0.0765	BestValid 0.0765
	Epoch 60:	Loss 3.0017	TrainAcc 0.1960	ValidAcc 0.1100	BestValid 0.1100
	Epoch 70:	Loss 2.9456	TrainAcc 0.2173	ValidAcc 0.1588	BestValid 0.1588
	Epoch 80:	Loss 2.8716	TrainAcc 0.2802	ValidAcc 0.2980	BestValid 0.2980
	Epoch 90:	Loss 2.8137	TrainAcc 0.2976	ValidAcc 0.3126	BestValid 0.3126
Node 2, Layer-level comm throughput (grad): 0.181 GBps
Node 2, Layer-level comm throughput (act): -nan GBps
Node 3, Layer-level comm throughput (grad): -nan GBps
Node 1, Layer-level comm throughput (grad): -nan GBps
Node 0, Layer-level comm throughput (act): -nan GBps
Node 0, Layer-level comm throughput (grad): 0.157 GBps
Node 1, Layer-level comm throughput (act): 0.064 GBps
Node 3, Layer-level comm throughput (act): 0.054 GBps
	Epoch 100:	Loss 2.7370	TrainAcc 0.3214	ValidAcc 0.3307	BestValid 0.3307
Node 3, GPU memory consumption: 3.973 GB
Node 3, compression time: 0.793s, compression size: 0.505GB, throughput: 0.636GBps
Node 3, decompression time: 0.262s, compression size: 0.505GB, throughput: 2.500GBps
Node 3, pure compute time: 93.676 s, total compute time: 94.732 s
Node 3, wait_for_task_time: 60.003 s, wait_for_other_gpus_time: 0.009 s
------------------------node id 3,  per-epoch time: 1.806614 s---------------
Node 2, GPU memory consumption: 3.973 GB
Node 2, compression time: 0.474s, compression size: 0.656GB, throughput: 1.384GBps
Node 2, decompression time: 0.410s, compression size: 0.656GB, throughput: 1.230GBps
Node 2, pure compute time: 147.845 s, total compute time: 148.729 s
Node 2, wait_for_task_time: 18.235 s, wait_for_other_gpus_time: 0.010 s
------------------------node id 2,  per-epoch time: 1.806614 s---------------
Node 0, GPU memory consumption: 3.973 GB
Node 0, compression time: 0.498s, compression size: 0.656GB, throughput: 1.317GBps
Node 0, decompression time: 0.400s, compression size: 0.656GB, throughput: 1.260GBps
Node 0, pure compute time: 148.137 s, total compute time: 149.036 s
Node 0, wait_for_task_time: 18.042 s, wait_for_other_gpus_time: 0.011 s
------------------------node id 0,  per-epoch time: 1.806612 s---------------
Node 1, GPU memory consumption: 3.973 GB
Node 1, compression time: 0.824s, compression size: 0.505GB, throughput: 0.613GBps
Node 1, decompression time: 0.258s, compression size: 0.505GB, throughput: 2.539GBps
Node 1, pure compute time: 96.706 s, total compute time: 97.789 s
Node 1, wait_for_task_time: 57.139 s, wait_for_other_gpus_time: 0.014 s
------------------------node id 1,  per-epoch time: 1.806613 s---------------
************ Profiling Results ************
	Bubble: 36.825373 (s) (20.23 percentage)
	Compute: 133.658573 (s) (73.43 percentage)
	GradSync: 0.519401 (s) (0.29 percentage)
	GraphComm: 1.751774 (s) (0.96 percentage)
	Imbalance: 5.773940 (s) (3.17 percentage)
	LayerComm: 3.504956 (s) (1.93 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.034 GB
Highest valid_acc: 0.3307
Target test_acc: 0.3001
Epoch to reach the target acc: 100
Node 0, sent 2459.487 MB data
Node 2, sent 2541.301 MB data
Node 3, sent 2541.301 MB data
Node 1, sent 2459.487 MB data
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 2] Success 
[MPI Rank 3] Success 
