g000.anvil.rcac.purdue.edu
Mon May  8 19:41:36 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   32C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

Consolidate compiler generated dependencies of target context
Consolidate compiler generated dependencies of target core
Consolidate compiler generated dependencies of target cudahelp
[ 11%] Built target context
[ 36%] Built target core
[ 77%] Built target cudahelp
Consolidate compiler generated dependencies of target estimate_comm_volume
Consolidate compiler generated dependencies of target OSDI2023_MULTI_NODES_graphsage
Consolidate compiler generated dependencies of target OSDI2023_MULTI_NODES_gcnii
Consolidate compiler generated dependencies of target OSDI2023_MULTI_NODES_gcn
[ 83%] Built target estimate_comm_volume
[100%] Built target OSDI2023_MULTI_NODES_gcnii
[100%] Built target OSDI2023_MULTI_NODES_gcn
[100%] Built target OSDI2023_MULTI_NODES_graphsage
Initialized node 0 on machine g000.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 0.072 seconds.
Building the CSC structure...
        It takes 0.039 seconds.
Building the Feature Vector...
        It takes 0.118 seconds.
Building the Label Vector...
        It takes 0.066 seconds.
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCNII layers: 8
The number of hidden units: 256
The number of training epoches: 1000
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.000
The checkpointed weight file: /anvil/projects/x-cis220117/saved_weights_pipe
The random seed: 1
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
Number of GPUs: 1
train nodes 90941, valid nodes 29799, test nodes 48603
GPU 0, layer [0, 8)
*** Node 0, starting model training...
Number of operators: 40
0 169343 0 40
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: NULL
*** Node 0 owns the partition [0, 40) x [0, 169343)
WARNING: the current version only applies to linear GNN models!
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_AGGREGATION, output tensors: 6
    Op 7: type OPERATOR_WEIGHT, output tensors: 7
    Op 8: type OPERATOR_MATMUL, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_AGGREGATION, output tensors: 11
    Op 12: type OPERATOR_WEIGHT, output tensors: 12
    Op 13: type OPERATOR_MATMUL, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_AGGREGATION, output tensors: 16
    Op 17: type OPERATOR_WEIGHT, output tensors: 17
    Op 18: type OPERATOR_MATMUL, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_AGGREGATION, output tensors: 21
    Op 22: type OPERATOR_WEIGHT, output tensors: 22
    Op 23: type OPERATOR_MATMUL, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_AGGREGATION, output tensors: 26
    Op 27: type OPERATOR_WEIGHT, output tensors: 27
    Op 28: type OPERATOR_MATMUL, output tensors: 28
    Op 29: type OPERATOR_RELU, output tensors: 29
    Op 30: type OPERATOR_DROPOUT, output tensors: 30
    Op 31: type OPERATOR_AGGREGATION, output tensors: 31
    Op 32: type OPERATOR_WEIGHT, output tensors: 32
    Op 33: type OPERATOR_MATMUL, output tensors: 33
    Op 34: type OPERATOR_RELU, output tensors: 34
    Op 35: type OPERATOR_DROPOUT, output tensors: 35
    Op 36: type OPERATOR_AGGREGATION, output tensors: 36
    Op 37: type OPERATOR_WEIGHT, output tensors: 37
    Op 38: type OPERATOR_MATMUL, output tensors: 38
    Op 39: type OPERATOR_SOFTMAX, output tensors: 39
Boundaries: 0 169343
Fragments: [0, 169343)
Chunks (number of global chunks: 16): 0-[0, 10584) 1-[10584, 21168) 2-[21168, 31752) 3-[31752, 42336) 4-[42336, 52920) 5-[52920, 63504) 6-[63504, 74088) 7-[74088, 84672) 8-[84672, 95256) ... 15-[158760, 169343)
169343, 2484941, 2484941
Number of vertices per chunk: 10584
csr in-out ready !*** Node 0, setting up some other necessary information...
*** Node 0, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 40)...
+++++++++ Node 0, mapping weight op 22
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 27
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 32
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 37
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 17
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 1
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 7
using the Pytorch initialization method.
+++++++++ Node 0, mapping weight op 12
using the Pytorch initialization method.
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.001000000
	Epoch 10:	Loss 3.37878	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
	Epoch 20:	Loss 3.14664	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
	Epoch 30:	Loss 2.99095	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
	Epoch 40:	Loss 2.83145	TrainAcc 0.2735	ValidAcc 0.2970	TestAcc 0.2675
	Epoch 50:	Loss 2.71742	TrainAcc 0.2317	ValidAcc 0.1173	TestAcc 0.0896
	Epoch 60:	Loss 2.47002	TrainAcc 0.3478	ValidAcc 0.3455	TestAcc 0.3044
	Epoch 70:	Loss 2.25682	TrainAcc 0.4156	ValidAcc 0.4326	TestAcc 0.4001
	Epoch 80:	Loss 2.10092	TrainAcc 0.4589	ValidAcc 0.4711	TestAcc 0.4476
	Epoch 90:	Loss 1.93242	TrainAcc 0.4917	ValidAcc 0.5267	TestAcc 0.5128
	Epoch 100:	Loss 1.80175	TrainAcc 0.5082	ValidAcc 0.5396	TestAcc 0.5295
	Epoch 110:	Loss 1.72750	TrainAcc 0.5372	ValidAcc 0.5611	TestAcc 0.5532
	Epoch 120:	Loss 1.65102	TrainAcc 0.5458	ValidAcc 0.5558	TestAcc 0.5357
	Epoch 130:	Loss 1.60998	TrainAcc 0.5623	ValidAcc 0.5835	TestAcc 0.5819
	Epoch 140:	Loss 1.56372	TrainAcc 0.5607	ValidAcc 0.5763	TestAcc 0.5636
	Epoch 150:	Loss 1.55217	TrainAcc 0.5724	ValidAcc 0.5879	TestAcc 0.5754
	Epoch 160:	Loss 1.51669	TrainAcc 0.5788	ValidAcc 0.5946	TestAcc 0.5925
	Epoch 170:	Loss 1.49957	TrainAcc 0.5927	ValidAcc 0.6042	TestAcc 0.5997
	Epoch 180:	Loss 1.46496	TrainAcc 0.5999	ValidAcc 0.6030	TestAcc 0.5879
	Epoch 190:	Loss 1.43740	TrainAcc 0.6075	ValidAcc 0.6121	TestAcc 0.5987
	Epoch 200:	Loss 1.40426	TrainAcc 0.6147	ValidAcc 0.6167	TestAcc 0.6155
	Epoch 210:	Loss 1.39043	TrainAcc 0.6226	ValidAcc 0.6250	TestAcc 0.6192
	Epoch 220:	Loss 1.35408	TrainAcc 0.6295	ValidAcc 0.6337	TestAcc 0.6285
	Epoch 230:	Loss 1.33512	TrainAcc 0.6360	ValidAcc 0.6369	TestAcc 0.6284
	Epoch 240:	Loss 1.30583	TrainAcc 0.6416	ValidAcc 0.6388	TestAcc 0.6275
	Epoch 250:	Loss 1.29915	TrainAcc 0.6432	ValidAcc 0.6428	TestAcc 0.6387
	Epoch 260:	Loss 1.27964	TrainAcc 0.6505	ValidAcc 0.6458	TestAcc 0.6319
	Epoch 270:	Loss 1.26045	TrainAcc 0.6538	ValidAcc 0.6469	TestAcc 0.6253
	Epoch 280:	Loss 1.24396	TrainAcc 0.6566	ValidAcc 0.6467	TestAcc 0.6292
	Epoch 290:	Loss 1.23793	TrainAcc 0.6541	ValidAcc 0.6409	TestAcc 0.6189
	Epoch 300:	Loss 1.22958	TrainAcc 0.6583	ValidAcc 0.6528	TestAcc 0.6454
	Epoch 310:	Loss 1.21865	TrainAcc 0.6623	ValidAcc 0.6543	TestAcc 0.6407
	Epoch 320:	Loss 1.20378	TrainAcc 0.6664	ValidAcc 0.6577	TestAcc 0.6436
	Epoch 330:	Loss 1.19506	TrainAcc 0.6686	ValidAcc 0.6604	TestAcc 0.6460
	Epoch 340:	Loss 1.18656	TrainAcc 0.6674	ValidAcc 0.6636	TestAcc 0.6555
	Epoch 350:	Loss 1.17990	TrainAcc 0.6628	ValidAcc 0.6459	TestAcc 0.6271
	Epoch 360:	Loss 1.17165	TrainAcc 0.6728	ValidAcc 0.6604	TestAcc 0.6451
	Epoch 370:	Loss 1.17237	TrainAcc 0.6728	ValidAcc 0.6582	TestAcc 0.6363
	Epoch 380:	Loss 1.16332	TrainAcc 0.6765	ValidAcc 0.6708	TestAcc 0.6646
	Epoch 390:	Loss 1.16083	TrainAcc 0.6775	ValidAcc 0.6702	TestAcc 0.6587
	Epoch 400:	Loss 1.15524	TrainAcc 0.6684	ValidAcc 0.6510	TestAcc 0.6355
	Epoch 410:	Loss 1.15079	TrainAcc 0.6775	ValidAcc 0.6693	TestAcc 0.6656
	Epoch 420:	Loss 1.14403	TrainAcc 0.6804	ValidAcc 0.6673	TestAcc 0.6505
	Epoch 430:	Loss 1.13637	TrainAcc 0.6761	ValidAcc 0.6666	TestAcc 0.6502
	Epoch 440:	Loss 1.13158	TrainAcc 0.6796	ValidAcc 0.6603	TestAcc 0.6391
	Epoch 450:	Loss 1.12425	TrainAcc 0.6815	ValidAcc 0.6667	TestAcc 0.6528
	Epoch 460:	Loss 1.12078	TrainAcc 0.6836	ValidAcc 0.6739	TestAcc 0.6680
	Epoch 470:	Loss 1.11771	TrainAcc 0.6845	ValidAcc 0.6747	TestAcc 0.6632
	Epoch 480:	Loss 1.11496	TrainAcc 0.6778	ValidAcc 0.6662	TestAcc 0.6599
	Epoch 490:	Loss 1.13037	TrainAcc 0.6859	ValidAcc 0.6720	TestAcc 0.6581
	Epoch 500:	Loss 1.10889	TrainAcc 0.6736	ValidAcc 0.6466	TestAcc 0.6218
	Epoch 510:	Loss 1.10866	TrainAcc 0.6835	ValidAcc 0.6708	TestAcc 0.6666
	Epoch 520:	Loss 1.10286	TrainAcc 0.6888	ValidAcc 0.6770	TestAcc 0.6665
	Epoch 530:	Loss 1.09546	TrainAcc 0.6893	ValidAcc 0.6714	TestAcc 0.6539
	Epoch 540:	Loss 1.09227	TrainAcc 0.6911	ValidAcc 0.6659	TestAcc 0.6479
	Epoch 550:	Loss 1.09725	TrainAcc 0.6914	ValidAcc 0.6794	TestAcc 0.6740
	Epoch 560:	Loss 1.08878	TrainAcc 0.6923	ValidAcc 0.6744	TestAcc 0.6610
	Epoch 570:	Loss 1.08865	TrainAcc 0.6956	ValidAcc 0.6837	TestAcc 0.6745
	Epoch 580:	Loss 1.08011	TrainAcc 0.6968	ValidAcc 0.6826	TestAcc 0.6732
	Epoch 590:	Loss 1.07874	TrainAcc 0.6972	ValidAcc 0.6853	TestAcc 0.6769
	Epoch 600:	Loss 1.07750	TrainAcc 0.6980	ValidAcc 0.6840	TestAcc 0.6721
	Epoch 610:	Loss 1.07135	TrainAcc 0.6973	ValidAcc 0.6780	TestAcc 0.6629
	Epoch 620:	Loss 1.06811	TrainAcc 0.6978	ValidAcc 0.6832	TestAcc 0.6710
	Epoch 630:	Loss 1.06550	TrainAcc 0.6978	ValidAcc 0.6817	TestAcc 0.6695
	Epoch 640:	Loss 1.06233	TrainAcc 0.6980	ValidAcc 0.6841	TestAcc 0.6727
	Epoch 650:	Loss 1.06124	TrainAcc 0.7007	ValidAcc 0.6870	TestAcc 0.6814
	Epoch 660:	Loss 1.05647	TrainAcc 0.6937	ValidAcc 0.6658	TestAcc 0.6462
	Epoch 670:	Loss 1.07774	TrainAcc 0.7017	ValidAcc 0.6855	TestAcc 0.6752
	Epoch 680:	Loss 1.05403	TrainAcc 0.6920	ValidAcc 0.6600	TestAcc 0.6340
	Epoch 690:	Loss 1.05717	TrainAcc 0.6965	ValidAcc 0.6798	TestAcc 0.6753
	Epoch 700:	Loss 1.04885	TrainAcc 0.6903	ValidAcc 0.6668	TestAcc 0.6668
	Epoch 710:	Loss 1.06092	TrainAcc 0.7027	ValidAcc 0.6837	TestAcc 0.6803
	Epoch 720:	Loss 1.05163	TrainAcc 0.7035	ValidAcc 0.6791	TestAcc 0.6627
	Epoch 730:	Loss 1.04147	TrainAcc 0.7039	ValidAcc 0.6869	TestAcc 0.6770
	Epoch 740:	Loss 1.03934	TrainAcc 0.7050	ValidAcc 0.6893	TestAcc 0.6810
	Epoch 750:	Loss 1.03552	TrainAcc 0.7060	ValidAcc 0.6878	TestAcc 0.6765
	Epoch 760:	Loss 1.03341	TrainAcc 0.7058	ValidAcc 0.6894	TestAcc 0.6830
	Epoch 770:	Loss 1.03083	TrainAcc 0.7076	ValidAcc 0.6892	TestAcc 0.6775
	Epoch 780:	Loss 1.02866	TrainAcc 0.7077	ValidAcc 0.6901	TestAcc 0.6806
	Epoch 790:	Loss 1.02639	TrainAcc 0.7048	ValidAcc 0.6855	TestAcc 0.6766
	Epoch 800:	Loss 1.02530	TrainAcc 0.7078	ValidAcc 0.6856	TestAcc 0.6688
	Epoch 810:	Loss 1.02346	TrainAcc 0.7084	ValidAcc 0.6924	TestAcc 0.6855
	Epoch 820:	Loss 1.02042	TrainAcc 0.7083	ValidAcc 0.6883	TestAcc 0.6763
	Epoch 830:	Loss 1.01952	TrainAcc 0.7085	ValidAcc 0.6908	TestAcc 0.6823
	Epoch 840:	Loss 1.01635	TrainAcc 0.7109	ValidAcc 0.6894	TestAcc 0.6735
	Epoch 850:	Loss 1.01591	TrainAcc 0.7096	ValidAcc 0.6901	TestAcc 0.6773
	Epoch 860:	Loss 1.01368	TrainAcc 0.7106	ValidAcc 0.6907	TestAcc 0.6759
	Epoch 870:	Loss 1.01299	TrainAcc 0.7126	ValidAcc 0.6933	TestAcc 0.6807
	Epoch 880:	Loss 1.01123	TrainAcc 0.7116	ValidAcc 0.6873	TestAcc 0.6712
	Epoch 890:	Loss 1.00882	TrainAcc 0.7136	ValidAcc 0.6927	TestAcc 0.6789
	Epoch 900:	Loss 1.00547	TrainAcc 0.7116	ValidAcc 0.6829	TestAcc 0.6633
	Epoch 910:	Loss 1.00888	TrainAcc 0.7074	ValidAcc 0.6799	TestAcc 0.6599
	Epoch 920:	Loss 1.00335	TrainAcc 0.7102	ValidAcc 0.6874	TestAcc 0.6770
	Epoch 930:	Loss 1.00269	TrainAcc 0.7114	ValidAcc 0.6904	TestAcc 0.6759
	Epoch 940:	Loss 1.00315	TrainAcc 0.7136	ValidAcc 0.6961	TestAcc 0.6865
	Epoch 950:	Loss 1.00154	TrainAcc 0.7097	ValidAcc 0.6860	TestAcc 0.6687
	Epoch 960:	Loss 1.00023	TrainAcc 0.7125	ValidAcc 0.6909	TestAcc 0.6747
	Epoch 970:	Loss 0.99795	TrainAcc 0.7135	ValidAcc 0.6917	TestAcc 0.6791
	Epoch 980:	Loss 0.99558	TrainAcc 0.7123	ValidAcc 0.6911	TestAcc 0.6760
	Epoch 990:	Loss 0.99266	TrainAcc 0.7153	ValidAcc 0.6948	TestAcc 0.6826
Node 0, Layer-level comm throughput (act): -nan GBps
Node 0, Layer-level comm throughput (grad): -nan GBps
	Epoch 1000:	Loss 0.99218	TrainAcc 0.7156	ValidAcc 0.6907	TestAcc 0.6720
Node 0, GPU memory consumption: 9.257 GB
Node 0, compression time: 0.000s, compression size: 0.000GB, throughput: -nanGBps
Node 0, decompression time: 0.000s, compression size: 0.000GB, throughput: -nanGBps
Node 0, pure compute time: 146.723 s, total compute time: 146.723 s
Node 0, wait_for_task_time: 0.004 s, wait_for_other_gpus_time: 0.000 s
------------------------node id 0,  per-epoch time: 0.162019 s---------------
************ Profiling Results ************
	Bubble: 1.184453 (s) (0.73 percentage)
	Compute: 160.187205 (s) (98.86 percentage)
	GradSync: 0.630299 (s) (0.39 percentage)
	GraphComm: 0.026074 (s) (0.02 percentage)
	Imbalance: 0.001175 (s) (0.00 percentage)
	LayerComm: 0.000000 (s) (0.00 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.000 GB
Highest valid_acc: 0.6961
Target test_acc: 0.6865
Epoch to reach the target acc: 940
[MPI Rank 0] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCN layers: 8
The number of hidden units: 256
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g000.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 0.070 seconds.
Building the CSC structure...
        It takes 0.038 seconds.
Building the Feature Vector...
        It takes 0.149 seconds.
Building the Label Vector...
        It takes 0.056 seconds.
Number of classes: 40
Number of feature dimensions: 128
Dropout: 0.000 
train nodes 90941, valid nodes 29799, test nodes 48603
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 40
    Number of vertices: 169343
*** Done preparing the STD tensor.
Version 0	Loss 3.2097	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 1	Loss 3.1528	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 2	Loss 2.9503	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 3	Loss 2.8850	TrainAcc 0.2738	ValidAcc 0.2974	TestAcc 0.2680
Version 4	Loss 2.7755	TrainAcc 0.2262	ValidAcc 0.1036	TestAcc 0.0769
Version 5	Loss 2.4336	TrainAcc 0.3470	ValidAcc 0.3443	TestAcc 0.3054
Version 6	Loss 2.2629	TrainAcc 0.4116	ValidAcc 0.4282	TestAcc 0.3950
Version 7	Loss 2.0404	TrainAcc 0.4565	ValidAcc 0.4612	TestAcc 0.4366
Version 8	Loss 1.8841	TrainAcc 0.4911	ValidAcc 0.5237	TestAcc 0.5087
Version 9	Loss 1.8115	TrainAcc 0.5071	ValidAcc 0.5365	TestAcc 0.5266
Version 10	Loss 1.7013	TrainAcc 0.5375	ValidAcc 0.5616	TestAcc 0.5548
Version 11	Loss 1.6591	TrainAcc 0.5454	ValidAcc 0.5542	TestAcc 0.5338
Version 12	Loss 1.6099	TrainAcc 0.5616	ValidAcc 0.5834	TestAcc 0.5822
Version 13	Loss 1.5969	TrainAcc 0.5589	ValidAcc 0.5718	TestAcc 0.5570
Version 14	Loss 1.5624	TrainAcc 0.5720	ValidAcc 0.5872	TestAcc 0.5743
Version 15	Loss 1.5545	TrainAcc 0.5756	ValidAcc 0.5901	TestAcc 0.5890
Version 16	Loss 1.4911	TrainAcc 0.5927	ValidAcc 0.6044	TestAcc 0.6001
Version 17	Loss 1.4700	TrainAcc 0.5992	ValidAcc 0.6017	TestAcc 0.5855
Version 18	Loss 1.4372	TrainAcc 0.6075	ValidAcc 0.6116	TestAcc 0.5987
Version 19	Loss 1.4140	TrainAcc 0.6131	ValidAcc 0.6140	TestAcc 0.6127
Version 20	Loss 1.3767	TrainAcc 0.6226	ValidAcc 0.6252	TestAcc 0.6183
Version 21	Loss 1.3511	TrainAcc 0.6296	ValidAcc 0.6331	TestAcc 0.6285
Version 22	Loss 1.3296	TrainAcc 0.6359	ValidAcc 0.6355	TestAcc 0.6266
Version 23	Loss 1.3161	TrainAcc 0.6408	ValidAcc 0.6378	TestAcc 0.6254
Version 24	Loss 1.3010	TrainAcc 0.6429	ValidAcc 0.6427	TestAcc 0.6389
Version 25	Loss 1.2758	TrainAcc 0.6505	ValidAcc 0.6437	TestAcc 0.6287
Version 26	Loss 1.2599	TrainAcc 0.6536	ValidAcc 0.6475	TestAcc 0.6254
Version 27	Loss 1.2478	TrainAcc 0.6563	ValidAcc 0.6458	TestAcc 0.6280
Version 28	Loss 1.2609	TrainAcc 0.6530	ValidAcc 0.6374	TestAcc 0.6133
Version 29	Loss 1.2355	TrainAcc 0.6569	ValidAcc 0.6496	TestAcc 0.6404
Version 30	Loss 1.2279	TrainAcc 0.6615	ValidAcc 0.6519	TestAcc 0.6365
Version 31	Loss 1.2062	TrainAcc 0.6662	ValidAcc 0.6581	TestAcc 0.6436
Version 32	Loss 1.1968	TrainAcc 0.6684	ValidAcc 0.6599	TestAcc 0.6446
Version 33	Loss 1.1962	TrainAcc 0.6665	ValidAcc 0.6615	TestAcc 0.6536
Version 34	Loss 1.2294	TrainAcc 0.6601	ValidAcc 0.6388	TestAcc 0.6171
Version 35	Loss 1.1790	TrainAcc 0.6725	ValidAcc 0.6603	TestAcc 0.6443
Version 36	Loss 1.1738	TrainAcc 0.6724	ValidAcc 0.6579	TestAcc 0.6357
Version 37	Loss 1.1609	TrainAcc 0.6765	ValidAcc 0.6713	TestAcc 0.6676
Version 38	Loss 1.1591	TrainAcc 0.6775	ValidAcc 0.6711	TestAcc 0.6623
Version 39	Loss 1.1945	TrainAcc 0.6650	ValidAcc 0.6416	TestAcc 0.6247
Version 40	Loss 1.1589	TrainAcc 0.6770	ValidAcc 0.6681	TestAcc 0.6645
Version 41	Loss 1.1423	TrainAcc 0.6803	ValidAcc 0.6678	TestAcc 0.6510
Version 42	Loss 1.1668	TrainAcc 0.6755	ValidAcc 0.6647	TestAcc 0.6481
Version 43	Loss 1.1576	TrainAcc 0.6774	ValidAcc 0.6526	TestAcc 0.6284
Version 44	Loss 1.1507	TrainAcc 0.6806	ValidAcc 0.6635	TestAcc 0.6473
Version 45	Loss 1.1266	TrainAcc 0.6830	ValidAcc 0.6717	TestAcc 0.6646
Version 46	Loss 1.1301	TrainAcc 0.6841	ValidAcc 0.6738	TestAcc 0.6624
Version 47	Loss 1.1536	TrainAcc 0.6745	ValidAcc 0.6584	TestAcc 0.6522
Version 48	Loss 1.1233	TrainAcc 0.6849	ValidAcc 0.6711	TestAcc 0.6584
Version 49	Loss 1.1928	TrainAcc 0.6694	ValidAcc 0.6367	TestAcc 0.6058
Version 50	Loss 1.1323	TrainAcc 0.6816	ValidAcc 0.6669	TestAcc 0.6636
Version 51	Loss 1.1206	TrainAcc 0.6876	ValidAcc 0.6739	TestAcc 0.6612
Version 52	Loss 1.1150	TrainAcc 0.6887	ValidAcc 0.6688	TestAcc 0.6505
Version 53	Loss 1.1157	TrainAcc 0.6901	ValidAcc 0.6641	TestAcc 0.6442
Version 54	Loss 1.1030	TrainAcc 0.6911	ValidAcc 0.6787	TestAcc 0.6732
Version 55	Loss 1.1021	TrainAcc 0.6920	ValidAcc 0.6722	TestAcc 0.6569
Version 56	Loss 1.0840	TrainAcc 0.6958	ValidAcc 0.6841	TestAcc 0.6742
Version 57	Loss 1.0823	TrainAcc 0.6968	ValidAcc 0.6830	TestAcc 0.6735
Version 58	Loss 1.0776	TrainAcc 0.6971	ValidAcc 0.6856	TestAcc 0.6765
Version 59	Loss 1.0762	TrainAcc 0.6977	ValidAcc 0.6841	TestAcc 0.6741
Version 60	Loss 1.0845	TrainAcc 0.6967	ValidAcc 0.6746	TestAcc 0.6606
Version 61	Loss 1.0716	TrainAcc 0.6976	ValidAcc 0.6827	TestAcc 0.6695
Version 62	Loss 1.0798	TrainAcc 0.6975	ValidAcc 0.6805	TestAcc 0.6683
Version 63	Loss 1.0688	TrainAcc 0.6975	ValidAcc 0.6821	TestAcc 0.6707
Version 64	Loss 1.0655	TrainAcc 0.7002	ValidAcc 0.6857	TestAcc 0.6810
Version 65	Loss 1.1027	TrainAcc 0.6919	ValidAcc 0.6620	TestAcc 0.6391
Version 66	Loss 1.0583	TrainAcc 0.7018	ValidAcc 0.6865	TestAcc 0.6733
Version 67	Loss 1.1126	TrainAcc 0.6903	ValidAcc 0.6543	TestAcc 0.6256
Version 68	Loss 1.0888	TrainAcc 0.6933	ValidAcc 0.6714	TestAcc 0.6691
Version 69	Loss 1.1102	TrainAcc 0.6863	ValidAcc 0.6565	TestAcc 0.6586
Version 70	Loss 1.0501	TrainAcc 0.7035	ValidAcc 0.6851	TestAcc 0.6809
Version 71	Loss 1.0544	TrainAcc 0.7031	ValidAcc 0.6756	TestAcc 0.6578
Version 72	Loss 1.0544	TrainAcc 0.7035	ValidAcc 0.6860	TestAcc 0.6767
Version 73	Loss 1.0418	TrainAcc 0.7048	ValidAcc 0.6895	TestAcc 0.6793
Version 74	Loss 1.0473	TrainAcc 0.7058	ValidAcc 0.6879	TestAcc 0.6758
Version 75	Loss 1.0391	TrainAcc 0.7053	ValidAcc 0.6893	TestAcc 0.6828
Version 76	Loss 1.0398	TrainAcc 0.7075	ValidAcc 0.6885	TestAcc 0.6769
Version 77	Loss 1.0333	TrainAcc 0.7072	ValidAcc 0.6895	TestAcc 0.6796
Version 78	Loss 1.0503	TrainAcc 0.7045	ValidAcc 0.6843	TestAcc 0.6746
Version 79	Loss 1.0362	TrainAcc 0.7073	ValidAcc 0.6842	TestAcc 0.6652
Version 80	Loss 1.0335	TrainAcc 0.7083	ValidAcc 0.6925	TestAcc 0.6853
Version 81	Loss 1.0292	TrainAcc 0.7081	ValidAcc 0.6871	TestAcc 0.6744
Version 82	Loss 1.0262	TrainAcc 0.7081	ValidAcc 0.6902	TestAcc 0.6815
Version 83	Loss 1.0279	TrainAcc 0.7103	ValidAcc 0.6858	TestAcc 0.6695
Version 84	Loss 1.0287	TrainAcc 0.7091	ValidAcc 0.6890	TestAcc 0.6766
Version 85	Loss 1.0212	TrainAcc 0.7102	ValidAcc 0.6889	TestAcc 0.6739
Version 86	Loss 1.0156	TrainAcc 0.7124	ValidAcc 0.6933	TestAcc 0.6796
Version 87	Loss 1.0179	TrainAcc 0.7112	ValidAcc 0.6849	TestAcc 0.6669
Version 88	Loss 1.0123	TrainAcc 0.7134	ValidAcc 0.6914	TestAcc 0.6793
Version 89	Loss 1.0210	TrainAcc 0.7112	ValidAcc 0.6798	TestAcc 0.6592
Version 90	Loss 1.0332	TrainAcc 0.7060	ValidAcc 0.6761	TestAcc 0.6532
Version 91	Loss 1.0228	TrainAcc 0.7094	ValidAcc 0.6862	TestAcc 0.6751
Version 92	Loss 1.0185	TrainAcc 0.7108	ValidAcc 0.6891	TestAcc 0.6751
Version 93	Loss 1.0078	TrainAcc 0.7134	ValidAcc 0.6955	TestAcc 0.6851
Version 94	Loss 1.0209	TrainAcc 0.7093	ValidAcc 0.6848	TestAcc 0.6658
Version 95	Loss 1.0080	TrainAcc 0.7118	ValidAcc 0.6902	TestAcc 0.6734
Version 96	Loss 1.0107	TrainAcc 0.7132	ValidAcc 0.6906	TestAcc 0.6779
Version 97	Loss 1.0073	TrainAcc 0.7115	ValidAcc 0.6880	TestAcc 0.6714
Version 98	Loss 0.9967	TrainAcc 0.7151	ValidAcc 0.6941	TestAcc 0.6817
Version 99	Loss 0.9987	TrainAcc 0.7150	ValidAcc 0.6893	TestAcc 0.6699
Version 93 achieved the highest validation accuracy 0.6955 (test accuracy: 0.6851)
