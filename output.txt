g002.anvil.rcac.purdue.edu
Sun Apr  2 22:56:27 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                    0 |
| N/A   53C    P0    64W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  2%] Building CXX object CMakeFiles/core.dir/core/src/application.cc.o
[  2%] Building CXX object CMakeFiles/core.dir/core/src/dataflow.cc.o
[  7%] Built target context
[  7%] Building CXX object CMakeFiles/parallel.dir/core/src/parallel/graph_parallel.cc.o
[ 10%] Building CXX object CMakeFiles/core.dir/core/src/engine.cc.o
[ 10%] Building CXX object CMakeFiles/core.dir/core/src/executor.cc.o
[ 10%] Building CXX object CMakeFiles/parallel.dir/core/src/parallel/hybrid_parallel.cc.o
[ 11%] Building CXX object CMakeFiles/core.dir/core/src/partitioner.cc.o
[ 12%] Building CXX object CMakeFiles/parallel.dir/core/src/parallel/pipelined_model_parallel.cc.o
[ 14%] Building CXX object CMakeFiles/parallel.dir/core/src/parallel/model_parallel.cc.o
[ 14%] Building CXX object CMakeFiles/parallel.dir/core/src/parallel/mixed_parallel.cc.o
[ 15%] Building CUDA object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_data_compressor.cu.o
[ 16%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_executor.cc.o
[ 17%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_hybrid_parallel.cc.o
[ 18%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_loss.cc.o
[ 19%] Building CUDA object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_hybrid_parallel.cu.o
[ 20%] Building CUDA object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_loss.cu.o
[ 21%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_model_parallel.cc.o
[ 22%] Building CUDA object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_model_parallel.cu.o
[ 23%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_optimizer.cc.o
[ 27%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_resource.cc.o
[ 27%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_single_cpu_engine.cc.o
[ 28%] Building CUDA object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_pipeline_parallel.cu.o
[ 28%] Building CUDA object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_optimizer.cu.o
[ 30%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_pipeline_parallel.cc.o
[ 30%] Building CUDA object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_single_cpu_engine.cu.o
[ 31%] Linking CXX shared library libcore.so
[ 34%] Built target core
[ 35%] Linking CXX static library libparallel.a
[ 35%] Built target parallel
[ 36%] Linking CXX static library libcudahelp.a
[ 39%] Built target cudahelp
[ 48%] Linking CXX executable test_full_structual_graph
[ 52%] Linking CXX executable test_trivial
[ 52%] Linking CXX executable test_cuda_graph
[ 52%] Linking CXX executable test_cuda_data_compression
[ 52%] Linking CXX executable test_nccl_thread
[ 52%] Linking CXX executable test_mpi_structual_graph
[ 52%] Linking CXX executable test_mpi_loader
[ 52%] Linking CXX executable test_nccl_mpi
[ 52%] Linking CXX executable test_full_non_structual_graph
[ 52%] Linking CXX executable test_cuda
[ 52%] Linking CXX executable estimate_comm_volume
[ 58%] Building CXX object tests/CMakeFiles/test_mpi_model_parallel.dir/test_mpi_model_parallel.cc.o
[ 58%] Linking CXX executable test_mpi_combined
[ 58%] Linking CXX executable test_mpi_non_structual_graph
[ 58%] Linking CXX executable test_graph
[ 58%] Building CXX object tests/CMakeFiles/test_single_node_fullgpu_training.dir/test_single_node_fullgpu_training.cc.o
[ 59%] Linking CXX executable test_hello_world
[ 60%] Building CXX object tests/CMakeFiles/test_single_node_gpu_training.dir/test_single_node_gpu_training.cc.o
[ 59%] Building CXX object tests/CMakeFiles/test_single_node_training.dir/test_single_node_training.cc.o
[ 63%] Building CXX object tests/CMakeFiles/test_mpi_gpu_hybrid.dir/test_mpi_gpu_hybrid.cc.o
[ 62%] Building CXX object tests/CMakeFiles/test_mpi_pipelined_model_parallel.dir/test_mpi_pipelined_model_parallel.cc.o
[ 63%] Building CXX object tests/CMakeFiles/test_mpi_gpu_pipelined_model_parallel.dir/test_mpi_gpu_pipelined_model_parallel.cc.o
[ 64%] Building CXX object tests/CMakeFiles/test_cuda_pipeline_parallel.dir/test_cuda_pipeline_parallel.cc.o
[ 64%] Building CXX object tests/CMakeFiles/test_mpi_gpu_model_parallel.dir/test_mpi_gpu_model_parallel.cc.o
[ 65%] Building CXX object tests/CMakeFiles/test_cuda_model_parallel.dir/test_cuda_model_parallel.cc.o
[ 68%] Building CXX object applications/single_gpu/CMakeFiles/OSDI2023_SINGLE_NODE_gcn_inference.dir/gcn_inference.cc.o
[ 68%] Building CXX object tests/CMakeFiles/test_two_layer_hybrid_parallelism_designer.dir/test_two_layer_hybrid_parallelism_designer.cc.o
[ 68%] Building CXX object applications/single_gpu/CMakeFiles/OSDI2023_SINGLE_NODE_gcn.dir/gcn.cc.o
[ 69%] Building CXX object applications/async_multi_gpus/CMakeFiles/OSDI2023_MULTI_NODES_gcn.dir/gcn.cc.o
[ 71%] Built target test_trivial
[ 71%] Built target test_mpi_loader
[ 72%] Built target test_cuda_graph
[ 73%] Built target test_mpi_non_structual_graph
[ 75%] Built target test_mpi_combined
[ 78%] Built target test_full_non_structual_graph
[ 78%] Built target test_graph
[ 78%] Built target test_full_structual_graph
[ 79%] Built target test_mpi_structual_graph
[ 80%] Built target test_cuda_data_compression
[ 81%] Built target test_hello_world
[ 82%] Built target estimate_comm_volume
[ 83%] Built target test_cuda
[ 84%] Built target test_nccl_mpi
[ 85%] Built target test_nccl_thread
[ 86%] Linking CXX executable test_single_node_training
[ 87%] Linking CXX executable test_mpi_model_parallel
[ 88%] Linking CXX executable test_single_node_gpu_training
[ 89%] Linking CXX executable test_mpi_gpu_model_parallel
[ 90%] Linking CXX executable test_mpi_pipelined_model_parallel
[ 91%] Linking CXX executable test_mpi_gpu_pipelined_model_parallel
[ 91%] Built target test_single_node_training
[ 91%] Built target test_mpi_model_parallel
[ 92%] Linking CXX executable test_single_node_fullgpu_training
[ 93%] Linking CXX executable test_cuda_model_parallel
[ 93%] Built target test_mpi_pipelined_model_parallel
[ 93%] Built target test_single_node_gpu_training
[ 93%] Built target test_mpi_gpu_pipelined_model_parallel
[ 94%] Linking CXX executable test_mpi_gpu_hybrid
[ 94%] Built target test_mpi_gpu_model_parallel
[ 94%] Built target test_single_node_fullgpu_training
[ 95%] Linking CXX executable test_cuda_pipeline_parallel
[ 95%] Built target test_mpi_gpu_hybrid
[ 95%] Built target test_cuda_model_parallel
[ 95%] Built target test_cuda_pipeline_parallel
[ 96%] Linking CXX executable gcn_inference
[ 97%] Linking CXX executable gcn
[ 97%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[ 97%] Built target OSDI2023_SINGLE_NODE_gcn
[ 98%] Linking CXX executable gcn
[100%] Linking CXX executable test_two_layer_hybrid_parallelism_designer
[100%] Built target test_two_layer_hybrid_parallelism_designer
[100%] Built target OSDI2023_MULTI_NODES_gcn
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/reddit
The number of GCN layers: 3
The number of hidden units: 256
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /anvil/projects/x-cis220117/saved_weights_pipe
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/reddit
The number of GCN layers: 3
The number of hidden units: 256
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /anvil/projects/x-cis220117/saved_weights_pipe
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/reddit
The number of GCN layers: 3
The number of hidden units: 256
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /anvil/projects/x-cis220117/saved_weights_pipe
The random seed: 3
The scaling down factor of out-of-chunk gradients: 0.100000
Initialized node 0 on machine g002.anvil.rcac.purdue.edu
Initialized node 1 on machine g009.anvil.rcac.purdue.edu
Initialized node 2 on machine g010.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.810 seconds.
Building the CSC structure...
        It takes 1.887 seconds.
Building the CSC structure...
        It takes 1.897 seconds.
Building the CSC structure...
        It takes 1.770 seconds.
        It takes 1.747 seconds.
        It takes 1.752 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.325 seconds.
Building the Label Vector...
        It takes 0.324 seconds.
Building the Label Vector...
        It takes 0.044 seconds.
Number of classes: 41
Number of feature dimensions: 602
Number of vertices: 232965
        It takes 0.331 seconds.
Building the Label Vector...
        It takes 0.029 seconds.
Number of classes: 41
Number of feature dimensions: 602
Number of vertices: 232965
        It takes 0.034 seconds.
Number of classes: 41
Number of feature dimensions: 602
Number of vertices: 232965
train nodes 153431, valid nodes 23831, test nodes 55703
Number of GPUs: 3
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 15
0 232965 0 6
0 232965 6 11
0 232965 11 15
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 6) x [0, 232965)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_AGGREGATION, output tensors: 6
    Op 7: type OPERATOR_WEIGHT, output tensors: 7
    Op 8: type OPERATOR_MATMUL, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_AGGREGATION, output tensors: 11
    Op 12: type OPERATOR_WEIGHT, output tensors: 12
    Op 13: type OPERATOR_MATMUL, output tensors: 13
    Op 14: type OPERATOR_SOFTMAX, output tensors: 14
Boundaries: 0 0 0 232965 232965 232965
Fragments: [0, 232965)
Chunks (number of global chunks: 12): 0-[0, 19414) 1-[19414, 38828) 2-[38828, 58242) 3-[58242, 77656) 4-[77656, 97070) 5-[97070, 116484) 6-[116484, 135898) 7-[135898, 155312) 8-[155312, 174726) ... 11-[213554, 232965)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 5)
(I-link dependencies): node 0 should send activation to nodes: 1 (tensor: 5)
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
train nodes 153431, valid nodes 23831, test nodes 55703
Number of GPUs: 3
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
WARNING: the current version only applies to linear GNN models!
*** Node 1, starting model training...
Number of operators: 15
0 232965 0 6
0 232965 6 11
0 232965 11 15
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [6, 11) x [0, 232965)
*** Node 1, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 5)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 10)
(I-link dependencies): node 1 should send activation to nodes: 2 (tensor: 10)
(I-link dependencies): node 1 should receive activation from nodes: 0 (tensor: 5)
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
232965, 114848857, 114848857
Number of vertices per chunk: 19414
train nodes 153431, valid nodes 23831, test nodes 55703
Number of GPUs: 3
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
WARNING: the current version only applies to linear GNN models!
*** Node 2, starting model training...
Number of operators: 15
0 232965 0 6
0 232965 6 11
0 232965 11 15
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the partition [11, 15) x [0, 232965)
*** Node 2, constructing the helper classes...
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 10)
(Backwarding) Node 2 (fragment 0) depends on nodes:
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes: 1 (tensor: 10)
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
232965, 114848857, 114848857
Number of vertices per chunk: 19414
232965, 114848857, 114848857
Number of vertices per chunk: 19414
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 1, starting the helper threads...
*** Node 2, starting the helper threads...
+++++++++ Node 1 initializing the weights for op[6, 11)...
+++++++++ Node 1, mapping weight op 7
+++++++++ Node 0 initializing the weights for op[0, 6)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 2 initializing the weights for op[11, 15)...
+++++++++ Node 2, mapping weight op 12
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.003000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.003000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 1.36831	TrainAcc 0.7533	ValidAcc 0.7739	TestAcc 0.7679
    Epoch 19:	Loss 0.77119	TrainAcc 0.8556	ValidAcc 0.8673	TestAcc 0.8635
    Epoch 29:	Loss 0.47342	TrainAcc 0.9068	ValidAcc 0.9144	TestAcc 0.9151
    Epoch 39:	Loss 0.41795	TrainAcc 0.9157	ValidAcc 0.9233	TestAcc 0.9218
    Epoch 49:	Loss 0.36465	TrainAcc 0.9245	ValidAcc 0.9296	TestAcc 0.9298
    Epoch 59:	Loss 0.34855	TrainAcc 0.9272	ValidAcc 0.9321	TestAcc 0.9319
    Epoch 69:	Loss 0.33219	TrainAcc 0.9297	ValidAcc 0.9341	TestAcc 0.9350
    Epoch 79:	Loss 0.32193	TrainAcc 0.9322	ValidAcc 0.9365	TestAcc 0.9366
    Epoch 89:	Loss 0.31301	TrainAcc 0.9337	ValidAcc 0.9370	TestAcc 0.9381
    Epoch 99:	Loss 0.30764	TrainAcc 0.9343	ValidAcc 0.9373	TestAcc 0.9380
    Epoch 109:	Loss 0.30113	TrainAcc 0.9351	ValidAcc 0.9388	TestAcc 0.9391
    Epoch 119:	Loss 0.29699	TrainAcc 0.9362	ValidAcc 0.9392	TestAcc 0.9395
    Epoch 129:	Loss 0.29271	TrainAcc 0.9368	ValidAcc 0.9393	TestAcc 0.9405
    Epoch 139:	Loss 0.28897	TrainAcc 0.9370	ValidAcc 0.9394	TestAcc 0.9406
    Epoch 149:	Loss 0.28450	TrainAcc 0.9380	ValidAcc 0.9405	TestAcc 0.9418
    Epoch 159:	Loss 0.28249	TrainAcc 0.9382	ValidAcc 0.9401	TestAcc 0.9420
    Epoch 169:	Loss 0.27957	TrainAcc 0.9387	ValidAcc 0.9404	TestAcc 0.9421
    Epoch 179:	Loss 0.27604	TrainAcc 0.9392	ValidAcc 0.9409	TestAcc 0.9424
    Epoch 189:	Loss 0.27213	TrainAcc 0.9396	ValidAcc 0.9408	TestAcc 0.9427
    Epoch 199:	Loss 0.27106	TrainAcc 0.9400	ValidAcc 0.9418	TestAcc 0.9423
    Epoch 209:	Loss 0.26862	TrainAcc 0.9401	ValidAcc 0.9414	TestAcc 0.9428
    Epoch 219:	Loss 0.26678	TrainAcc 0.9413	ValidAcc 0.9422	TestAcc 0.9435
    Epoch 229:	Loss 0.26474	TrainAcc 0.9414	ValidAcc 0.9422	TestAcc 0.9439
    Epoch 239:	Loss 0.26274	TrainAcc 0.9416	ValidAcc 0.9427	TestAcc 0.9437
    Epoch 249:	Loss 0.26028	TrainAcc 0.9418	ValidAcc 0.9431	TestAcc 0.9441
    Epoch 259:	Loss 0.25902	TrainAcc 0.9423	ValidAcc 0.9422	TestAcc 0.9440
    Epoch 269:	Loss 0.25791	TrainAcc 0.9422	ValidAcc 0.9433	TestAcc 0.9439
    Epoch 279:	Loss 0.25665	TrainAcc 0.9427	ValidAcc 0.9431	TestAcc 0.9443
    Epoch 289:	Loss 0.25403	TrainAcc 0.9431	ValidAcc 0.9424	TestAcc 0.9439
    Epoch 299:	Loss 0.25315	TrainAcc 0.9429	ValidAcc 0.9429	TestAcc 0.9439
    Epoch 309:	Loss 0.25096	TrainAcc 0.9433	ValidAcc 0.9424	TestAcc 0.9449
    Epoch 319:	Loss 0.25054	TrainAcc 0.9438	ValidAcc 0.9441	TestAcc 0.9446
    Epoch 329:	Loss 0.24890	TrainAcc 0.9437	ValidAcc 0.9436	TestAcc 0.9446
    Epoch 339:	Loss 0.24819	TrainAcc 0.9440	ValidAcc 0.9435	TestAcc 0.9447
    Epoch 349:	Loss 0.24587	TrainAcc 0.9441	ValidAcc 0.9439	TestAcc 0.9448
    Epoch 359:	Loss 0.24518	TrainAcc 0.9446	ValidAcc 0.9436	TestAcc 0.9448
    Epoch 369:	Loss 0.24421	TrainAcc 0.9445	ValidAcc 0.9442	TestAcc 0.9457
    Epoch 379:	Loss 0.24348	TrainAcc 0.9447	ValidAcc 0.9441	TestAcc 0.9451
    Epoch 389:	Loss 0.24281	TrainAcc 0.9452	ValidAcc 0.9441	TestAcc 0.9459
    Epoch 399:	Loss 0.24042	TrainAcc 0.9454	ValidAcc 0.9442	TestAcc 0.9454
    Epoch 409:	Loss 0.23941	TrainAcc 0.9453	ValidAcc 0.9437	TestAcc 0.9456
    Epoch 419:	Loss 0.23807	TrainAcc 0.9457	ValidAcc 0.9444	TestAcc 0.9457
    Epoch 429:	Loss 0.23831	TrainAcc 0.9455	ValidAcc 0.9445	TestAcc 0.9453
    Epoch 439:	Loss 0.23677	TrainAcc 0.9458	ValidAcc 0.9439	TestAcc 0.9460
    Epoch 449:	Loss 0.23609	TrainAcc 0.9462	ValidAcc 0.9455	TestAcc 0.9462
    Epoch 459:	Loss 0.23595	TrainAcc 0.9461	ValidAcc 0.9442	TestAcc 0.9456
    Epoch 469:	Loss 0.23476	TrainAcc 0.9465	ValidAcc 0.9444	TestAcc 0.9459
    Epoch 479:	Loss 0.23495	TrainAcc 0.9458	ValidAcc 0.9442	TestAcc 0.9460
    Epoch 489:	Loss 0.23319	TrainAcc 0.9465	ValidAcc 0.9441	TestAcc 0.9456
    Epoch 499:	Loss 0.23282	TrainAcc 0.9463	ValidAcc 0.9439	TestAcc 0.9460
    Epoch 509:	Loss 0.23157	TrainAcc 0.9463	ValidAcc 0.9447	TestAcc 0.9459
    Epoch 519:	Loss 0.23099	TrainAcc 0.9468	ValidAcc 0.9452	TestAcc 0.9456
    Epoch 529:	Loss 0.23005	TrainAcc 0.9470	ValidAcc 0.9452	TestAcc 0.9456
    Epoch 539:	Loss 0.22923	TrainAcc 0.9470	ValidAcc 0.9451	TestAcc 0.9463
    Epoch 549:	Loss 0.22829	TrainAcc 0.9471	ValidAcc 0.9448	TestAcc 0.9461
    Epoch 559:	Loss 0.22824	TrainAcc 0.9473	ValidAcc 0.9444	TestAcc 0.9468
    Epoch 569:	Loss 0.22824	TrainAcc 0.9472	ValidAcc 0.9445	TestAcc 0.9462
    Epoch 579:	Loss 0.22809	TrainAcc 0.9471	ValidAcc 0.9452	TestAcc 0.9466
    Epoch 589:	Loss 0.22576	TrainAcc 0.9474	ValidAcc 0.9450	TestAcc 0.9461
    Epoch 599:	Loss 0.22489	TrainAcc 0.9478	ValidAcc 0.9449	TestAcc 0.9456
    Epoch 609:	Loss 0.22444	TrainAcc 0.9479	ValidAcc 0.9453	TestAcc 0.9468
    Epoch 619:	Loss 0.22388	TrainAcc 0.9481	ValidAcc 0.9451	TestAcc 0.9460
    Epoch 629:	Loss 0.22403	TrainAcc 0.9479	ValidAcc 0.9445	TestAcc 0.9464
    Epoch 639:	Loss 0.22363	TrainAcc 0.9478	ValidAcc 0.9450	TestAcc 0.9459
    Epoch 649:	Loss 0.22194	TrainAcc 0.9486	ValidAcc 0.9455	TestAcc 0.9465
    Epoch 659:	Loss 0.22185	TrainAcc 0.9484	ValidAcc 0.9462	TestAcc 0.9465
    Epoch 669:	Loss 0.22157	TrainAcc 0.9486	ValidAcc 0.9451	TestAcc 0.9465
    Epoch 679:	Loss 0.22001	TrainAcc 0.9486	ValidAcc 0.9447	TestAcc 0.9469
    Epoch 689:	Loss 0.22032	TrainAcc 0.9488	ValidAcc 0.9465	TestAcc 0.9471
    Epoch 699:	Loss 0.21987	TrainAcc 0.9491	ValidAcc 0.9454	TestAcc 0.9474
    Epoch 709:	Loss 0.22020	TrainAcc 0.9483	ValidAcc 0.9456	TestAcc 0.9468
    Epoch 719:	Loss 0.21884	TrainAcc 0.9490	ValidAcc 0.9462	TestAcc 0.9469
    Epoch 729:	Loss 0.21788	TrainAcc 0.9492	ValidAcc 0.9459	TestAcc 0.9468
    Epoch 739:	Loss 0.21741	TrainAcc 0.9491	ValidAcc 0.9454	TestAcc 0.9461
    Epoch 749:	Loss 0.21791	TrainAcc 0.9491	ValidAcc 0.9449	TestAcc 0.9464
    Epoch 759:	Loss 0.21681	TrainAcc 0.9496	ValidAcc 0.9465	TestAcc 0.9463
    Epoch 769:	Loss 0.21600	TrainAcc 0.9497	ValidAcc 0.9460	TestAcc 0.9464
    Epoch 779:	Loss 0.21565	TrainAcc 0.9497	ValidAcc 0.9464	TestAcc 0.9467
    Epoch 789:	Loss 0.21540	TrainAcc 0.9495	ValidAcc 0.9468	TestAcc 0.9470
    Epoch 799:	Loss 0.21465	TrainAcc 0.9500	ValidAcc 0.9448	TestAcc 0.9468
    Epoch 809:	Loss 0.21401	TrainAcc 0.9498	ValidAcc 0.9463	TestAcc 0.9470
    Epoch 819:	Loss 0.21484	TrainAcc 0.9496	ValidAcc 0.9458	TestAcc 0.9459
    Epoch 829:	Loss 0.21482	TrainAcc 0.9497	ValidAcc 0.9467	TestAcc 0.9470
    Epoch 839:	Loss 0.21371	TrainAcc 0.9502	ValidAcc 0.9462	TestAcc 0.9468
    Epoch 849:	Loss 0.21314	TrainAcc 0.9500	ValidAcc 0.9469	TestAcc 0.9471
    Epoch 859:	Loss 0.21250	TrainAcc 0.9500	ValidAcc 0.9460	TestAcc 0.9466
    Epoch 869:	Loss 0.21307	TrainAcc 0.9499	ValidAcc 0.9456	TestAcc 0.9461
    Epoch 879:	Loss 0.21187	TrainAcc 0.9500	ValidAcc 0.9455	TestAcc 0.9466
    Epoch 889:	Loss 0.21139	TrainAcc 0.9504	ValidAcc 0.9470	TestAcc 0.9470
    Epoch 899:	Loss 0.21151	TrainAcc 0.9502	ValidAcc 0.9456	TestAcc 0.9471
    Epoch 909:	Loss 0.21082	TrainAcc 0.9508	ValidAcc 0.9465	TestAcc 0.9475
    Epoch 919:	Loss 0.21027	TrainAcc 0.9507	ValidAcc 0.9459	TestAcc 0.9472
    Epoch 929:	Loss 0.21041	TrainAcc 0.9504	ValidAcc 0.9454	TestAcc 0.9471
    Epoch 939:	Loss 0.20963	TrainAcc 0.9506	ValidAcc 0.9469	TestAcc 0.9466
    Epoch 949:	Loss 0.20799	TrainAcc 0.9506	ValidAcc 0.9466	TestAcc 0.9471
    Epoch 959:	Loss 0.20842	TrainAcc 0.9506	ValidAcc 0.9468	TestAcc 0.9475
    Epoch 969:	Loss 0.20793	TrainAcc 0.9509	ValidAcc 0.9470	TestAcc 0.9470
    Epoch 979:	Loss 0.20853	TrainAcc 0.9506	ValidAcc 0.9463	TestAcc 0.9468
    Epoch 989:	Loss 0.20690	TrainAcc 0.9512	ValidAcc 0.9465	TestAcc 0.9474
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 9.807 GBps
Node 2, Layer-level comm throughput (act): 11.095 GBps
Node 2, Layer-level comm throughput (grad): -nan GBps
Node 1, Layer-level comm throughput (grad): 11.068 GBps
Node 0, Layer-level comm throughput (grad): 9.870 GBps
    Epoch 999:	Loss 0.20677	TrainAcc 0.9516	ValidAcc 0.9468	TestAcc 0.9472
Node 0, compression time: 1.106s, compression size: 222.173GB, throughput: 200.875GBps
Node 0, decompression time: 3.564s, compression size: 222.173GB, throughput: 62.336GBps
Node 0, pure compute time: 72.519 s, total compute time: 77.189 s
Node 0, wait_for_task_time: 23.098 s, wait_for_other_gpus_time: 0.005 s
------------------------node id 0,  per-epoch time: 0.102932 s---------------
Node 2, compression time: 1.708s, compression size: 222.173GB, throughput: 130.087GBps
Node 2, decompression time: 3.637s, compression size: 222.173GB, throughput: 61.092GBps
Node 2, pure compute time: 57.927 s, total compute time: 63.272 s
Node 2, wait_for_task_time: 14.740 s, wait_for_other_gpus_time: 0.007 s
Node 1, compression time: 2.669s, compression size: 444.345GB, throughput: 166.478GBps
Node 1, decompression time: 13.390s, compression size: 444.345GB, throughput: 33.186GBps
Node 1, pure compute time: 65.875 s, total compute time: 81.934 s
Node 1, wait_for_task_time: 13.315 s, wait_for_other_gpus_time: 0.005 s
------------------------node id 1,  per-epoch time: 0.102932 s---------------
------------------------node id 2,  per-epoch time: 0.102932 s---------------
************ Profiling Results ************
	Bubble: 14.791519 (s) (14.33 percentage)
	Compute: 76.831694 (s) (74.43 percentage)
	GradSync: 0.735686 (s) (0.71 percentage)
	GraphComm: 0.023577 (s) (0.02 percentage)
	Imbalance: 8.205527 (s) (7.95 percentage)
	LayerComm: 2.643532 (s) (2.56 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.284 GB
Highest valid_acc: 0.9470
Target test_acc: 0.9470
Epoch to reach the target acc: 970
[MPI Rank 1] Success 
[MPI Rank 0] Success 
[MPI Rank 2] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/reddit
The number of GCN layers: 3
The number of hidden units: 256
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g002.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.772 seconds.
Building the CSC structure...
        It takes 1.727 seconds.
Building the Feature Vector...
        It takes 0.318 seconds.
Building the Label Vector...
        It takes 0.040 seconds.
Number of classes: 41
Number of feature dimensions: 602
Dropout: 0.000 
train nodes 153431, valid nodes 23831, test nodes 55703
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 41
    Number of vertices: 232965
*** Done preparing the STD tensor.
Version 0	Loss 1.0861	TrainAcc 0.7856	ValidAcc 0.8010	TestAcc 0.7997
Version 1	Loss 0.6312	TrainAcc 0.8690	ValidAcc 0.8796	TestAcc 0.8784
Version 2	Loss 0.4360	TrainAcc 0.9114	ValidAcc 0.9176	TestAcc 0.9192
Version 3	Loss 0.3778	TrainAcc 0.9202	ValidAcc 0.9279	TestAcc 0.9266
Version 4	Loss 0.3438	TrainAcc 0.9284	ValidAcc 0.9335	TestAcc 0.9332
Version 5	Loss 0.3246	TrainAcc 0.9319	ValidAcc 0.9365	TestAcc 0.9372
Version 6	Loss 0.3145	TrainAcc 0.9333	ValidAcc 0.9367	TestAcc 0.9382
Version 7	Loss 0.3050	TrainAcc 0.9358	ValidAcc 0.9379	TestAcc 0.9399
Version 8	Loss 0.2985	TrainAcc 0.9370	ValidAcc 0.9392	TestAcc 0.9412
Version 9	Loss 0.2922	TrainAcc 0.9380	ValidAcc 0.9402	TestAcc 0.9419
Version 10	Loss 0.2874	TrainAcc 0.9381	ValidAcc 0.9403	TestAcc 0.9422
Version 11	Loss 0.2824	TrainAcc 0.9394	ValidAcc 0.9407	TestAcc 0.9427
Version 12	Loss 0.2783	TrainAcc 0.9400	ValidAcc 0.9411	TestAcc 0.9436
Version 13	Loss 0.2746	TrainAcc 0.9406	ValidAcc 0.9415	TestAcc 0.9439
Version 14	Loss 0.2711	TrainAcc 0.9410	ValidAcc 0.9413	TestAcc 0.9441
Version 15	Loss 0.2682	TrainAcc 0.9417	ValidAcc 0.9423	TestAcc 0.9447
Version 16	Loss 0.2651	TrainAcc 0.9419	ValidAcc 0.9421	TestAcc 0.9449
Version 17	Loss 0.2624	TrainAcc 0.9423	ValidAcc 0.9423	TestAcc 0.9449
Version 18	Loss 0.2598	TrainAcc 0.9428	ValidAcc 0.9426	TestAcc 0.9455
Version 19	Loss 0.2573	TrainAcc 0.9438	ValidAcc 0.9439	TestAcc 0.9458
Version 20	Loss 0.2553	TrainAcc 0.9438	ValidAcc 0.9434	TestAcc 0.9460
Version 21	Loss 0.2529	TrainAcc 0.9442	ValidAcc 0.9436	TestAcc 0.9459
Version 22	Loss 0.2512	TrainAcc 0.9447	ValidAcc 0.9440	TestAcc 0.9461
Version 23	Loss 0.2494	TrainAcc 0.9449	ValidAcc 0.9445	TestAcc 0.9465
Version 24	Loss 0.2478	TrainAcc 0.9451	ValidAcc 0.9445	TestAcc 0.9464
Version 25	Loss 0.2461	TrainAcc 0.9451	ValidAcc 0.9443	TestAcc 0.9465
Version 26	Loss 0.2442	TrainAcc 0.9457	ValidAcc 0.9449	TestAcc 0.9466
Version 27	Loss 0.2428	TrainAcc 0.9461	ValidAcc 0.9454	TestAcc 0.9471
Version 28	Loss 0.2413	TrainAcc 0.9459	ValidAcc 0.9453	TestAcc 0.9469
Version 29	Loss 0.2399	TrainAcc 0.9463	ValidAcc 0.9457	TestAcc 0.9469
Version 30	Loss 0.2385	TrainAcc 0.9467	ValidAcc 0.9457	TestAcc 0.9469
Version 31	Loss 0.2376	TrainAcc 0.9468	ValidAcc 0.9457	TestAcc 0.9471
Version 32	Loss 0.2359	TrainAcc 0.9472	ValidAcc 0.9460	TestAcc 0.9473
Version 33	Loss 0.2349	TrainAcc 0.9472	ValidAcc 0.9454	TestAcc 0.9474
Version 34	Loss 0.2338	TrainAcc 0.9478	ValidAcc 0.9457	TestAcc 0.9477
Version 35	Loss 0.2329	TrainAcc 0.9476	ValidAcc 0.9460	TestAcc 0.9473
Version 36	Loss 0.2319	TrainAcc 0.9478	ValidAcc 0.9464	TestAcc 0.9477
Version 37	Loss 0.2309	TrainAcc 0.9480	ValidAcc 0.9460	TestAcc 0.9476
Version 38	Loss 0.2300	TrainAcc 0.9483	ValidAcc 0.9462	TestAcc 0.9479
Version 39	Loss 0.2289	TrainAcc 0.9486	ValidAcc 0.9463	TestAcc 0.9480
Version 40	Loss 0.2277	TrainAcc 0.9488	ValidAcc 0.9462	TestAcc 0.9482
Version 41	Loss 0.2269	TrainAcc 0.9489	ValidAcc 0.9466	TestAcc 0.9484
Version 42	Loss 0.2260	TrainAcc 0.9491	ValidAcc 0.9463	TestAcc 0.9482
Version 43	Loss 0.2255	TrainAcc 0.9490	ValidAcc 0.9465	TestAcc 0.9481
Version 44	Loss 0.2250	TrainAcc 0.9490	ValidAcc 0.9464	TestAcc 0.9480
Version 45	Loss 0.2238	TrainAcc 0.9495	ValidAcc 0.9468	TestAcc 0.9485
Version 46	Loss 0.2228	TrainAcc 0.9496	ValidAcc 0.9465	TestAcc 0.9481
Version 47	Loss 0.2221	TrainAcc 0.9497	ValidAcc 0.9469	TestAcc 0.9482
Version 48	Loss 0.2215	TrainAcc 0.9500	ValidAcc 0.9476	TestAcc 0.9483
Version 49	Loss 0.2205	TrainAcc 0.9499	ValidAcc 0.9465	TestAcc 0.9480
Version 50	Loss 0.2198	TrainAcc 0.9501	ValidAcc 0.9469	TestAcc 0.9484
Version 51	Loss 0.2195	TrainAcc 0.9503	ValidAcc 0.9472	TestAcc 0.9484
Version 52	Loss 0.2188	TrainAcc 0.9501	ValidAcc 0.9463	TestAcc 0.9482
Version 53	Loss 0.2179	TrainAcc 0.9506	ValidAcc 0.9472	TestAcc 0.9487
Version 54	Loss 0.2173	TrainAcc 0.9506	ValidAcc 0.9478	TestAcc 0.9487
Version 55	Loss 0.2166	TrainAcc 0.9508	ValidAcc 0.9474	TestAcc 0.9487
Version 56	Loss 0.2158	TrainAcc 0.9508	ValidAcc 0.9470	TestAcc 0.9487
Version 57	Loss 0.2152	TrainAcc 0.9510	ValidAcc 0.9475	TestAcc 0.9486
Version 58	Loss 0.2157	TrainAcc 0.9507	ValidAcc 0.9479	TestAcc 0.9484
Version 59	Loss 0.2142	TrainAcc 0.9513	ValidAcc 0.9480	TestAcc 0.9487
Version 60	Loss 0.2133	TrainAcc 0.9516	ValidAcc 0.9474	TestAcc 0.9487
Version 61	Loss 0.2129	TrainAcc 0.9514	ValidAcc 0.9475	TestAcc 0.9491
Version 62	Loss 0.2130	TrainAcc 0.9513	ValidAcc 0.9478	TestAcc 0.9488
Version 63	Loss 0.2122	TrainAcc 0.9515	ValidAcc 0.9476	TestAcc 0.9487
Version 64	Loss 0.2120	TrainAcc 0.9510	ValidAcc 0.9470	TestAcc 0.9482
Version 65	Loss 0.2107	TrainAcc 0.9519	ValidAcc 0.9477	TestAcc 0.9485
Version 66	Loss 0.2105	TrainAcc 0.9518	ValidAcc 0.9479	TestAcc 0.9487
Version 67	Loss 0.2100	TrainAcc 0.9520	ValidAcc 0.9479	TestAcc 0.9487
Version 68	Loss 0.2099	TrainAcc 0.9519	ValidAcc 0.9479	TestAcc 0.9488
Version 69	Loss 0.2088	TrainAcc 0.9521	ValidAcc 0.9481	TestAcc 0.9492
Version 70	Loss 0.2087	TrainAcc 0.9520	ValidAcc 0.9474	TestAcc 0.9491
Version 71	Loss 0.2078	TrainAcc 0.9523	ValidAcc 0.9478	TestAcc 0.9489
Version 72	Loss 0.2071	TrainAcc 0.9526	ValidAcc 0.9474	TestAcc 0.9487
Version 73	Loss 0.2071	TrainAcc 0.9525	ValidAcc 0.9480	TestAcc 0.9489
Version 74	Loss 0.2067	TrainAcc 0.9526	ValidAcc 0.9486	TestAcc 0.9490
Version 75	Loss 0.2059	TrainAcc 0.9525	ValidAcc 0.9480	TestAcc 0.9488
Version 76	Loss 0.2055	TrainAcc 0.9525	ValidAcc 0.9481	TestAcc 0.9490
Version 77	Loss 0.2053	TrainAcc 0.9526	ValidAcc 0.9481	TestAcc 0.9490
Version 78	Loss 0.2047	TrainAcc 0.9528	ValidAcc 0.9482	TestAcc 0.9494
Version 79	Loss 0.2051	TrainAcc 0.9525	ValidAcc 0.9482	TestAcc 0.9490
Version 80	Loss 0.2047	TrainAcc 0.9528	ValidAcc 0.9482	TestAcc 0.9492
Version 81	Loss 0.2040	TrainAcc 0.9528	ValidAcc 0.9482	TestAcc 0.9490
Version 82	Loss 0.2033	TrainAcc 0.9533	ValidAcc 0.9480	TestAcc 0.9494
Version 83	Loss 0.2028	TrainAcc 0.9530	ValidAcc 0.9477	TestAcc 0.9491
Version 84	Loss 0.2030	TrainAcc 0.9529	ValidAcc 0.9490	TestAcc 0.9494
Version 85	Loss 0.2021	TrainAcc 0.9536	ValidAcc 0.9481	TestAcc 0.9490
Version 86	Loss 0.2028	TrainAcc 0.9526	ValidAcc 0.9477	TestAcc 0.9482
Version 87	Loss 0.2013	TrainAcc 0.9533	ValidAcc 0.9482	TestAcc 0.9492
Version 88	Loss 0.2014	TrainAcc 0.9533	ValidAcc 0.9480	TestAcc 0.9492
Version 89	Loss 0.2016	TrainAcc 0.9530	ValidAcc 0.9485	TestAcc 0.9487
Version 90	Loss 0.2001	TrainAcc 0.9540	ValidAcc 0.9485	TestAcc 0.9492
Version 91	Loss 0.1996	TrainAcc 0.9539	ValidAcc 0.9483	TestAcc 0.9493
Version 92	Loss 0.1996	TrainAcc 0.9540	ValidAcc 0.9483	TestAcc 0.9492
Version 93	Loss 0.1988	TrainAcc 0.9538	ValidAcc 0.9485	TestAcc 0.9494
Version 94	Loss 0.1988	TrainAcc 0.9542	ValidAcc 0.9488	TestAcc 0.9497
Version 95	Loss 0.1985	TrainAcc 0.9539	ValidAcc 0.9486	TestAcc 0.9492
Version 96	Loss 0.1981	TrainAcc 0.9539	ValidAcc 0.9491	TestAcc 0.9498
Version 97	Loss 0.1972	TrainAcc 0.9541	ValidAcc 0.9486	TestAcc 0.9493
Version 98	Loss 0.1972	TrainAcc 0.9542	ValidAcc 0.9482	TestAcc 0.9490
Version 99	Loss 0.1974	TrainAcc 0.9539	ValidAcc 0.9486	TestAcc 0.9496
Version 96 achieved the highest validation accuracy 0.9491 (test accuracy: 0.9498)
