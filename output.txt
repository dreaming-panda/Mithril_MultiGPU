g006.anvil.rcac.purdue.edu
Thu Jan 19 19:24:20 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   33C    P0    52W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  4%] Built target context
[ 19%] Built target parallel
[ 19%] Built target core
[ 39%] Built target cudahelp
[ 53%] Built target test_mpi_gpu_pipelined_model_parallel
[ 62%] Built target test_mpi_combined
[ 62%] Built target test_mpi_gpu_hybrid
[ 62%] Built target test_cuda_data_compression
[ 62%] Built target test_cuda_graph
[ 82%] Built target test_cuda_pipeline_parallel
[ 82%] Built target test_mpi_model_parallel
[ 82%] Built target test_cuda_model_parallel
[ 82%] Built target test_single_node_fullgpu_training
[ 82%] Built target test_mpi_gpu_model_parallel
[ 82%] Built target test_mpi_loader
[ 82%] Built target test_full_structual_graph
[ 82%] Built target test_cuda
[ 82%] Built target test_trivial
[ 91%] Built target test_hello_world
[ 91%] Built target test_single_node_gpu_training
[ 91%] Built target test_mpi_pipelined_model_parallel
[ 91%] Built target test_single_node_training
[ 91%] Built target test_full_non_structual_graph
[ 91%] Built target test_mpi_non_structual_graph
[ 91%] Built target estimate_comm_volume
[ 91%] Built target test_nccl_thread
[ 91%] Built target test_graph
[ 91%] Built target test_nccl_mpi
[ 91%] Built target test_mpi_structual_graph
[ 95%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[ 95%] Built target OSDI2023_SINGLE_NODE_gcn
[100%] Built target OSDI2023_MULTI_NODES_gcn
[100%] Built target test_two_layer_hybrid_parallelism_designer
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
Initialized node 1 on machine g007.anvil.rcac.purdue.edu
Initialized node 0 on machine g006.anvil.rcac.purdue.edu
Initialized node 3 on machine g010.anvil.rcac.purdue.edu
Initialized node 2 on machine g008.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.037 seconds.
Building the CSC structure...
        It takes 0.038 seconds.
Building the CSC structure...
        It takes 0.039 seconds.
Building the CSC structure...
        It takes 0.037 seconds.
        It takes 0.038 seconds.
        It takes 0.038 seconds.
        It takes 0.073 seconds.
Building the CSC structure...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.037 seconds.
Building the Feature Vector...
        It takes 0.053 seconds.
Building the Label Vector...
        It takes 0.021 seconds.
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
        It takes 0.080 seconds.
Building the Label Vector...
        It takes 0.120 seconds.
Building the Label Vector...
        It takes 0.123 seconds.
Building the Label Vector...
        It takes 0.055 seconds.
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
        It takes 0.056 seconds.
        It takes 0.054 seconds.
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
train nodes 90941, valid nodes 29799, test nodes 48603
Number of GPUs: 4
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
WARNING: the current version only applies to linear GNN models!
*** Node 2, starting model training...
Number of operators: 20
0 169343 0 6
0 169343 6 11
0 169343 11 16
0 169343 16 20
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the partition [11, 16) x [0, 169343)
*** Node 2, constructing the helper classes...
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 10)
(Backwarding) Node 2 (fragment 0) depends on nodes: 3 (Tensor: 15)
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
169343, 2484941, 2484941
train nodes 90941, valid nodes 29799, test nodes 48603
Number of GPUs: 4
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
*** Node 3, starting model training...
Number of operators: 20
0 169343 0 6
0 169343 6 11
0 169343 11 16
0 169343 16 20
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the partition [16, 20) x [0, 169343)
*** Node 3, constructing the helper classes...
train nodes 90941, valid nodes 29799, test nodes 48603
Number of GPUs: 4
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
*** Node 0, starting model training...
Number of operators: 20
0 169343 0 6
0 169343 6 11
0 169343 11 16
0 169343 16 20
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 6) x [0, 169343)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_SOFTMAX, output tensors: 19
(Forwarding) Node 3 (fragment 0) depends on nodes: 2 (Tensor: 15)
(Backwarding) Node 3 (fragment 0) depends on nodes:
(I-link dependencies): node 3 should send activation to nodes:
(I-link dependencies): node 3 should receive activation from nodes:
(I-link dependencies): node 3 should send gradient to nodes:
(I-link dependencies): node 3 should receive gradient from nodes:
Boundaries: 0 0 0 0 169343 169343 169343 169343
Fragments: [0, 169343)
Chunks (number of global chunks: 32): 0-[0, 5292) 1-[5292, 10584) 2-[10584, 15876) 3-[15876, 21168) 4-[21168, 26460) 5-[26460, 31752) 6-[31752, 37044) 7-[37044, 42336) 8-[42336, 47628) ... 31-[164052, 169343)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 5)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
169343, 2484941, 2484941
169343, 2484941, 2484941
train nodes 90941, valid nodes 29799, test nodes 48603
Number of GPUs: 4
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
WARNING: the current version only applies to linear GNN models!
*** Node 1, starting model training...
Number of operators: 20
0 169343 0 6
0 169343 6 11
0 169343 11 16
0 169343 16 20
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [6, 11) x [0, 169343)
*** Node 1, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 5)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 10)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
169343, 2484941, 2484941
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 3, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 2, starting the helper threads...
*** Node 3, starting the helper threads...
*** Node 1, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 6)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 3 initializing the weights for op[16, 20)...
+++++++++ Node 3, mapping weight op 16
+++++++++ Node 1 initializing the weights for op[6, 11)...
+++++++++ Node 1, mapping weight op 6
+++++++++ Node 2 initializing the weights for op[11, 16)...
+++++++++ Node 2, mapping weight op 11
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.001000000
*** Node 2, starting task scheduling...
*** Node 3, starting task scheduling...
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
    Epoch 9:	Loss 34.62736	TrainAcc 0.1791	ValidAcc 0.0764	TestAcc 0.0586
    Epoch 19:	Loss 31.33066	TrainAcc 0.2575	ValidAcc 0.2563	TestAcc 0.2377
    Epoch 29:	Loss 29.46005	TrainAcc 0.2948	ValidAcc 0.3148	TestAcc 0.2831
    Epoch 39:	Loss 26.92010	TrainAcc 0.3669	ValidAcc 0.3667	TestAcc 0.3380
    Epoch 49:	Loss 24.78038	TrainAcc 0.3208	ValidAcc 0.3355	TestAcc 0.3122
    Epoch 59:	Loss 22.83818	TrainAcc 0.4142	ValidAcc 0.4126	TestAcc 0.3827
    Epoch 69:	Loss 21.82246	TrainAcc 0.4130	ValidAcc 0.4554	TestAcc 0.4483
    Epoch 79:	Loss 21.19797	TrainAcc 0.3925	ValidAcc 0.3887	TestAcc 0.4069
    Epoch 89:	Loss 20.36048	TrainAcc 0.4461	ValidAcc 0.4456	TestAcc 0.4188
    Epoch 99:	Loss 19.67440	TrainAcc 0.4570	ValidAcc 0.4890	TestAcc 0.5062
    Epoch 109:	Loss 19.10287	TrainAcc 0.4822	ValidAcc 0.4906	TestAcc 0.4634
    Epoch 119:	Loss 18.52922	TrainAcc 0.4869	ValidAcc 0.5145	TestAcc 0.5272
    Epoch 129:	Loss 18.26603	TrainAcc 0.4862	ValidAcc 0.4838	TestAcc 0.4570
    Epoch 139:	Loss 17.87554	TrainAcc 0.5121	ValidAcc 0.5409	TestAcc 0.5497
    Epoch 149:	Loss 17.60667	TrainAcc 0.5213	ValidAcc 0.5300	TestAcc 0.5050
    Epoch 159:	Loss 17.43108	TrainAcc 0.5096	ValidAcc 0.5123	TestAcc 0.5048
    Epoch 169:	Loss 17.12577	TrainAcc 0.5204	ValidAcc 0.5334	TestAcc 0.5286
    Epoch 179:	Loss 16.85247	TrainAcc 0.5327	ValidAcc 0.5276	TestAcc 0.5050
    Epoch 189:	Loss 16.58918	TrainAcc 0.5510	ValidAcc 0.5653	TestAcc 0.5648
    Epoch 199:	Loss 16.35886	TrainAcc 0.5577	ValidAcc 0.5523	TestAcc 0.5253
    Epoch 209:	Loss 16.14158	TrainAcc 0.5644	ValidAcc 0.5847	TestAcc 0.5844
    Epoch 219:	Loss 15.89891	TrainAcc 0.5676	ValidAcc 0.5658	TestAcc 0.5441
    Epoch 229:	Loss 15.69670	TrainAcc 0.5696	ValidAcc 0.5907	TestAcc 0.5857
    Epoch 239:	Loss 15.47171	TrainAcc 0.5735	ValidAcc 0.5700	TestAcc 0.5503
    Epoch 249:	Loss 15.34753	TrainAcc 0.5772	ValidAcc 0.5992	TestAcc 0.5943
    Epoch 259:	Loss 15.16586	TrainAcc 0.5807	ValidAcc 0.5874	TestAcc 0.5713
    Epoch 269:	Loss 15.04722	TrainAcc 0.5841	ValidAcc 0.6049	TestAcc 0.6003
    Epoch 279:	Loss 14.91102	TrainAcc 0.5872	ValidAcc 0.5921	TestAcc 0.5799
    Epoch 289:	Loss 14.79951	TrainAcc 0.5925	ValidAcc 0.6040	TestAcc 0.5991
    Epoch 299:	Loss 14.71617	TrainAcc 0.5914	ValidAcc 0.6039	TestAcc 0.5953
    Epoch 309:	Loss 14.63001	TrainAcc 0.5966	ValidAcc 0.6054	TestAcc 0.5922
    Epoch 319:	Loss 14.51724	TrainAcc 0.5978	ValidAcc 0.6098	TestAcc 0.6027
    Epoch 329:	Loss 14.42979	TrainAcc 0.6010	ValidAcc 0.6066	TestAcc 0.5890
    Epoch 339:	Loss 14.33208	TrainAcc 0.6007	ValidAcc 0.6132	TestAcc 0.6078
    Epoch 349:	Loss 14.29495	TrainAcc 0.5979	ValidAcc 0.6054	TestAcc 0.5937
    Epoch 359:	Loss 14.21649	TrainAcc 0.6024	ValidAcc 0.6121	TestAcc 0.6037
    Epoch 369:	Loss 14.13417	TrainAcc 0.6035	ValidAcc 0.6120	TestAcc 0.6045
    Epoch 379:	Loss 14.08795	TrainAcc 0.6065	ValidAcc 0.6217	TestAcc 0.6175
    Epoch 389:	Loss 14.01419	TrainAcc 0.6092	ValidAcc 0.6169	TestAcc 0.6075
    Epoch 399:	Loss 13.93377	TrainAcc 0.6106	ValidAcc 0.6241	TestAcc 0.6199
    Epoch 409:	Loss 13.85514	TrainAcc 0.6139	ValidAcc 0.6252	TestAcc 0.6208
    Epoch 419:	Loss 13.79818	TrainAcc 0.6138	ValidAcc 0.6250	TestAcc 0.6133
    Epoch 429:	Loss 13.75100	TrainAcc 0.6165	ValidAcc 0.6284	TestAcc 0.6286
    Epoch 439:	Loss 13.70748	TrainAcc 0.6175	ValidAcc 0.6264	TestAcc 0.6169
    Epoch 449:	Loss 13.67567	TrainAcc 0.6188	ValidAcc 0.6285	TestAcc 0.6178
    Epoch 459:	Loss 13.64852	TrainAcc 0.6166	ValidAcc 0.6316	TestAcc 0.6287
    Epoch 469:	Loss 13.63309	TrainAcc 0.6181	ValidAcc 0.6211	TestAcc 0.6068
    Epoch 479:	Loss 13.61342	TrainAcc 0.6191	ValidAcc 0.6279	TestAcc 0.6274
    Epoch 489:	Loss 13.59799	TrainAcc 0.6223	ValidAcc 0.6305	TestAcc 0.6167
    Epoch 499:	Loss 13.56609	TrainAcc 0.6233	ValidAcc 0.6303	TestAcc 0.6184
    Epoch 509:	Loss 13.57993	TrainAcc 0.6178	ValidAcc 0.6330	TestAcc 0.6322
    Epoch 519:	Loss 13.59018	TrainAcc 0.6162	ValidAcc 0.6120	TestAcc 0.5874
    Epoch 529:	Loss 13.59779	TrainAcc 0.6098	ValidAcc 0.6199	TestAcc 0.6231
    Epoch 539:	Loss 13.56503	TrainAcc 0.6159	ValidAcc 0.6064	TestAcc 0.5831
    Epoch 549:	Loss 13.56287	TrainAcc 0.6075	ValidAcc 0.6137	TestAcc 0.6095
    Epoch 559:	Loss 13.50487	TrainAcc 0.6168	ValidAcc 0.6098	TestAcc 0.5850
    Epoch 569:	Loss 13.47365	TrainAcc 0.6175	ValidAcc 0.6267	TestAcc 0.6263
    Epoch 579:	Loss 13.37563	TrainAcc 0.6250	ValidAcc 0.6247	TestAcc 0.6030
    Epoch 589:	Loss 13.31227	TrainAcc 0.6264	ValidAcc 0.6397	TestAcc 0.6347
    Epoch 599:	Loss 13.22253	TrainAcc 0.6334	ValidAcc 0.6392	TestAcc 0.6312
    Epoch 609:	Loss 13.17397	TrainAcc 0.6326	ValidAcc 0.6429	TestAcc 0.6350
    Epoch 619:	Loss 13.09959	TrainAcc 0.6339	ValidAcc 0.6437	TestAcc 0.6338
    Epoch 629:	Loss 13.06838	TrainAcc 0.6326	ValidAcc 0.6407	TestAcc 0.6317
    Epoch 639:	Loss 13.00151	TrainAcc 0.6339	ValidAcc 0.6431	TestAcc 0.6388
    Epoch 649:	Loss 12.96205	TrainAcc 0.6364	ValidAcc 0.6445	TestAcc 0.6348
    Epoch 659:	Loss 12.92418	TrainAcc 0.6370	ValidAcc 0.6470	TestAcc 0.6431
    Epoch 669:	Loss 12.89714	TrainAcc 0.6378	ValidAcc 0.6436	TestAcc 0.6293
    Epoch 679:	Loss 12.87315	TrainAcc 0.6390	ValidAcc 0.6490	TestAcc 0.6478
    Epoch 689:	Loss 12.85501	TrainAcc 0.6373	ValidAcc 0.6452	TestAcc 0.6319
    Epoch 699:	Loss 12.82209	TrainAcc 0.6400	ValidAcc 0.6502	TestAcc 0.6472
    Epoch 709:	Loss 12.79170	TrainAcc 0.6382	ValidAcc 0.6476	TestAcc 0.6328
    Epoch 719:	Loss 12.77279	TrainAcc 0.6404	ValidAcc 0.6477	TestAcc 0.6445
    Epoch 729:	Loss 12.76005	TrainAcc 0.6409	ValidAcc 0.6469	TestAcc 0.6375
    Epoch 739:	Loss 12.73447	TrainAcc 0.6409	ValidAcc 0.6498	TestAcc 0.6468
    Epoch 749:	Loss 12.72828	TrainAcc 0.6416	ValidAcc 0.6481	TestAcc 0.6359
    Epoch 759:	Loss 12.69240	TrainAcc 0.6427	ValidAcc 0.6525	TestAcc 0.6454
    Epoch 769:	Loss 12.64496	TrainAcc 0.6439	ValidAcc 0.6506	TestAcc 0.6389
    Epoch 779:	Loss 12.65942	TrainAcc 0.6424	ValidAcc 0.6534	TestAcc 0.6475
    Epoch 789:	Loss 12.61751	TrainAcc 0.6450	ValidAcc 0.6470	TestAcc 0.6377
    Epoch 799:	Loss 12.61722	TrainAcc 0.6442	ValidAcc 0.6509	TestAcc 0.6504
    Epoch 809:	Loss 12.61572	TrainAcc 0.6406	ValidAcc 0.6505	TestAcc 0.6374
    Epoch 819:	Loss 12.62512	TrainAcc 0.6415	ValidAcc 0.6465	TestAcc 0.6393
    Epoch 829:	Loss 12.59846	TrainAcc 0.6456	ValidAcc 0.6508	TestAcc 0.6420
    Epoch 839:	Loss 12.57081	TrainAcc 0.6466	ValidAcc 0.6533	TestAcc 0.6476
    Epoch 849:	Loss 12.59624	TrainAcc 0.6425	ValidAcc 0.6499	TestAcc 0.6431
    Epoch 859:	Loss 12.60927	TrainAcc 0.6423	ValidAcc 0.6479	TestAcc 0.6427
    Epoch 869:	Loss 12.57226	TrainAcc 0.6423	ValidAcc 0.6505	TestAcc 0.6425
    Epoch 879:	Loss 12.58022	TrainAcc 0.6421	ValidAcc 0.6463	TestAcc 0.6385
    Epoch 889:	Loss 12.54579	TrainAcc 0.6436	ValidAcc 0.6473	TestAcc 0.6357
    Epoch 899:	Loss 12.52723	TrainAcc 0.6460	ValidAcc 0.6515	TestAcc 0.6413
    Epoch 909:	Loss 12.48435	TrainAcc 0.6480	ValidAcc 0.6509	TestAcc 0.6396
    Epoch 919:	Loss 12.45453	TrainAcc 0.6479	ValidAcc 0.6523	TestAcc 0.6438
    Epoch 929:	Loss 12.43400	TrainAcc 0.6480	ValidAcc 0.6505	TestAcc 0.6368
    Epoch 939:	Loss 12.41363	TrainAcc 0.6487	ValidAcc 0.6528	TestAcc 0.6484
    Epoch 949:	Loss 12.37616	TrainAcc 0.6488	ValidAcc 0.6521	TestAcc 0.6397
    Epoch 959:	Loss 12.35417	TrainAcc 0.6475	ValidAcc 0.6571	TestAcc 0.6535
    Epoch 969:	Loss 12.33203	TrainAcc 0.6503	ValidAcc 0.6526	TestAcc 0.6389
    Epoch 979:	Loss 12.32265	TrainAcc 0.6515	ValidAcc 0.6608	TestAcc 0.6538
    Epoch 989:	Loss 12.29231	TrainAcc 0.6506	ValidAcc 0.6557	TestAcc 0.6404
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 10.201 GBps
Node 2, Layer-level comm throughput (act): 10.187 GBps
Node 3, Layer-level comm throughput (act): 10.154 GBps
Node 3, Layer-level comm throughput (grad): -nan GBps
Node 2, Layer-level comm throughput (grad): 10.146 GBps
Node 1, Layer-level comm throughput (grad): 10.384 GBps
Node 0, Layer-level comm throughput (grad): 10.362 GBps
    Epoch 999:	Loss 12.25176	TrainAcc 0.6524	ValidAcc 0.6565	TestAcc 0.6500
Node 0, compression time: 1.741s, compression size: 80.749GB, throughput: 46.371GBps
Node 0, decompression time: 2.148s, compression size: 80.749GB, throughput: 37.598GBps
Node 0, pure compute time: 9.550 s, total compute time: 13.439 s
Node 0, wait_for_task_time: 9.702 s, wait_for_other_gpus_time: 0.005 s
------------------------node id 0,  per-epoch time: 0.025333 s---------------
Node 3, compression time: 2.011s, compression size: 80.749GB, throughput: 40.151GBps
Node 3, decompression time: 2.047s, compression size: 80.749GB, throughput: 39.447GBps
Node 3, pure compute time: 12.108 s, total compute time: 16.166 s
Node 3, wait_for_task_time: 1.289 s, wait_for_other_gpus_time: 0.006 s
------------------------node id 3,  per-epoch time: 0.025333 s---------------
Node 1, compression time: 4.097s, compression size: 161.498GB, throughput: 39.423GBps
Node 1, decompression time: 5.636s, compression size: 161.498GB, throughput: 28.654GBps
Node 1, pure compute time: 8.524 s, total compute time: 18.257 s
Node 1, wait_for_task_time: 4.237 s, wait_for_other_gpus_time: 0.006 s
------------------------node id 1,  per-epoch time: 0.025333 s---------------
Node 2, compression time: 4.103s, compression size: 161.498GB, throughput: 39.361GBps
Node 2, decompression time: 5.375s, compression size: 161.498GB, throughput: 30.046GBps
Node 2, pure compute time: 8.591 s, total compute time: 18.069 s
Node 2, wait_for_task_time: 3.829 s, wait_for_other_gpus_time: 0.006 s
------------------------node id 2,  per-epoch time: 0.025333 s---------------
ERROR: undercount the overhead: breakdown sum / all time: 0.583
************ Profiling Results ************
	Bubble: 2.136813 (s) (14.28 percentage)
	Compute: 9.705183 (s) (64.84 percentage)
	GradSync: 0.353379 (s) (2.36 percentage)
	GraphComm: 0.023512 (s) (0.16 percentage)
	Imbalance: 1.585799 (s) (10.59 percentage)
	LayerComm: 1.163921 (s) (7.78 percentage)
ERROR: undercount the overhead: breakdown sum / all time: 0.583
	Layer-level communication (cluster-wide, per epoch): 0.184 GB
Highest valid_acc: 0.6608
Target test_acc: 0.6538
Epoch to reach the target acc: 980
ERROR: undercount the overhead: breakdown sum / all time: 0.583
ERROR: undercount the overhead: breakdown sum / all time: 0.583
[MPI Rank 3] Success 
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 2] Success 
