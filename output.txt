g015.anvil.rcac.purdue.edu
Fri Jan  6 16:27:47 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                    0 |
| N/A   37C    P0    54W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  4%] Built target context
[ 16%] Built target core
[ 22%] Built target parallel
[ 39%] Built target cudahelp
[ 52%] Built target test_cuda_pipeline_parallel
[ 54%] Built target test_mpi_structual_graph
[ 52%] Built target test_cuda
[ 52%] Built target test_cuda_graph
[ 56%] Built target test_mpi_gpu_pipelined_model_parallel
[ 55%] Built target test_trivial
[ 55%] Built target test_hello_world
[ 60%] Built target test_mpi_loader
[ 69%] Built target test_mpi_combined
[ 72%] Built target test_single_node_fullgpu_training
[ 67%] Built target test_mpi_gpu_hybrid
[ 67%] Built target test_mpi_gpu_model_parallel
[ 72%] Built target test_graph
[ 72%] Built target test_cuda_model_parallel
[ 73%] Built target test_full_structual_graph
[ 76%] Built target test_nccl_thread
[ 76%] Built target test_full_non_structual_graph
[ 81%] Built target test_mpi_non_structual_graph
[ 83%] Built target test_single_node_training
[ 84%] Built target test_mpi_model_parallel
[ 86%] Built target estimate_comm_volume
[ 87%] Built target test_nccl_mpi
[ 89%] Built target test_mpi_pipelined_model_parallel
[ 91%] Built target test_single_node_gpu_training
[ 97%] Built target OSDI2023_MULTI_NODES_gcn
[ 97%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[ 98%] Built target test_two_layer_hybrid_parallelism_designer
[100%] Built target OSDI2023_SINGLE_NODE_gcn
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/reddit
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
Initialized node g015.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.740 seconds.
Building the CSC structure...
        It takes 1.665 seconds.
Building the Feature Vector...
        It takes 0.298 seconds.
Building the Label Vector...
        It takes 0.027 seconds.
Number of classes: 41
Number of feature dimensions: 602
Number of vertices: 232965
train nodes 153431, valid nodes 23831, test nodes 55703
Number of GPUs: 1
GPU 0, layer [0, 4)
*** Node 0, starting model training...
Number of operators: 20
0 232965 0 20
*** Node 0 owns the partition [0, 20) x [0, 232965)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_SOFTMAX, output tensors: 19
Boundaries: 0 232965
Fragments: [0, 232965)
Chunks (number of global chunks: 1): 0-[0, 232965)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes:
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
232965, 114848857, 114848857
csr in-out ready !*** Node 0, setting up some other necessary information...
*** Node 0, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 20)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 0, mapping weight op 6
+++++++++ Node 0, mapping weight op 11
+++++++++ Node 0, mapping weight op 16
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.001000000
    Epoch 0:	Loss 3.74138	TrainAcc 0.0138	ValidAcc 0.0130	TestAcc 0.0134
    Epoch 1:	Loss 3.57076	TrainAcc 0.1729	ValidAcc 0.1843	TestAcc 0.1801
    Epoch 2:	Loss 3.46121	TrainAcc 0.2466	ValidAcc 0.2555	TestAcc 0.2530
    Epoch 3:	Loss 3.36998	TrainAcc 0.2835	ValidAcc 0.2900	TestAcc 0.2871
    Epoch 4:	Loss 3.28575	TrainAcc 0.3343	ValidAcc 0.3424	TestAcc 0.3346
    Epoch 5:	Loss 3.19867	TrainAcc 0.4165	ValidAcc 0.4530	TestAcc 0.4490
    Epoch 6:	Loss 3.10440	TrainAcc 0.4437	ValidAcc 0.4802	TestAcc 0.4762
    Epoch 7:	Loss 2.99836	TrainAcc 0.4511	ValidAcc 0.4871	TestAcc 0.4832
    Epoch 8:	Loss 2.88727	TrainAcc 0.4628	ValidAcc 0.4978	TestAcc 0.4932
    Epoch 9:	Loss 2.76982	TrainAcc 0.4758	ValidAcc 0.5095	TestAcc 0.5048
    Epoch 10:	Loss 2.64947	TrainAcc 0.4790	ValidAcc 0.5131	TestAcc 0.5087
    Epoch 11:	Loss 2.52949	TrainAcc 0.4823	ValidAcc 0.5169	TestAcc 0.5121
    Epoch 12:	Loss 2.40641	TrainAcc 0.5041	ValidAcc 0.5376	TestAcc 0.5358
    Epoch 13:	Loss 2.28734	TrainAcc 0.5632	ValidAcc 0.6006	TestAcc 0.5968
    Epoch 14:	Loss 2.17798	TrainAcc 0.5665	ValidAcc 0.6042	TestAcc 0.6005
    Epoch 15:	Loss 2.08595	TrainAcc 0.5697	ValidAcc 0.6075	TestAcc 0.6036
    Epoch 16:	Loss 2.00023	TrainAcc 0.5935	ValidAcc 0.6294	TestAcc 0.6242
    Epoch 17:	Loss 1.91324	TrainAcc 0.5935	ValidAcc 0.6285	TestAcc 0.6249
    Epoch 18:	Loss 1.81891	TrainAcc 0.5872	ValidAcc 0.6215	TestAcc 0.6163
    Epoch 19:	Loss 1.73256	TrainAcc 0.6167	ValidAcc 0.6431	TestAcc 0.6374
    Epoch 20:	Loss 1.64562	TrainAcc 0.6685	ValidAcc 0.6891	TestAcc 0.6848
    Epoch 21:	Loss 1.56930	TrainAcc 0.6979	ValidAcc 0.7178	TestAcc 0.7112
    Epoch 22:	Loss 1.50429	TrainAcc 0.7111	ValidAcc 0.7281	TestAcc 0.7219
    Epoch 23:	Loss 1.43573	TrainAcc 0.7191	ValidAcc 0.7388	TestAcc 0.7314
    Epoch 24:	Loss 1.36816	TrainAcc 0.7293	ValidAcc 0.7473	TestAcc 0.7409
    Epoch 25:	Loss 1.30494	TrainAcc 0.7497	ValidAcc 0.7677	TestAcc 0.7618
    Epoch 26:	Loss 1.24470	TrainAcc 0.7642	ValidAcc 0.7805	TestAcc 0.7780
    Epoch 27:	Loss 1.18602	TrainAcc 0.7781	ValidAcc 0.7934	TestAcc 0.7916
    Epoch 28:	Loss 1.12977	TrainAcc 0.7911	ValidAcc 0.8082	TestAcc 0.8034
    Epoch 29:	Loss 1.08545	TrainAcc 0.7999	ValidAcc 0.8187	TestAcc 0.8148
    Epoch 30:	Loss 1.03647	TrainAcc 0.8072	ValidAcc 0.8271	TestAcc 0.8219
    Epoch 31:	Loss 0.98863	TrainAcc 0.8229	ValidAcc 0.8387	TestAcc 0.8346
    Epoch 32:	Loss 0.95229	TrainAcc 0.8308	ValidAcc 0.8474	TestAcc 0.8427
    Epoch 33:	Loss 0.91232	TrainAcc 0.8385	ValidAcc 0.8551	TestAcc 0.8512
    Epoch 34:	Loss 0.88227	TrainAcc 0.8418	ValidAcc 0.8557	TestAcc 0.8524
    Epoch 35:	Loss 0.85171	TrainAcc 0.8454	ValidAcc 0.8604	TestAcc 0.8555
    Epoch 36:	Loss 0.81914	TrainAcc 0.8495	ValidAcc 0.8643	TestAcc 0.8584
    Epoch 37:	Loss 0.78626	TrainAcc 0.8540	ValidAcc 0.8683	TestAcc 0.8634
    Epoch 38:	Loss 0.76427	TrainAcc 0.8566	ValidAcc 0.8705	TestAcc 0.8660
    Epoch 39:	Loss 0.74555	TrainAcc 0.8608	ValidAcc 0.8733	TestAcc 0.8706
    Epoch 40:	Loss 0.72486	TrainAcc 0.8658	ValidAcc 0.8784	TestAcc 0.8746
    Epoch 41:	Loss 0.70991	TrainAcc 0.8638	ValidAcc 0.8760	TestAcc 0.8722
    Epoch 42:	Loss 0.69237	TrainAcc 0.8672	ValidAcc 0.8794	TestAcc 0.8755
    Epoch 43:	Loss 0.67594	TrainAcc 0.8673	ValidAcc 0.8800	TestAcc 0.8766
    Epoch 44:	Loss 0.65761	TrainAcc 0.8672	ValidAcc 0.8799	TestAcc 0.8766
    Epoch 45:	Loss 0.65033	TrainAcc 0.8693	ValidAcc 0.8821	TestAcc 0.8794
    Epoch 46:	Loss 0.63656	TrainAcc 0.8759	ValidAcc 0.8887	TestAcc 0.8862
    Epoch 47:	Loss 0.62064	TrainAcc 0.8798	ValidAcc 0.8896	TestAcc 0.8871
    Epoch 48:	Loss 0.61057	TrainAcc 0.8777	ValidAcc 0.8887	TestAcc 0.8843
    Epoch 49:	Loss 0.60292	TrainAcc 0.8804	ValidAcc 0.8922	TestAcc 0.8883
    Epoch 50:	Loss 0.59576	TrainAcc 0.8818	ValidAcc 0.8939	TestAcc 0.8900
    Epoch 51:	Loss 0.58471	TrainAcc 0.8839	ValidAcc 0.8961	TestAcc 0.8912
    Epoch 52:	Loss 0.57823	TrainAcc 0.8830	ValidAcc 0.8962	TestAcc 0.8908
    Epoch 53:	Loss 0.57095	TrainAcc 0.8833	ValidAcc 0.8940	TestAcc 0.8894
    Epoch 54:	Loss 0.56326	TrainAcc 0.8861	ValidAcc 0.8978	TestAcc 0.8927
    Epoch 55:	Loss 0.55894	TrainAcc 0.8872	ValidAcc 0.8989	TestAcc 0.8958
    Epoch 56:	Loss 0.55685	TrainAcc 0.8875	ValidAcc 0.9001	TestAcc 0.8961
    Epoch 57:	Loss 0.54859	TrainAcc 0.8879	ValidAcc 0.8998	TestAcc 0.8952
    Epoch 58:	Loss 0.54346	TrainAcc 0.8884	ValidAcc 0.8999	TestAcc 0.8961
    Epoch 59:	Loss 0.53729	TrainAcc 0.8915	ValidAcc 0.9030	TestAcc 0.8989
    Epoch 60:	Loss 0.53055	TrainAcc 0.8926	ValidAcc 0.9031	TestAcc 0.9011
    Epoch 61:	Loss 0.53031	TrainAcc 0.8916	ValidAcc 0.9027	TestAcc 0.8997
    Epoch 62:	Loss 0.52316	TrainAcc 0.8926	ValidAcc 0.9047	TestAcc 0.9013
    Epoch 63:	Loss 0.51829	TrainAcc 0.8944	ValidAcc 0.9039	TestAcc 0.9014
    Epoch 64:	Loss 0.51199	TrainAcc 0.8969	ValidAcc 0.9048	TestAcc 0.9029
    Epoch 65:	Loss 0.51241	TrainAcc 0.8958	ValidAcc 0.9055	TestAcc 0.9029
    Epoch 66:	Loss 0.50351	TrainAcc 0.8972	ValidAcc 0.9069	TestAcc 0.9032
    Epoch 67:	Loss 0.50385	TrainAcc 0.8964	ValidAcc 0.9052	TestAcc 0.9044
    Epoch 68:	Loss 0.49972	TrainAcc 0.8977	ValidAcc 0.9075	TestAcc 0.9043
    Epoch 69:	Loss 0.49686	TrainAcc 0.8978	ValidAcc 0.9066	TestAcc 0.9035
    Epoch 70:	Loss 0.49625	TrainAcc 0.8987	ValidAcc 0.9077	TestAcc 0.9050
    Epoch 71:	Loss 0.49089	TrainAcc 0.8990	ValidAcc 0.9101	TestAcc 0.9069
    Epoch 72:	Loss 0.48774	TrainAcc 0.9000	ValidAcc 0.9091	TestAcc 0.9069
    Epoch 73:	Loss 0.48747	TrainAcc 0.8997	ValidAcc 0.9111	TestAcc 0.9075
    Epoch 74:	Loss 0.48334	TrainAcc 0.9007	ValidAcc 0.9109	TestAcc 0.9072
    Epoch 75:	Loss 0.48079	TrainAcc 0.9014	ValidAcc 0.9105	TestAcc 0.9081
    Epoch 76:	Loss 0.48018	TrainAcc 0.9014	ValidAcc 0.9106	TestAcc 0.9082
    Epoch 77:	Loss 0.47406	TrainAcc 0.9028	ValidAcc 0.9118	TestAcc 0.9096
    Epoch 78:	Loss 0.47142	TrainAcc 0.9028	ValidAcc 0.9121	TestAcc 0.9098
    Epoch 79:	Loss 0.46895	TrainAcc 0.9029	ValidAcc 0.9114	TestAcc 0.9102
    Epoch 80:	Loss 0.46881	TrainAcc 0.9026	ValidAcc 0.9112	TestAcc 0.9093
    Epoch 81:	Loss 0.46705	TrainAcc 0.9038	ValidAcc 0.9123	TestAcc 0.9111
    Epoch 82:	Loss 0.46580	TrainAcc 0.9037	ValidAcc 0.9135	TestAcc 0.9102
    Epoch 83:	Loss 0.46167	TrainAcc 0.9041	ValidAcc 0.9134	TestAcc 0.9119
    Epoch 84:	Loss 0.46139	TrainAcc 0.9045	ValidAcc 0.9131	TestAcc 0.9113
    Epoch 85:	Loss 0.45726	TrainAcc 0.9053	ValidAcc 0.9128	TestAcc 0.9116
    Epoch 86:	Loss 0.45891	TrainAcc 0.9047	ValidAcc 0.9123	TestAcc 0.9122
    Epoch 87:	Loss 0.45390	TrainAcc 0.9066	ValidAcc 0.9140	TestAcc 0.9129
    Epoch 88:	Loss 0.45373	TrainAcc 0.9061	ValidAcc 0.9152	TestAcc 0.9122
    Epoch 89:	Loss 0.45216	TrainAcc 0.9066	ValidAcc 0.9138	TestAcc 0.9121
    Epoch 90:	Loss 0.45179	TrainAcc 0.9059	ValidAcc 0.9144	TestAcc 0.9120
    Epoch 91:	Loss 0.44846	TrainAcc 0.9064	ValidAcc 0.9148	TestAcc 0.9124
    Epoch 92:	Loss 0.44690	TrainAcc 0.9072	ValidAcc 0.9156	TestAcc 0.9123
    Epoch 93:	Loss 0.44555	TrainAcc 0.9070	ValidAcc 0.9146	TestAcc 0.9132
    Epoch 94:	Loss 0.44401	TrainAcc 0.9074	ValidAcc 0.9154	TestAcc 0.9132
    Epoch 95:	Loss 0.44468	TrainAcc 0.9070	ValidAcc 0.9150	TestAcc 0.9131
    Epoch 96:	Loss 0.44073	TrainAcc 0.9076	ValidAcc 0.9165	TestAcc 0.9135
    Epoch 97:	Loss 0.44006	TrainAcc 0.9077	ValidAcc 0.9155	TestAcc 0.9143
    Epoch 98:	Loss 0.43889	TrainAcc 0.9079	ValidAcc 0.9176	TestAcc 0.9148
    Epoch 99:	Loss 0.43855	TrainAcc 0.9080	ValidAcc 0.9169	TestAcc 0.9150
------------------------node id 0,  total time 12.268609s (per-epoch: 0.122686s)---------------
************ Profiling Results ************
	Bubble: 0.000000 (s) (0.00 percentage)
	Compute: 12.162992 (s) (99.32 percentage)
	GradSync: 0.023154 (s) (0.19 percentage)
	GraphComm: 0.059878 (s) (0.49 percentage)
	Imbalance: 0.000453 (s) (0.00 percentage)
	LayerComm: 0.000000 (s) (0.00 percentage)
	Graph-level communication (cluster-wide, per epoch): 0.000 GB
	Layer-level communication (cluster-wide, per epoch): 0.000 GB
	Graph+Layer-level communication (cluster-wide, per epoch): 0.000 GB
	Parameter-server communication (cluster-wide, per epoch): 0.000 GB
	Graph-level dev2host communication time: 0.000 s, throughput: -nan GBps
	Graph-level memcpy communication time: 0.000 s, throughput: -nan GBps
	Graph-level net Activation communication time: 0.000 s, throughput: -nan GBps
	Graph-level net Gradient communication time: 0.000 s, throughput: -nan GBps
	Graph-level network batch size: -nan Bytes
Highest valid_acc: 0.9176
Target test_acc: 0.9148
Epoch to reach the target acc: 99
[MPI Rank 0] Success 
