g006.anvil.rcac.purdue.edu
Wed May 17 21:47:00 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                    0 |
| N/A   33C    P0    55W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[ 11%] Built target context
[ 36%] Built target core
[ 77%] Built target cudahelp
[ 83%] Built target estimate_comm_volume
[ 97%] Built target OSDI2023_MULTI_NODES_gcn
[100%] Built target OSDI2023_MULTI_NODES_graphsage
[100%] Built target OSDI2023_MULTI_NODES_gcnii
Initialized node 0 on machine g006.anvil.rcac.purdue.edu
Initialized node 1 on machine g007.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 0.000 seconds.
Building the CSC structure...
        It takes 0.000 seconds.
Building the Feature Vector...
Building the CSR structure...
        It takes 0.000 seconds.
Building the CSC structure...
        It takes 0.000 seconds.
Building the Feature Vector...
        It takes 0.043 seconds.
Building the Label Vector...
        It takes 0.000 seconds.
        It takes 0.039 seconds.
Building the Label Vector...
        It takes 0.000 seconds.
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/cora
The number of GCNII layers: 64
The number of hidden units: 64
The number of training epoches: 1500
Learning rate: 0.010000
The partition strategy: model
The dropout rate: 0.000
The checkpointed weight file: /anvil/projects/x-cis220117/saved_weights_pipe
The random seed: 5
GCN hyper-parameter alpha: 0.000000
GCN hyper-parameter lambda: 0.500000
Number of classes: 7
Number of feature dimensions: 1433
Number of vertices: 2708
Number of GPUs: 2
train nodes 140, valid nodes 500, test nodes 1000
GPU 0, layer [0, 33)
GPU 1, layer [33, 66)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the model-level partition [0, 230)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_DROPOUT, output tensors: 1
    Op 2: type OPERATOR_WEIGHT, output tensors: 2
    Op 3: type OPERATOR_MATMUL, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_AGGREGATION, output tensors: 6
    Op 7: type OPERATOR_ADD, output tensors: 7
    Op 8: type OPERATOR_WEIGHT, output tensors: 8
    Op 9: type OPERATOR_MATMUL, output tensors: 9
    Op 10: type OPERATOR_ADD, output tensors: 10
    Op 11: type OPERATOR_RELU, output tensors: 11
    Op 12: type OPERATOR_DROPOUT, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_ADD, output tensors: 14
    Op 15: type OPERATOR_WEIGHT, output tensors: 15
    Op 16: type OPERATOR_MATMUL, output tensors: 16
    Op 17: type OPERATOR_ADD, output tensors: 17
    Op 18: type OPERATOR_RELU, output tensors: 18
    Op 19: type OPERATOR_DROPOUT, output tensors: 19
    Op 20: type OPERATOR_AGGREGATION, output tensors: 20
    Op 21: type OPERATOR_ADD, output tensors: 21
    Op 22: type OPERATOR_WEIGHT, output tensors: 22
    Op 23: type OPERATOR_MATMUL, output tensors: 23
    Op 24: type OPERATOR_ADD, output tensors: 24
    Op 25: type OPERATOR_RELU, output tensors: 25
    Op 26: type OPERATOR_DROPOUT, output tensors: 26
    Op 27: type OPERATOR_AGGREGATION, output tensors: 27
    Op 28: type OPERATOR_ADD, output tensors: 28
    Op 29: type OPERATOR_WEIGHT, output tensors: 29
    Op 30: type OPERATOR_MATMUL, output tensors: 30
    Op 31: type OPERATOR_ADD, output tensors: 31
    Op 32: type OPERATOR_RELU, output tensors: 32
    Op 33: type OPERATOR_DROPOUT, output tensors: 33
    Op 34: type OPERATOR_AGGREGATION, output tensors: 34
    Op 35: type OPERATOR_ADD, output tensors: 35
    Op 36: type OPERATOR_WEIGHT, output tensors: 36
    Op 37: type OPERATOR_MATMUL, output tensors: 37
    Op 38: type OPERATOR_ADD, output tensors: 38
    Op 39: type OPERATOR_RELU, output tensors: 39
    Op 40: type OPERATOR_DROPOUT, output tensors: 40
    Op 41: type OPERATOR_AGGREGATION, output tensors: 41
    Op 42: type OPERATOR_ADD, output tensors: 42
    Op 43: type OPERATOR_WEIGHT, output tensors: 43
    Op 44: type OPERATOR_MATMUL, output tensors: 44
    Op 45: type OPERATOR_ADD, output tensors: 45
    Op 46: type OPERATOR_RELU, output tensors: 46
    Op 47: type OPERATOR_DROPOUT, output tensors: 47
    Op 48: type OPERATOR_AGGREGATION, output tensors: 48
    Op 49: type OPERATOR_ADD, output tensors: 49
    Op 50: type OPERATOR_WEIGHT, output tensors: 50
    Op 51: type OPERATOR_MATMUL, output tensors: 51
    Op 52: type OPERATOR_ADD, output tensors: 52
    Op 53: type OPERATOR_RELU, output tensors: 53
    Op 54: type OPERATOR_DROPOUT, output tensors: 54
    Op 55: type OPERATOR_AGGREGATION, output tensors: 55
    Op 56: type OPERATOR_ADD, output tensors: 56
    Op 57: type OPERATOR_WEIGHT, output tensors: 57
    Op 58: type OPERATOR_MATMUL, output tensors: 58
    Op 59: type OPERATOR_ADD, output tensors: 59
    Op 60: type OPERATOR_RELU, output tensors: 60
    Op 61: type OPERATOR_DROPOUT, output tensors: 61
    Op 62: type OPERATOR_AGGREGATION, output tensors: 62
    Op 63: type OPERATOR_ADD, output tensors: 63
    Op 64: type OPERATOR_WEIGHT, output tensors: 64
    Op 65: type OPERATOR_MATMUL, output tensors: 65
    Op 66: type OPERATOR_ADD, output tensors: 66
    Op 67: type OPERATOR_RELU, output tensors: 67
    Op 68: type OPERATOR_DROPOUT, output tensors: 68
    Op 69: type OPERATOR_AGGREGATION, output tensors: 69
    Op 70: type OPERATOR_ADD, output tensors: 70
    Op 71: type OPERATOR_WEIGHT, output tensors: 71
    Op 72: type OPERATOR_MATMUL, output tensors: 72
    Op 73: type OPERATOR_ADD, output tensors: 73
    Op 74: type OPERATOR_RELU, output tensors: 74
    Op 75: type OPERATOR_DROPOUT, output tensors: 75
    Op 76: type OPERATOR_AGGREGATION, output tensors: 76
    Op 77: type OPERATOR_ADD, output tensors: 77
    Op 78: type OPERATOR_WEIGHT, output tensors: 78
    Op 79: type OPERATOR_MATMUL, output tensors: 79
    Op 80: type OPERATOR_ADD, output tensors: 80
    Op 81: type OPERATOR_RELU, output tensors: 81
    Op 82: type OPERATOR_DROPOUT, output tensors: 82
    Op 83: type OPERATOR_AGGREGATION, output tensors: 83
    Op 84: type OPERATOR_ADD, output tensors: 84
    Op 85: type OPERATOR_WEIGHT, output tensors: 85
    Op 86: type OPERATOR_MATMUL, output tensors: 86
    Op 87: type OPERATOR_ADD, output tensors: 87
    Op 88: type OPERATOR_RELU, output tensors: 88
    Op 89: type OPERATOR_DROPOUT, output tensors: 89
    Op 90: type OPERATOR_AGGREGATION, output tensors: 90
    Op 91: type OPERATOR_ADD, output tensors: 91
    Op 92: type OPERATOR_WEIGHT, output tensors: 92
    Op 93: type OPERATOR_MATMUL, output tensors: 93
    Op 94: type OPERATOR_ADD, output tensors: 94
    Op 95: type OPERATOR_RELU, output tensors: 95
    Op 96: type OPERATOR_DROPOUT, output tensors: 96
    Op 97: type OPERATOR_AGGREGATION, output tensors: 97
    Op 98: type OPERATOR_ADD, output tensors: 98
    Op 99: type OPERATOR_WEIGHT, output tensors: 99
    Op 100: type OPERATOR_MATMUL, output tensors: 100
    Op 101: type OPERATOR_ADD, output tensors: 101
    Op 102: type OPERATOR_RELU, output tensors: 102
    Op 103: type OPERATOR_DROPOUT, output tensors: 103
    Op 104: type OPERATOR_AGGREGATION, output tensors: 104
    Op 105: type OPERATOR_ADD, output tensors: 105
    Op 106: type OPERATOR_WEIGHT, output tensors: 106
    Op 107: type OPERATOR_MATMUL, output tensors: 107
    Op 108: type OPERATOR_ADD, output tensors: 108
    Op 109: type OPERATOR_RELU, output tensors: 109
    Op 110: type OPERATOR_DROPOUT, output tensors: 110
    Op 111: type OPERATOR_AGGREGATION, output tensors: 111
    Op 112: type OPERATOR_ADD, output tensors: 112
    Op 113: type OPERATOR_WEIGHT, output tensors: 113
    Op 114: type OPERATOR_MATMUL, output tensors: 114
    Op 115: type OPERATOR_ADD, output tensors: 115
    Op 116: type OPERATOR_RELU, output tensors: 116
    Op 117: type OPERATOR_DROPOUT, output tensors: 117
    Op 118: type OPERATOR_AGGREGATION, output tensors: 118
    Op 119: type OPERATOR_ADD, output tensors: 119
    Op 120: type OPERATOR_WEIGHT, output tensors: 120
    Op 121: type OPERATOR_MATMUL, output tensors: 121
    Op 122: type OPERATOR_ADD, output tensors: 122
    Op 123: type OPERATOR_RELU, output tensors: 123
    Op 124: type OPERATOR_DROPOUT, output tensors: 124
    Op 125: type OPERATOR_AGGREGATION, output tensors: 125
    Op 126: type OPERATOR_ADD, output tensors: 126
    Op 127: type OPERATOR_WEIGHT, output tensors: 127
    Op 128: type OPERATOR_MATMUL, output tensors: 128
    Op 129: type OPERATOR_ADD, output tensors: 129
    Op 130: type OPERATOR_RELU, output tensors: 130
    Op 131: type OPERATOR_DROPOUT, output tensors: 131
    Op 132: type OPERATOR_AGGREGATION, output tensors: 132
    Op 133: type OPERATOR_ADD, output tensors: 133
    Op 134: type OPERATOR_WEIGHT, output tensors: 134
    Op 135: type OPERATOR_MATMUL, output tensors: 135
    Op 136: type OPERATOR_ADD, output tensors: 136
    Op 137: type OPERATOR_RELU, output tensors: 137
    Op 138: type OPERATOR_DROPOUT, output tensors: 138
    Op 139: type OPERATOR_AGGREGATION, output tensors: 139
    Op 140: type OPERATOR_ADD, output tensors: 140
    Op 141: type OPERATOR_WEIGHT, output tensors: 141
    Op 142: type OPERATOR_MATMUL, output tensors: 142
    Op 143: type OPERATOR_ADD, output tensors: 143
    Op 144: type OPERATOR_RELU, output tensors: 144
    Op 145: type OPERATOR_DROPOUT, output tensors: 145
    Op 146: type OPERATOR_AGGREGATION, output tensors: 146
    Op 147: type OPERATOR_ADD, output tensors: 147
    Op 148: type OPERATOR_WEIGHT, output tensors: 148
    Op 149: type OPERATOR_MATMUL, output tensors: 149
    Op 150: type OPERATOR_ADD, output tensors: 150
    Op 151: type OPERATOR_RELU, output tensors: 151
    Op 152: type OPERATOR_DROPOUT, output tensors: 152
    Op 153: type OPERATOR_AGGREGATION, output tensors: 153
    Op 154: type OPERATOR_ADD, output tensors: 154
    Op 155: type OPERATOR_WEIGHT, output tensors: 155
    Op 156: type OPERATOR_MATMUL, output tensors: 156
    Op 157: type OPERATOR_ADD, output tensors: 157
    Op 158: type OPERATOR_RELU, output tensors: 158
    Op 159: type OPERATOR_DROPOUT, output tensors: 159
    Op 160: type OPERATOR_AGGREGATION, output tensors: 160
    Op 161: type OPERATOR_ADD, output tensors: 161
    Op 162: type OPERATOR_WEIGHT, output tensors: 162
    Op 163: type OPERATOR_MATMUL, output tensors: 163
    Op 164: type OPERATOR_ADD, output tensors: 164
    Op 165: type OPERATOR_RELU, output tensors: 165
    Op 166: type OPERATOR_DROPOUT, output tensors: 166
    Op 167: type OPERATOR_AGGREGATION, output tensors: 167
    Op 168: type OPERATOR_ADD, output tensors: 168
    Op 169: type OPERATOR_WEIGHT, output tensors: 169
    Op 170: type OPERATOR_MATMUL, output tensors: 170
    Op 171: type OPERATOR_ADD, output tensors: 171
    Op 172: type OPERATOR_RELU, output tensors: 172
    Op 173: type OPERATOR_DROPOUT, output tensors: 173
    Op 174: type OPERATOR_AGGREGATION, output tensors: 174
    Op 175: type OPERATOR_ADD, output tensors: 175
    Op 176: type OPERATOR_WEIGHT, output tensors: 176
    Op 177: type OPERATOR_MATMUL, output tensors: 177
    Op 178: type OPERATOR_ADD, output tensors: 178
    Op 179: type OPERATOR_RELU, output tensors: 179
    Op 180: type OPERATOR_DROPOUT, output tensors: 180
    Op 181: type OPERATOR_AGGREGATION, output tensors: 181
    Op 182: type OPERATOR_ADD, output tensors: 182
    Op 183: type OPERATOR_WEIGHT, output tensors: 183
    Op 184: type OPERATOR_MATMUL, output tensors: 184
    Op 185: type OPERATOR_ADD, output tensors: 185
    Op 186: type OPERATOR_RELU, output tensors: 186
    Op 187: type OPERATOR_DROPOUT, output tensors: 187
    Op 188: type OPERATOR_AGGREGATION, output tensors: 188
    Op 189: type OPERATOR_ADD, output tensors: 189
    Op 190: type OPERATOR_WEIGHT, output tensors: 190
    Op 191: type OPERATOR_MATMUL, output tensors: 191
    Op 192: type OPERATOR_ADD, output tensors: 192
    Op 193: type OPERATOR_RELU, output tensors: 193
    Op 194: type OPERATOR_DROPOUT, output tensors: 194
    Op 195: type OPERATOR_AGGREGATION, output tensors: 195
    Op 196: type OPERATOR_ADD, output tensors: 196
    Op 197: type OPERATOR_WEIGHT, output tensors: 197
    Op 198: type OPERATOR_MATMUL, output tensors: 198
    Op 199: type OPERATOR_ADD, output tensors: 199
    Op 200: type OPERATOR_RELU, output tensors: 200
    Op 201: type OPERATOR_DROPOUT, output tensors: 201
    Op 202: type OPERATOR_AGGREGATION, output tensors: 202
    Op 203: type OPERATOR_ADD, output tensors: 203
    Op 204: type OPERATOR_WEIGHT, output tensors: 204
    Op 205: type OPERATOR_MATMUL, output tensors: 205
    Op 206: type OPERATOR_ADD, output tensors: 206
    Op 207: type OPERATOR_RELU, output tensors: 207
    Op 208: type OPERATOR_DROPOUT, output tensors: 208
    Op 209: type OPERATOR_AGGREGATION, output tensors: 209
    Op 210: type OPERATOR_ADD, output tensors: 210
    Op 211: type OPERATOR_WEIGHT, output tensors: 211
    Op 212: type OPERATOR_MATMUL, output tensors: 212
    Op 213: type OPERATOR_ADD, output tensors: 213
    Op 214: type OPERATOR_RELU, output tensors: 214
    Op 215: type OPERATOR_DROPOUT, output tensors: 215
    Op 216: type OPERATOR_AGGREGATION, output tensors: 216
    Op 217: type OPERATOR_ADD, output tensors: 217
    Op 218: type OPERATOR_WEIGHT, output tensors: 218
    Op 219: type OPERATOR_MATMUL, output tensors: 219
    Op 220: type OPERATOR_ADD, output tensors: 220
    Op 221: type OPERATOR_RELU, output tensors: 221
    Op 222: type OPERATOR_DROPOUT, output tensors: 222
    Op 223: type OPERATOR_AGGREGATION, output tensors: 223
    Op 224: type OPERATOR_ADD, output tensors: 224
    Op 225: type OPERATOR_WEIGHT, output tensors: 225
    Op 226: type OPERATOR_MATMUL, output tensors: 226
    Op 227: type OPERATOR_ADD, output tensors: 227
    Op 228: type OPERATOR_RELU, output tensors: 228
    Op 229: type OPERATOR_DROPOUT, output tensors: 229
    Op 230: type OPERATOR_AGGREGATION, output tensors: 230
    Op 231: type OPERATOR_ADD, output tensors: 231
    Op 232: type OPERATOR_WEIGHT, output tensors: 232
    Op 233: type OPERATOR_MATMUL, output tensors: 233
    Op 234: type OPERATOR_ADD, output tensors: 234
    Op 235: type OPERATOR_RELU, output tensors: 235
    Op 236: type OPERATOR_DROPOUT, output tensors: 236
    Op 237: type OPERATOR_AGGREGATION, output tensors: 237
    Op 238: type OPERATOR_ADD, output tensors: 238
    Op 239: type OPERATOR_WEIGHT, output tensors: 239
    Op 240: type OPERATOR_MATMUL, output tensors: 240
    Op 241: type OPERATOR_ADD, output tensors: 241
    Op 242: type OPERATOR_RELU, output tensors: 242
    Op 243: type OPERATOR_DROPOUT, output tensors: 243
    Op 244: type OPERATOR_AGGREGATION, output tensors: 244
    Op 245: type OPERATOR_ADD, output tensors: 245
    Op 246: type OPERATOR_WEIGHT, output tensors: 246
    Op 247: type OPERATOR_MATMUL, output tensors: 247
    Op 248: type OPERATOR_ADD, output tensors: 248
    Op 249: type OPERATOR_RELU, output tensors: 249
    Op 250: type OPERATOR_DROPOUT, output tensors: 250
    Op 251: type OPERATOR_AGGREGATION, output tensors: 251
    Op 252: type OPERATOR_ADD, output tensors: 252
    Op 253: type OPERATOR_WEIGHT, output tensors: 253
    Op 254: type OPERATOR_MATMUL, output tensors: 254
    Op 255: type OPERATOR_ADD, output tensors: 255
    Op 256: type OPERATOR_RELU, output tensors: 256
    Op 257: type OPERATOR_DROPOUT, output tensors: 257
    Op 258: type OPERATOR_AGGREGATION, output tensors: 258
    Op 259: type OPERATOR_ADD, output tensors: 259
    Op 260: type OPERATOR_WEIGHT, output tensors: 260
    Op 261: type OPERATOR_MATMUL, output tensors: 261
    Op 262: type OPERATOR_ADD, output tensors: 262
    Op 263: type OPERATOR_RELU, output tensors: 263
    Op 264: type OPERATOR_DROPOUT, output tensors: 264
    Op 265: type OPERATOR_AGGREGATION, output tensors: 265
    Op 266: type OPERATOR_ADD, output tensors: 266
    Op 267: type OPERATOR_WEIGHT, output tensors: 267
    Op 268: type OPERATOR_MATMUL, output tensors: 268
    Op 269: type OPERATOR_ADD, output tensors: 269
    Op 270: type OPERATOR_RELU, output tensors: 270
    Op 271: type OPERATOR_DROPOUT, output tensors: 271
    Op 272: type OPERATOR_AGGREGATION, output tensors: 272
    Op 273: type OPERATOR_ADD, output tensors: 273
    Op 274: type OPERATOR_WEIGHT, output tensors: 274
    Op 275: type OPERATOR_MATMUL, output tensors: 275
    Op 276: type OPERATOR_ADD, output tensors: 276
    Op 277: type OPERATOR_RELU, output tensors: 277
    Op 278: type OPERATOR_DROPOUT, output tensors: 278
    Op 279: type OPERATOR_AGGREGATION, output tensors: 279
    Op 280: type OPERATOR_ADD, output tensors: 280
    Op 281: type OPERATOR_WEIGHT, output tensors: 281
    Op 282: type OPERATOR_MATMUL, output tensors: 282
    Op 283: type OPERATOR_ADD, output tensors: 283
    Op 284: type OPERATOR_RELU, output tensors: 284
    Op 285: type OPERATOR_DROPOUT, output tensors: 285
    Op 286: type OPERATOR_AGGREGATION, output tensors: 286
    Op 287: type OPERATOR_ADD, output tensors: 287
    Op 288: type OPERATOR_WEIGHT, output tensors: 288
    Op 289: type OPERATOR_MATMUL, output tensors: 289
    Op 290: type OPERATOR_ADD, output tensors: 290
    Op 291: type OPERATOR_RELU, output tensors: 291
    Op 292: type OPERATOR_DROPOUT, output tensors: 292
    Op 293: type OPERATOR_AGGREGATION, output tensors: 293
    Op 294: type OPERATOR_ADD, output tensors: 294
    Op 295: type OPERATOR_WEIGHT, output tensors: 295
    Op 296: type OPERATOR_MATMUL, output tensors: 296
    Op 297: type OPERATOR_ADD, output tensors: 297
    Op 298: type OPERATOR_RELU, output tensors: 298
    Op 299: type OPERATOR_DROPOUT, output tensors: 299
    Op 300: type OPERATOR_AGGREGATION, output tensors: 300
    Op 301: type OPERATOR_ADD, output tensors: 301
    Op 302: type OPERATOR_WEIGHT, output tensors: 302
    Op 303: type OPERATOR_MATMUL, output tensors: 303
    Op 304: type OPERATOR_ADD, output tensors: 304
    Op 305: type OPERATOR_RELU, output tensors: 305
    Op 306: type OPERATOR_DROPOUT, output tensors: 306
    Op 307: type OPERATOR_AGGREGATION, output tensors: 307
    Op 308: type OPERATOR_ADD, output tensors: 308
    Op 309: type OPERATOR_WEIGHT, output tensors: 309
    Op 310: type OPERATOR_MATMUL, output tensors: 310
    Op 311: type OPERATOR_ADD, output tensors: 311
    Op 312: type OPERATOR_RELU, output tensors: 312
    Op 313: type OPERATOR_DROPOUT, output tensors: 313
    Op 314: type OPERATOR_AGGREGATION, output tensors: 314
    Op 315: type OPERATOR_ADD, output tensors: 315
    Op 316: type OPERATOR_WEIGHT, output tensors: 316
    Op 317: type OPERATOR_MATMUL, output tensors: 317
    Op 318: type OPERATOR_ADD, output tensors: 318
    Op 319: type OPERATOR_RELU, output tensors: 319
    Op 320: type OPERATOR_DROPOUT, output tensors: 320
    Op 321: type OPERATOR_AGGREGATION, output tensors: 321
    Op 322: type OPERATOR_ADD, output tensors: 322
    Op 323: type OPERATOR_WEIGHT, output tensors: 323
    Op 324: type OPERATOR_MATMUL, output tensors: 324
    Op 325: type OPERATOR_ADD, output tensors: 325
    Op 326: type OPERATOR_RELU, output tensors: 326
    Op 327: type OPERATOR_DROPOUT, output tensors: 327
    Op 328: type OPERATOR_AGGREGATION, output tensors: 328
    Op 329: type OPERATOR_ADD, output tensors: 329
    Op 330: type OPERATOR_WEIGHT, output tensors: 330
    Op 331: type OPERATOR_MATMUL, output tensors: 331
    Op 332: type OPERATOR_ADD, output tensors: 332
    Op 333: type OPERATOR_RELU, output tensors: 333
    Op 334: type OPERATOR_DROPOUT, output tensors: 334
    Op 335: type OPERATOR_AGGREGATION, output tensors: 335
    Op 336: type OPERATOR_ADD, output tensors: 336
    Op 337: type OPERATOR_WEIGHT, output tensors: 337
    Op 338: type OPERATOR_MATMUL, output tensors: 338
    Op 339: type OPERATOR_ADD, output tensors: 339
    Op 340: type OPERATOR_RELU, output tensors: 340
    Op 341: type OPERATOR_DROPOUT, output tensors: 341
    Op 342: type OPERATOR_AGGREGATION, output tensors: 342
    Op 343: type OPERATOR_ADD, output tensors: 343
    Op 344: type OPERATOR_WEIGHT, output tensors: 344
    Op 345: type OPERATOR_MATMUL, output tensors: 345
    Op 346: type OPERATOR_ADD, output tensors: 346
    Op 347: type OPERATOR_RELU, output tensors: 347
    Op 348: type OPERATOR_DROPOUT, output tensors: 348
    Op 349: type OPERATOR_AGGREGATION, output tensors: 349
    Op 350: type OPERATOR_ADD, output tensors: 350
    Op 351: type OPERATOR_WEIGHT, output tensors: 351
    Op 352: type OPERATOR_MATMUL, output tensors: 352
    Op 353: type OPERATOR_ADD, output tensors: 353
    Op 354: type OPERATOR_RELU, output tensors: 354
    Op 355: type OPERATOR_DROPOUT, output tensors: 355
    Op 356: type OPERATOR_AGGREGATION, output tensors: 356
    Op 357: type OPERATOR_ADD, output tensors: 357
    Op 358: type OPERATOR_WEIGHT, output tensors: 358
    Op 359: type OPERATOR_MATMUL, output tensors: 359
    Op 360: type OPERATOR_ADD, output tensors: 360
    Op 361: type OPERATOR_RELU, output tensors: 361
    Op 362: type OPERATOR_DROPOUT, output tensors: 362
    Op 363: type OPERATOR_AGGREGATION, output tensors: 363
    Op 364: type OPERATOR_ADD, output tensors: 364
    Op 365: type OPERATOR_WEIGHT, output tensors: 365
    Op 366: type OPERATOR_MATMUL, output tensors: 366
    Op 367: type OPERATOR_ADD, output tensors: 367
    Op 368: type OPERATOR_RELU, output tensors: 368
    Op 369: type OPERATOR_DROPOUT, output tensors: 369
    Op 370: type OPERATOR_AGGREGATION, output tensors: 370
    Op 371: type OPERATOR_ADD, output tensors: 371
    Op 372: type OPERATOR_WEIGHT, output tensors: 372
    Op 373: type OPERATOR_MATMUL, output tensors: 373
    Op 374: type OPERATOR_ADD, output tensors: 374
    Op 375: type OPERATOR_RELU, output tensors: 375
    Op 376: type OPERATOR_DROPOUT, output tensors: 376
    Op 377: type OPERATOR_AGGREGATION, output tensors: 377
    Op 378: type OPERATOR_ADD, output tensors: 378
    Op 379: type OPERATOR_WEIGHT, output tensors: 379
    Op 380: type OPERATOR_MATMUL, output tensors: 380
    Op 381: type OPERATOR_ADD, output tensors: 381
    Op 382: type OPERATOR_RELU, output tensors: 382
    Op 383: type OPERATOR_DROPOUT, output tensors: 383
    Op 384: type OPERATOR_AGGREGATION, output tensors: 384
    Op 385: type OPERATOR_ADD, output tensors: 385
    Op 386: type OPERATOR_WEIGHT, output tensors: 386
    Op 387: type OPERATOR_MATMUL, output tensors: 387
    Op 388: type OPERATOR_ADD, output tensors: 388
    Op 389: type OPERATOR_RELU, output tensors: 389
    Op 390: type OPERATOR_DROPOUT, output tensors: 390
    Op 391: type OPERATOR_AGGREGATION, output tensors: 391
    Op 392: type OPERATOR_ADD, output tensors: 392
    Op 393: type OPERATOR_WEIGHT, output tensors: 393
    Op 394: type OPERATOR_MATMUL, output tensors: 394
    Op 395: type OPERATOR_ADD, output tensors: 395
    Op 396: type OPERATOR_RELU, output tensors: 396
    Op 397: type OPERATOR_DROPOUT, output tensors: 397
    Op 398: type OPERATOR_AGGREGATION, output tensors: 398
    Op 399: type OPERATOR_ADD, output tensors: 399
    Op 400: type OPERATOR_WEIGHT, output tensors: 400
    Op 401: type OPERATOR_MATMUL, output tensors: 401
    Op 402: type OPERATOR_ADD, output tensors: 402
    Op 403: type OPERATOR_RELU, output tensors: 403
    Op 404: type OPERATOR_DROPOUT, output tensors: 404
    Op 405: type OPERATOR_AGGREGATION, output tensors: 405
    Op 406: type OPERATOR_ADD, output tensors: 406
    Op 407: type OPERATOR_WEIGHT, output tensors: 407
    Op 408: type OPERATOR_MATMUL, output tensors: 408
    Op 409: type OPERATOR_ADD, output tensors: 409
    Op 410: type OPERATOR_RELU, output tensors: 410
    Op 411: type OPERATOR_DROPOUT, output tensors: 411
    Op 412: type OPERATOR_AGGREGATION, output tensors: 412
    Op 413: type OPERATOR_ADD, output tensors: 413
    Op 414: type OPERATOR_WEIGHT, output tensors: 414
    Op 415: type OPERATOR_MATMUL, output tensors: 415
    Op 416: type OPERATOR_ADD, output tensors: 416
    Op 417: type OPERATOR_RELU, output tensors: 417
    Op 418: type OPERATOR_DROPOUT, output tensors: 418
    Op 419: type OPERATOR_AGGREGATION, output tensors: 419
    Op 420: type OPERATOR_ADD, output tensors: 420
    Op 421: type OPERATOR_WEIGHT, output tensors: 421
    Op 422: type OPERATOR_MATMUL, output tensors: 422
    Op 423: type OPERATOR_ADD, output tensors: 423
    Op 424: type OPERATOR_RELU, output tensors: 424
    Op 425: type OPERATOR_DROPOUT, output tensors: 425
    Op 426: type OPERATOR_AGGREGATION, output tensors: 426
    Op 427: type OPERATOR_ADD, output tensors: 427
    Op 428: type OPERATOR_WEIGHT, output tensors: 428
    Op 429: type OPERATOR_MATMUL, output tensors: 429
    Op 430: type OPERATOR_ADD, output tensors: 430
    Op 431: type OPERATOR_RELU, output tensors: 431
    Op 432: type OPERATOR_DROPOUT, output tensors: 432
    Op 433: type OPERATOR_AGGREGATION, output tensors: 433
    Op 434: type OPERATOR_ADD, output tensors: 434
    Op 435: type OPERATOR_WEIGHT, output tensors: 435
    Op 436: type OPERATOR_MATMUL, output tensors: 436
    Op 437: type OPERATOR_ADD, output tensors: 437
    Op 438: type OPERATOR_RELU, output tensors: 438
    Op 439: type OPERATOR_DROPOUT, output tensors: 439
    Op 440: type OPERATOR_AGGREGATION, output tensors: 440
    Op 441: type OPERATOR_ADD, output tensors: 441
    Op 442: type OPERATOR_WEIGHT, output tensors: 442
    Op 443: type OPERATOR_MATMUL, output tensors: 443
    Op 444: type OPERATOR_ADD, output tensors: 444
    Op 445: type OPERATOR_RELU, output tensors: 445
    Op 446: type OPERATOR_DROPOUT, output tensors: 446
    Op 447: type OPERATOR_AGGREGATION, output tensors: 447
    Op 448: type OPERATOR_ADD, output tensors: 448
    Op 449: type OPERATOR_WEIGHT, output tensors: 449
    Op 450: type OPERATOR_MATMUL, output tensors: 450
    Op 451: type OPERATOR_ADD, output tensors: 451
    Op 452: type OPERATOR_RELU, output tensors: 452
    Op 453: type OPERATOR_DROPOUT, output tensors: 453
    Op 454: type OPERATOR_WEIGHT, output tensors: 454
    Op 455: type OPERATOR_MATMUL, output tensors: 455
    Op 456: type OPERATOR_SOFTMAX, output tensors: 456
Boundaries: 0 0 2708 2708
Fragments: [0, 2708)
Chunks (number of global chunks: 1): 0-[0, 2708)
2708, 13264, 13264
Number of vertices per chunk: 2708
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 33)
GPU 1, layer [33, 66)
*** Node 1, starting model training...
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [230, 457)
*** Node 1, constructing the helper classes...
2708, 13264, 13264
Number of vertices per chunk: 2708
csr in-out ready !*** Node 1, setting up some other necessary information...
csr in-out ready !*** Node 0, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 1, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 230)...
+++++++++ Node 0, mapping weight op 2
+++++++++ Node 0, mapping weight op 8
+++++++++ Node 0, mapping weight op 15
+++++++++ Node 0, mapping weight op 22
+++++++++ Node 0, mapping weight op 29
+++++++++ Node 0, mapping weight op 36
+++++++++ Node 0, mapping weight op 43
+++++++++ Node 0, mapping weight op 50
+++++++++ Node 0, mapping weight op 57
+++++++++ Node 0, mapping weight op 64
+++++++++ Node 0, mapping weight op 71
+++++++++ Node 0, mapping weight op 78
+++++++++ Node 0, mapping weight op 85
+++++++++ Node 0, mapping weight op 92
+++++++++ Node 0, mapping weight op 99
+++++++++ Node 0, mapping weight op 106
+++++++++ Node 0, mapping weight op 113
+++++++++ Node 0, mapping weight op 120
+++++++++ Node 0, mapping weight op 127
+++++++++ Node 0, mapping weight op 134
+++++++++ Node 0, mapping weight op 141
+++++++++ Node 0, mapping weight op 148
+++++++++ Node 0, mapping weight op 155
+++++++++ Node 0, mapping weight op 162
+++++++++ Node 0, mapping weight op 169
+++++++++ Node 0, mapping weight op 176
+++++++++ Node 0, mapping weight op 183
+++++++++ Node 0, mapping weight op 190
+++++++++ Node 0, mapping weight op 197
+++++++++ Node 0, mapping weight op 204
+++++++++ Node 0, mapping weight op 211
+++++++++ Node 0, mapping weight op 218
+++++++++ Node 0, mapping weight op 225
+++++++++ Node 1 initializing the weights for op[230, 457)...
+++++++++ Node 1, mapping weight op 232
+++++++++ Node 1, mapping weight op 239
+++++++++ Node 1, mapping weight op 246
+++++++++ Node 1, mapping weight op 253
+++++++++ Node 1, mapping weight op 260
+++++++++ Node 1, mapping weight op 267
+++++++++ Node 1, mapping weight op 274
+++++++++ Node 1, mapping weight op 281
+++++++++ Node 1, mapping weight op 288
+++++++++ Node 1, mapping weight op 295
+++++++++ Node 1, mapping weight op 302
+++++++++ Node 1, mapping weight op 309
+++++++++ Node 1, mapping weight op 316
+++++++++ Node 1, mapping weight op 323
+++++++++ Node 1, mapping weight op 330
+++++++++ Node 1, mapping weight op 337
+++++++++ Node 1, mapping weight op 344
+++++++++ Node 1, mapping weight op 351
+++++++++ Node 1, mapping weight op 358
+++++++++ Node 1, mapping weight op 365
+++++++++ Node 1, mapping weight op 372
+++++++++ Node 1, mapping weight op 379
+++++++++ Node 1, mapping weight op 386
+++++++++ Node 1, mapping weight op 393
+++++++++ Node 1, mapping weight op 400
+++++++++ Node 1, mapping weight op 407
+++++++++ Node 1, mapping weight op 414
+++++++++ Node 1, mapping weight op 421
+++++++++ Node 1, mapping weight op 428
+++++++++ Node 1, mapping weight op 435
+++++++++ Node 1, mapping weight op 442
+++++++++ Node 1, mapping weight op 449
+++++++++ Node 1, mapping weight op 454
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.010000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.010000000
	Epoch 10:	Loss 1.9455	TrainAcc 0.2286	ValidAcc 0.1760	BestValid 0.1760
	Epoch 20:	Loss 1.9456	TrainAcc 0.1714	ValidAcc 0.0660	BestValid 0.1760
	Epoch 30:	Loss 1.9449	TrainAcc 0.1500	ValidAcc 0.0580	BestValid 0.1760
	Epoch 40:	Loss 1.8666	TrainAcc 0.1429	ValidAcc 0.0580	BestValid 0.1760
	Epoch 50:	Loss 1.8096	TrainAcc 0.2786	ValidAcc 0.1200	BestValid 0.1760
	Epoch 60:	Loss 1.8051	TrainAcc 0.2786	ValidAcc 0.1460	BestValid 0.1760
	Epoch 70:	Loss 1.7744	TrainAcc 0.2429	ValidAcc 0.2160	BestValid 0.2160
	Epoch 80:	Loss 1.6608	TrainAcc 0.2143	ValidAcc 0.1780	BestValid 0.2160
	Epoch 90:	Loss 1.6692	TrainAcc 0.2071	ValidAcc 0.1600	BestValid 0.2160
	Epoch 100:	Loss 1.5609	TrainAcc 0.3357	ValidAcc 0.2740	BestValid 0.2740
	Epoch 110:	Loss 1.5098	TrainAcc 0.4643	ValidAcc 0.3300	BestValid 0.3300
	Epoch 120:	Loss 1.3958	TrainAcc 0.4429	ValidAcc 0.3140	BestValid 0.3300
	Epoch 130:	Loss 1.2929	TrainAcc 0.4357	ValidAcc 0.2980	BestValid 0.3300
	Epoch 140:	Loss 1.2372	TrainAcc 0.4429	ValidAcc 0.3320	BestValid 0.3320
	Epoch 150:	Loss 1.1993	TrainAcc 0.4429	ValidAcc 0.3220	BestValid 0.3320
	Epoch 160:	Loss 1.1663	TrainAcc 0.5643	ValidAcc 0.4100	BestValid 0.4100
	Epoch 170:	Loss 1.1468	TrainAcc 0.5500	ValidAcc 0.4280	BestValid 0.4280
	Epoch 180:	Loss 1.1111	TrainAcc 0.5643	ValidAcc 0.4400	BestValid 0.4400
	Epoch 190:	Loss 1.2246	TrainAcc 0.5143	ValidAcc 0.4220	BestValid 0.4400
	Epoch 200:	Loss 1.1853	TrainAcc 0.5643	ValidAcc 0.4400	BestValid 0.4400
	Epoch 210:	Loss 1.1237	TrainAcc 0.5857	ValidAcc 0.4340	BestValid 0.4400
	Epoch 220:	Loss 1.0654	TrainAcc 0.6214	ValidAcc 0.4660	BestValid 0.4660
	Epoch 230:	Loss 1.0264	TrainAcc 0.6286	ValidAcc 0.4860	BestValid 0.4860
	Epoch 240:	Loss 0.9853	TrainAcc 0.6643	ValidAcc 0.4960	BestValid 0.4960
	Epoch 250:	Loss 1.0381	TrainAcc 0.5571	ValidAcc 0.4440	BestValid 0.4960
	Epoch 260:	Loss 0.9936	TrainAcc 0.6214	ValidAcc 0.4740	BestValid 0.4960
	Epoch 270:	Loss 0.9671	TrainAcc 0.6571	ValidAcc 0.5380	BestValid 0.5380
	Epoch 280:	Loss 0.9047	TrainAcc 0.7071	ValidAcc 0.5580	BestValid 0.5580
	Epoch 290:	Loss 1.0612	TrainAcc 0.2786	ValidAcc 0.2660	BestValid 0.5580
	Epoch 300:	Loss 1.3541	TrainAcc 0.4857	ValidAcc 0.4740	BestValid 0.5580
	Epoch 310:	Loss 1.1459	TrainAcc 0.6143	ValidAcc 0.4660	BestValid 0.5580
	Epoch 320:	Loss 1.0675	TrainAcc 0.6214	ValidAcc 0.4680	BestValid 0.5580
	Epoch 330:	Loss 1.0319	TrainAcc 0.6500	ValidAcc 0.4780	BestValid 0.5580
	Epoch 340:	Loss 0.9712	TrainAcc 0.6571	ValidAcc 0.5120	BestValid 0.5580
	Epoch 350:	Loss 0.9186	TrainAcc 0.6929	ValidAcc 0.5480	BestValid 0.5580
	Epoch 360:	Loss 0.8669	TrainAcc 0.7000	ValidAcc 0.5700	BestValid 0.5700
	Epoch 370:	Loss 0.8060	TrainAcc 0.7214	ValidAcc 0.5920	BestValid 0.5920
	Epoch 380:	Loss 0.7660	TrainAcc 0.7214	ValidAcc 0.5840	BestValid 0.5920
	Epoch 390:	Loss 0.7345	TrainAcc 0.7429	ValidAcc 0.6100	BestValid 0.6100
	Epoch 400:	Loss 0.6942	TrainAcc 0.7357	ValidAcc 0.6060	BestValid 0.6100
	Epoch 410:	Loss 0.6839	TrainAcc 0.7643	ValidAcc 0.6540	BestValid 0.6540
	Epoch 420:	Loss 0.6562	TrainAcc 0.7786	ValidAcc 0.6500	BestValid 0.6540
	Epoch 430:	Loss 0.6530	TrainAcc 0.7500	ValidAcc 0.6140	BestValid 0.6540
	Epoch 440:	Loss 0.6471	TrainAcc 0.6643	ValidAcc 0.5280	BestValid 0.6540
	Epoch 450:	Loss 0.6449	TrainAcc 0.7429	ValidAcc 0.6420	BestValid 0.6540
	Epoch 460:	Loss 0.6325	TrainAcc 0.8000	ValidAcc 0.6780	BestValid 0.6780
	Epoch 470:	Loss 0.5958	TrainAcc 0.7786	ValidAcc 0.6720	BestValid 0.6780
	Epoch 480:	Loss 0.5780	TrainAcc 0.7857	ValidAcc 0.6660	BestValid 0.6780
	Epoch 490:	Loss 1.8273	TrainAcc 0.4857	ValidAcc 0.3780	BestValid 0.6780
	Epoch 500:	Loss 0.8647	TrainAcc 0.6500	ValidAcc 0.5760	BestValid 0.6780
	Epoch 510:	Loss 0.8433	TrainAcc 0.6786	ValidAcc 0.6160	BestValid 0.6780
	Epoch 520:	Loss 0.7921	TrainAcc 0.7429	ValidAcc 0.6080	BestValid 0.6780
	Epoch 530:	Loss 0.7356	TrainAcc 0.7214	ValidAcc 0.6480	BestValid 0.6780
	Epoch 540:	Loss 0.6868	TrainAcc 0.7643	ValidAcc 0.6460	BestValid 0.6780
	Epoch 550:	Loss 0.6488	TrainAcc 0.7643	ValidAcc 0.6260	BestValid 0.6780
	Epoch 560:	Loss 0.6261	TrainAcc 0.7714	ValidAcc 0.6280	BestValid 0.6780
	Epoch 570:	Loss 0.6092	TrainAcc 0.7786	ValidAcc 0.6180	BestValid 0.6780
	Epoch 580:	Loss 0.5966	TrainAcc 0.7643	ValidAcc 0.6580	BestValid 0.6780
	Epoch 590:	Loss 0.5818	TrainAcc 0.7571	ValidAcc 0.6140	BestValid 0.6780
	Epoch 600:	Loss 0.5730	TrainAcc 0.7714	ValidAcc 0.6500	BestValid 0.6780
	Epoch 610:	Loss 0.5641	TrainAcc 0.8000	ValidAcc 0.6620	BestValid 0.6780
	Epoch 620:	Loss 0.5573	TrainAcc 0.8214	ValidAcc 0.6820	BestValid 0.6820
	Epoch 630:	Loss 0.5489	TrainAcc 0.8143	ValidAcc 0.6580	BestValid 0.6820
	Epoch 640:	Loss 0.5426	TrainAcc 0.8143	ValidAcc 0.6540	BestValid 0.6820
	Epoch 650:	Loss 0.5356	TrainAcc 0.8143	ValidAcc 0.6680	BestValid 0.6820
	Epoch 660:	Loss 0.5486	TrainAcc 0.7857	ValidAcc 0.6920	BestValid 0.6920
	Epoch 670:	Loss 0.5238	TrainAcc 0.8214	ValidAcc 0.6840	BestValid 0.6920
	Epoch 680:	Loss 0.5198	TrainAcc 0.8214	ValidAcc 0.6800	BestValid 0.6920
	Epoch 690:	Loss 0.5180	TrainAcc 0.8286	ValidAcc 0.6680	BestValid 0.6920
	Epoch 700:	Loss 0.5237	TrainAcc 0.8286	ValidAcc 0.6660	BestValid 0.6920
	Epoch 710:	Loss 0.5125	TrainAcc 0.8214	ValidAcc 0.6620	BestValid 0.6920
	Epoch 720:	Loss 0.5191	TrainAcc 0.8357	ValidAcc 0.6860	BestValid 0.6920
	Epoch 730:	Loss 0.5055	TrainAcc 0.8357	ValidAcc 0.6740	BestValid 0.6920
	Epoch 740:	Loss 0.5594	TrainAcc 0.7857	ValidAcc 0.7120	BestValid 0.7120
	Epoch 750:	Loss 0.9158	TrainAcc 0.3143	ValidAcc 0.4660	BestValid 0.7120
	Epoch 760:	Loss 0.7904	TrainAcc 0.6429	ValidAcc 0.5140	BestValid 0.7120
	Epoch 770:	Loss 0.7685	TrainAcc 0.7429	ValidAcc 0.6200	BestValid 0.7120
	Epoch 780:	Loss 0.7071	TrainAcc 0.7429	ValidAcc 0.6660	BestValid 0.7120
	Epoch 790:	Loss 0.6667	TrainAcc 0.7429	ValidAcc 0.6480	BestValid 0.7120
	Epoch 800:	Loss 0.6354	TrainAcc 0.7500	ValidAcc 0.6640	BestValid 0.7120
	Epoch 810:	Loss 0.6081	TrainAcc 0.7714	ValidAcc 0.6800	BestValid 0.7120
	Epoch 820:	Loss 0.5832	TrainAcc 0.7857	ValidAcc 0.7060	BestValid 0.7120
	Epoch 830:	Loss 0.5626	TrainAcc 0.8143	ValidAcc 0.6900	BestValid 0.7120
	Epoch 840:	Loss 0.5482	TrainAcc 0.8286	ValidAcc 0.6920	BestValid 0.7120
	Epoch 850:	Loss 0.5381	TrainAcc 0.8357	ValidAcc 0.6880	BestValid 0.7120
	Epoch 860:	Loss 0.5298	TrainAcc 0.8357	ValidAcc 0.6840	BestValid 0.7120
	Epoch 870:	Loss 0.5226	TrainAcc 0.8357	ValidAcc 0.6840	BestValid 0.7120
	Epoch 880:	Loss 0.5167	TrainAcc 0.8357	ValidAcc 0.6820	BestValid 0.7120
	Epoch 890:	Loss 0.5124	TrainAcc 0.8357	ValidAcc 0.6820	BestValid 0.7120
	Epoch 900:	Loss 0.5091	TrainAcc 0.8357	ValidAcc 0.6820	BestValid 0.7120
	Epoch 910:	Loss 0.5058	TrainAcc 0.8357	ValidAcc 0.6840	BestValid 0.7120
	Epoch 920:	Loss 0.5032	TrainAcc 0.8357	ValidAcc 0.6820	BestValid 0.7120
	Epoch 930:	Loss 0.5005	TrainAcc 0.8357	ValidAcc 0.6880	BestValid 0.7120
	Epoch 940:	Loss 0.4981	TrainAcc 0.8357	ValidAcc 0.6880	BestValid 0.7120
	Epoch 950:	Loss 0.5008	TrainAcc 0.8357	ValidAcc 0.6860	BestValid 0.7120
	Epoch 960:	Loss 0.4952	TrainAcc 0.8357	ValidAcc 0.6900	BestValid 0.7120
	Epoch 970:	Loss 0.4932	TrainAcc 0.8357	ValidAcc 0.6980	BestValid 0.7120
	Epoch 980:	Loss 0.4909	TrainAcc 0.8357	ValidAcc 0.6960	BestValid 0.7120
	Epoch 990:	Loss 0.4887	TrainAcc 0.8357	ValidAcc 0.6960	BestValid 0.7120
	Epoch 1000:	Loss 0.4882	TrainAcc 0.8429	ValidAcc 0.6960	BestValid 0.7120
	Epoch 1010:	Loss 0.4890	TrainAcc 0.8500	ValidAcc 0.6980	BestValid 0.7120
	Epoch 1020:	Loss 0.4866	TrainAcc 0.8500	ValidAcc 0.7000	BestValid 0.7120
	Epoch 1030:	Loss 0.4834	TrainAcc 0.8500	ValidAcc 0.7040	BestValid 0.7120
	Epoch 1040:	Loss 0.4840	TrainAcc 0.8500	ValidAcc 0.6880	BestValid 0.7120
	Epoch 1050:	Loss 0.4818	TrainAcc 0.8500	ValidAcc 0.7040	BestValid 0.7120
	Epoch 1060:	Loss 0.4807	TrainAcc 0.8429	ValidAcc 0.6920	BestValid 0.7120
	Epoch 1070:	Loss 0.4771	TrainAcc 0.8500	ValidAcc 0.7000	BestValid 0.7120
	Epoch 1080:	Loss 0.4974	TrainAcc 0.8429	ValidAcc 0.7280	BestValid 0.7280
	Epoch 1090:	Loss 0.4829	TrainAcc 0.8571	ValidAcc 0.7180	BestValid 0.7280
	Epoch 1100:	Loss 0.4801	TrainAcc 0.8429	ValidAcc 0.7140	BestValid 0.7280
	Epoch 1110:	Loss 0.4729	TrainAcc 0.8500	ValidAcc 0.7020	BestValid 0.7280
	Epoch 1120:	Loss 0.4725	TrainAcc 0.8500	ValidAcc 0.6900	BestValid 0.7280
	Epoch 1130:	Loss 0.4707	TrainAcc 0.8500	ValidAcc 0.7080	BestValid 0.7280
	Epoch 1140:	Loss 0.4689	TrainAcc 0.8500	ValidAcc 0.6900	BestValid 0.7280
	Epoch 1150:	Loss 0.4666	TrainAcc 0.8571	ValidAcc 0.7020	BestValid 0.7280
	Epoch 1160:	Loss 0.4737	TrainAcc 0.8643	ValidAcc 0.7200	BestValid 0.7280
	Epoch 1170:	Loss 0.4953	TrainAcc 0.8500	ValidAcc 0.7000	BestValid 0.7280
	Epoch 1180:	Loss 0.4669	TrainAcc 0.8571	ValidAcc 0.7000	BestValid 0.7280
	Epoch 1190:	Loss 0.4651	TrainAcc 0.8571	ValidAcc 0.7020	BestValid 0.7280
	Epoch 1200:	Loss 0.4632	TrainAcc 0.8500	ValidAcc 0.7020	BestValid 0.7280
	Epoch 1210:	Loss 0.4612	TrainAcc 0.8571	ValidAcc 0.7180	BestValid 0.7280
	Epoch 1220:	Loss 0.4646	TrainAcc 0.8429	ValidAcc 0.6920	BestValid 0.7280
	Epoch 1230:	Loss 0.4583	TrainAcc 0.8571	ValidAcc 0.7040	BestValid 0.7280
	Epoch 1240:	Loss 0.4550	TrainAcc 0.8643	ValidAcc 0.7040	BestValid 0.7280
	Epoch 1250:	Loss 0.4666	TrainAcc 0.8571	ValidAcc 0.7320	BestValid 0.7320
	Epoch 1260:	Loss 0.4536	TrainAcc 0.8571	ValidAcc 0.7040	BestValid 0.7320
	Epoch 1270:	Loss 0.4517	TrainAcc 0.8571	ValidAcc 0.6960	BestValid 0.7320
	Epoch 1280:	Loss 0.4537	TrainAcc 0.8643	ValidAcc 0.6980	BestValid 0.7320
	Epoch 1290:	Loss 0.5360	TrainAcc 0.7071	ValidAcc 0.7160	BestValid 0.7320
	Epoch 1300:	Loss 1.6750	TrainAcc 0.5214	ValidAcc 0.3920	BestValid 0.7320
	Epoch 1310:	Loss 0.8940	TrainAcc 0.6286	ValidAcc 0.6300	BestValid 0.7320
	Epoch 1320:	Loss 0.8443	TrainAcc 0.7143	ValidAcc 0.6540	BestValid 0.7320
	Epoch 1330:	Loss 0.7806	TrainAcc 0.7500	ValidAcc 0.6560	BestValid 0.7320
	Epoch 1340:	Loss 0.7207	TrainAcc 0.7571	ValidAcc 0.6640	BestValid 0.7320
	Epoch 1350:	Loss 0.6678	TrainAcc 0.7714	ValidAcc 0.6700	BestValid 0.7320
	Epoch 1360:	Loss 0.6248	TrainAcc 0.7857	ValidAcc 0.7000	BestValid 0.7320
	Epoch 1370:	Loss 0.5870	TrainAcc 0.8071	ValidAcc 0.7120	BestValid 0.7320
	Epoch 1380:	Loss 0.5503	TrainAcc 0.8286	ValidAcc 0.7080	BestValid 0.7320
	Epoch 1390:	Loss 0.5168	TrainAcc 0.8500	ValidAcc 0.7160	BestValid 0.7320
	Epoch 1400:	Loss 0.4977	TrainAcc 0.8500	ValidAcc 0.7240	BestValid 0.7320
	Epoch 1410:	Loss 0.4887	TrainAcc 0.8500	ValidAcc 0.7040	BestValid 0.7320
	Epoch 1420:	Loss 0.4809	TrainAcc 0.8357	ValidAcc 0.7040	BestValid 0.7320
	Epoch 1430:	Loss 0.4786	TrainAcc 0.8500	ValidAcc 0.7100	BestValid 0.7320
	Epoch 1440:	Loss 0.4742	TrainAcc 0.8571	ValidAcc 0.7060	BestValid 0.7320
	Epoch 1450:	Loss 0.4702	TrainAcc 0.8571	ValidAcc 0.7060	BestValid 0.7320
	Epoch 1460:	Loss 0.4681	TrainAcc 0.8643	ValidAcc 0.6880	BestValid 0.7320
	Epoch 1470:	Loss 0.4679	TrainAcc 0.8571	ValidAcc 0.7080	BestValid 0.7320
	Epoch 1480:	Loss 0.4638	TrainAcc 0.8571	ValidAcc 0.7060	BestValid 0.7320
	Epoch 1490:	Loss 0.4621	TrainAcc 0.8571	ValidAcc 0.7040	BestValid 0.7320
Node 0, Layer-level comm throughput (grad): 8.973 GBps
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (grad): -nan GBps
Node 1, Layer-level comm throughput (act): 9.455 GBps
	Epoch 1500:	Loss 0.4592	TrainAcc 0.8571	ValidAcc 0.7020	BestValid 0.7320
Node 0, GPU memory consumption: 2.664 GB
Node 0, compression time: 0.128s, compression size: 1.259GB, throughput: 9.849GBps
Node 0, decompression time: 0.117s, compression size: 1.259GB, throughput: 8.247GBps
Node 0, pure compute time: 25.986 s, total compute time: 26.231 s
Node 0, wait_for_task_time: 27.157 s, wait_for_other_gpus_time: 0.023 s
------------------------node id 0,  per-epoch time: 0.043085 s---------------
Node 1, GPU memory consumption: 1.798 GB
Node 1, compression time: 0.113s, compression size: 0.968GB, throughput: 8.601GBps
Node 1, decompression time: 0.161s, compression size: 0.968GB, throughput: 7.843GBps
Node 1, pure compute time: 25.542 s, total compute time: 25.815 s
Node 1, wait_for_task_time: 12.285 s, wait_for_other_gpus_time: 0.009 s
------------------------node id 1,  per-epoch time: 0.043085 s---------------
************ Profiling Results ************
	Bubble: 20.550285 (s) (31.59 percentage)
	Compute: 29.297096 (s) (45.04 percentage)
	GradSync: 4.907497 (s) (7.54 percentage)
	GraphComm: 0.053928 (s) (0.08 percentage)
	Imbalance: 10.030188 (s) (15.42 percentage)
	LayerComm: 0.213932 (s) (0.33 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.003 GB
Highest valid_acc: 0.7320
Target test_acc: 0.7110
Epoch to reach the target acc: 1250
[MPI Rank 0] Success 
[MPI Rank 1] Success 
