g001.anvil.rcac.purdue.edu
Thu Feb 16 13:27:09 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   30C    P0    68W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  5%] Built target context
[ 17%] Built target parallel
[ 19%] Built target core
[ 39%] Built target cudahelp
[ 45%] Built target test_mpi_gpu_hybrid
[ 50%] Built target test_mpi_gpu_pipelined_model_parallel
[ 50%] Built target test_cuda_data_compression
[ 50%] Built target test_cuda_graph
[ 52%] Built target test_mpi_gpu_model_parallel
[ 54%] Built target test_cuda_pipeline_parallel
[ 71%] Built target test_cuda_model_parallel
[ 85%] Built target test_full_non_structual_graph
[ 71%] Built target test_mpi_structual_graph
[ 71%] Built target test_trivial
[ 71%] Built target test_cuda
[ 71%] Built target test_mpi_combined
[ 86%] Built target test_single_node_fullgpu_training
[ 86%] Built target test_hello_world
[ 86%] Built target test_single_node_gpu_training
[ 86%] Built target test_mpi_loader
[ 86%] Built target test_graph
[ 86%] Built target test_nccl_thread
[ 86%] Built target test_mpi_non_structual_graph
[ 91%] Built target test_single_node_training
[ 91%] Built target test_mpi_model_parallel
[ 91%] Built target test_nccl_mpi
[ 91%] Built target estimate_comm_volume
[ 91%] Built target test_mpi_pipelined_model_parallel
[ 91%] Built target test_full_structual_graph
[ 95%] Built target OSDI2023_SINGLE_NODE_gcn
[ 97%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[100%] Built target test_two_layer_hybrid_parallelism_designer
[100%] Built target OSDI2023_MULTI_NODES_gcn
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCN layers: 8
The number of hidden units: 256
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.003000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: saved_weights_pipe
The random seed: 17
The scaling down factor of out-of-chunk gradients: 0.100000
Initialized node 0 on machine g001.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 0.037 seconds.
Building the CSC structure...
        It takes 0.037 seconds.
Building the Feature Vector...
        It takes 0.062 seconds.
Building the Label Vector...
        It takes 0.024 seconds.
Number of classes: 40
Number of feature dimensions: 128
Number of vertices: 169343
train nodes 90941, valid nodes 29799, test nodes 48603
Number of GPUs: 1
GPU 0, layer [0, 8)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 40
0 169343 0 40
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: NULL
*** Node 0 owns the partition [0, 40) x [0, 169343)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_WEIGHT, output tensors: 21
    Op 22: type OPERATOR_MATMUL, output tensors: 22
    Op 23: type OPERATOR_AGGREGATION, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_WEIGHT, output tensors: 26
    Op 27: type OPERATOR_MATMUL, output tensors: 27
    Op 28: type OPERATOR_AGGREGATION, output tensors: 28
    Op 29: type OPERATOR_RELU, output tensors: 29
    Op 30: type OPERATOR_DROPOUT, output tensors: 30
    Op 31: type OPERATOR_WEIGHT, output tensors: 31
    Op 32: type OPERATOR_MATMUL, output tensors: 32
    Op 33: type OPERATOR_AGGREGATION, output tensors: 33
    Op 34: type OPERATOR_RELU, output tensors: 34
    Op 35: type OPERATOR_DROPOUT, output tensors: 35
    Op 36: type OPERATOR_WEIGHT, output tensors: 36
    Op 37: type OPERATOR_MATMUL, output tensors: 37
    Op 38: type OPERATOR_AGGREGATION, output tensors: 38
    Op 39: type OPERATOR_SOFTMAX, output tensors: 39
Boundaries: 0 169343
Fragments: [0, 169343)
Chunks (number of global chunks: 12): 0-[0, 14112) 1-[14112, 28224) 2-[28224, 42336) 3-[42336, 56448) 4-[56448, 70560) 5-[70560, 84672) 6-[84672, 98784) 7-[98784, 112896) 8-[112896, 127008) ... 11-[155232, 169343)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes:
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
169343, 2484941, 2484941
Number of vertices per chunk: 14112
csr in-out ready !*** Node 0, setting up some other necessary information...
*** Node 0, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 40)...
+++++++++ Node 0, mapping weight op 26
+++++++++ Node 0, mapping weight op 31
+++++++++ Node 0, mapping weight op 36
+++++++++ Node 0, mapping weight op 16
+++++++++ Node 0, mapping weight op 21
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 0, mapping weight op 6
+++++++++ Node 0, mapping weight op 11
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.003000000
    Epoch 9:	Loss 3.38497	TrainAcc 0.1790	ValidAcc 0.0763	TestAcc 0.0586
    Epoch 19:	Loss 2.97192	TrainAcc 0.1791	ValidAcc 0.0762	TestAcc 0.0586
    Epoch 29:	Loss 2.88988	TrainAcc 0.1783	ValidAcc 0.0761	TestAcc 0.0588
    Epoch 39:	Loss 2.84925	TrainAcc 0.1789	ValidAcc 0.0763	TestAcc 0.0586
    Epoch 49:	Loss 2.83234	TrainAcc 0.1790	ValidAcc 0.0763	TestAcc 0.0586
    Epoch 59:	Loss 2.75745	TrainAcc 0.1795	ValidAcc 0.0771	TestAcc 0.0591
    Epoch 69:	Loss 2.52773	TrainAcc 0.2931	ValidAcc 0.3061	TestAcc 0.2745
    Epoch 79:	Loss 2.34697	TrainAcc 0.3316	ValidAcc 0.3381	TestAcc 0.3073
    Epoch 89:	Loss 2.19406	TrainAcc 0.3783	ValidAcc 0.3640	TestAcc 0.3281
Node 0, Layer-level comm throughput (act): -nan GBps
Node 0, Layer-level comm throughput (grad): -nan GBps
    Epoch 99:	Loss 2.01911	TrainAcc 0.4259	ValidAcc 0.3962	TestAcc 0.3594
Node 0, compression time: 0.000s, compression size: 0.000GB, throughput: -nanGBps
Node 0, decompression time: 0.000s, compression size: 0.000GB, throughput: -nanGBps
Node 0, pure compute time: 9.284 s, total compute time: 9.284 s
Node 0, wait_for_task_time: 0.000 s, wait_for_other_gpus_time: 0.000 s
------------------------node id 0,  per-epoch time: 0.102314 s---------------
************ Profiling Results ************
	Bubble: 0.111491 (s) (1.08 percentage)
	Compute: 10.190876 (s) (98.27 percentage)
	GradSync: 0.065813 (s) (0.63 percentage)
	GraphComm: 0.002427 (s) (0.02 percentage)
	Imbalance: 0.000100 (s) (0.00 percentage)
	LayerComm: 0.000000 (s) (0.00 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.000 GB
Highest valid_acc: 0.3962
Target test_acc: 0.3594
Epoch to reach the target acc: 100
[MPI Rank 0] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_arxiv
The number of GCN layers: 8
The number of hidden units: 256
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g001.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 0.040 seconds.
Building the CSC structure...
        It takes 0.038 seconds.
Building the Feature Vector...
        It takes 0.056 seconds.
Building the Label Vector...
        It takes 0.020 seconds.
Number of classes: 40
Number of feature dimensions: 128
Dropout: 0.000 
train nodes 90941, valid nodes 29799, test nodes 48603
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 40
    Number of vertices: 169343
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 1	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 2	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 3	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 4	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 5	TrainAcc 0.1791	ValidAcc 0.0763	TestAcc 0.0586
Version 6	TrainAcc 0.3052	ValidAcc 0.3185	TestAcc 0.2824
Version 7	TrainAcc 0.3593	ValidAcc 0.3584	TestAcc 0.3219
Version 8	TrainAcc 0.3950	ValidAcc 0.3732	TestAcc 0.3353
Version 9	TrainAcc 0.4742	ValidAcc 0.4716	TestAcc 0.4446
Version 9 achieved the highest validation accuracy 0.4716 (test accuracy: 0.4446)
