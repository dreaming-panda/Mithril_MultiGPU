g006.anvil.rcac.purdue.edu
Fri Jan 27 19:21:11 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   28C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  4%] Built target context
[ 18%] Built target parallel
[ 19%] Built target core
[ 20%] Building CXX object CMakeFiles/cudahelp.dir/core/src/cuda/cuda_graph_parallel.cc.o
[ 21%] Linking CXX static library libcudahelp.a
[ 40%] Built target cudahelp
[ 41%] Linking CXX executable test_mpi_combined
[ 43%] Linking CXX executable test_graph
[ 43%] Linking CXX executable test_mpi_gpu_model_parallel
[ 52%] Linking CXX executable test_full_structual_graph
[ 55%] Linking CXX executable test_cuda_model_parallel
[ 55%] Linking CXX executable test_single_node_fullgpu_training
[ 55%] Linking CXX executable test_nccl_mpi
[ 55%] Linking CXX executable test_hello_world
[ 55%] Linking CXX executable test_nccl_thread
[ 55%] Linking CXX executable test_single_node_training
[ 59%] Linking CXX executable test_cuda_pipeline_parallel
[ 55%] Linking CXX executable test_cuda_graph
[ 55%] Linking CXX executable test_mpi_gpu_pipelined_model_parallel
[ 55%] Linking CXX executable test_mpi_gpu_hybrid
[ 59%] Linking CXX executable test_mpi_structual_graph
[ 59%] Linking CXX executable test_cuda
[ 59%] Linking CXX executable test_mpi_pipelined_model_parallel
[ 59%] Linking CXX executable test_mpi_loader
[ 62%] Linking CXX executable estimate_comm_volume
[ 63%] Linking CXX executable test_single_node_gpu_training
[ 62%] Linking CXX executable test_mpi_non_structual_graph
[ 62%] Linking CXX executable test_full_non_structual_graph
[ 63%] Linking CXX executable test_trivial
[ 64%] Linking CXX executable test_mpi_model_parallel
[ 65%] Linking CXX executable test_two_layer_hybrid_parallelism_designer
[ 68%] Linking CXX executable gcn
[ 68%] Linking CXX executable gcn_graph_parallel
[ 70%] Linking CXX executable gcn
[ 70%] Linking CXX executable gcn_inference
[ 71%] Built target test_full_structual_graph
[ 73%] Built target test_mpi_loader
[ 73%] Built target test_trivial
[ 74%] Built target test_graph
[ 75%] Built target test_mpi_non_structual_graph
[ 76%] Built target test_full_non_structual_graph
[ 77%] Built target test_mpi_structual_graph
[ 80%] Built target estimate_comm_volume
[ 80%] Built target test_hello_world
[ 80%] Built target test_cuda
[ 82%] Built target test_single_node_training
[ 82%] Built target test_mpi_combined
[ 83%] Built target test_mpi_pipelined_model_parallel
[ 86%] Built target test_cuda_graph
[ 86%] Built target test_single_node_gpu_training
[ 86%] Built target test_mpi_gpu_model_parallel
[ 89%] Built target test_mpi_model_parallel
[ 89%] Built target test_mpi_gpu_hybrid
[ 89%] Built target test_two_layer_hybrid_parallelism_designer
[ 90%] Built target test_single_node_fullgpu_training
[ 91%] Built target test_mpi_gpu_pipelined_model_parallel
[ 92%] Built target test_cuda_pipeline_parallel
[ 93%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[ 94%] Built target OSDI2023_SINGLE_NODE_gcn
[ 95%] Built target OSDI2023_MULTI_NODES_gcn
[ 96%] Built target test_nccl_thread
[ 97%] Built target test_nccl_mpi
[ 98%] Built target test_cuda_model_parallel
[100%] Built target OSDI2023_MULTI_NODES_gcn_graph_parallel
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/metis_4_gpu/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/metis_4_gpu/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/metis_4_gpu/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/metis_4_gpu/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: hybrid
The dropout rate: 0.500
Initialized node g008.anvil.rcac.purdue.edu
Initialized node g011.anvil.rcac.purdue.edu
Initialized node g010.anvil.rcac.purdue.edu
Initialized node g006.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.910 seconds.
Building the CSC structure...
        It takes 1.938 seconds.
Building the CSC structure...
        It takes 1.948 seconds.
Building the CSC structure...
        It takes 1.953 seconds.
Building the CSC structure...
        It takes 1.852 seconds.
        It takes 1.847 seconds.
        It takes 1.842 seconds.
        It takes 1.853 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.667 seconds.
Building the Label Vector...
        It takes 0.788 seconds.
Building the Label Vector...
        It takes 0.785 seconds.
Building the Label Vector...
        It takes 0.791 seconds.
Building the Label Vector...
        It takes 0.326 seconds.
        It takes 0.463 seconds.
        It takes 0.465 seconds.
        It takes 0.450 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
Number of classes: 47
Number of feature dimensions: 100
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
[Node 1]: distributed graph prepared: start: 602287, end: 1225638 , send vertices: 370914.
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
start[0]: 0, end[0]: 602287start[1]: 602287, end[1]: 1225638start[2]: 1225638, end[2]: 1830644start[3]: 1830644, end[3]: 2449029[Node 0]: distributed graph prepared: start: 0, end: 602287 , send vertices: 536600.
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
[Node 2]: distributed graph prepared: start: 1225638, end: 1830644 , send vertices: 660492.
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
[Node 3]: distributed graph prepared: start: 1830644, end: 2449029 , send vertices: 700662.
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
*** Done preparing the weight tensor.

****** Start model training... ******
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
*** Done preparing the STD tensor.
*** Done preparing the weight tensor.

****** Start model training... ******
2449029
2449029
2449029
2449029
    Epoch 9:	Loss 3.54236	TrainAcc 0.3390	ValidAcc 0.3355	TestAcc 0.2626
    Epoch 19:	Loss 2.60806	TrainAcc 0.3510	ValidAcc 0.3466	TestAcc 0.2730
    Epoch 29:	Loss 2.08121	TrainAcc 0.4390	ValidAcc 0.4403	TestAcc 0.3321
    Epoch 39:	Loss 1.72163	TrainAcc 0.5030	ValidAcc 0.4976	TestAcc 0.3642
    Epoch 49:	Loss 1.43891	TrainAcc 0.6098	ValidAcc 0.5945	TestAcc 0.4286
    Epoch 59:	Loss 1.25829	TrainAcc 0.6537	ValidAcc 0.6407	TestAcc 0.4652
    Epoch 69:	Loss 1.13945	TrainAcc 0.6930	ValidAcc 0.6817	TestAcc 0.4960
    Epoch 79:	Loss 1.03624	TrainAcc 0.7346	ValidAcc 0.7226	TestAcc 0.5250
    Epoch 89:	Loss 0.94944	TrainAcc 0.7586	ValidAcc 0.7488	TestAcc 0.5483
    Epoch 99:	Loss 0.87778	TrainAcc 0.7854	ValidAcc 0.7762	TestAcc 0.5721

Average per-epoch runtime: 0.425 (s)
Highest validation acc: 0.7762
Target test acc: 0.5721
Epochs to reach the target acc: 100
Communication volume (cluster-wide, per-epoch): 3.237 GB
Communication time: 0.311 s
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 2] Success 
[MPI Rank 3] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g006.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.991 seconds.
Building the CSC structure...
        It takes 1.933 seconds.
Building the Feature Vector...
        It takes 0.733 seconds.
Building the Label Vector...
        It takes 0.428 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.000 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.3390	ValidAcc 0.3388	TestAcc 0.2896
Version 1	TrainAcc 0.3507	ValidAcc 0.3515	TestAcc 0.2968
Version 2	TrainAcc 0.4463	ValidAcc 0.4524	TestAcc 0.3684
Version 3	TrainAcc 0.5151	ValidAcc 0.5141	TestAcc 0.4029
Version 4	TrainAcc 0.6243	ValidAcc 0.6207	TestAcc 0.4787
Version 5	TrainAcc 0.6743	ValidAcc 0.6657	TestAcc 0.5125
Version 6	TrainAcc 0.7091	ValidAcc 0.7054	TestAcc 0.5408
Version 7	TrainAcc 0.7487	ValidAcc 0.7442	TestAcc 0.5722
Version 8	TrainAcc 0.7674	ValidAcc 0.7641	TestAcc 0.5922
Version 9	TrainAcc 0.7954	ValidAcc 0.7946	TestAcc 0.6251
Version 9 achieved the highest validation accuracy 0.7946 (test accuracy: 0.6251)
