g006.anvil.rcac.purdue.edu
Fri Jan 27 23:37:48 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   28C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  4%] Built target context
[ 15%] Built target core
[ 19%] Built target parallel
[ 39%] Built target cudahelp
[ 53%] Built target test_cuda_model_parallel
[ 54%] Built target test_mpi_gpu_hybrid
[ 54%] Built target test_cuda_graph
[ 71%] Built target test_cuda_pipeline_parallel
[ 83%] Built target test_cuda
[ 72%] Built target test_nccl_thread
[ 72%] Built target test_graph
[ 72%] Built target test_cuda_data_compression
[ 72%] Built target test_mpi_loader
[ 72%] Built target test_mpi_combined
[ 83%] Built target test_hello_world
[ 72%] Built target test_trivial
[ 83%] Built target test_mpi_non_structual_graph
[ 83%] Built target test_mpi_gpu_model_parallel
[ 83%] Built target test_full_non_structual_graph
[ 83%] Built target test_mpi_model_parallel
[ 83%] Built target test_full_structual_graph
[ 83%] Built target test_nccl_mpi
[ 88%] Built target estimate_comm_volume
[ 88%] Built target test_mpi_pipelined_model_parallel
[ 88%] Built target test_mpi_structual_graph
[ 90%] Built target test_single_node_fullgpu_training
[ 91%] Built target test_single_node_training
[ 90%] Built target test_single_node_gpu_training
[ 91%] Built target test_mpi_gpu_pipelined_model_parallel
[ 97%] Built target test_two_layer_hybrid_parallelism_designer
[ 98%] Built target OSDI2023_SINGLE_NODE_gcn
[100%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[100%] Built target OSDI2023_MULTI_NODES_gcn
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: saved_weights
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: saved_weights
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: saved_weights
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 1000
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: saved_weights
Initialized node 1 on machine g008.anvil.rcac.purdue.edu
Initialized node 2 on machine g010.anvil.rcac.purdue.edu
Initialized node 3 on machine g011.anvil.rcac.purdue.edu
Initialized node 0 on machine g006.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 1.876 seconds.
Building the CSC structure...
        It takes 1.955 seconds.
Building the CSC structure...
        It takes 1.960 seconds.
Building the CSC structure...
        It takes 1.956 seconds.
Building the CSC structure...
        It takes 1.847 seconds.
        It takes 1.884 seconds.
        It takes 1.889 seconds.
        It takes 1.884 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.593 seconds.
Building the Label Vector...
        It takes 0.616 seconds.
Building the Label Vector...
        It takes 0.703 seconds.
Building the Label Vector...
        It takes 0.702 seconds.
Building the Label Vector...
        It takes 0.322 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.325 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.418 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.410 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 4
WARNING: the current version only applies to linear GNN models!
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
*** Node 2, starting model training...
Number of operators: 40
0 2449029 0 11
0 2449029 11 21
0 2449029 21 31
0 2449029 31 40
Node 2, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 2, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 2 owns the partition [21, 31) x [0, 2449029)
*** Node 2, constructing the helper classes...
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 20)
(Backwarding) Node 2 (fragment 0) depends on nodes: 3 (Tensor: 30)
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 4
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
*** Node 1, starting model training...
Number of operators: 40
0 2449029 0 11
0 2449029 11 21
0 2449029 21 31
WARNING: the current version only applies to linear GNN models!
0 2449029 31 40
Node 1, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 1, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 1 owns the partition [11, 21) x [0, 2449029)
*** Node 1, constructing the helper classes...
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 10)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 20)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 4
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
WARNING: the current version only applies to linear GNN models!
*** Node 3, starting model training...
Number of operators: 40
0 2449029 0 11
0 2449029 11 21
0 2449029 21 31
0 2449029 31 40
Node 3, Pipeline Input Tensor: OPERATOR_DROPOUT
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the partition [31, 40) x [0, 2449029)
*** Node 3, constructing the helper classes...
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 4
GPU 0, layer [0, 2)
GPU 1, layer [2, 4)
GPU 2, layer [4, 6)
GPU 3, layer [6, 8)
WARNING: the current version only applies to linear GNN models!
*** Node 0, starting model training...
Number of operators: 40
0 2449029 0 11
0 2449029 11 21
0 2449029 21 31
0 2449029 31 40
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: OPERATOR_DROPOUT
*** Node 0 owns the partition [0, 11) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_RELU, output tensors: 19
    Op 20: type OPERATOR_DROPOUT, output tensors: 20
    Op 21: type OPERATOR_WEIGHT, output tensors: 21
    Op 22: type OPERATOR_MATMUL, output tensors: 22
    Op 23: type OPERATOR_AGGREGATION, output tensors: 23
    Op 24: type OPERATOR_RELU, output tensors: 24
    Op 25: type OPERATOR_DROPOUT, output tensors: 25
    Op 26: type OPERATOR_WEIGHT, output tensors: 26
    Op 27: type OPERATOR_MATMUL, output tensors: 27
    Op 28: type OPERATOR_AGGREGATION, output tensors: 28
    Op 29: type OPERATOR_RELU, output tensors: 29
    Op 30: type OPERATOR_DROPOUT, output tensors: 30
    Op 31: type OPERATOR_WEIGHT, output tensors: 31
    Op 32: type OPERATOR_MATMUL, output tensors: 32
    Op 33: type OPERATOR_AGGREGATION, output tensors: 33
    Op 34: type OPERATOR_RELU, output tensors: 34
    Op 35: type OPERATOR_DROPOUT, output tensors: 35
    Op 36: type OPERATOR_WEIGHT, output tensors: 36
    Op 37: type OPERATOR_MATMUL, output tensors: 37
    Op 38: type OPERATOR_AGGREGATION, output tensors: 38
    Op 39: type OPERATOR_SOFTMAX, output tensors: 39
(Forwarding) Node 3 (fragment 0) depends on nodes: 2 (Tensor: 30)
(Backwarding) Node 3 (fragment 0) depends on nodes:
(I-link dependencies): node 3 should send activation to nodes:
(I-link dependencies): node 3 should receive activation from nodes:
(I-link dependencies): node 3 should send gradient to nodes:
(I-link dependencies): node 3 should receive gradient from nodes:
Boundaries: 0 0 0 0 2449029 2449029 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 32): 0-[0, 76533) 1-[76533, 153066) 2-[153066, 229599) 3-[229599, 306132) 4-[306132, 382665) 5-[382665, 459198) 6-[459198, 535731) 7-[535731, 612264) 8-[612264, 688797) ... 31-[2372523, 2449029)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 10)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
2449029, 126167053, 126167053
Number of vertices per chunk: 153065
2449029, 126167053, 126167053
Number of vertices per chunk: 153065
2449029, 126167053, 126167053
Number of vertices per chunk: 153065
2449029, 126167053, 126167053
Number of vertices per chunk: 153065
csr in-out ready !*** Node 0, setting up some other necessary information...
csr in-out ready !*** Node 2, setting up some other necessary information...
csr in-out ready !*** Node 3, setting up some other necessary information...
csr in-out ready !*** Node 1, setting up some other necessary information...
*** Node 0, starting the helper threads...
*** Node 2, starting the helper threads...
*** Node 3, starting the helper threads...
*** Node 1, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 11)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 0, mapping weight op 6
+++++++++ Node 2 initializing the weights for op[21, 31)...
+++++++++ Node 2, mapping weight op 21
+++++++++ Node 2, mapping weight op 26
+++++++++ Node 1 initializing the weights for op[11, 21)...
+++++++++ Node 1, mapping weight op 11
+++++++++ Node 1, mapping weight op 16
+++++++++ Node 3 initializing the weights for op[31, 40)...
+++++++++ Node 3, mapping weight op 31
+++++++++ Node 3, mapping weight op 36
RANDOMLY DISPATCH THE CHUNKS...
*** Node 0, starting task scheduling...



*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.001000000
    Epoch 9:	Loss 0.00000	TrainAcc 0.1788	ValidAcc 0.1705	TestAcc 0.1256
    Epoch 19:	Loss 0.00000	TrainAcc 0.3082	ValidAcc 0.3070	TestAcc 0.2543
    Epoch 29:	Loss 0.00000	TrainAcc 0.2422	ValidAcc 0.2281	TestAcc 0.1606
    Epoch 39:	Loss 0.00000	TrainAcc 0.3084	ValidAcc 0.3071	TestAcc 0.2579
    Epoch 49:	Loss 0.00000	TrainAcc 0.4138	ValidAcc 0.3857	TestAcc 0.2641
    Epoch 59:	Loss 0.00000	TrainAcc 0.4702	ValidAcc 0.4625	TestAcc 0.3371
    Epoch 69:	Loss 0.00000	TrainAcc 0.4905	ValidAcc 0.4736	TestAcc 0.3340
    Epoch 79:	Loss 0.00000	TrainAcc 0.5952	ValidAcc 0.5871	TestAcc 0.4294
    Epoch 89:	Loss 0.00000	TrainAcc 0.5405	ValidAcc 0.5334	TestAcc 0.3873
    Epoch 99:	Loss 0.00000	TrainAcc 0.5561	ValidAcc 0.5488	TestAcc 0.4050
    Epoch 109:	Loss 0.00000	TrainAcc 0.6283	ValidAcc 0.6194	TestAcc 0.4354
    Epoch 119:	Loss 0.00000	TrainAcc 0.6094	ValidAcc 0.6006	TestAcc 0.4346
    Epoch 129:	Loss 0.00000	TrainAcc 0.6277	ValidAcc 0.6179	TestAcc 0.4476
    Epoch 139:	Loss 0.00000	TrainAcc 0.6631	ValidAcc 0.6476	TestAcc 0.4681
    Epoch 149:	Loss 0.00000	TrainAcc 0.6891	ValidAcc 0.6774	TestAcc 0.4903
    Epoch 159:	Loss 0.00000	TrainAcc 0.6986	ValidAcc 0.6816	TestAcc 0.4900
    Epoch 169:	Loss 0.00000	TrainAcc 0.7045	ValidAcc 0.6920	TestAcc 0.5098
    Epoch 179:	Loss 0.00000	TrainAcc 0.7030	ValidAcc 0.6891	TestAcc 0.4986
    Epoch 189:	Loss 0.00000	TrainAcc 0.7126	ValidAcc 0.7024	TestAcc 0.5168
    Epoch 199:	Loss 0.00000	TrainAcc 0.7139	ValidAcc 0.6985	TestAcc 0.5086
    Epoch 209:	Loss 0.00000	TrainAcc 0.7252	ValidAcc 0.7177	TestAcc 0.5287
    Epoch 219:	Loss 0.00000	TrainAcc 0.7269	ValidAcc 0.7118	TestAcc 0.5190
    Epoch 229:	Loss 0.00000	TrainAcc 0.7494	ValidAcc 0.7424	TestAcc 0.5534
    Epoch 239:	Loss 0.00000	TrainAcc 0.7554	ValidAcc 0.7380	TestAcc 0.5420
    Epoch 249:	Loss 0.00000	TrainAcc 0.7745	ValidAcc 0.7689	TestAcc 0.5759
    Epoch 259:	Loss 0.00000	TrainAcc 0.7896	ValidAcc 0.7795	TestAcc 0.5785
    Epoch 269:	Loss 0.00000	TrainAcc 0.7830	ValidAcc 0.7742	TestAcc 0.5712
    Epoch 279:	Loss 0.00000	TrainAcc 0.7715	ValidAcc 0.7650	TestAcc 0.5752
    Epoch 289:	Loss 0.00000	TrainAcc 0.7792	ValidAcc 0.7720	TestAcc 0.5731
    Epoch 299:	Loss 0.00000	TrainAcc 0.8017	ValidAcc 0.7933	TestAcc 0.5925
    Epoch 309:	Loss 0.00000	TrainAcc 0.8154	ValidAcc 0.8077	TestAcc 0.6075
    Epoch 319:	Loss 0.00000	TrainAcc 0.8173	ValidAcc 0.8057	TestAcc 0.6062
    Epoch 329:	Loss 0.00000	TrainAcc 0.8313	ValidAcc 0.8205	TestAcc 0.6198
    Epoch 339:	Loss 0.00000	TrainAcc 0.8301	ValidAcc 0.8217	TestAcc 0.6240
    Epoch 349:	Loss 0.00000	TrainAcc 0.8397	ValidAcc 0.8312	TestAcc 0.6296
    Epoch 359:	Loss 0.00000	TrainAcc 0.8419	ValidAcc 0.8318	TestAcc 0.6328
    Epoch 369:	Loss 0.00000	TrainAcc 0.8361	ValidAcc 0.8285	TestAcc 0.6298
    Epoch 379:	Loss 0.00000	TrainAcc 0.8377	ValidAcc 0.8312	TestAcc 0.6312
    Epoch 389:	Loss 0.00000	TrainAcc 0.8353	ValidAcc 0.8271	TestAcc 0.6277
    Epoch 399:	Loss 0.00000	TrainAcc 0.8359	ValidAcc 0.8314	TestAcc 0.6339
    Epoch 409:	Loss 0.00000	TrainAcc 0.8431	ValidAcc 0.8345	TestAcc 0.6307
    Epoch 419:	Loss 0.00000	TrainAcc 0.8383	ValidAcc 0.8338	TestAcc 0.6393
    Epoch 429:	Loss 0.00000	TrainAcc 0.8441	ValidAcc 0.8359	TestAcc 0.6331
    Epoch 439:	Loss 0.00000	TrainAcc 0.8386	ValidAcc 0.8332	TestAcc 0.6418
    Epoch 449:	Loss 0.00000	TrainAcc 0.8411	ValidAcc 0.8316	TestAcc 0.6314
    Epoch 459:	Loss 0.00000	TrainAcc 0.8395	ValidAcc 0.8355	TestAcc 0.6435
    Epoch 469:	Loss 0.00000	TrainAcc 0.8440	ValidAcc 0.8351	TestAcc 0.6331
    Epoch 479:	Loss 0.00000	TrainAcc 0.8493	ValidAcc 0.8421	TestAcc 0.6485
    Epoch 489:	Loss 0.00000	TrainAcc 0.8516	ValidAcc 0.8429	TestAcc 0.6445
    Epoch 499:	Loss 0.00000	TrainAcc 0.8532	ValidAcc 0.8470	TestAcc 0.6496
    Epoch 509:	Loss 0.00000	TrainAcc 0.8556	ValidAcc 0.8471	TestAcc 0.6513
    Epoch 519:	Loss 0.00000	TrainAcc 0.8567	ValidAcc 0.8511	TestAcc 0.6512
    Epoch 529:	Loss 0.00000	TrainAcc 0.8601	ValidAcc 0.8528	TestAcc 0.6571
    Epoch 539:	Loss 0.00000	TrainAcc 0.8602	ValidAcc 0.8528	TestAcc 0.6581
    Epoch 549:	Loss 0.00000	TrainAcc 0.8600	ValidAcc 0.8546	TestAcc 0.6571
    Epoch 559:	Loss 0.00000	TrainAcc 0.8577	ValidAcc 0.8507	TestAcc 0.6561
    Epoch 569:	Loss 0.00000	TrainAcc 0.8593	ValidAcc 0.8538	TestAcc 0.6615
    Epoch 579:	Loss 0.00000	TrainAcc 0.8629	ValidAcc 0.8551	TestAcc 0.6610
    Epoch 589:	Loss 0.00000	TrainAcc 0.8631	ValidAcc 0.8572	TestAcc 0.6695
    Epoch 599:	Loss 0.00000	TrainAcc 0.8639	ValidAcc 0.8576	TestAcc 0.6612
    Epoch 609:	Loss 0.00000	TrainAcc 0.8618	ValidAcc 0.8565	TestAcc 0.6709
    Epoch 619:	Loss 0.00000	TrainAcc 0.8646	ValidAcc 0.8562	TestAcc 0.6619
    Epoch 629:	Loss 0.00000	TrainAcc 0.8632	ValidAcc 0.8561	TestAcc 0.6727
    Epoch 639:	Loss 0.00000	TrainAcc 0.8660	ValidAcc 0.8578	TestAcc 0.6672
    Epoch 649:	Loss 0.00000	TrainAcc 0.8653	ValidAcc 0.8588	TestAcc 0.6752
    Epoch 659:	Loss 0.00000	TrainAcc 0.8660	ValidAcc 0.8570	TestAcc 0.6700
    Epoch 669:	Loss 0.00000	TrainAcc 0.8672	ValidAcc 0.8612	TestAcc 0.6769
    Epoch 679:	Loss 0.00000	TrainAcc 0.8672	ValidAcc 0.8587	TestAcc 0.6739
    Epoch 689:	Loss 0.00000	TrainAcc 0.8676	ValidAcc 0.8611	TestAcc 0.6776
    Epoch 699:	Loss 0.00000	TrainAcc 0.8671	ValidAcc 0.8606	TestAcc 0.6759
    Epoch 709:	Loss 0.00000	TrainAcc 0.8686	ValidAcc 0.8616	TestAcc 0.6786
    Epoch 719:	Loss 0.00000	TrainAcc 0.8684	ValidAcc 0.8617	TestAcc 0.6781
    Epoch 729:	Loss 0.00000	TrainAcc 0.8713	ValidAcc 0.8625	TestAcc 0.6814
    Epoch 739:	Loss 0.00000	TrainAcc 0.8709	ValidAcc 0.8636	TestAcc 0.6832
    Epoch 749:	Loss 0.00000	TrainAcc 0.8714	ValidAcc 0.8645	TestAcc 0.6838
    Epoch 759:	Loss 0.00000	TrainAcc 0.8702	ValidAcc 0.8659	TestAcc 0.6858
    Epoch 769:	Loss 0.00000	TrainAcc 0.8699	ValidAcc 0.8605	TestAcc 0.6797
    Epoch 779:	Loss 0.00000	TrainAcc 0.8677	ValidAcc 0.8633	TestAcc 0.6869
    Epoch 789:	Loss 0.00000	TrainAcc 0.8671	ValidAcc 0.8599	TestAcc 0.6738
    Epoch 799:	Loss 0.00000	TrainAcc 0.8670	ValidAcc 0.8621	TestAcc 0.6861
    Epoch 809:	Loss 0.00000	TrainAcc 0.8685	ValidAcc 0.8603	TestAcc 0.6762
    Epoch 819:	Loss 0.00000	TrainAcc 0.8692	ValidAcc 0.8640	TestAcc 0.6887
    Epoch 829:	Loss 0.00000	TrainAcc 0.8726	ValidAcc 0.8630	TestAcc 0.6819
    Epoch 839:	Loss 0.00000	TrainAcc 0.8719	ValidAcc 0.8659	TestAcc 0.6897
    Epoch 849:	Loss 0.00000	TrainAcc 0.8722	ValidAcc 0.8630	TestAcc 0.6846
    Epoch 859:	Loss 0.00000	TrainAcc 0.8705	ValidAcc 0.8644	TestAcc 0.6847
    Epoch 869:	Loss 0.00000	TrainAcc 0.8724	ValidAcc 0.8634	TestAcc 0.6860
    Epoch 879:	Loss 0.00000	TrainAcc 0.8729	ValidAcc 0.8649	TestAcc 0.6852
    Epoch 889:	Loss 0.00000	TrainAcc 0.8735	ValidAcc 0.8670	TestAcc 0.6903
    Epoch 899:	Loss 0.00000	TrainAcc 0.8772	ValidAcc 0.8672	TestAcc 0.6904
    Epoch 909:	Loss 0.00000	TrainAcc 0.8747	ValidAcc 0.8694	TestAcc 0.6936
    Epoch 919:	Loss 0.00000	TrainAcc 0.8749	ValidAcc 0.8667	TestAcc 0.6878
    Epoch 929:	Loss 0.00000	TrainAcc 0.8711	ValidAcc 0.8661	TestAcc 0.6885
    Epoch 939:	Loss 0.00000	TrainAcc 0.8754	ValidAcc 0.8651	TestAcc 0.6856
    Epoch 949:	Loss 0.00000	TrainAcc 0.8736	ValidAcc 0.8705	TestAcc 0.6920
    Epoch 959:	Loss 0.00000	TrainAcc 0.8793	ValidAcc 0.8692	TestAcc 0.6913
    Epoch 969:	Loss 0.00000	TrainAcc 0.8770	ValidAcc 0.8715	TestAcc 0.6959
    Epoch 979:	Loss 0.00000	TrainAcc 0.8761	ValidAcc 0.8703	TestAcc 0.6897
    Epoch 989:	Loss 0.00000	TrainAcc 0.8762	ValidAcc 0.8700	TestAcc 0.6942
Node 0, Layer-level comm throughput (act): -nan GBps
Node 1, Layer-level comm throughput (act): 11.036 GBps
Node 2, Layer-level comm throughput (act): 10.841 GBps
Node 3, Layer-level comm throughput (act): 11.152 GBps
Node 3, Layer-level comm throughput (grad): -nan GBps
Node 2, Layer-level comm throughput (grad): 11.202 GBps
Node 1, Layer-level comm throughput (grad): 11.140 GBps
Node 0, Layer-level comm throughput (grad): 11.079 GBps
    Epoch 999:	Loss 0.00000	TrainAcc 0.8757	ValidAcc 0.8691	TestAcc 0.6911
Node 0, compression time: 2.635s, compression size: 437.921GB, throughput: 166.215GBps
Node 0, decompression time: 7.252s, compression size: 437.921GB, throughput: 60.388GBps
Node 0, pure compute time: 89.400 s, total compute time: 99.286 s
Node 0, wait_for_task_time: 25.640 s, wait_for_other_gpus_time: 0.006 s
------------------------node id 0,  per-epoch time: 0.132649 s---------------
Node 2, compression time: 6.076s, compression size: 875.841GB, throughput: 144.142GBps
Node 2, decompression time: 18.243s, compression size: 875.841GB, throughput: 48.010GBps
Node 1, compression time: 6.097s, compression size: 875.841GB, throughput: 143.656GBps
Node 1, decompression time: 20.308s, compression size: 875.841GB, throughput: 43.128GBps
Node 1, pure compute time: 81.149 s, total compute time: 107.554 s
Node 1, wait_for_task_time: 14.751 s, wait_for_other_gpus_time: 0.009 s
Node 2, pure compute time: 81.328 s, total compute time: 105.647 s
Node 2, wait_for_task_time: 13.730 s, wait_for_other_gpus_time: 0.010 s
------------------------node id 2,  per-epoch time: 0.132649 s---------------
Node 3, compression time: 3.767s, compression size: 437.921GB, throughput: 116.266GBps
Node 3, decompression time: 7.159s, compression size: 437.921GB, throughput: 61.171GBps
Node 3, pure compute time: 93.671 s, total compute time: 104.596 s
Node 3, wait_for_task_time: 7.002 s, wait_for_other_gpus_time: 0.009 s
------------------------node id 3,  per-epoch time: 0.132649 s---------------
------------------------node id 1,  per-epoch time: 0.132649 s---------------
************ Profiling Results ************
	Bubble: 12.849989 (s) (9.65 percentage)
	Compute: 112.446735 (s) (84.43 percentage)
	GradSync: 0.474917 (s) (0.36 percentage)
	GraphComm: 0.032177 (s) (0.02 percentage)
	Imbalance: 4.660334 (s) (3.50 percentage)
	LayerComm: 2.719868 (s) (2.04 percentage)
	Layer-level communication (cluster-wide, per epoch): 0.924 GB
Highest valid_acc: 0.8715
Target test_acc: 0.6959
Epoch to reach the target acc: 970
[MPI Rank 3] Success 
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 2] Success 
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 8
The number of hidden units: 48
The number of training epoches: 0
Learning rate: 0.000000
Initialized node g006.anvil.rcac.purdue.edu
Building the CSR structure...
        It takes 1.969 seconds.
Building the CSC structure...
        It takes 1.920 seconds.
Building the Feature Vector...
        It takes 0.612 seconds.
Building the Label Vector...
        It takes 0.334 seconds.
Number of classes: 47
Number of feature dimensions: 100
Dropout: 0.000 
train nodes 196615, valid nodes 39323, test nodes 2213091
*** Allocating resources for all tensors...
    OP_TYPE: OPERATOR_INPUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_RELU
    OP_TYPE: OPERATOR_DROPOUT
    OP_TYPE: OPERATOR_WEIGHT
    OP_TYPE: OPERATOR_MATMUL
    OP_TYPE: OPERATOR_AGGREGATION
    OP_TYPE: OPERATOR_SOFTMAX
*** Done allocating resource.
*** Preparing the input tensor...
*** Done preparing the input tensor.
*** Preparing the STD tensor...
    Number of labels: 47
    Number of vertices: 2449029
*** Done preparing the STD tensor.
Version 0	TrainAcc 0.3083	ValidAcc 0.3083	TestAcc 0.2689
Version 1	TrainAcc 0.3084	ValidAcc 0.3083	TestAcc 0.2692
Version 2	TrainAcc 0.1771	ValidAcc 0.1654	TestAcc 0.1250
Version 3	TrainAcc 0.3084	ValidAcc 0.3083	TestAcc 0.2692
Version 4	TrainAcc 0.4355	ValidAcc 0.4215	TestAcc 0.3256
Version 5	TrainAcc 0.5299	ValidAcc 0.5325	TestAcc 0.4383
Version 6	TrainAcc 0.5414	ValidAcc 0.5373	TestAcc 0.4188
Version 7	TrainAcc 0.5460	ValidAcc 0.5513	TestAcc 0.4540
Version 8	TrainAcc 0.5204	ValidAcc 0.5239	TestAcc 0.4203
Version 9	TrainAcc 0.5520	ValidAcc 0.5519	TestAcc 0.4342
Version 10	TrainAcc 0.6369	ValidAcc 0.6417	TestAcc 0.4947
Version 11	TrainAcc 0.6312	ValidAcc 0.6273	TestAcc 0.4831
Version 12	TrainAcc 0.6376	ValidAcc 0.6345	TestAcc 0.4911
Version 13	TrainAcc 0.6573	ValidAcc 0.6526	TestAcc 0.5090
Version 14	TrainAcc 0.6829	ValidAcc 0.6795	TestAcc 0.5237
Version 15	TrainAcc 0.7078	ValidAcc 0.6985	TestAcc 0.5371
Version 16	TrainAcc 0.7168	ValidAcc 0.7118	TestAcc 0.5558
Version 17	TrainAcc 0.7127	ValidAcc 0.7033	TestAcc 0.5438
Version 18	TrainAcc 0.7240	ValidAcc 0.7197	TestAcc 0.5685
Version 19	TrainAcc 0.7320	ValidAcc 0.7217	TestAcc 0.5588
Version 20	TrainAcc 0.7441	ValidAcc 0.7408	TestAcc 0.5886
Version 21	TrainAcc 0.7494	ValidAcc 0.7375	TestAcc 0.5752
Version 22	TrainAcc 0.7649	ValidAcc 0.7650	TestAcc 0.6148
Version 23	TrainAcc 0.7575	ValidAcc 0.7486	TestAcc 0.5859
Version 24	TrainAcc 0.7715	ValidAcc 0.7712	TestAcc 0.6265
Version 25	TrainAcc 0.8020	ValidAcc 0.7970	TestAcc 0.6324
Version 26	TrainAcc 0.8077	ValidAcc 0.8051	TestAcc 0.6405
Version 27	TrainAcc 0.8055	ValidAcc 0.8036	TestAcc 0.6425
Version 28	TrainAcc 0.7939	ValidAcc 0.7926	TestAcc 0.6345
Version 29	TrainAcc 0.8106	ValidAcc 0.8074	TestAcc 0.6451
Version 30	TrainAcc 0.8228	ValidAcc 0.8215	TestAcc 0.6614
Version 31	TrainAcc 0.8221	ValidAcc 0.8173	TestAcc 0.6577
Version 32	TrainAcc 0.8341	ValidAcc 0.8300	TestAcc 0.6697
Version 33	TrainAcc 0.8314	ValidAcc 0.8299	TestAcc 0.6689
Version 34	TrainAcc 0.8474	ValidAcc 0.8436	TestAcc 0.6798
Version 35	TrainAcc 0.8449	ValidAcc 0.8429	TestAcc 0.6803
Version 36	TrainAcc 0.8472	ValidAcc 0.8443	TestAcc 0.6802
Version 37	TrainAcc 0.8432	ValidAcc 0.8423	TestAcc 0.6812
Version 38	TrainAcc 0.8433	ValidAcc 0.8408	TestAcc 0.6764
Version 39	TrainAcc 0.8422	ValidAcc 0.8416	TestAcc 0.6823
Version 40	TrainAcc 0.8491	ValidAcc 0.8443	TestAcc 0.6797
Version 41	TrainAcc 0.8464	ValidAcc 0.8467	TestAcc 0.6863
Version 42	TrainAcc 0.8566	ValidAcc 0.8524	TestAcc 0.6859
Version 43	TrainAcc 0.8482	ValidAcc 0.8475	TestAcc 0.6891
Version 44	TrainAcc 0.8547	ValidAcc 0.8512	TestAcc 0.6859
Version 45	TrainAcc 0.8476	ValidAcc 0.8472	TestAcc 0.6896
Version 46	TrainAcc 0.8511	ValidAcc 0.8471	TestAcc 0.6823
Version 47	TrainAcc 0.8526	ValidAcc 0.8510	TestAcc 0.6916
Version 48	TrainAcc 0.8537	ValidAcc 0.8504	TestAcc 0.6864
Version 49	TrainAcc 0.8572	ValidAcc 0.8543	TestAcc 0.6948
Version 50	TrainAcc 0.8581	ValidAcc 0.8560	TestAcc 0.6938
Version 51	TrainAcc 0.8592	ValidAcc 0.8579	TestAcc 0.6953
Version 52	TrainAcc 0.8640	ValidAcc 0.8605	TestAcc 0.6992
Version 53	TrainAcc 0.8649	ValidAcc 0.8629	TestAcc 0.7024
Version 54	TrainAcc 0.8661	ValidAcc 0.8632	TestAcc 0.7008
Version 55	TrainAcc 0.8643	ValidAcc 0.8611	TestAcc 0.7026
Version 56	TrainAcc 0.8649	ValidAcc 0.8636	TestAcc 0.7021
Version 57	TrainAcc 0.8670	ValidAcc 0.8633	TestAcc 0.7061
Version 58	TrainAcc 0.8676	ValidAcc 0.8648	TestAcc 0.7138
Version 59	TrainAcc 0.8691	ValidAcc 0.8657	TestAcc 0.7087
Version 60	TrainAcc 0.8667	ValidAcc 0.8645	TestAcc 0.7173
Version 61	TrainAcc 0.8695	ValidAcc 0.8657	TestAcc 0.7077
Version 62	TrainAcc 0.8669	ValidAcc 0.8642	TestAcc 0.7191
Version 63	TrainAcc 0.8703	ValidAcc 0.8667	TestAcc 0.7123
Version 64	TrainAcc 0.8683	ValidAcc 0.8660	TestAcc 0.7201
Version 65	TrainAcc 0.8713	ValidAcc 0.8664	TestAcc 0.7176
Version 66	TrainAcc 0.8690	ValidAcc 0.8670	TestAcc 0.7213
Version 67	TrainAcc 0.8708	ValidAcc 0.8669	TestAcc 0.7196
Version 68	TrainAcc 0.8702	ValidAcc 0.8681	TestAcc 0.7223
Version 69	TrainAcc 0.8709	ValidAcc 0.8678	TestAcc 0.7208
Version 70	TrainAcc 0.8716	ValidAcc 0.8688	TestAcc 0.7239
Version 71	TrainAcc 0.8719	ValidAcc 0.8682	TestAcc 0.7223
Version 72	TrainAcc 0.8731	ValidAcc 0.8697	TestAcc 0.7258
Version 73	TrainAcc 0.8738	ValidAcc 0.8708	TestAcc 0.7245
Version 74	TrainAcc 0.8754	ValidAcc 0.8718	TestAcc 0.7280
Version 75	TrainAcc 0.8760	ValidAcc 0.8725	TestAcc 0.7288
Version 76	TrainAcc 0.8758	ValidAcc 0.8720	TestAcc 0.7283
Version 77	TrainAcc 0.8755	ValidAcc 0.8715	TestAcc 0.7299
Version 78	TrainAcc 0.8730	ValidAcc 0.8694	TestAcc 0.7229
Version 79	TrainAcc 0.8713	ValidAcc 0.8687	TestAcc 0.7282
Version 80	TrainAcc 0.8721	ValidAcc 0.8675	TestAcc 0.7211
Version 81	TrainAcc 0.8719	ValidAcc 0.8695	TestAcc 0.7296
Version 82	TrainAcc 0.8753	ValidAcc 0.8693	TestAcc 0.7248
Version 83	TrainAcc 0.8745	ValidAcc 0.8726	TestAcc 0.7321
Version 84	TrainAcc 0.8780	ValidAcc 0.8706	TestAcc 0.7271
Version 85	TrainAcc 0.8748	ValidAcc 0.8728	TestAcc 0.7299
Version 86	TrainAcc 0.8762	ValidAcc 0.8690	TestAcc 0.7246
Version 87	TrainAcc 0.8748	ValidAcc 0.8718	TestAcc 0.7280
Version 88	TrainAcc 0.8768	ValidAcc 0.8717	TestAcc 0.7275
Version 89	TrainAcc 0.8800	ValidAcc 0.8756	TestAcc 0.7324
Version 90	TrainAcc 0.8791	ValidAcc 0.8760	TestAcc 0.7335
Version 91	TrainAcc 0.8821	ValidAcc 0.8751	TestAcc 0.7322
Version 92	TrainAcc 0.8776	ValidAcc 0.8750	TestAcc 0.7309
Version 93	TrainAcc 0.8804	ValidAcc 0.8730	TestAcc 0.7288
Version 94	TrainAcc 0.8779	ValidAcc 0.8757	TestAcc 0.7325
Version 95	TrainAcc 0.8823	ValidAcc 0.8761	TestAcc 0.7321
Version 96	TrainAcc 0.8811	ValidAcc 0.8784	TestAcc 0.7372
Version 97	TrainAcc 0.8817	ValidAcc 0.8759	TestAcc 0.7325
Version 98	TrainAcc 0.8814	ValidAcc 0.8776	TestAcc 0.7349
Version 99	TrainAcc 0.8810	ValidAcc 0.8759	TestAcc 0.7315
Version 96 achieved the highest validation accuracy 0.8784 (test accuracy: 0.7372)
