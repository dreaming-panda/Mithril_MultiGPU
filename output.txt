g011.anvil.rcac.purdue.edu
Thu Dec 22 23:33:27 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   29C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   27C    P0    49W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                    0 |
| N/A   28C    P0    49W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA A100-SXM...  On   | 00000000:C1:00.0 Off |                    0 |
| N/A   28C    P0    50W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Currently Loaded Modules:
  1) modtree/gpu            5) mpfr/4.0.2    9) numactl/2.0.14
  2) nccl/cuda-11.2_2.8.4   6) mpc/1.1.0    10) cuda/11.4.2
  3) cudnn/cuda-11.2_8.1    7) gcc/11.2.0   11) openmpi/4.0.6
  4) gmp/6.2.1              8) zlib/1.2.11  12) boost/1.74.0

 

[  4%] Built target context
[ 18%] Built target parallel
[ 20%] Built target core
[ 39%] Built target cudahelp
[ 69%] Built target test_mpi_combined
[ 77%] Built target test_mpi_gpu_pipelined_model_parallel
[ 83%] Built target test_single_node_training
[ 77%] Built target test_hello_world
[ 77%] Built target test_mpi_structual_graph
[ 77%] Built target test_trivial
[ 77%] Built target test_full_structual_graph
[ 77%] Built target test_cuda_model_parallel
[ 77%] Built target test_mpi_loader
[ 77%] Built target test_mpi_gpu_model_parallel
[ 77%] Built target test_mpi_gpu_hybrid
[ 87%] Built target test_mpi_pipelined_model_parallel
[ 90%] Built target test_mpi_model_parallel
[ 90%] Built target test_nccl_thread
[ 90%] Built target test_graph
[ 90%] Built target test_cuda_graph
[ 90%] Built target test_single_node_fullgpu_training
[ 90%] Built target test_cuda_pipeline_parallel
[ 91%] Built target test_full_non_structual_graph
[ 91%] Built target estimate_comm_volume
[ 90%] Built target test_mpi_non_structual_graph
[ 90%] Built target test_single_node_gpu_training
[ 90%] Built target test_cuda
[ 91%] Built target test_nccl_mpi
[ 97%] Built target test_two_layer_hybrid_parallelism_designer
[100%] Built target OSDI2023_SINGLE_NODE_gcn_inference
[100%] Built target OSDI2023_MULTI_NODES_gcn
[100%] Built target OSDI2023_SINGLE_NODE_gcn
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The graph dataset locates at /anvil/projects/x-cis220117/gnn_datasets/reordered/ogbn_products
The number of GCN layers: 4
The number of hidden units: 128
The number of training epoches: 100
The number of startup epoches: 0
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
Initialized node g011.anvil.rcac.purdue.edu
Initialized node g011.anvil.rcac.purdue.edu
Initialized node g011.anvil.rcac.purdue.edu
Initialized node g011.anvil.rcac.purdue.edu
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 2.094 seconds.
Building the CSC structure...
        It takes 2.211 seconds.
Building the CSC structure...
        It takes 2.232 seconds.
Building the CSC structure...
        It takes 2.217 seconds.
Building the CSC structure...
        It takes 2.005 seconds.
        It takes 2.042 seconds.
        It takes 2.061 seconds.
        It takes 2.079 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.847 seconds.
Building the Label Vector...
        It takes 0.789 seconds.
Building the Label Vector...
        It takes 0.758 seconds.
Building the Label Vector...
        It takes 0.765 seconds.
Building the Label Vector...
        It takes 0.459 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.413 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.396 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
        It takes 0.392 seconds.
Number of classes: 47
Number of feature dimensions: 100
Number of vertices: 2449029
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 4
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
*** Node 2, starting model training...
Number of operators: 20
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 20
*** Node 2 owns the partition [11, 16) x [0, 2449029)
*** Node 2, constructing the helper classes...
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
train nodes 196615, valid nodes 39323, test nodes 2213091
Number of GPUs: 4
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
*** Node 3, starting model training...
Number of operators: 20
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 20
*** Node 3 owns the partition [16, 20) x [0, 2449029)
*** Node 3, constructing the helper classes...
Number of GPUs: 4
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
*** Node 1, starting model training...
Number of operators: 20
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 20
*** Node 1 owns the partition [6, 11) x [0, 2449029)
*** Node 1, constructing the helper classes...
Number of GPUs: 4
GPU 0, layer [0, 1)
GPU 1, layer [1, 2)
GPU 2, layer [2, 3)
GPU 3, layer [3, 4)
*** Node 0, starting model training...
Number of operators: 20
0 2449029 0 6
0 2449029 6 11
0 2449029 11 16
0 2449029 16 20
*** Node 0 owns the partition [0, 6) x [0, 2449029)
*** Node 0, constructing the helper classes...
Operators:
    Op 0: type OPERATOR_INPUT, output tensors: 0
    Op 1: type OPERATOR_WEIGHT, output tensors: 1
    Op 2: type OPERATOR_MATMUL, output tensors: 2
    Op 3: type OPERATOR_AGGREGATION, output tensors: 3
    Op 4: type OPERATOR_RELU, output tensors: 4
    Op 5: type OPERATOR_DROPOUT, output tensors: 5
    Op 6: type OPERATOR_WEIGHT, output tensors: 6
    Op 7: type OPERATOR_MATMUL, output tensors: 7
    Op 8: type OPERATOR_AGGREGATION, output tensors: 8
    Op 9: type OPERATOR_RELU, output tensors: 9
    Op 10: type OPERATOR_DROPOUT, output tensors: 10
    Op 11: type OPERATOR_WEIGHT, output tensors: 11
    Op 12: type OPERATOR_MATMUL, output tensors: 12
    Op 13: type OPERATOR_AGGREGATION, output tensors: 13
    Op 14: type OPERATOR_RELU, output tensors: 14
    Op 15: type OPERATOR_DROPOUT, output tensors: 15
    Op 16: type OPERATOR_WEIGHT, output tensors: 16
    Op 17: type OPERATOR_MATMUL, output tensors: 17
    Op 18: type OPERATOR_AGGREGATION, output tensors: 18
    Op 19: type OPERATOR_SOFTMAX, output tensors: 19
(Forwarding) Node 3 (fragment 0) depends on nodes: 2 (Tensor: 15)
(Backwarding) Node 3 (fragment 0) depends on nodes:
(I-link dependencies): node 3 should send activation to nodes:
(I-link dependencies): node 3 should receive activation from nodes:
(I-link dependencies): node 3 should send gradient to nodes:
(I-link dependencies): node 3 should receive gradient from nodes:
(Forwarding) Node 2 (fragment 0) depends on nodes: 1 (Tensor: 10)
(Backwarding) Node 2 (fragment 0) depends on nodes: 3 (Tensor: 15)
(I-link dependencies): node 2 should send activation to nodes:
(I-link dependencies): node 2 should receive activation from nodes:
(I-link dependencies): node 2 should send gradient to nodes:
(I-link dependencies): node 2 should receive gradient from nodes:
Boundaries: 0 0 0 0 2449029 2449029 2449029 2449029
Fragments: [0, 2449029)
Chunks (number of global chunks: 33): 0-[0, 76532) 1-[76532, 153064) 2-[153064, 229596) 3-[229596, 306128) 4-[306128, 382660) 5-[382660, 459192) 6-[459192, 535724) 7-[535724, 612256) 8-[612256, 688788) ... 32-[2449024, 2449029)
(Forwarding) Node 0 (fragment 0) depends on nodes:
(Backwarding) Node 0 (fragment 0) depends on nodes: 1 (Tensor: 5)
(I-link dependencies): node 0 should send activation to nodes:
(I-link dependencies): node 0 should receive activation from nodes:
(I-link dependencies): node 0 should send gradient to nodes:
(I-link dependencies): node 0 should receive gradient from nodes:
(Forwarding) Node 1 (fragment 0) depends on nodes: 0 (Tensor: 5)
(Backwarding) Node 1 (fragment 0) depends on nodes: 2 (Tensor: 10)
(I-link dependencies): node 1 should send activation to nodes:
(I-link dependencies): node 1 should receive activation from nodes:
(I-link dependencies): node 1 should send gradient to nodes:
(I-link dependencies): node 1 should receive gradient from nodes:
2449029, 126167053, 126167053
2449029, 126167053, 126167053
2449029, 126167053, 126167053
2449029, 126167053, 126167053
csr in-out ready !*** Node 2, setting up some other necessary information...
*** Node 2, starting the helper threads...
csr in-out ready !*** Node 3, setting up some other necessary information...
*** Node 3, starting the helper threads...
csr in-out ready !*** Node 0, setting up some other necessary information...
*** Node 0, starting the helper threads...
csr in-out ready !*** Node 1, setting up some other necessary information...
*** Node 1, starting the helper threads...
+++++++++ Node 0 initializing the weights for op[0, 6)...
+++++++++ Node 0, mapping weight op 1
+++++++++ Node 2 initializing the weights for op[11, 16)...
+++++++++ Node 2, mapping weight op 11
+++++++++ Node 3 initializing the weights for op[16, 20)...
+++++++++ Node 3, mapping weight op 16
+++++++++ Node 1 initializing the weights for op[6, 11)...
+++++++++ Node 1, mapping weight op 6
RANDOMLY DISPATCH THE CHUNKS...
*** Node 3, starting task scheduling...
*** Node 1, starting task scheduling...
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
The learning rate specified by the user: 0.001000000
    Epoch 0:	Loss 3.88187	TrainAcc 0.0060	ValidAcc 0.0075	TestAcc 0.0140
    Epoch 1:	Loss 3.83239	TrainAcc 0.0211	ValidAcc 0.0249	TestAcc 0.0296
    Epoch 2:	Loss 3.73357	TrainAcc 0.1611	ValidAcc 0.1706	TestAcc 0.1463
    Epoch 3:	Loss 3.61136	TrainAcc 0.3813	ValidAcc 0.3738	TestAcc 0.2873
    Epoch 4:	Loss 3.47385	TrainAcc 0.3824	ValidAcc 0.3798	TestAcc 0.3081
    Epoch 5:	Loss 3.32198	TrainAcc 0.3735	ValidAcc 0.3703	TestAcc 0.3059
    Epoch 6:	Loss 3.15936	TrainAcc 0.3608	ValidAcc 0.3581	TestAcc 0.3000
    Epoch 7:	Loss 2.99443	TrainAcc 0.3491	ValidAcc 0.3473	TestAcc 0.2940
    Epoch 8:	Loss 2.83748	TrainAcc 0.3426	ValidAcc 0.3420	TestAcc 0.2918
    Epoch 9:	Loss 2.69471	TrainAcc 0.3460	ValidAcc 0.3460	TestAcc 0.2939
    Epoch 10:	Loss 2.55318	TrainAcc 0.3622	ValidAcc 0.3597	TestAcc 0.3032
    Epoch 11:	Loss 2.39711	TrainAcc 0.3766	ValidAcc 0.3759	TestAcc 0.3181
    Epoch 12:	Loss 2.22461	TrainAcc 0.4198	ValidAcc 0.4241	TestAcc 0.3562
    Epoch 13:	Loss 2.07693	TrainAcc 0.5036	ValidAcc 0.5099	TestAcc 0.4124
    Epoch 14:	Loss 1.98562	TrainAcc 0.5634	ValidAcc 0.5612	TestAcc 0.4419
    Epoch 15:	Loss 1.93406	TrainAcc 0.5826	ValidAcc 0.5809	TestAcc 0.4494
    Epoch 16:	Loss 1.87504	TrainAcc 0.6202	ValidAcc 0.6139	TestAcc 0.4648
    Epoch 17:	Loss 1.79645	TrainAcc 0.6140	ValidAcc 0.6074	TestAcc 0.4646
    Epoch 18:	Loss 1.71026	TrainAcc 0.6052	ValidAcc 0.6047	TestAcc 0.4683
    Epoch 19:	Loss 1.62390	TrainAcc 0.6130	ValidAcc 0.6076	TestAcc 0.4734
    Epoch 20:	Loss 1.57153	TrainAcc 0.6047	ValidAcc 0.5971	TestAcc 0.4666
    Epoch 21:	Loss 1.55436	TrainAcc 0.5769	ValidAcc 0.5730	TestAcc 0.4536
    Epoch 22:	Loss 1.54064	TrainAcc 0.5692	ValidAcc 0.5678	TestAcc 0.4519
    Epoch 23:	Loss 1.48742	TrainAcc 0.5971	ValidAcc 0.5961	TestAcc 0.4716
    Epoch 24:	Loss 1.40232	TrainAcc 0.6476	ValidAcc 0.6432	TestAcc 0.5055
    Epoch 25:	Loss 1.32048	TrainAcc 0.7002	ValidAcc 0.6957	TestAcc 0.5409
    Epoch 26:	Loss 1.26318	TrainAcc 0.7365	ValidAcc 0.7284	TestAcc 0.5632
    Epoch 27:	Loss 1.23789	TrainAcc 0.7482	ValidAcc 0.7418	TestAcc 0.5705
    Epoch 28:	Loss 1.23458	TrainAcc 0.7415	ValidAcc 0.7358	TestAcc 0.5671
    Epoch 29:	Loss 1.22902	TrainAcc 0.7362	ValidAcc 0.7327	TestAcc 0.5656
    Epoch 30:	Loss 1.20762	TrainAcc 0.7369	ValidAcc 0.7339	TestAcc 0.5686
    Epoch 31:	Loss 1.16893	TrainAcc 0.7473	ValidAcc 0.7438	TestAcc 0.5767
    Epoch 32:	Loss 1.11797	TrainAcc 0.7641	ValidAcc 0.7606	TestAcc 0.5908
    Epoch 33:	Loss 1.06923	TrainAcc 0.7786	ValidAcc 0.7732	TestAcc 0.6001
    Epoch 34:	Loss 1.03269	TrainAcc 0.7862	ValidAcc 0.7806	TestAcc 0.6058
    Epoch 35:	Loss 1.00717	TrainAcc 0.7918	ValidAcc 0.7857	TestAcc 0.6076
    Epoch 36:	Loss 0.99489	TrainAcc 0.7934	ValidAcc 0.7858	TestAcc 0.6054
    Epoch 37:	Loss 0.98721	TrainAcc 0.7924	ValidAcc 0.7854	TestAcc 0.6041
    Epoch 38:	Loss 0.98473	TrainAcc 0.7894	ValidAcc 0.7826	TestAcc 0.6016
    Epoch 39:	Loss 0.97277	TrainAcc 0.7888	ValidAcc 0.7803	TestAcc 0.6016
    Epoch 40:	Loss 0.94831	TrainAcc 0.7923	ValidAcc 0.7844	TestAcc 0.6063
    Epoch 41:	Loss 0.92116	TrainAcc 0.7984	ValidAcc 0.7911	TestAcc 0.6135
    Epoch 42:	Loss 0.88991	TrainAcc 0.8065	ValidAcc 0.7985	TestAcc 0.6221
    Epoch 43:	Loss 0.86488	TrainAcc 0.8109	ValidAcc 0.8039	TestAcc 0.6288
    Epoch 44:	Loss 0.84951	TrainAcc 0.8115	ValidAcc 0.8050	TestAcc 0.6352
    Epoch 45:	Loss 0.83806	TrainAcc 0.8137	ValidAcc 0.8070	TestAcc 0.6396
    Epoch 46:	Loss 0.83048	TrainAcc 0.8150	ValidAcc 0.8091	TestAcc 0.6425
    Epoch 47:	Loss 0.82341	TrainAcc 0.8158	ValidAcc 0.8107	TestAcc 0.6460
    Epoch 48:	Loss 0.81452	TrainAcc 0.8184	ValidAcc 0.8144	TestAcc 0.6488
    Epoch 49:	Loss 0.80760	TrainAcc 0.8225	ValidAcc 0.8188	TestAcc 0.6525
    Epoch 50:	Loss 0.79654	TrainAcc 0.8267	ValidAcc 0.8239	TestAcc 0.6572
    Epoch 51:	Loss 0.78281	TrainAcc 0.8305	ValidAcc 0.8262	TestAcc 0.6614
    Epoch 52:	Loss 0.76938	TrainAcc 0.8329	ValidAcc 0.8305	TestAcc 0.6641
    Epoch 53:	Loss 0.75667	TrainAcc 0.8348	ValidAcc 0.8311	TestAcc 0.6662
    Epoch 54:	Loss 0.74504	TrainAcc 0.8367	ValidAcc 0.8332	TestAcc 0.6664
    Epoch 55:	Loss 0.73741	TrainAcc 0.8380	ValidAcc 0.8344	TestAcc 0.6663
    Epoch 56:	Loss 0.72884	TrainAcc 0.8385	ValidAcc 0.8351	TestAcc 0.6654
    Epoch 57:	Loss 0.72398	TrainAcc 0.8376	ValidAcc 0.8347	TestAcc 0.6642
    Epoch 58:	Loss 0.71695	TrainAcc 0.8378	ValidAcc 0.8343	TestAcc 0.6617
    Epoch 59:	Loss 0.71256	TrainAcc 0.8391	ValidAcc 0.8357	TestAcc 0.6617
    Epoch 60:	Loss 0.70561	TrainAcc 0.8407	ValidAcc 0.8367	TestAcc 0.6628
    Epoch 61:	Loss 0.70332	TrainAcc 0.8391	ValidAcc 0.8344	TestAcc 0.6621
    Epoch 62:	Loss 0.69810	TrainAcc 0.8403	ValidAcc 0.8366	TestAcc 0.6640
    Epoch 63:	Loss 0.69195	TrainAcc 0.8412	ValidAcc 0.8366	TestAcc 0.6650
    Epoch 64:	Loss 0.68023	TrainAcc 0.8444	ValidAcc 0.8417	TestAcc 0.6693
    Epoch 65:	Loss 0.66953	TrainAcc 0.8478	ValidAcc 0.8432	TestAcc 0.6718
    Epoch 66:	Loss 0.66393	TrainAcc 0.8500	ValidAcc 0.8450	TestAcc 0.6744
    Epoch 67:	Loss 0.65982	TrainAcc 0.8495	ValidAcc 0.8444	TestAcc 0.6745
    Epoch 68:	Loss 0.66205	TrainAcc 0.8482	ValidAcc 0.8429	TestAcc 0.6748
    Epoch 69:	Loss 0.65965	TrainAcc 0.8481	ValidAcc 0.8442	TestAcc 0.6756
    Epoch 70:	Loss 0.65348	TrainAcc 0.8493	ValidAcc 0.8438	TestAcc 0.6770
    Epoch 71:	Loss 0.64906	TrainAcc 0.8516	ValidAcc 0.8474	TestAcc 0.6780
    Epoch 72:	Loss 0.64152	TrainAcc 0.8539	ValidAcc 0.8488	TestAcc 0.6795
    Epoch 73:	Loss 0.63499	TrainAcc 0.8554	ValidAcc 0.8511	TestAcc 0.6814
    Epoch 74:	Loss 0.63303	TrainAcc 0.8545	ValidAcc 0.8508	TestAcc 0.6806
    Epoch 75:	Loss 0.63310	TrainAcc 0.8533	ValidAcc 0.8503	TestAcc 0.6816
    Epoch 76:	Loss 0.63170	TrainAcc 0.8527	ValidAcc 0.8489	TestAcc 0.6816
    Epoch 77:	Loss 0.62620	TrainAcc 0.8539	ValidAcc 0.8502	TestAcc 0.6823
    Epoch 78:	Loss 0.61799	TrainAcc 0.8563	ValidAcc 0.8534	TestAcc 0.6835
    Epoch 79:	Loss 0.61352	TrainAcc 0.8579	ValidAcc 0.8545	TestAcc 0.6834
    Epoch 80:	Loss 0.61083	TrainAcc 0.8583	ValidAcc 0.8530	TestAcc 0.6833
    Epoch 81:	Loss 0.61138	TrainAcc 0.8572	ValidAcc 0.8535	TestAcc 0.6826
    Epoch 82:	Loss 0.61142	TrainAcc 0.8568	ValidAcc 0.8521	TestAcc 0.6829
    Epoch 83:	Loss 0.61050	TrainAcc 0.8561	ValidAcc 0.8513	TestAcc 0.6821
    Epoch 84:	Loss 0.60711	TrainAcc 0.8584	ValidAcc 0.8527	TestAcc 0.6829
    Epoch 85:	Loss 0.60055	TrainAcc 0.8599	ValidAcc 0.8554	TestAcc 0.6839
    Epoch 86:	Loss 0.59345	TrainAcc 0.8628	ValidAcc 0.8568	TestAcc 0.6861
    Epoch 87:	Loss 0.59040	TrainAcc 0.8636	ValidAcc 0.8577	TestAcc 0.6861
    Epoch 88:	Loss 0.59121	TrainAcc 0.8629	ValidAcc 0.8575	TestAcc 0.6866
    Epoch 89:	Loss 0.58997	TrainAcc 0.8627	ValidAcc 0.8572	TestAcc 0.6871
    Epoch 90:	Loss 0.59010	TrainAcc 0.8623	ValidAcc 0.8569	TestAcc 0.6881
    Epoch 91:	Loss 0.58622	TrainAcc 0.8640	ValidAcc 0.8586	TestAcc 0.6891
    Epoch 92:	Loss 0.58173	TrainAcc 0.8643	ValidAcc 0.8592	TestAcc 0.6907
    Epoch 93:	Loss 0.57654	TrainAcc 0.8652	ValidAcc 0.8619	TestAcc 0.6906
    Epoch 94:	Loss 0.57668	TrainAcc 0.8647	ValidAcc 0.8601	TestAcc 0.6894
    Epoch 95:	Loss 0.57732	TrainAcc 0.8655	ValidAcc 0.8594	TestAcc 0.6895
    Epoch 96:	Loss 0.57977	TrainAcc 0.8636	ValidAcc 0.8596	TestAcc 0.6899
    Epoch 97:	Loss 0.57750	TrainAcc 0.8646	ValidAcc 0.8591	TestAcc 0.6899
    Epoch 98:	Loss 0.57398	TrainAcc 0.8645	ValidAcc 0.8596	TestAcc 0.6908
------------------------node id 1,  total time 81.845123s (per-epoch: 0.818451s)---------------
------------------------node id 3,  total time 81.845288s (per-epoch: 0.818453s)---------------
    Epoch 99:	Loss 0.56727	TrainAcc 0.8665	ValidAcc 0.8621	TestAcc 0.6932
------------------------node id 0,  total time 81.845552s (per-epoch: 0.818456s)---------------
------------------------node id 2,  total time 81.845531s (per-epoch: 0.818455s)---------------
************ Profiling Results ************
	Bubble: 14.488955 (s) (17.70 percentage)
	Compute: 21.709147 (s) (26.53 percentage)
	GradSync: 0.037588 (s) (0.05 percentage)
	GraphComm: 0.004234 (s) (0.01 percentage)
	Imbalance: 10.449596 (s) (12.77 percentage)
	LayerComm: 35.153713 (s) (42.95 percentage)
	Graph-level communication (cluster-wide, per epoch): 0.000 GB
	Layer-level communication (cluster-wide, per epoch): 7.007 GB
	Graph+Layer-level communication (cluster-wide, per epoch): 7.007 GB
	Parameter-server communication (cluster-wide, per epoch): 0.001 GB
	Graph-level dev2host communication time: 0.000 s, throughput: -nan GBps
	Graph-level memcpy communication time: 0.000 s, throughput: -nan GBps
	Graph-level net Activation communication time: 0.000 s, throughput: -nan GBps
	Graph-level net Gradient communication time: 0.000 s, throughput: -nan GBps
	Graph-level network batch size: -nan Bytes
Highest valid_acc: 0.8621
Target test_acc: 0.6932
Epoch to reach the target acc: 100
[MPI Rank 3] Success 
[MPI Rank 0] Success 
[MPI Rank 2] Success 
[MPI Rank 1] Success 
