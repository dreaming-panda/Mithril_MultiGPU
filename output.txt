Sat Sep 16 22:26:09 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    On   | 00000000:01:00.0 Off |                  Off |
| 30%   43C    P8    23W / 230W |     19MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    On   | 00000000:25:00.0 Off |                  Off |
| 30%   44C    P8    18W / 230W |      3MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A5000    On   | 00000000:81:00.0 Off |                  Off |
| 30%   46C    P8    15W / 230W |      3MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A5000    On   | 00000000:C1:00.0 Off |                  Off |
| 30%   47C    P8    17W / 230W |      3MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
gnerv7
gnerv7
gnerv7
gnerv7
[ 18%] Built target context
[ 34%] Built target core
[ 73%] Built target cudahelp
[ 86%] Built target OSDI2023_MULTI_NODES_resgcn
[ 86%] Built target OSDI2023_MULTI_NODES_gcnii
[ 86%] Built target estimate_comm_volume
[ 86%] Built target OSDI2023_MULTI_NODES_gcn
[ 86%] Built target OSDI2023_MULTI_NODES_graphsage
Running experiments...
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
Initializing the runtime environment
DONE MPI INITDONE MPI INIT
Initialized node 1 on machine gnerv7
DONE MPI INIT
Initialized node 2 on machine gnerv7
DONE MPI INIT
Initialized node 3 on machine gnerv7

Initialized node 0 on machine gnerv7
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
Building the CSR structure...
        It takes 0.008 seconds.
Building the CSC structure...
        It takes 0.008 seconds.
Building the CSC structure...
        It takes 0.009 seconds.
Building the CSC structure...
        It takes 0.009 seconds.
Building the CSC structure...
        It takes 0.008 seconds.
        It takes 0.008 seconds.
        It takes 0.008 seconds.
        It takes 0.008 seconds.
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
Building the Feature Vector...
        It takes 0.023 seconds.
Building the Label Vector...
        It takes 0.000 seconds.
        It takes 0.024 seconds.
Building the Label Vector...
        It takes 0.024 seconds.
        It takes 0.024 seconds.
Building the Label Vector...
        It takes 0.000 seconds.
Building the Label Vector...
        It takes 0.000 seconds.
        It takes 0.000 seconds.
The graph dataset locates at /shared_hdd_storage/jingjichen/gnn_datasets/partitioned_graphs/squirrel/4_parts
The number of GCNII layers: 32
The number of hidden units: 1000
The number of training epoches: 100
Learning rate: 0.001000
The partition strategy: model
The dropout rate: 0.500
The checkpointed weight file: /tmp/saved_weights_pipe
The random seed: 1
Number of classes: 5
Number of feature dimensions: 2089
Number of vertices: 5201
Number of GPUs: 4
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
5201, 401907, 401907
Number of vertices per chunk: 1301
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
5201, 401907, 401907
Number of vertices per chunk: 1301
csr in-out ready !Start Cost Model Initialization...
csr in-out ready !Start Cost Model Initialization...
train nodes 2496, valid nodes 1664, test nodes 1041
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
Chunks (number of global chunks: 4): 0-[0, 1301) 1-[1301, 2601) 2-[2601, 3901) 3-[3901, 5201)
5201, 401907, 401907
Number of vertices per chunk: 1301
csr in-out ready !Start Cost Model Initialization...
***** Start profiling the layer-level communication performance *******
GPU 0, layer [0, 32)
WARNING: the current version only applies to linear GNN models!
WARNING: currently, exact inference during the whole training process will enforce the evaluation frequency to every 25 epoches.
5201, 401907, 401907
Number of vertices per chunk: 1301
csr in-out ready !Start Cost Model Initialization...
The layer-level communication performance: 115.393 Gbps (per GPU), 461.572 Gbps (aggregated)
The layer-level communication performance: 115.251 Gbps (per GPU), 461.002 Gbps (aggregated)
The layer-level communication performance: 115.080 Gbps (per GPU), 460.319 Gbps (aggregated)
The layer-level communication performance: 115.073 Gbps (per GPU), 460.292 Gbps (aggregated)
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
****** Start profiling the graph-level communication performance with supernodesize = 2 ******
The graph-level communication performance (supernode = 2): 157.343 Gbps (per GPU), 629.374 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 157.343 Gbps (per GPU), 629.374 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 157.252 Gbps (per GPU), 629.009 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 2): 157.255 Gbps (per GPU), 629.020 Gbps (aggregated, cluster-wide)
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
****** Start profiling the graph-level communication performance with supernodesize = 4 ******
The graph-level communication performance (supernode = 4): 104.067 Gbps (per GPU), 416.266 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 104.066 Gbps (per GPU), 416.263 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 104.066 Gbps (per GPU), 416.263 Gbps (aggregated, cluster-wide)
The graph-level communication performance (supernode = 4): 104.066 Gbps (per GPU), 416.266 Gbps (aggregated, cluster-wide)
 LType   LT0   LT1   LT2 Ratio  VSum  ESum
 chk_0  4.78ms  3.27ms  3.34ms  1.46  1.30K  0.27M
 chk_1  3.83ms  2.26ms  2.40ms  1.69  1.30K  0.04M
 chk_2  3.84ms  2.17ms  2.32ms  1.77  1.30K  0.02M
 chk_3  3.90ms  2.36ms  2.55ms  1.65  1.30K  0.07M
   Avg  4.09  2.51  2.65
   Max  4.78  3.27  3.34
   Min  3.83  2.17  2.32
 Ratio  1.25  1.51  1.44
   Var  0.16  0.19  0.16
Profiling takes 0.491 s
*** Node 0, starting model training...
*** Node 2, starting model training...
*** Node 3, starting model training...
*** Node 1, starting model training...
Num Stages: 1 / 1
Node 2, Pipeline Input Tensor: NULL
Node 2, Pipeline Output Tensor: NULL
*** Node 2 owns the model-level partition [0, 358)
*** Node 2, constructing the helper classes...
Node 2, Local Vertex Begin: 2601, Num Local Vertices: 1300
Num Stages: 1 / 1
Node 3, Pipeline Input Tensor: NULL
Node 3, Pipeline Output Tensor: NULL
*** Node 3 owns the model-level partition [0, 358)
*** Node 3, constructing the helper classes...
Node 3, Local Vertex Begin: 3901, Num Local Vertices: 1300
Num Stages: 1 / 1
Node 0, Pipeline Input Tensor: NULL
Node 0, Pipeline Output Tensor: NULL
*** Node 0 owns the model-level partition [0, 358)
*** Node 0, constructing the helper classes...
Node 0, Local Vertex Begin: 0, Num Local Vertices: 1301
Num Stages: 1 / 1
Node 1, Pipeline Input Tensor: NULL
Node 1, Pipeline Output Tensor: NULL
*** Node 1 owns the model-level partition [0, 358)
*** Node 1, constructing the helper classes...
Node 1, Local Vertex Begin: 1301, Num Local Vertices: 1300
*** Node 1, setting up some other necessary information...
*** Node 3, setting up some other necessary information...
*** Node 2, setting up some other necessary information...
*** Node 0, setting up some other necessary information...
+++++++++ Node 1 initializing the weights for op[0, 358)...
+++++++++ Node 2 initializing the weights for op[0, 358)...
+++++++++ Node 3 initializing the weights for op[0, 358)...
+++++++++ Node 0 initializing the weights for op[0, 358)...
Node 0, discovering the vertices that will be sent across graph boundary...
Node 1, discovering the vertices that will be sent across graph boundary...
Node 2, discovering the vertices that will be sent across graph boundary...
Node 3, discovering the vertices that will be sent across graph boundary...
The number of mirror vertices: 6723
Node 0, discovering the vertices that will be received across the graph boundary.
Node 1, discovering the vertices that will be received across the graph boundary.
Node 2, discovering the vertices that will be received across the graph boundary.
Node 3, discovering the vertices that will be received across the graph boundary.
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
****** Start Scheduling the Tasks in a Pipelined Fashion ******
*** Node 0, starting task scheduling...



The learning rate specified by the user: 0.001000000
*** Node 1, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 2, starting task scheduling...
The learning rate specified by the user: 0.001000000
*** Node 3, starting task scheduling...
The learning rate specified by the user: 0.001000000
	Epoch 1:	Loss 2.2005	TrainAcc 0.2292	ValidAcc 0.2200	TestAcc 0.2200	BestValid 0.2200
	Epoch 50:	Loss 1.5007	TrainAcc 0.3494	ValidAcc 0.3546	TestAcc 0.3266	BestValid 0.3546
	Epoch 100:	Loss 1.4519	TrainAcc 0.3806	ValidAcc 0.3660	TestAcc 0.3381	BestValid 0.3660
****** Epoch Time (Excluding Evaluation Cost): 0.171 s ******
****** Breakdown Analysis ******
Cluster-Wide Average, Bubble-Pipeline: 0.334 ms (Max: 0.512, Min: 0.032, Sum: 1.334)
Cluster-Wide Average, Compute: 76.947 ms (Max: 92.552, Min: 70.604, Sum: 307.787)
Cluster-Wide Average, Communication-Layer: 0.008 ms (Max: 0.009, Min: 0.007, Sum: 0.032)
Cluster-Wide Average, Bubble-Imbalance: 0.016 ms (Max: 0.017, Min: 0.014, Sum: 0.063)
Cluster-Wide Average, Communication-Graph: 66.315 ms (Max: 72.369, Min: 50.959, Sum: 265.260)
Cluster-Wide Average, Optimization: 25.791 ms (Max: 25.895, Min: 25.688, Sum: 103.163)
Cluster-Wide Average, Others: 1.337 ms (Max: 1.355, Min: 1.297, Sum: 5.350)
****** Breakdown Sum: 170.747 ms ******
Cluster-Wide Average, GPU Memory Consumption: 5.466 GB (Max: 5.766, Min: 5.340, Sum: 21.866)
Cluster-Wide Average, Graph-Level Communication Throughput: 59.538 Gbps (Max: 95.512, Min: 37.916, Sum: 238.151)
Cluster-Wide Average, Layer-Level Communication Throughput: 0.000 Gbps (Max: 0.000, Min: 0.000, Sum: 0.000)
Layer-level communication (cluster-wide, per-epoch): 0.000 GB
Graph-level communication (cluster-wide, per-epoch): 1.603 GB
Weight-sync communication (cluster-wide, per-epoch): 0.763 GB
Total communication (cluster-wide, per-epoch): 2.366 GB
****** Accuracy Results ******
Highest valid_acc: 0.3660
Target test_acc: 0.3381
Epoch to reach the target acc: 99
[MPI Rank 0] Success 
[MPI Rank 1] Success 
[MPI Rank 2] Success 
[MPI Rank 3] Success 
